Namespace(seed=7, cuda=-1, env_path='output/ml1m/env/ml1m_user_env_lr0.001_reg0.0003.env', reward_func='mean_with_cost', max_step_per_episode=20, initial_temper=20, urm_log_path='output/ml1m/env/log/ml1m_user_env_lr0.001_reg0.0003.model.log', temper_sweet_point=0.9, temper_prob_lag=100, sasrec_n_layer=2, sasrec_d_model=32, sasrec_d_forward=64, sasrec_n_head=4, sasrec_dropout=0.1, critic_hidden_dims=[256, 64], critic_dropout_rate=0.2, gamma=0.9, n_iter=[50000], train_every_n_step=1, initial_greedy_epsilon=0.0, final_greedy_epsilon=0.0, elbow_greedy=0.1, check_episode=10, with_eval=False, save_path='output/ml1m/agents/hac_SASRec_actor0.0001_critic0.001_behave0.00001_hacoef0.1_niter50000_reg0.00001_ep0_noise0.1_bs64_epbs32_step20_topk1_seed7/model', episode_batch_size=32, batch_size=64, actor_lr=0.0001, critic_lr=0.001, actor_decay=1e-05, critic_decay=1e-05, target_mitigate_coef=0.01, behavior_lr=1e-05, behavior_decay=1e-05, hyper_actor_coef=0.1, slate_size=9, buffer_size=100000, start_timestamp=2000, noise_var=0.1, q_laplace_smoothness=0.5, topk_rate=1.0, empty_start_rate=0.0, device='cpu')
step: 0 @ episode report: {'average_total_reward': np.float64(0.0), 'reward_variance': np.float64(0.0), 'max_total_reward': np.float64(0.0), 'min_total_reward': np.float64(0.0), 'average_n_step': np.float64(0.0), 'max_n_step': np.float64(0.0), 'min_n_step': np.float64(0.0), 'buffer_size': 2048} @ step loss: {'critic_loss': np.float64(0.2494354546070099), 'actor_loss': np.float64(0.09359893202781677), 'hyper_actor_loss': np.float64(0.0891341045498848), 'behavior_loss': np.float64(1.052399754524231)}
step: 10 @ episode report: {'average_total_reward': np.float32(0.27999997), 'reward_variance': np.float32(0.07224198), 'max_total_reward': np.float32(0.6777778), 'min_total_reward': np.float32(-0.20000002), 'average_n_step': np.float32(2.7), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 2368} @ step loss: {'critic_loss': np.float64(0.16893137395381927), 'actor_loss': np.float64(-0.04940007347613573), 'hyper_actor_loss': np.float64(0.08924866989254951), 'behavior_loss': np.float64(1.1810205936431886)}
step: 20 @ episode report: {'average_total_reward': np.float32(0.4777778), 'reward_variance': np.float32(0.13039507), 'max_total_reward': np.float32(1.1666667), 'min_total_reward': np.float32(-0.077777795), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 2688} @ step loss: {'critic_loss': np.float64(0.11232584789395332), 'actor_loss': np.float64(-0.0643725786358118), 'hyper_actor_loss': np.float64(0.08951787650585175), 'behavior_loss': np.float64(1.2304974317550659)}
step: 30 @ episode report: {'average_total_reward': np.float32(0.6166667), 'reward_variance': np.float32(0.048549395), 'max_total_reward': np.float32(1.0444446), 'min_total_reward': np.float32(0.31111112), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(3.0), 'buffer_size': 3008} @ step loss: {'critic_loss': np.float64(0.07615532241761684), 'actor_loss': np.float64(-0.13623821809887887), 'hyper_actor_loss': np.float64(0.08950287625193595), 'behavior_loss': np.float64(1.2225734353065492)}
step: 40 @ episode report: {'average_total_reward': np.float32(0.96111107), 'reward_variance': np.float32(0.24756172), 'max_total_reward': np.float32(1.8), 'min_total_reward': np.float32(0.044444427), 'average_n_step': np.float32(3.1), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(2.0), 'buffer_size': 3328} @ step loss: {'critic_loss': np.float64(0.06856036446988582), 'actor_loss': np.float64(-0.2286664843559265), 'hyper_actor_loss': np.float64(0.08914055079221725), 'behavior_loss': np.float64(1.2156113266944886)}
step: 50 @ episode report: {'average_total_reward': np.float32(1.448889), 'reward_variance': np.float32(0.15042469), 'max_total_reward': np.float32(2.0444446), 'min_total_reward': np.float32(0.92222226), 'average_n_step': np.float32(3.6), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 3648} @ step loss: {'critic_loss': np.float64(0.05844113975763321), 'actor_loss': np.float64(-0.40875521004199983), 'hyper_actor_loss': np.float64(0.08805120065808296), 'behavior_loss': np.float64(1.1782491683959961)}
step: 60 @ episode report: {'average_total_reward': np.float32(1.2633334), 'reward_variance': np.float32(0.33516175), 'max_total_reward': np.float32(2.0444446), 'min_total_reward': np.float32(0.5555556), 'average_n_step': np.float32(3.5), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 3968} @ step loss: {'critic_loss': np.float64(0.056975200027227405), 'actor_loss': np.float64(-0.5697870045900345), 'hyper_actor_loss': np.float64(0.08615740910172462), 'behavior_loss': np.float64(1.2477060794830321)}
step: 70 @ episode report: {'average_total_reward': np.float32(1.0244443), 'reward_variance': np.float32(0.22784694), 'max_total_reward': np.float32(1.9222223), 'min_total_reward': np.float32(0.31111103), 'average_n_step': np.float32(3.2), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 4288} @ step loss: {'critic_loss': np.float64(0.05242590103298426), 'actor_loss': np.float64(-0.6073082387447357), 'hyper_actor_loss': np.float64(0.0843026615679264), 'behavior_loss': np.float64(1.3097288250923156)}
step: 80 @ episode report: {'average_total_reward': np.float32(1.2244445), 'reward_variance': np.float32(0.31952593), 'max_total_reward': np.float32(1.9222224), 'min_total_reward': np.float32(0.18888885), 'average_n_step': np.float32(3.4), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 4608} @ step loss: {'critic_loss': np.float64(0.050489587150514124), 'actor_loss': np.float64(-0.7057380020618439), 'hyper_actor_loss': np.float64(0.08304633870720864), 'behavior_loss': np.float64(1.3997803926467896)}
step: 90 @ episode report: {'average_total_reward': np.float32(1.3855556), 'reward_variance': np.float32(0.32266793), 'max_total_reward': np.float32(2.0444446), 'min_total_reward': np.float32(0.5555556), 'average_n_step': np.float32(3.5), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 4928} @ step loss: {'critic_loss': np.float64(0.044739565998315814), 'actor_loss': np.float64(-0.8827426254749298), 'hyper_actor_loss': np.float64(0.08241790756583214), 'behavior_loss': np.float64(1.3610913038253785)}
step: 100 @ episode report: {'average_total_reward': np.float32(1.7077777), 'reward_variance': np.float32(0.7581742), 'max_total_reward': np.float32(3.4111114), 'min_total_reward': np.float32(0.67777777), 'average_n_step': np.float32(3.7), 'max_n_step': np.float32(5.0), 'min_n_step': np.float32(3.0), 'buffer_size': 5248} @ step loss: {'critic_loss': np.float64(0.04503850024193525), 'actor_loss': np.float64(-1.0494397580623627), 'hyper_actor_loss': np.float64(0.08243591189384461), 'behavior_loss': np.float64(1.3453640937805176)}
step: 110 @ episode report: {'average_total_reward': np.float32(3.478889), 'reward_variance': np.float32(1.183542), 'max_total_reward': np.float32(5.533334), 'min_total_reward': np.float32(1.8000002), 'average_n_step': np.float32(5.3), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(4.0), 'buffer_size': 5568} @ step loss: {'critic_loss': np.float64(0.05777755565941334), 'actor_loss': np.float64(-1.2744593381881715), 'hyper_actor_loss': np.float64(0.08263331577181816), 'behavior_loss': np.float64(1.3049477219581604)}
step: 120 @ episode report: {'average_total_reward': np.float32(4.286667), 'reward_variance': np.float32(0.5513285), 'max_total_reward': np.float32(5.533334), 'min_total_reward': np.float32(3.1666667), 'average_n_step': np.float32(5.9), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(5.0), 'buffer_size': 5888} @ step loss: {'critic_loss': np.float64(0.06713835299015045), 'actor_loss': np.float64(-1.3361833214759826), 'hyper_actor_loss': np.float64(0.08346449509263039), 'behavior_loss': np.float64(1.1638303697109222)}
step: 130 @ episode report: {'average_total_reward': np.float32(5.2355556), 'reward_variance': np.float32(2.0848842), 'max_total_reward': np.float32(7.6555557), 'min_total_reward': np.float32(2.2888892), 'average_n_step': np.float32(6.8), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(4.0), 'buffer_size': 6208} @ step loss: {'critic_loss': np.float64(0.07176913246512413), 'actor_loss': np.float64(-1.3045130729675294), 'hyper_actor_loss': np.float64(0.08395245224237442), 'behavior_loss': np.float64(1.1030292570590974)}
step: 140 @ episode report: {'average_total_reward': np.float32(5.208889), 'reward_variance': np.float32(0.53189623), 'max_total_reward': np.float32(6.6555552), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(6.7), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(6.0), 'buffer_size': 6528} @ step loss: {'critic_loss': np.float64(0.08948954194784164), 'actor_loss': np.float64(-1.3237006187438964), 'hyper_actor_loss': np.float64(0.08390326425433159), 'behavior_loss': np.float64(1.0257850289344788)}
step: 150 @ episode report: {'average_total_reward': np.float32(6.6700006), 'reward_variance': np.float32(0.45185286), 'max_total_reward': np.float32(7.7777777), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(8.1), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(7.0), 'buffer_size': 6848} @ step loss: {'critic_loss': np.float64(0.09928115010261536), 'actor_loss': np.float64(-1.2144667625427246), 'hyper_actor_loss': np.float64(0.083849685639143), 'behavior_loss': np.float64(0.9110943794250488)}
step: 160 @ episode report: {'average_total_reward': np.float32(6.245556), 'reward_variance': np.float32(1.6550725), 'max_total_reward': np.float32(8.777778), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(7.7), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 7168} @ step loss: {'critic_loss': np.float64(0.12959343269467355), 'actor_loss': np.float64(-1.225445318222046), 'hyper_actor_loss': np.float64(0.08342109024524688), 'behavior_loss': np.float64(0.9363728344440461)}
step: 170 @ episode report: {'average_total_reward': np.float32(6.6577783), 'reward_variance': np.float32(2.7134776), 'max_total_reward': np.float32(9.777779), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.1), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 7488} @ step loss: {'critic_loss': np.float64(0.1484835922718048), 'actor_loss': np.float64(-1.237583339214325), 'hyper_actor_loss': np.float64(0.08290838450193405), 'behavior_loss': np.float64(0.8767217695713043)}
step: 180 @ episode report: {'average_total_reward': np.float32(7.0700006), 'reward_variance': np.float32(2.5032852), 'max_total_reward': np.float32(9.777778), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(8.5), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 7808} @ step loss: {'critic_loss': np.float64(0.15185772478580475), 'actor_loss': np.float64(-1.3013682246208191), 'hyper_actor_loss': np.float64(0.08255099654197692), 'behavior_loss': np.float64(0.9130083978176117)}
step: 190 @ episode report: {'average_total_reward': np.float32(7.38), 'reward_variance': np.float32(2.4983895), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.7), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 8128} @ step loss: {'critic_loss': np.float64(0.17429763525724412), 'actor_loss': np.float64(-1.3305085897445679), 'hyper_actor_loss': np.float64(0.0829025849699974), 'behavior_loss': np.float64(0.8597514152526855)}
step: 200 @ episode report: {'average_total_reward': np.float32(6.9433336), 'reward_variance': np.float32(1.2291719), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 8448} @ step loss: {'critic_loss': np.float64(0.194579017162323), 'actor_loss': np.float64(-1.3252508521080018), 'hyper_actor_loss': np.float64(0.08300609514117241), 'behavior_loss': np.float64(0.8132534325122833)}
step: 210 @ episode report: {'average_total_reward': np.float32(7.1555557), 'reward_variance': np.float32(2.2879262), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(8.5), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 8768} @ step loss: {'critic_loss': np.float64(0.20100993439555168), 'actor_loss': np.float64(-1.2676724076271058), 'hyper_actor_loss': np.float64(0.08334338590502739), 'behavior_loss': np.float64(0.8008822858333587)}
step: 220 @ episode report: {'average_total_reward': np.float32(6.418889), 'reward_variance': np.float32(2.032298), 'max_total_reward': np.float32(7.777779), 'min_total_reward': np.float32(3.411111), 'average_n_step': np.float32(7.8), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(5.0), 'buffer_size': 9088} @ step loss: {'critic_loss': np.float64(0.21152124106884002), 'actor_loss': np.float64(-1.3049031496047974), 'hyper_actor_loss': np.float64(0.08329992294311524), 'behavior_loss': np.float64(0.7634059190750122)}
step: 230 @ episode report: {'average_total_reward': np.float32(7.267778), 'reward_variance': np.float32(0.9793199), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 9408} @ step loss: {'critic_loss': np.float64(0.2150678351521492), 'actor_loss': np.float64(-1.3712555527687074), 'hyper_actor_loss': np.float64(0.08332634344696999), 'behavior_loss': np.float64(0.7358091771602631)}
step: 240 @ episode report: {'average_total_reward': np.float32(7.0922227), 'reward_variance': np.float32(1.8946431), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.411112), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 9728} @ step loss: {'critic_loss': np.float64(0.23339018523693084), 'actor_loss': np.float64(-1.41249760389328), 'hyper_actor_loss': np.float64(0.08380725979804993), 'behavior_loss': np.float64(0.7442789375782013)}
step: 250 @ episode report: {'average_total_reward': np.float32(7.5555563), 'reward_variance': np.float32(1.3553585), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(8.9), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 10048} @ step loss: {'critic_loss': np.float64(0.23550590127706528), 'actor_loss': np.float64(-1.3673874735832214), 'hyper_actor_loss': np.float64(0.08405027016997338), 'behavior_loss': np.float64(0.6810296773910522)}
step: 260 @ episode report: {'average_total_reward': np.float32(7.467778), 'reward_variance': np.float32(1.6071466), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(8.8), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 10368} @ step loss: {'critic_loss': np.float64(0.23058131486177444), 'actor_loss': np.float64(-1.2940270543098449), 'hyper_actor_loss': np.float64(0.08379296362400054), 'behavior_loss': np.float64(0.712055367231369)}
step: 270 @ episode report: {'average_total_reward': np.float32(7.067778), 'reward_variance': np.float32(1.1472703), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 10688} @ step loss: {'critic_loss': np.float64(0.24817729294300078), 'actor_loss': np.float64(-1.3512688636779786), 'hyper_actor_loss': np.float64(0.08371772766113281), 'behavior_loss': np.float64(0.7049904227256775)}
step: 280 @ episode report: {'average_total_reward': np.float32(7.667778), 'reward_variance': np.float32(3.2417893), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(9.0), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 11008} @ step loss: {'critic_loss': np.float64(0.23100051134824753), 'actor_loss': np.float64(-1.2939896941184998), 'hyper_actor_loss': np.float64(0.08390239924192429), 'behavior_loss': np.float64(0.6821023285388946)}
step: 290 @ episode report: {'average_total_reward': np.float32(6.9433336), 'reward_variance': np.float32(3.3648753), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 11328} @ step loss: {'critic_loss': np.float64(0.2113395720720291), 'actor_loss': np.float64(-1.3865808486938476), 'hyper_actor_loss': np.float64(0.08471741750836373), 'behavior_loss': np.float64(0.6806216061115264)}
step: 300 @ episode report: {'average_total_reward': np.float32(6.172223), 'reward_variance': np.float32(6.587686), 'max_total_reward': np.float32(11.022223), 'min_total_reward': np.float32(2.166667), 'average_n_step': np.float32(7.7), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(4.0), 'buffer_size': 11648} @ step loss: {'critic_loss': np.float64(0.2379418581724167), 'actor_loss': np.float64(-1.3779961347579956), 'hyper_actor_loss': np.float64(0.0856569156050682), 'behavior_loss': np.float64(0.6819262862205505)}
step: 310 @ episode report: {'average_total_reward': np.float32(3.2544446), 'reward_variance': np.float32(2.1311717), 'max_total_reward': np.float32(6.1666675), 'min_total_reward': np.float32(1.8000001), 'average_n_step': np.float32(5.1), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(4.0), 'buffer_size': 11968} @ step loss: {'critic_loss': np.float64(0.2156720533967018), 'actor_loss': np.float64(-1.2540178656578065), 'hyper_actor_loss': np.float64(0.08613978773355484), 'behavior_loss': np.float64(0.7134166836738587)}
step: 320 @ episode report: {'average_total_reward': np.float32(2.7788892), 'reward_variance': np.float32(0.46307287), 'max_total_reward': np.float32(4.288889), 'min_total_reward': np.float32(2.0444446), 'average_n_step': np.float32(4.6), 'max_n_step': np.float32(6.0), 'min_n_step': np.float32(4.0), 'buffer_size': 12288} @ step loss: {'critic_loss': np.float64(0.21694644540548325), 'actor_loss': np.float64(-1.2393389821052552), 'hyper_actor_loss': np.float64(0.08555449619889259), 'behavior_loss': np.float64(0.7260985314846039)}
step: 330 @ episode report: {'average_total_reward': np.float32(3.154445), 'reward_variance': np.float32(1.0631716), 'max_total_reward': np.float32(5.6555557), 'min_total_reward': np.float32(2.0444446), 'average_n_step': np.float32(5.0), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(4.0), 'buffer_size': 12608} @ step loss: {'critic_loss': np.float64(0.23539384976029396), 'actor_loss': np.float64(-1.1656975030899048), 'hyper_actor_loss': np.float64(0.08527376353740693), 'behavior_loss': np.float64(0.7519384801387787)}
step: 340 @ episode report: {'average_total_reward': np.float32(4.747778), 'reward_variance': np.float32(1.9557297), 'max_total_reward': np.float32(7.288889), 'min_total_reward': np.float32(2.1666667), 'average_n_step': np.float32(6.3), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(4.0), 'buffer_size': 12928} @ step loss: {'critic_loss': np.float64(0.24427498131990433), 'actor_loss': np.float64(-1.2219285488128662), 'hyper_actor_loss': np.float64(0.08427044302225113), 'behavior_loss': np.float64(0.7674116909503936)}
step: 350 @ episode report: {'average_total_reward': np.float32(6.9455557), 'reward_variance': np.float32(2.3038878), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 13248} @ step loss: {'critic_loss': np.float64(0.2173641949892044), 'actor_loss': np.float64(-1.1774759769439698), 'hyper_actor_loss': np.float64(0.08523248061537743), 'behavior_loss': np.float64(0.7608910858631134)}
step: 360 @ episode report: {'average_total_reward': np.float32(4.786667), 'reward_variance': np.float32(0.56814307), 'max_total_reward': np.float32(5.6555557), 'min_total_reward': np.float32(3.4111114), 'average_n_step': np.float32(6.4), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(5.0), 'buffer_size': 13568} @ step loss: {'critic_loss': np.float64(0.21639735549688338), 'actor_loss': np.float64(-1.2127796411514282), 'hyper_actor_loss': np.float64(0.08727142065763474), 'behavior_loss': np.float64(0.6881153464317322)}
step: 370 @ episode report: {'average_total_reward': np.float32(3.691111), 'reward_variance': np.float32(1.116662), 'max_total_reward': np.float32(5.533334), 'min_total_reward': np.float32(2.288889), 'average_n_step': np.float32(5.5), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(4.0), 'buffer_size': 13888} @ step loss: {'critic_loss': np.float64(0.24333009123802185), 'actor_loss': np.float64(-1.4057806491851808), 'hyper_actor_loss': np.float64(0.09015911668539048), 'behavior_loss': np.float64(0.6551831185817718)}
step: 380 @ episode report: {'average_total_reward': np.float32(1.3755556), 'reward_variance': np.float32(0.681131), 'max_total_reward': np.float32(3.0444446), 'min_total_reward': np.float32(0.3111111), 'average_n_step': np.float32(3.6), 'max_n_step': np.float32(5.0), 'min_n_step': np.float32(3.0), 'buffer_size': 14208} @ step loss: {'critic_loss': np.float64(0.21572522222995758), 'actor_loss': np.float64(-1.4843965411186217), 'hyper_actor_loss': np.float64(0.0913826934993267), 'behavior_loss': np.float64(0.6272674381732941)}
step: 390 @ episode report: {'average_total_reward': np.float32(0.9877777), 'reward_variance': np.float32(0.113270365), 'max_total_reward': np.float32(1.5555556), 'min_total_reward': np.float32(0.5555556), 'average_n_step': np.float32(3.2), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 14528} @ step loss: {'critic_loss': np.float64(0.21419054716825486), 'actor_loss': np.float64(-1.4210358738899231), 'hyper_actor_loss': np.float64(0.09117745906114579), 'behavior_loss': np.float64(0.6428479254245758)}
step: 400 @ episode report: {'average_total_reward': np.float32(1.1611111), 'reward_variance': np.float32(0.15452468), 'max_total_reward': np.float32(2.0444443), 'min_total_reward': np.float32(0.6777777), 'average_n_step': np.float32(3.3), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 14848} @ step loss: {'critic_loss': np.float64(0.21100203394889833), 'actor_loss': np.float64(-1.3160995721817017), 'hyper_actor_loss': np.float64(0.09085547477006913), 'behavior_loss': np.float64(0.6790434837341308)}
step: 410 @ episode report: {'average_total_reward': np.float32(1.697778), 'reward_variance': np.float32(0.15940246), 'max_total_reward': np.float32(2.288889), 'min_total_reward': np.float32(1.1666667), 'average_n_step': np.float32(3.8), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 15168} @ step loss: {'critic_loss': np.float64(0.23850127011537553), 'actor_loss': np.float64(-1.278928017616272), 'hyper_actor_loss': np.float64(0.09074963927268982), 'behavior_loss': np.float64(0.6569061934947967)}
step: 420 @ episode report: {'average_total_reward': np.float32(1.6611111), 'reward_variance': np.float32(0.92625314), 'max_total_reward': np.float32(3.0444448), 'min_total_reward': np.float32(0.044444427), 'average_n_step': np.float32(3.8), 'max_n_step': np.float32(5.0), 'min_n_step': np.float32(2.0), 'buffer_size': 15488} @ step loss: {'critic_loss': np.float64(0.25090172439813613), 'actor_loss': np.float64(-1.2187878370285035), 'hyper_actor_loss': np.float64(0.09062324464321136), 'behavior_loss': np.float64(0.6808764398097992)}
step: 430 @ episode report: {'average_total_reward': np.float32(2.5322223), 'reward_variance': np.float32(0.809147), 'max_total_reward': np.float32(4.0444446), 'min_total_reward': np.float32(1.1666666), 'average_n_step': np.float32(4.5), 'max_n_step': np.float32(6.0), 'min_n_step': np.float32(3.0), 'buffer_size': 15808} @ step loss: {'critic_loss': np.float64(0.23801193982362748), 'actor_loss': np.float64(-1.0782204866409302), 'hyper_actor_loss': np.float64(0.09020079374313354), 'behavior_loss': np.float64(0.6768935322761536)}
step: 440 @ episode report: {'average_total_reward': np.float32(2.7544446), 'reward_variance': np.float32(1.5482584), 'max_total_reward': np.float32(5.533334), 'min_total_reward': np.float32(1.1666667), 'average_n_step': np.float32(4.6), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(3.0), 'buffer_size': 16128} @ step loss: {'critic_loss': np.float64(0.2086434245109558), 'actor_loss': np.float64(-1.096431803703308), 'hyper_actor_loss': np.float64(0.09037454277276993), 'behavior_loss': np.float64(0.6504742980003357)}
step: 450 @ episode report: {'average_total_reward': np.float32(3.4644444), 'reward_variance': np.float32(1.3043408), 'max_total_reward': np.float32(5.6555557), 'min_total_reward': np.float32(1.9222221), 'average_n_step': np.float32(5.2), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(4.0), 'buffer_size': 16448} @ step loss: {'critic_loss': np.float64(0.2024049624800682), 'actor_loss': np.float64(-1.122527801990509), 'hyper_actor_loss': np.float64(0.09091987386345864), 'behavior_loss': np.float64(0.6702564239501954)}
step: 460 @ episode report: {'average_total_reward': np.float32(4.772222), 'reward_variance': np.float32(2.7262533), 'max_total_reward': np.float32(7.6555557), 'min_total_reward': np.float32(2.288889), 'average_n_step': np.float32(6.3), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(4.0), 'buffer_size': 16768} @ step loss: {'critic_loss': np.float64(0.21515318602323533), 'actor_loss': np.float64(-1.1923758268356324), 'hyper_actor_loss': np.float64(0.09056587666273117), 'behavior_loss': np.float64(0.6654137969017029)}
step: 470 @ episode report: {'average_total_reward': np.float32(5.347778), 'reward_variance': np.float32(2.2291121), 'max_total_reward': np.float32(8.777778), 'min_total_reward': np.float32(3.288889), 'average_n_step': np.float32(6.9), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(5.0), 'buffer_size': 17088} @ step loss: {'critic_loss': np.float64(0.20093441605567933), 'actor_loss': np.float64(-1.2687384724617004), 'hyper_actor_loss': np.float64(0.08959057331085205), 'behavior_loss': np.float64(0.6644936740398407)}
step: 480 @ episode report: {'average_total_reward': np.float32(6.145556), 'reward_variance': np.float32(2.5389247), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(7.6), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 17408} @ step loss: {'critic_loss': np.float64(0.21424129009246826), 'actor_loss': np.float64(-1.3819300651550293), 'hyper_actor_loss': np.float64(0.09011470749974251), 'behavior_loss': np.float64(0.6677825808525085)}
step: 490 @ episode report: {'average_total_reward': np.float32(5.608889), 'reward_variance': np.float32(0.982563), 'max_total_reward': np.float32(7.655556), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.1), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 17728} @ step loss: {'critic_loss': np.float64(0.1901116594672203), 'actor_loss': np.float64(-1.457580578327179), 'hyper_actor_loss': np.float64(0.08941571116447448), 'behavior_loss': np.float64(0.6321690022945404)}
step: 500 @ episode report: {'average_total_reward': np.float32(7.853334), 'reward_variance': np.float32(2.0085382), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(9.1), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 18048} @ step loss: {'critic_loss': np.float64(0.19849577993154527), 'actor_loss': np.float64(-1.5086021065711974), 'hyper_actor_loss': np.float64(0.08954779505729675), 'behavior_loss': np.float64(0.592994076013565)}
step: 510 @ episode report: {'average_total_reward': np.float32(6.4700003), 'reward_variance': np.float32(2.2206936), 'max_total_reward': np.float32(9.900002), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(7.9), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 18368} @ step loss: {'critic_loss': np.float64(0.2141862466931343), 'actor_loss': np.float64(-1.4436532974243164), 'hyper_actor_loss': np.float64(0.08985347747802734), 'behavior_loss': np.float64(0.6380758941173553)}
step: 520 @ episode report: {'average_total_reward': np.float32(7.2188888), 'reward_variance': np.float32(3.8562489), 'max_total_reward': np.float32(9.900002), 'min_total_reward': np.float32(3.4111114), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(5.0), 'buffer_size': 18688} @ step loss: {'critic_loss': np.float64(0.21576564610004426), 'actor_loss': np.float64(-1.4586330890655517), 'hyper_actor_loss': np.float64(0.09037360548973083), 'behavior_loss': np.float64(0.6088385581970215)}
step: 530 @ episode report: {'average_total_reward': np.float32(6.0211115), 'reward_variance': np.float32(2.7698386), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(4.166667), 'average_n_step': np.float32(7.5), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 19008} @ step loss: {'critic_loss': np.float64(0.2308237835764885), 'actor_loss': np.float64(-1.5339673638343811), 'hyper_actor_loss': np.float64(0.09023459330201149), 'behavior_loss': np.float64(0.6179191112518311)}
step: 540 @ episode report: {'average_total_reward': np.float32(6.4944444), 'reward_variance': np.float32(1.2431175), 'max_total_reward': np.float32(8.777778), 'min_total_reward': np.float32(4.411111), 'average_n_step': np.float32(7.9), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 19328} @ step loss: {'critic_loss': np.float64(0.19556057304143906), 'actor_loss': np.float64(-1.375489854812622), 'hyper_actor_loss': np.float64(0.09036673158407212), 'behavior_loss': np.float64(0.6151082813739777)}
step: 550 @ episode report: {'average_total_reward': np.float32(4.423334), 'reward_variance': np.float32(0.7963568), 'max_total_reward': np.float32(5.655556), 'min_total_reward': np.float32(3.2888892), 'average_n_step': np.float32(6.0), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(5.0), 'buffer_size': 19648} @ step loss: {'critic_loss': np.float64(0.21020080298185348), 'actor_loss': np.float64(-1.3044018507003785), 'hyper_actor_loss': np.float64(0.08972214683890342), 'behavior_loss': np.float64(0.639858889579773)}
step: 560 @ episode report: {'average_total_reward': np.float32(2.5955555), 'reward_variance': np.float32(1.5256099), 'max_total_reward': np.float32(4.922222), 'min_total_reward': np.float32(0.8000001), 'average_n_step': np.float32(4.6), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(3.0), 'buffer_size': 19968} @ step loss: {'critic_loss': np.float64(0.22386176139116287), 'actor_loss': np.float64(-1.3157557606697083), 'hyper_actor_loss': np.float64(0.08948599100112915), 'behavior_loss': np.float64(0.6743368685245514)}
step: 570 @ episode report: {'average_total_reward': np.float32(2.232222), 'reward_variance': np.float32(0.62299883), 'max_total_reward': np.float32(3.288889), 'min_total_reward': np.float32(0.92222226), 'average_n_step': np.float32(4.2), 'max_n_step': np.float32(5.0), 'min_n_step': np.float32(3.0), 'buffer_size': 20288} @ step loss: {'critic_loss': np.float64(0.22190186083316804), 'actor_loss': np.float64(-1.3747975707054139), 'hyper_actor_loss': np.float64(0.08903575390577316), 'behavior_loss': np.float64(0.6834980428218842)}
step: 580 @ episode report: {'average_total_reward': np.float32(2.0077777), 'reward_variance': np.float32(0.87592715), 'max_total_reward': np.float32(3.288889), 'min_total_reward': np.float32(0.92222226), 'average_n_step': np.float32(4.0), 'max_n_step': np.float32(5.0), 'min_n_step': np.float32(3.0), 'buffer_size': 20608} @ step loss: {'critic_loss': np.float64(0.23160126358270644), 'actor_loss': np.float64(-1.3758429408073425), 'hyper_actor_loss': np.float64(0.088214660435915), 'behavior_loss': np.float64(0.697436398267746)}
step: 590 @ episode report: {'average_total_reward': np.float32(1.5222223), 'reward_variance': np.float32(0.24190125), 'max_total_reward': np.float32(2.288889), 'min_total_reward': np.float32(0.67777777), 'average_n_step': np.float32(3.6), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 20928} @ step loss: {'critic_loss': np.float64(0.2351089522242546), 'actor_loss': np.float64(-1.3210700273513794), 'hyper_actor_loss': np.float64(0.08774556517601013), 'behavior_loss': np.float64(0.7229820787906647)}
step: 600 @ episode report: {'average_total_reward': np.float32(1.307778), 'reward_variance': np.float32(0.176742), 'max_total_reward': np.float32(2.0444446), 'min_total_reward': np.float32(0.8000001), 'average_n_step': np.float32(3.3), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 21248} @ step loss: {'critic_loss': np.float64(0.2403948724269867), 'actor_loss': np.float64(-1.3014143586158753), 'hyper_actor_loss': np.float64(0.08715080171823501), 'behavior_loss': np.float64(0.7490226447582244)}
step: 610 @ episode report: {'average_total_reward': np.float32(1.5955557), 'reward_variance': np.float32(0.24630126), 'max_total_reward': np.float32(2.288889), 'min_total_reward': np.float32(0.8), 'average_n_step': np.float32(3.6), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 21568} @ step loss: {'critic_loss': np.float64(0.2060711622238159), 'actor_loss': np.float64(-1.3496487855911254), 'hyper_actor_loss': np.float64(0.08654336109757424), 'behavior_loss': np.float64(0.7704312622547149)}
step: 620 @ episode report: {'average_total_reward': np.float32(1.3344446), 'reward_variance': np.float32(0.26443088), 'max_total_reward': np.float32(2.288889), 'min_total_reward': np.float32(0.8), 'average_n_step': np.float32(3.4), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 21888} @ step loss: {'critic_loss': np.float64(0.23489209413528442), 'actor_loss': np.float64(-1.375463855266571), 'hyper_actor_loss': np.float64(0.08592816814780235), 'behavior_loss': np.float64(0.8205505311489105)}
step: 630 @ episode report: {'average_total_reward': np.float32(1.4833335), 'reward_variance': np.float32(0.17361109), 'max_total_reward': np.float32(2.1666665), 'min_total_reward': np.float32(0.9222224), 'average_n_step': np.float32(3.5), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 22208} @ step loss: {'critic_loss': np.float64(0.2411483883857727), 'actor_loss': np.float64(-1.398985540866852), 'hyper_actor_loss': np.float64(0.08551945090293885), 'behavior_loss': np.float64(0.7863253295421601)}
step: 640 @ episode report: {'average_total_reward': np.float32(1.5855558), 'reward_variance': np.float32(0.35763094), 'max_total_reward': np.float32(2.288889), 'min_total_reward': np.float32(0.43333337), 'average_n_step': np.float32(3.7), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 22528} @ step loss: {'critic_loss': np.float64(0.2442786365747452), 'actor_loss': np.float64(-1.3854611396789551), 'hyper_actor_loss': np.float64(0.08485584259033203), 'behavior_loss': np.float64(0.8541436433792114)}
step: 650 @ episode report: {'average_total_reward': np.float32(2.0711112), 'reward_variance': np.float32(0.41146174), 'max_total_reward': np.float32(3.0444446), 'min_total_reward': np.float32(0.67777777), 'average_n_step': np.float32(4.1), 'max_n_step': np.float32(5.0), 'min_n_step': np.float32(3.0), 'buffer_size': 22848} @ step loss: {'critic_loss': np.float64(0.23600105196237564), 'actor_loss': np.float64(-1.318431031703949), 'hyper_actor_loss': np.float64(0.0843698613345623), 'behavior_loss': np.float64(0.8712394058704376)}
step: 660 @ episode report: {'average_total_reward': np.float32(1.6322224), 'reward_variance': np.float32(0.30136916), 'max_total_reward': np.float32(2.288889), 'min_total_reward': np.float32(0.8000001), 'average_n_step': np.float32(3.6), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 23168} @ step loss: {'critic_loss': np.float64(0.2508716359734535), 'actor_loss': np.float64(-1.330858314037323), 'hyper_actor_loss': np.float64(0.0841468669474125), 'behavior_loss': np.float64(0.8823404431343078)}
step: 670 @ episode report: {'average_total_reward': np.float32(1.9344447), 'reward_variance': np.float32(0.8681593), 'max_total_reward': np.float32(4.0444446), 'min_total_reward': np.float32(0.67777777), 'average_n_step': np.float32(4.0), 'max_n_step': np.float32(6.0), 'min_n_step': np.float32(3.0), 'buffer_size': 23488} @ step loss: {'critic_loss': np.float64(0.24839155673980712), 'actor_loss': np.float64(-1.4610501408576966), 'hyper_actor_loss': np.float64(0.08463992550969124), 'behavior_loss': np.float64(0.8313158094882965)}
step: 680 @ episode report: {'average_total_reward': np.float32(1.8711112), 'reward_variance': np.float32(0.30227655), 'max_total_reward': np.float32(2.9222224), 'min_total_reward': np.float32(0.9222223), 'average_n_step': np.float32(3.9), 'max_n_step': np.float32(5.0), 'min_n_step': np.float32(3.0), 'buffer_size': 23808} @ step loss: {'critic_loss': np.float64(0.2589428052306175), 'actor_loss': np.float64(-1.492961049079895), 'hyper_actor_loss': np.float64(0.08458655104041099), 'behavior_loss': np.float64(0.8990075647830963)}
step: 690 @ episode report: {'average_total_reward': np.float32(2.866667), 'reward_variance': np.float32(1.0962718), 'max_total_reward': np.float32(4.4111114), 'min_total_reward': np.float32(0.92222226), 'average_n_step': np.float32(4.7), 'max_n_step': np.float32(6.0), 'min_n_step': np.float32(3.0), 'buffer_size': 24128} @ step loss: {'critic_loss': np.float64(0.28479048758745196), 'actor_loss': np.float64(-1.4904771447181702), 'hyper_actor_loss': np.float64(0.08402921855449677), 'behavior_loss': np.float64(0.9127048909664154)}
step: 700 @ episode report: {'average_total_reward': np.float32(2.7644446), 'reward_variance': np.float32(0.7346865), 'max_total_reward': np.float32(4.288889), 'min_total_reward': np.float32(1.0444444), 'average_n_step': np.float32(4.5), 'max_n_step': np.float32(6.0), 'min_n_step': np.float32(3.0), 'buffer_size': 24448} @ step loss: {'critic_loss': np.float64(0.29208657145500183), 'actor_loss': np.float64(-1.412292242050171), 'hyper_actor_loss': np.float64(0.08339296504855156), 'behavior_loss': np.float64(0.9250135004520417)}
step: 710 @ episode report: {'average_total_reward': np.float32(4.2377777), 'reward_variance': np.float32(1.3701781), 'max_total_reward': np.float32(6.5333343), 'min_total_reward': np.float32(3.1666667), 'average_n_step': np.float32(5.9), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(5.0), 'buffer_size': 24768} @ step loss: {'critic_loss': np.float64(0.28560504168272016), 'actor_loss': np.float64(-1.4263062596321106), 'hyper_actor_loss': np.float64(0.0828729122877121), 'behavior_loss': np.float64(0.9994125008583069)}
step: 720 @ episode report: {'average_total_reward': np.float32(3.7644448), 'reward_variance': np.float32(0.7251803), 'max_total_reward': np.float32(5.2888894), 'min_total_reward': np.float32(2.9222221), 'average_n_step': np.float32(5.5), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(5.0), 'buffer_size': 25088} @ step loss: {'critic_loss': np.float64(0.2633097156882286), 'actor_loss': np.float64(-1.3919548869132996), 'hyper_actor_loss': np.float64(0.0825638271868229), 'behavior_loss': np.float64(0.9863818287849426)}
step: 730 @ episode report: {'average_total_reward': np.float32(4.2011113), 'reward_variance': np.float32(0.58504826), 'max_total_reward': np.float32(5.4111114), 'min_total_reward': np.float32(3.0444446), 'average_n_step': np.float32(5.9), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(5.0), 'buffer_size': 25408} @ step loss: {'critic_loss': np.float64(0.2808897405862808), 'actor_loss': np.float64(-1.4127074003219604), 'hyper_actor_loss': np.float64(0.08218844011425971), 'behavior_loss': np.float64(0.9864829480648041)}
step: 740 @ episode report: {'average_total_reward': np.float32(4.7744446), 'reward_variance': np.float32(0.80012476), 'max_total_reward': np.float32(6.655556), 'min_total_reward': np.float32(3.4111114), 'average_n_step': np.float32(6.4), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(5.0), 'buffer_size': 25728} @ step loss: {'critic_loss': np.float64(0.3029620170593262), 'actor_loss': np.float64(-1.4334131002426147), 'hyper_actor_loss': np.float64(0.08114418238401414), 'behavior_loss': np.float64(1.012954980134964)}
step: 750 @ episode report: {'average_total_reward': np.float32(4.8355556), 'reward_variance': np.float32(0.99340236), 'max_total_reward': np.float32(6.6555557), 'min_total_reward': np.float32(3.166667), 'average_n_step': np.float32(6.4), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(5.0), 'buffer_size': 26048} @ step loss: {'critic_loss': np.float64(0.2748985767364502), 'actor_loss': np.float64(-1.37128643989563), 'hyper_actor_loss': np.float64(0.08034287467598915), 'behavior_loss': np.float64(1.008607769012451)}
step: 760 @ episode report: {'average_total_reward': np.float32(4.6622224), 'reward_variance': np.float32(0.7795357), 'max_total_reward': np.float32(6.6555557), 'min_total_reward': np.float32(3.2888894), 'average_n_step': np.float32(6.3), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(5.0), 'buffer_size': 26368} @ step loss: {'critic_loss': np.float64(0.2791884675621986), 'actor_loss': np.float64(-1.4322988986968994), 'hyper_actor_loss': np.float64(0.0788856327533722), 'behavior_loss': np.float64(0.9934552788734436)}
step: 770 @ episode report: {'average_total_reward': np.float32(5.1844444), 'reward_variance': np.float32(2.2162032), 'max_total_reward': np.float32(7.411112), 'min_total_reward': np.float32(2.288889), 'average_n_step': np.float32(6.7), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(4.0), 'buffer_size': 26688} @ step loss: {'critic_loss': np.float64(0.28336364328861235), 'actor_loss': np.float64(-1.3907130002975463), 'hyper_actor_loss': np.float64(0.07745768800377846), 'behavior_loss': np.float64(0.9945900619029999)}
step: 780 @ episode report: {'average_total_reward': np.float32(4.5622225), 'reward_variance': np.float32(0.90481985), 'max_total_reward': np.float32(6.6555557), 'min_total_reward': np.float32(3.288889), 'average_n_step': np.float32(6.2), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(5.0), 'buffer_size': 27008} @ step loss: {'critic_loss': np.float64(0.28373668491840365), 'actor_loss': np.float64(-1.3838728427886964), 'hyper_actor_loss': np.float64(0.07639360576868057), 'behavior_loss': np.float64(1.0107287883758544)}
step: 790 @ episode report: {'average_total_reward': np.float32(5.221111), 'reward_variance': np.float32(0.6892953), 'max_total_reward': np.float32(6.6555557), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(6.7), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(6.0), 'buffer_size': 27328} @ step loss: {'critic_loss': np.float64(0.25618006438016894), 'actor_loss': np.float64(-1.4664801836013794), 'hyper_actor_loss': np.float64(0.07547250986099244), 'behavior_loss': np.float64(1.03059424161911)}
step: 800 @ episode report: {'average_total_reward': np.float32(4.7211113), 'reward_variance': np.float32(1.1218629), 'max_total_reward': np.float32(6.6555557), 'min_total_reward': np.float32(3.411111), 'average_n_step': np.float32(6.2), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(5.0), 'buffer_size': 27648} @ step loss: {'critic_loss': np.float64(0.2828988015651703), 'actor_loss': np.float64(-1.4345525860786439), 'hyper_actor_loss': np.float64(0.07454597875475884), 'behavior_loss': np.float64(1.0134474813938141)}
step: 810 @ episode report: {'average_total_reward': np.float32(4.15), 'reward_variance': np.float32(0.89790756), 'max_total_reward': np.float32(5.533334), 'min_total_reward': np.float32(2.288889), 'average_n_step': np.float32(5.8), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(4.0), 'buffer_size': 27968} @ step loss: {'critic_loss': np.float64(0.2639752119779587), 'actor_loss': np.float64(-1.460268795490265), 'hyper_actor_loss': np.float64(0.07394924536347389), 'behavior_loss': np.float64(1.0108021557331086)}
step: 820 @ episode report: {'average_total_reward': np.float32(4.45), 'reward_variance': np.float32(0.29645061), 'max_total_reward': np.float32(5.4111114), 'min_total_reward': np.float32(3.4111114), 'average_n_step': np.float32(6.1), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(5.0), 'buffer_size': 28288} @ step loss: {'critic_loss': np.float64(0.3017728358507156), 'actor_loss': np.float64(-1.4730283737182617), 'hyper_actor_loss': np.float64(0.07341004237532615), 'behavior_loss': np.float64(1.0832592248916626)}
step: 830 @ episode report: {'average_total_reward': np.float32(4.374444), 'reward_variance': np.float32(0.39064327), 'max_total_reward': np.float32(5.533334), 'min_total_reward': np.float32(3.4111114), 'average_n_step': np.float32(6.0), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(5.0), 'buffer_size': 28608} @ step loss: {'critic_loss': np.float64(0.28425985127687453), 'actor_loss': np.float64(-1.4388948917388915), 'hyper_actor_loss': np.float64(0.07278542518615723), 'behavior_loss': np.float64(1.0586007595062257)}
step: 840 @ episode report: {'average_total_reward': np.float32(4.8622227), 'reward_variance': np.float32(0.9478323), 'max_total_reward': np.float32(6.2888894), 'min_total_reward': np.float32(3.1666667), 'average_n_step': np.float32(6.5), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(5.0), 'buffer_size': 28928} @ step loss: {'critic_loss': np.float64(0.2708112999796867), 'actor_loss': np.float64(-1.4110317468643188), 'hyper_actor_loss': np.float64(0.07189693078398704), 'behavior_loss': np.float64(1.0636033117771149)}
step: 850 @ episode report: {'average_total_reward': np.float32(4.223333), 'reward_variance': np.float32(0.61811), 'max_total_reward': np.float32(5.533334), 'min_total_reward': np.float32(3.288889), 'average_n_step': np.float32(5.8), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(5.0), 'buffer_size': 29248} @ step loss: {'critic_loss': np.float64(0.2628029651939869), 'actor_loss': np.float64(-1.3083117961883546), 'hyper_actor_loss': np.float64(0.07136405482888222), 'behavior_loss': np.float64(1.0513768076896668)}
step: 860 @ episode report: {'average_total_reward': np.float32(3.8766665), 'reward_variance': np.float32(0.2649741), 'max_total_reward': np.float32(4.4111114), 'min_total_reward': np.float32(3.1666667), 'average_n_step': np.float32(5.6), 'max_n_step': np.float32(6.0), 'min_n_step': np.float32(5.0), 'buffer_size': 29568} @ step loss: {'critic_loss': np.float64(0.2522968232631683), 'actor_loss': np.float64(-1.268574845790863), 'hyper_actor_loss': np.float64(0.07108602076768875), 'behavior_loss': np.float64(1.0580645084381104)}
step: 870 @ episode report: {'average_total_reward': np.float32(4.298889), 'reward_variance': np.float32(0.6564803), 'max_total_reward': np.float32(5.6555557), 'min_total_reward': np.float32(3.288889), 'average_n_step': np.float32(5.9), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(5.0), 'buffer_size': 29888} @ step loss: {'critic_loss': np.float64(0.2871165782213211), 'actor_loss': np.float64(-1.4411540031433105), 'hyper_actor_loss': np.float64(0.0708754263818264), 'behavior_loss': np.float64(1.1075618982315063)}
step: 880 @ episode report: {'average_total_reward': np.float32(3.7766666), 'reward_variance': np.float32(0.94233227), 'max_total_reward': np.float32(5.4111114), 'min_total_reward': np.float32(2.0444443), 'average_n_step': np.float32(5.5), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(4.0), 'buffer_size': 30208} @ step loss: {'critic_loss': np.float64(0.2934668481349945), 'actor_loss': np.float64(-1.4072302103042602), 'hyper_actor_loss': np.float64(0.07111579105257988), 'behavior_loss': np.float64(1.146776795387268)}
step: 890 @ episode report: {'average_total_reward': np.float32(4.037778), 'reward_variance': np.float32(1.3506473), 'max_total_reward': np.float32(6.6555567), 'min_total_reward': np.float32(3.0444446), 'average_n_step': np.float32(5.7), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(5.0), 'buffer_size': 30528} @ step loss: {'critic_loss': np.float64(0.27171346098184584), 'actor_loss': np.float64(-1.413872230052948), 'hyper_actor_loss': np.float64(0.07046127840876579), 'behavior_loss': np.float64(1.142907691001892)}
step: 900 @ episode report: {'average_total_reward': np.float32(4.186667), 'reward_variance': np.float32(0.6927606), 'max_total_reward': np.float32(5.6555557), 'min_total_reward': np.float32(3.288889), 'average_n_step': np.float32(5.8), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(5.0), 'buffer_size': 30848} @ step loss: {'critic_loss': np.float64(0.268994602560997), 'actor_loss': np.float64(-1.4389726638793945), 'hyper_actor_loss': np.float64(0.06965088769793511), 'behavior_loss': np.float64(1.0871660947799682)}
step: 910 @ episode report: {'average_total_reward': np.float32(3.9522223), 'reward_variance': np.float32(0.6001001), 'max_total_reward': np.float32(5.4111114), 'min_total_reward': np.float32(2.288889), 'average_n_step': np.float32(5.7), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(4.0), 'buffer_size': 31168} @ step loss: {'critic_loss': np.float64(0.2546416163444519), 'actor_loss': np.float64(-1.425717532634735), 'hyper_actor_loss': np.float64(0.06914722546935081), 'behavior_loss': np.float64(1.130844873189926)}
step: 920 @ episode report: {'average_total_reward': np.float32(3.876667), 'reward_variance': np.float32(1.5762334), 'max_total_reward': np.float32(6.6555557), 'min_total_reward': np.float32(2.0444446), 'average_n_step': np.float32(5.6), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(4.0), 'buffer_size': 31488} @ step loss: {'critic_loss': np.float64(0.27204621583223343), 'actor_loss': np.float64(-1.4205093026161193), 'hyper_actor_loss': np.float64(0.06878916546702385), 'behavior_loss': np.float64(1.1575475931167603)}
step: 930 @ episode report: {'average_total_reward': np.float32(4.137778), 'reward_variance': np.float32(0.7078075), 'max_total_reward': np.float32(5.533334), 'min_total_reward': np.float32(2.9222221), 'average_n_step': np.float32(5.8), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(5.0), 'buffer_size': 31808} @ step loss: {'critic_loss': np.float64(0.25798811614513395), 'actor_loss': np.float64(-1.423772895336151), 'hyper_actor_loss': np.float64(0.06783995479345321), 'behavior_loss': np.float64(1.1933996319770812)}
step: 940 @ episode report: {'average_total_reward': np.float32(4.1011114), 'reward_variance': np.float32(1.0909002), 'max_total_reward': np.float32(5.655556), 'min_total_reward': np.float32(2.288889), 'average_n_step': np.float32(5.8), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(4.0), 'buffer_size': 32128} @ step loss: {'critic_loss': np.float64(0.24121879190206527), 'actor_loss': np.float64(-1.373693871498108), 'hyper_actor_loss': np.float64(0.06719662398099899), 'behavior_loss': np.float64(1.1983871817588807)}
step: 950 @ episode report: {'average_total_reward': np.float32(4.1255555), 'reward_variance': np.float32(1.0810137), 'max_total_reward': np.float32(5.533334), 'min_total_reward': np.float32(2.288889), 'average_n_step': np.float32(5.8), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(4.0), 'buffer_size': 32448} @ step loss: {'critic_loss': np.float64(0.3070122703909874), 'actor_loss': np.float64(-1.4241244554519654), 'hyper_actor_loss': np.float64(0.06676306277513504), 'behavior_loss': np.float64(1.208012545108795)}
step: 960 @ episode report: {'average_total_reward': np.float32(4.113333), 'reward_variance': np.float32(1.0694025), 'max_total_reward': np.float32(6.4111114), 'min_total_reward': np.float32(3.0444446), 'average_n_step': np.float32(5.8), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(5.0), 'buffer_size': 32768} @ step loss: {'critic_loss': np.float64(0.2649839401245117), 'actor_loss': np.float64(-1.3923160314559937), 'hyper_actor_loss': np.float64(0.06661201864480973), 'behavior_loss': np.float64(1.17714262008667)}
step: 970 @ episode report: {'average_total_reward': np.float32(3.5544448), 'reward_variance': np.float32(0.76628274), 'max_total_reward': np.float32(4.5333333), 'min_total_reward': np.float32(1.8000001), 'average_n_step': np.float32(5.4), 'max_n_step': np.float32(6.0), 'min_n_step': np.float32(4.0), 'buffer_size': 33088} @ step loss: {'critic_loss': np.float64(0.2342709094285965), 'actor_loss': np.float64(-1.3524147272109985), 'hyper_actor_loss': np.float64(0.066707281768322), 'behavior_loss': np.float64(1.194549036026001)}
step: 980 @ episode report: {'average_total_reward': np.float32(4.0255556), 'reward_variance': np.float32(0.23758161), 'max_total_reward': np.float32(4.533334), 'min_total_reward': np.float32(3.288889), 'average_n_step': np.float32(5.7), 'max_n_step': np.float32(6.0), 'min_n_step': np.float32(5.0), 'buffer_size': 33408} @ step loss: {'critic_loss': np.float64(0.2558374270796776), 'actor_loss': np.float64(-1.3254530549049377), 'hyper_actor_loss': np.float64(0.06635023429989814), 'behavior_loss': np.float64(1.2044105768203734)}
step: 990 @ episode report: {'average_total_reward': np.float32(4.1255555), 'reward_variance': np.float32(0.47503823), 'max_total_reward': np.float32(5.5333333), 'min_total_reward': np.float32(3.0444446), 'average_n_step': np.float32(5.8), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(5.0), 'buffer_size': 33728} @ step loss: {'critic_loss': np.float64(0.23052679151296615), 'actor_loss': np.float64(-1.26901695728302), 'hyper_actor_loss': np.float64(0.06603015884757042), 'behavior_loss': np.float64(1.210806679725647)}
step: 1000 @ episode report: {'average_total_reward': np.float32(3.776667), 'reward_variance': np.float32(0.96677655), 'max_total_reward': np.float32(5.5333333), 'min_total_reward': np.float32(2.288889), 'average_n_step': np.float32(5.5), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(4.0), 'buffer_size': 34048} @ step loss: {'critic_loss': np.float64(0.24722741097211837), 'actor_loss': np.float64(-1.2658369541168213), 'hyper_actor_loss': np.float64(0.06623187139630318), 'behavior_loss': np.float64(1.2649154663085938)}
step: 1010 @ episode report: {'average_total_reward': np.float32(3.952222), 'reward_variance': np.float32(0.41856918), 'max_total_reward': np.float32(5.2888894), 'min_total_reward': np.float32(3.166667), 'average_n_step': np.float32(5.7), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(5.0), 'buffer_size': 34368} @ step loss: {'critic_loss': np.float64(0.27021132707595824), 'actor_loss': np.float64(-1.2687161922454835), 'hyper_actor_loss': np.float64(0.06648707613348961), 'behavior_loss': np.float64(1.2381425380706788)}
step: 1020 @ episode report: {'average_total_reward': np.float32(4.4866667), 'reward_variance': np.float32(0.9227112), 'max_total_reward': np.float32(5.6555557), 'min_total_reward': np.float32(3.0444446), 'average_n_step': np.float32(6.1), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(5.0), 'buffer_size': 34688} @ step loss: {'critic_loss': np.float64(0.2766727447509766), 'actor_loss': np.float64(-1.367883026599884), 'hyper_actor_loss': np.float64(0.06723309829831123), 'behavior_loss': np.float64(1.2475776314735412)}
step: 1030 @ episode report: {'average_total_reward': np.float32(4.076667), 'reward_variance': np.float32(1.6182833), 'max_total_reward': np.float32(7.5333343), 'min_total_reward': np.float32(2.9222221), 'average_n_step': np.float32(5.8), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(5.0), 'buffer_size': 35008} @ step loss: {'critic_loss': np.float64(0.258431912958622), 'actor_loss': np.float64(-1.2849687218666077), 'hyper_actor_loss': np.float64(0.0677307404577732), 'behavior_loss': np.float64(1.2378803968429566)}
step: 1040 @ episode report: {'average_total_reward': np.float32(4.586667), 'reward_variance': np.float32(0.8035754), 'max_total_reward': np.float32(5.6555557), 'min_total_reward': np.float32(2.9222224), 'average_n_step': np.float32(6.2), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(5.0), 'buffer_size': 35328} @ step loss: {'critic_loss': np.float64(0.19818059355020523), 'actor_loss': np.float64(-1.269745147228241), 'hyper_actor_loss': np.float64(0.06816087812185287), 'behavior_loss': np.float64(1.2284478187561034)}
step: 1050 @ episode report: {'average_total_reward': np.float32(4.0255556), 'reward_variance': np.float32(0.5717544), 'max_total_reward': np.float32(5.533334), 'min_total_reward': np.float32(2.9222221), 'average_n_step': np.float32(5.7), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(5.0), 'buffer_size': 35648} @ step loss: {'critic_loss': np.float64(0.22437775433063506), 'actor_loss': np.float64(-1.2500660181045533), 'hyper_actor_loss': np.float64(0.06772715300321579), 'behavior_loss': np.float64(1.2747225046157837)}
step: 1060 @ episode report: {'average_total_reward': np.float32(3.9500008), 'reward_variance': np.float32(0.8113149), 'max_total_reward': np.float32(5.6555557), 'min_total_reward': np.float32(3.1666665), 'average_n_step': np.float32(5.6), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(5.0), 'buffer_size': 35968} @ step loss: {'critic_loss': np.float64(0.20707164257764815), 'actor_loss': np.float64(-1.3128533959388733), 'hyper_actor_loss': np.float64(0.067948317527771), 'behavior_loss': np.float64(1.2257298707962037)}
step: 1070 @ episode report: {'average_total_reward': np.float32(4.0255556), 'reward_variance': np.float32(0.92639637), 'max_total_reward': np.float32(6.5333333), 'min_total_reward': np.float32(3.1666667), 'average_n_step': np.float32(5.7), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(5.0), 'buffer_size': 36288} @ step loss: {'critic_loss': np.float64(0.2621344789862633), 'actor_loss': np.float64(-1.3839929938316344), 'hyper_actor_loss': np.float64(0.06866006329655647), 'behavior_loss': np.float64(1.2455185770988464)}
step: 1080 @ episode report: {'average_total_reward': np.float32(4.1255555), 'reward_variance': np.float32(0.46308765), 'max_total_reward': np.float32(5.4111114), 'min_total_reward': np.float32(3.166667), 'average_n_step': np.float32(5.8), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(5.0), 'buffer_size': 36608} @ step loss: {'critic_loss': np.float64(0.22055220305919648), 'actor_loss': np.float64(-1.2287355542182923), 'hyper_actor_loss': np.float64(0.06940914541482926), 'behavior_loss': np.float64(1.2659910559654235)}
step: 1090 @ episode report: {'average_total_reward': np.float32(4.15), 'reward_variance': np.float32(0.646031), 'max_total_reward': np.float32(5.533334), 'min_total_reward': np.float32(2.288889), 'average_n_step': np.float32(5.8), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(4.0), 'buffer_size': 36928} @ step loss: {'critic_loss': np.float64(0.21430328488349915), 'actor_loss': np.float64(-1.1602348208427429), 'hyper_actor_loss': np.float64(0.0704489916563034), 'behavior_loss': np.float64(1.1994625926017761)}
step: 1100 @ episode report: {'average_total_reward': np.float32(4.125556), 'reward_variance': np.float32(1.3972607), 'max_total_reward': np.float32(6.533334), 'min_total_reward': np.float32(2.1666667), 'average_n_step': np.float32(5.8), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(4.0), 'buffer_size': 37248} @ step loss: {'critic_loss': np.float64(0.2207990199327469), 'actor_loss': np.float64(-1.2329264163970948), 'hyper_actor_loss': np.float64(0.07188790440559387), 'behavior_loss': np.float64(1.1641940474510193)}
step: 1110 @ episode report: {'average_total_reward': np.float32(4.162223), 'reward_variance': np.float32(0.43230113), 'max_total_reward': np.float32(5.2888885), 'min_total_reward': np.float32(3.1666667), 'average_n_step': np.float32(5.8), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(5.0), 'buffer_size': 37568} @ step loss: {'critic_loss': np.float64(0.215465684235096), 'actor_loss': np.float64(-1.286117720603943), 'hyper_actor_loss': np.float64(0.07300463393330574), 'behavior_loss': np.float64(1.1307626247406006)}
step: 1120 @ episode report: {'average_total_reward': np.float32(4.0255556), 'reward_variance': np.float32(1.2870138), 'max_total_reward': np.float32(5.4111114), 'min_total_reward': np.float32(2.288889), 'average_n_step': np.float32(5.7), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(4.0), 'buffer_size': 37888} @ step loss: {'critic_loss': np.float64(0.19842618107795715), 'actor_loss': np.float64(-1.1952974438667296), 'hyper_actor_loss': np.float64(0.07410825267434121), 'behavior_loss': np.float64(1.1640831708908081)}
step: 1130 @ episode report: {'average_total_reward': np.float32(4.5133333), 'reward_variance': np.float32(0.67130387), 'max_total_reward': np.float32(6.411112), 'min_total_reward': np.float32(3.166667), 'average_n_step': np.float32(6.2), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(5.0), 'buffer_size': 38208} @ step loss: {'critic_loss': np.float64(0.20049514174461364), 'actor_loss': np.float64(-1.2362434267997742), 'hyper_actor_loss': np.float64(0.07627212703227997), 'behavior_loss': np.float64(1.1175929963588715)}
step: 1140 @ episode report: {'average_total_reward': np.float32(5.247778), 'reward_variance': np.float32(0.7897544), 'max_total_reward': np.float32(6.533334), 'min_total_reward': np.float32(3.4111114), 'average_n_step': np.float32(6.8), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(5.0), 'buffer_size': 38528} @ step loss: {'critic_loss': np.float64(0.2051194727420807), 'actor_loss': np.float64(-1.2170907735824585), 'hyper_actor_loss': np.float64(0.07747355923056602), 'behavior_loss': np.float64(1.0683771669864655)}
step: 1150 @ episode report: {'average_total_reward': np.float32(4.7477775), 'reward_variance': np.float32(2.268989), 'max_total_reward': np.float32(7.533334), 'min_total_reward': np.float32(2.288889), 'average_n_step': np.float32(6.3), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(4.0), 'buffer_size': 38848} @ step loss: {'critic_loss': np.float64(0.19066613167524338), 'actor_loss': np.float64(-1.2909749150276184), 'hyper_actor_loss': np.float64(0.07903332188725472), 'behavior_loss': np.float64(1.0616907596588134)}
step: 1160 @ episode report: {'average_total_reward': np.float32(5.286667), 'reward_variance': np.float32(1.3284147), 'max_total_reward': np.float32(6.6555557), 'min_total_reward': np.float32(3.166667), 'average_n_step': np.float32(6.9), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(5.0), 'buffer_size': 39168} @ step loss: {'critic_loss': np.float64(0.19143788516521454), 'actor_loss': np.float64(-1.3190520524978637), 'hyper_actor_loss': np.float64(0.07936451062560082), 'behavior_loss': np.float64(1.0228525221347808)}
step: 1170 @ episode report: {'average_total_reward': np.float32(4.896667), 'reward_variance': np.float32(1.3762232), 'max_total_reward': np.float32(7.5333333), 'min_total_reward': np.float32(3.2888892), 'average_n_step': np.float32(6.4), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(5.0), 'buffer_size': 39488} @ step loss: {'critic_loss': np.float64(0.1839679554104805), 'actor_loss': np.float64(-1.2746289253234864), 'hyper_actor_loss': np.float64(0.08026051074266434), 'behavior_loss': np.float64(0.962588369846344)}
step: 1180 @ episode report: {'average_total_reward': np.float32(4.835555), 'reward_variance': np.float32(0.48964962), 'max_total_reward': np.float32(6.411112), 'min_total_reward': np.float32(4.1666665), 'average_n_step': np.float32(6.4), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(6.0), 'buffer_size': 39808} @ step loss: {'critic_loss': np.float64(0.19803139120340346), 'actor_loss': np.float64(-1.2697283267974853), 'hyper_actor_loss': np.float64(0.08073205575346946), 'behavior_loss': np.float64(0.940025269985199)}
step: 1190 @ episode report: {'average_total_reward': np.float32(5.0233335), 'reward_variance': np.float32(1.0795424), 'max_total_reward': np.float32(6.655556), 'min_total_reward': np.float32(3.4111116), 'average_n_step': np.float32(6.6), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(5.0), 'buffer_size': 40128} @ step loss: {'critic_loss': np.float64(0.1997222952544689), 'actor_loss': np.float64(-1.2765913605690002), 'hyper_actor_loss': np.float64(0.08146915510296822), 'behavior_loss': np.float64(0.9349593162536621)}
step: 1200 @ episode report: {'average_total_reward': np.float32(5.7844443), 'reward_variance': np.float32(2.010499), 'max_total_reward': np.float32(7.7777786), 'min_total_reward': np.float32(3.4111114), 'average_n_step': np.float32(7.3), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(5.0), 'buffer_size': 40448} @ step loss: {'critic_loss': np.float64(0.20368448793888091), 'actor_loss': np.float64(-1.2861229300498962), 'hyper_actor_loss': np.float64(0.08196259588003159), 'behavior_loss': np.float64(0.8717397809028625)}
step: 1210 @ episode report: {'average_total_reward': np.float32(4.274445), 'reward_variance': np.float32(0.73768026), 'max_total_reward': np.float32(5.4111114), 'min_total_reward': np.float32(2.2888892), 'average_n_step': np.float32(5.9), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(4.0), 'buffer_size': 40768} @ step loss: {'critic_loss': np.float64(0.20450511947274208), 'actor_loss': np.float64(-1.2815827131271362), 'hyper_actor_loss': np.float64(0.0817651979625225), 'behavior_loss': np.float64(0.8363547027111053)}
step: 1220 @ episode report: {'average_total_reward': np.float32(4.46), 'reward_variance': np.float32(0.48588157), 'max_total_reward': np.float32(5.655556), 'min_total_reward': np.float32(3.2888892), 'average_n_step': np.float32(6.0), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(5.0), 'buffer_size': 41088} @ step loss: {'critic_loss': np.float64(0.21191979199647903), 'actor_loss': np.float64(-1.1327611923217773), 'hyper_actor_loss': np.float64(0.08316175267100334), 'behavior_loss': np.float64(0.7583310663700104)}
step: 1230 @ episode report: {'average_total_reward': np.float32(4.074445), 'reward_variance': np.float32(0.97419864), 'max_total_reward': np.float32(5.6555557), 'min_total_reward': np.float32(2.1666667), 'average_n_step': np.float32(5.7), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(4.0), 'buffer_size': 41408} @ step loss: {'critic_loss': np.float64(0.19173220172524452), 'actor_loss': np.float64(-1.151466977596283), 'hyper_actor_loss': np.float64(0.08393743485212327), 'behavior_loss': np.float64(0.7391290068626404)}
step: 1240 @ episode report: {'average_total_reward': np.float32(4.3133335), 'reward_variance': np.float32(0.95747674), 'max_total_reward': np.float32(6.533334), 'min_total_reward': np.float32(3.166667), 'average_n_step': np.float32(6.0), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(5.0), 'buffer_size': 41728} @ step loss: {'critic_loss': np.float64(0.17458880841732025), 'actor_loss': np.float64(-1.1027681589126588), 'hyper_actor_loss': np.float64(0.08324806019663811), 'behavior_loss': np.float64(0.7845952332019805)}
step: 1250 @ episode report: {'average_total_reward': np.float32(4.8622227), 'reward_variance': np.float32(0.63610363), 'max_total_reward': np.float32(6.6555557), 'min_total_reward': np.float32(4.0444446), 'average_n_step': np.float32(6.5), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(6.0), 'buffer_size': 42048} @ step loss: {'critic_loss': np.float64(0.1801509365439415), 'actor_loss': np.float64(-1.1411921501159668), 'hyper_actor_loss': np.float64(0.0821010410785675), 'behavior_loss': np.float64(0.7879822790622711)}
step: 1260 @ episode report: {'average_total_reward': np.float32(4.9355555), 'reward_variance': np.float32(1.7421926), 'max_total_reward': np.float32(7.6555557), 'min_total_reward': np.float32(2.288889), 'average_n_step': np.float32(6.5), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(4.0), 'buffer_size': 42368} @ step loss: {'critic_loss': np.float64(0.19722171127796173), 'actor_loss': np.float64(-1.1981088876724244), 'hyper_actor_loss': np.float64(0.08113137409090995), 'behavior_loss': np.float64(0.8029058814048767)}
step: 1270 @ episode report: {'average_total_reward': np.float32(4.6988883), 'reward_variance': np.float32(1.8381348), 'max_total_reward': np.float32(7.533334), 'min_total_reward': np.float32(2.0444446), 'average_n_step': np.float32(6.3), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(4.0), 'buffer_size': 42688} @ step loss: {'critic_loss': np.float64(0.19311962574720382), 'actor_loss': np.float64(-1.1495683431625365), 'hyper_actor_loss': np.float64(0.08186430335044861), 'behavior_loss': np.float64(0.8325634241104126)}
step: 1280 @ episode report: {'average_total_reward': np.float32(4.7377777), 'reward_variance': np.float32(0.8837827), 'max_total_reward': np.float32(6.4111114), 'min_total_reward': np.float32(3.166667), 'average_n_step': np.float32(6.4), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(5.0), 'buffer_size': 43008} @ step loss: {'critic_loss': np.float64(0.17095421478152276), 'actor_loss': np.float64(-1.1609143972396851), 'hyper_actor_loss': np.float64(0.08081680834293366), 'behavior_loss': np.float64(0.7846004724502563)}
step: 1290 @ episode report: {'average_total_reward': np.float32(4.55), 'reward_variance': np.float32(1.5587472), 'max_total_reward': np.float32(7.411112), 'min_total_reward': np.float32(3.288889), 'average_n_step': np.float32(6.2), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(5.0), 'buffer_size': 43328} @ step loss: {'critic_loss': np.float64(0.18700848072767257), 'actor_loss': np.float64(-1.1417814493179321), 'hyper_actor_loss': np.float64(0.07992713302373886), 'behavior_loss': np.float64(0.7954204857349396)}
step: 1300 @ episode report: {'average_total_reward': np.float32(4.886667), 'reward_variance': np.float32(0.70372343), 'max_total_reward': np.float32(6.4111114), 'min_total_reward': np.float32(3.4111114), 'average_n_step': np.float32(6.5), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(5.0), 'buffer_size': 43648} @ step loss: {'critic_loss': np.float64(0.15839389264583587), 'actor_loss': np.float64(-1.1569371581077577), 'hyper_actor_loss': np.float64(0.07787660881876945), 'behavior_loss': np.float64(0.8415459096431732)}
step: 1310 @ episode report: {'average_total_reward': np.float32(4.6355557), 'reward_variance': np.float32(0.64387167), 'max_total_reward': np.float32(5.6555552), 'min_total_reward': np.float32(3.288889), 'average_n_step': np.float32(6.2), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(5.0), 'buffer_size': 43968} @ step loss: {'critic_loss': np.float64(0.16428592652082444), 'actor_loss': np.float64(-1.138317835330963), 'hyper_actor_loss': np.float64(0.07800238654017448), 'behavior_loss': np.float64(0.8071264863014221)}
step: 1320 @ episode report: {'average_total_reward': np.float32(4.8744445), 'reward_variance': np.float32(1.1047418), 'max_total_reward': np.float32(6.6555557), 'min_total_reward': np.float32(3.288889), 'average_n_step': np.float32(6.5), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(5.0), 'buffer_size': 44288} @ step loss: {'critic_loss': np.float64(0.16660727486014365), 'actor_loss': np.float64(-1.1790091156959535), 'hyper_actor_loss': np.float64(0.07719874083995819), 'behavior_loss': np.float64(0.8302156686782837)}
step: 1330 @ episode report: {'average_total_reward': np.float32(4.8988886), 'reward_variance': np.float32(0.84509784), 'max_total_reward': np.float32(7.411112), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(6.5), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 44608} @ step loss: {'critic_loss': np.float64(0.18160430565476418), 'actor_loss': np.float64(-1.1257766008377075), 'hyper_actor_loss': np.float64(0.07629681453108787), 'behavior_loss': np.float64(0.8459791243076324)}
step: 1340 @ episode report: {'average_total_reward': np.float32(3.937778), 'reward_variance': np.float32(1.1265975), 'max_total_reward': np.float32(5.5333333), 'min_total_reward': np.float32(2.0444446), 'average_n_step': np.float32(5.6), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(4.0), 'buffer_size': 44928} @ step loss: {'critic_loss': np.float64(0.2033621147274971), 'actor_loss': np.float64(-1.1339894652366638), 'hyper_actor_loss': np.float64(0.07572239339351654), 'behavior_loss': np.float64(0.8606654107570648)}
step: 1350 @ episode report: {'average_total_reward': np.float32(4.35), 'reward_variance': np.float32(0.9438826), 'max_total_reward': np.float32(6.411111), 'min_total_reward': np.float32(3.0444443), 'average_n_step': np.float32(6.0), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(5.0), 'buffer_size': 45248} @ step loss: {'critic_loss': np.float64(0.1723473884165287), 'actor_loss': np.float64(-1.1237635374069215), 'hyper_actor_loss': np.float64(0.0758187159895897), 'behavior_loss': np.float64(0.8162995278835297)}
step: 1360 @ episode report: {'average_total_reward': np.float32(4.186667), 'reward_variance': np.float32(0.6349087), 'max_total_reward': np.float32(5.288889), 'min_total_reward': np.float32(2.288889), 'average_n_step': np.float32(5.8), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(4.0), 'buffer_size': 45568} @ step loss: {'critic_loss': np.float64(0.15145312920212745), 'actor_loss': np.float64(-1.0512728214263916), 'hyper_actor_loss': np.float64(0.07679885029792785), 'behavior_loss': np.float64(0.819199514389038)}
step: 1370 @ episode report: {'average_total_reward': np.float32(4.1788893), 'reward_variance': np.float32(0.5928259), 'max_total_reward': np.float32(5.4111114), 'min_total_reward': np.float32(2.677778), 'average_n_step': np.float32(6.0), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(5.0), 'buffer_size': 45888} @ step loss: {'critic_loss': np.float64(0.194199800491333), 'actor_loss': np.float64(-1.1978116512298584), 'hyper_actor_loss': np.float64(0.07791238129138947), 'behavior_loss': np.float64(0.7698199212551117)}
step: 1380 @ episode report: {'average_total_reward': np.float32(4.723333), 'reward_variance': np.float32(1.1900606), 'max_total_reward': np.float32(6.533334), 'min_total_reward': np.float32(3.288889), 'average_n_step': np.float32(6.3), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(5.0), 'buffer_size': 46208} @ step loss: {'critic_loss': np.float64(0.18739860951900483), 'actor_loss': np.float64(-1.1372562646865845), 'hyper_actor_loss': np.float64(0.07734387740492821), 'behavior_loss': np.float64(0.778845876455307)}
step: 1390 @ episode report: {'average_total_reward': np.float32(3.788889), 'reward_variance': np.float32(0.7227901), 'max_total_reward': np.float32(5.288889), 'min_total_reward': np.float32(2.288889), 'average_n_step': np.float32(5.5), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(4.0), 'buffer_size': 46528} @ step loss: {'critic_loss': np.float64(0.20104188174009324), 'actor_loss': np.float64(-1.1043847799301147), 'hyper_actor_loss': np.float64(0.07682694494724274), 'behavior_loss': np.float64(0.7679519057273865)}
step: 1400 @ episode report: {'average_total_reward': np.float32(3.7400002), 'reward_variance': np.float32(0.32936296), 'max_total_reward': np.float32(4.4111114), 'min_total_reward': np.float32(2.9222221), 'average_n_step': np.float32(5.5), 'max_n_step': np.float32(6.0), 'min_n_step': np.float32(5.0), 'buffer_size': 46848} @ step loss: {'critic_loss': np.float64(0.18247987926006318), 'actor_loss': np.float64(-1.0665838241577148), 'hyper_actor_loss': np.float64(0.07598180025815963), 'behavior_loss': np.float64(0.7896438896656036)}
step: 1410 @ episode report: {'average_total_reward': np.float32(3.8888886), 'reward_variance': np.float32(0.3187655), 'max_total_reward': np.float32(4.533334), 'min_total_reward': np.float32(2.9222224), 'average_n_step': np.float32(5.6), 'max_n_step': np.float32(6.0), 'min_n_step': np.float32(5.0), 'buffer_size': 47168} @ step loss: {'critic_loss': np.float64(0.1777049943804741), 'actor_loss': np.float64(-0.9921643555164337), 'hyper_actor_loss': np.float64(0.07555868104100227), 'behavior_loss': np.float64(0.7964547753334046)}
step: 1420 @ episode report: {'average_total_reward': np.float32(3.9644446), 'reward_variance': np.float32(0.52836525), 'max_total_reward': np.float32(5.5333333), 'min_total_reward': np.float32(2.9222226), 'average_n_step': np.float32(5.7), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(5.0), 'buffer_size': 47488} @ step loss: {'critic_loss': np.float64(0.16377561539411545), 'actor_loss': np.float64(-0.9770248174667359), 'hyper_actor_loss': np.float64(0.0748997338116169), 'behavior_loss': np.float64(0.8096924483776092)}
step: 1430 @ episode report: {'average_total_reward': np.float32(4.113333), 'reward_variance': np.float32(0.435995), 'max_total_reward': np.float32(5.411111), 'min_total_reward': np.float32(3.0444446), 'average_n_step': np.float32(5.8), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(5.0), 'buffer_size': 47808} @ step loss: {'critic_loss': np.float64(0.1498930387198925), 'actor_loss': np.float64(-0.9986032664775848), 'hyper_actor_loss': np.float64(0.07404507547616959), 'behavior_loss': np.float64(0.7812219500541687)}
step: 1440 @ episode report: {'average_total_reward': np.float32(4.076667), 'reward_variance': np.float32(0.6900853), 'max_total_reward': np.float32(5.655556), 'min_total_reward': np.float32(3.1666667), 'average_n_step': np.float32(5.8), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(5.0), 'buffer_size': 48128} @ step loss: {'critic_loss': np.float64(0.17001927644014359), 'actor_loss': np.float64(-1.0355841398239136), 'hyper_actor_loss': np.float64(0.07375500574707985), 'behavior_loss': np.float64(0.7554966449737549)}
step: 1450 @ episode report: {'average_total_reward': np.float32(3.5133336), 'reward_variance': np.float32(1.4728346), 'max_total_reward': np.float32(5.6555557), 'min_total_reward': np.float32(2.1666667), 'average_n_step': np.float32(5.2), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(4.0), 'buffer_size': 48448} @ step loss: {'critic_loss': np.float64(0.16301662102341652), 'actor_loss': np.float64(-1.1006060600280763), 'hyper_actor_loss': np.float64(0.07360115274786949), 'behavior_loss': np.float64(0.7778743267059326)}
step: 1460 @ episode report: {'average_total_reward': np.float32(3.3277779), 'reward_variance': np.float32(1.3528458), 'max_total_reward': np.float32(4.533334), 'min_total_reward': np.float32(1.0444444), 'average_n_step': np.float32(5.1), 'max_n_step': np.float32(6.0), 'min_n_step': np.float32(3.0), 'buffer_size': 48768} @ step loss: {'critic_loss': np.float64(0.158207868039608), 'actor_loss': np.float64(-1.062838888168335), 'hyper_actor_loss': np.float64(0.0735851526260376), 'behavior_loss': np.float64(0.7301403939723968)}
step: 1470 @ episode report: {'average_total_reward': np.float32(3.3400002), 'reward_variance': np.float32(0.37316552), 'max_total_reward': np.float32(4.533334), 'min_total_reward': np.float32(2.288889), 'average_n_step': np.float32(5.1), 'max_n_step': np.float32(6.0), 'min_n_step': np.float32(4.0), 'buffer_size': 49088} @ step loss: {'critic_loss': np.float64(0.14564668238162995), 'actor_loss': np.float64(-1.0767432928085328), 'hyper_actor_loss': np.float64(0.0739600658416748), 'behavior_loss': np.float64(0.7181000530719757)}
step: 1480 @ episode report: {'average_total_reward': np.float32(3.5011108), 'reward_variance': np.float32(0.38986307), 'max_total_reward': np.float32(4.4111114), 'min_total_reward': np.float32(2.288889), 'average_n_step': np.float32(5.2), 'max_n_step': np.float32(6.0), 'min_n_step': np.float32(4.0), 'buffer_size': 49408} @ step loss: {'critic_loss': np.float64(0.14363605603575708), 'actor_loss': np.float64(-1.0281074285507201), 'hyper_actor_loss': np.float64(0.07424496114253998), 'behavior_loss': np.float64(0.7032316982746124)}
step: 1490 @ episode report: {'average_total_reward': np.float32(3.0544448), 'reward_variance': np.float32(0.26689997), 'max_total_reward': np.float32(3.9222224), 'min_total_reward': np.float32(2.1666667), 'average_n_step': np.float32(4.9), 'max_n_step': np.float32(6.0), 'min_n_step': np.float32(4.0), 'buffer_size': 49728} @ step loss: {'critic_loss': np.float64(0.15046589374542235), 'actor_loss': np.float64(-1.0586535930633545), 'hyper_actor_loss': np.float64(0.07378239184617996), 'behavior_loss': np.float64(0.7048013150691986)}
step: 1500 @ episode report: {'average_total_reward': np.float32(3.0277781), 'reward_variance': np.float32(0.520821), 'max_total_reward': np.float32(4.288889), 'min_total_reward': np.float32(2.166667), 'average_n_step': np.float32(4.8), 'max_n_step': np.float32(6.0), 'min_n_step': np.float32(4.0), 'buffer_size': 50048} @ step loss: {'critic_loss': np.float64(0.1429615281522274), 'actor_loss': np.float64(-1.0168226480484008), 'hyper_actor_loss': np.float64(0.07284364774823189), 'behavior_loss': np.float64(0.7122219920158386)}
step: 1510 @ episode report: {'average_total_reward': np.float32(3.6644447), 'reward_variance': np.float32(1.2090567), 'max_total_reward': np.float32(5.5333333), 'min_total_reward': np.float32(1.8000001), 'average_n_step': np.float32(5.4), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(4.0), 'buffer_size': 50368} @ step loss: {'critic_loss': np.float64(0.1429864451289177), 'actor_loss': np.float64(-1.0124155461788178), 'hyper_actor_loss': np.float64(0.07185514196753502), 'behavior_loss': np.float64(0.7158338069915772)}
step: 1520 @ episode report: {'average_total_reward': np.float32(3.1155555), 'reward_variance': np.float32(1.0310173), 'max_total_reward': np.float32(4.5333333), 'min_total_reward': np.float32(1.1666666), 'average_n_step': np.float32(4.9), 'max_n_step': np.float32(6.0), 'min_n_step': np.float32(3.0), 'buffer_size': 50688} @ step loss: {'critic_loss': np.float64(0.13445981368422508), 'actor_loss': np.float64(-1.0429152488708495), 'hyper_actor_loss': np.float64(0.07098375707864761), 'behavior_loss': np.float64(0.733691519498825)}
step: 1530 @ episode report: {'average_total_reward': np.float32(3.1277778), 'reward_variance': np.float32(0.63361126), 'max_total_reward': np.float32(4.533334), 'min_total_reward': np.float32(1.9222223), 'average_n_step': np.float32(4.9), 'max_n_step': np.float32(6.0), 'min_n_step': np.float32(4.0), 'buffer_size': 51008} @ step loss: {'critic_loss': np.float64(0.13169334903359414), 'actor_loss': np.float64(-1.0325069546699523), 'hyper_actor_loss': np.float64(0.07034217938780785), 'behavior_loss': np.float64(0.7527162671089173)}
step: 1540 @ episode report: {'average_total_reward': np.float32(3.637778), 'reward_variance': np.float32(0.5214125), 'max_total_reward': np.float32(4.533334), 'min_total_reward': np.float32(2.1666667), 'average_n_step': np.float32(5.3), 'max_n_step': np.float32(6.0), 'min_n_step': np.float32(4.0), 'buffer_size': 51328} @ step loss: {'critic_loss': np.float64(0.14403281807899476), 'actor_loss': np.float64(-1.0764463305473329), 'hyper_actor_loss': np.float64(0.0696004718542099), 'behavior_loss': np.float64(0.7311861157417298)}
step: 1550 @ episode report: {'average_total_reward': np.float32(3.288889), 'reward_variance': np.float32(0.52167916), 'max_total_reward': np.float32(4.533334), 'min_total_reward': np.float32(2.0444446), 'average_n_step': np.float32(5.0), 'max_n_step': np.float32(6.0), 'min_n_step': np.float32(4.0), 'buffer_size': 51648} @ step loss: {'critic_loss': np.float64(0.1382335126399994), 'actor_loss': np.float64(-1.0794941306114196), 'hyper_actor_loss': np.float64(0.06855606511235238), 'behavior_loss': np.float64(0.7750239908695221)}
step: 1560 @ episode report: {'average_total_reward': np.float32(3.3644447), 'reward_variance': np.float32(1.2354271), 'max_total_reward': np.float32(5.5333333), 'min_total_reward': np.float32(1.8000001), 'average_n_step': np.float32(5.1), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(4.0), 'buffer_size': 51968} @ step loss: {'critic_loss': np.float64(0.1278611607849598), 'actor_loss': np.float64(-1.0072100341320038), 'hyper_actor_loss': np.float64(0.06771918907761573), 'behavior_loss': np.float64(0.8199450075626373)}
step: 1570 @ episode report: {'average_total_reward': np.float32(3.5155556), 'reward_variance': np.float32(0.38370872), 'max_total_reward': np.float32(4.4111114), 'min_total_reward': np.float32(2.288889), 'average_n_step': np.float32(5.3), 'max_n_step': np.float32(6.0), 'min_n_step': np.float32(4.0), 'buffer_size': 52288} @ step loss: {'critic_loss': np.float64(0.12495428919792176), 'actor_loss': np.float64(-1.030988347530365), 'hyper_actor_loss': np.float64(0.06701075285673141), 'behavior_loss': np.float64(0.8296540021896363)}
step: 1580 @ episode report: {'average_total_reward': np.float32(3.1277778), 'reward_variance': np.float32(0.31790745), 'max_total_reward': np.float32(4.166667), 'min_total_reward': np.float32(2.0444446), 'average_n_step': np.float32(4.9), 'max_n_step': np.float32(6.0), 'min_n_step': np.float32(4.0), 'buffer_size': 52608} @ step loss: {'critic_loss': np.float64(0.1338854745030403), 'actor_loss': np.float64(-0.9927438497543335), 'hyper_actor_loss': np.float64(0.06665771156549453), 'behavior_loss': np.float64(0.8094274461269378)}
step: 1590 @ episode report: {'average_total_reward': np.float32(3.191111), 'reward_variance': np.float32(0.2417728), 'max_total_reward': np.float32(4.1666665), 'min_total_reward': np.float32(2.0444446), 'average_n_step': np.float32(5.0), 'max_n_step': np.float32(6.0), 'min_n_step': np.float32(4.0), 'buffer_size': 52928} @ step loss: {'critic_loss': np.float64(0.1571672037243843), 'actor_loss': np.float64(-1.0413887619972229), 'hyper_actor_loss': np.float64(0.06615992933511734), 'behavior_loss': np.float64(0.8442388236522674)}
step: 1600 @ episode report: {'average_total_reward': np.float32(3.0644445), 'reward_variance': np.float32(0.18248895), 'max_total_reward': np.float32(3.4111114), 'min_total_reward': np.float32(2.288889), 'average_n_step': np.float32(4.8), 'max_n_step': np.float32(5.0), 'min_n_step': np.float32(4.0), 'buffer_size': 53248} @ step loss: {'critic_loss': np.float64(0.13033307567238808), 'actor_loss': np.float64(-0.931851613521576), 'hyper_actor_loss': np.float64(0.06610325425863266), 'behavior_loss': np.float64(0.871362429857254)}
step: 1610 @ episode report: {'average_total_reward': np.float32(3.3522224), 'reward_variance': np.float32(0.61019886), 'max_total_reward': np.float32(5.4111114), 'min_total_reward': np.float32(2.0444446), 'average_n_step': np.float32(5.1), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(4.0), 'buffer_size': 53568} @ step loss: {'critic_loss': np.float64(0.1419228047132492), 'actor_loss': np.float64(-0.9407122373580933), 'hyper_actor_loss': np.float64(0.06580718159675598), 'behavior_loss': np.float64(0.887171596288681)}
step: 1620 @ episode report: {'average_total_reward': np.float32(3.2522225), 'reward_variance': np.float32(1.1313349), 'max_total_reward': np.float32(5.4111114), 'min_total_reward': np.float32(2.0444443), 'average_n_step': np.float32(5.0), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(4.0), 'buffer_size': 53888} @ step loss: {'critic_loss': np.float64(0.14928072690963745), 'actor_loss': np.float64(-0.920966112613678), 'hyper_actor_loss': np.float64(0.06554752886295319), 'behavior_loss': np.float64(0.8768945634365082)}
step: 1630 @ episode report: {'average_total_reward': np.float32(3.4155555), 'reward_variance': np.float32(0.69015324), 'max_total_reward': np.float32(4.533334), 'min_total_reward': np.float32(2.1666667), 'average_n_step': np.float32(5.2), 'max_n_step': np.float32(6.0), 'min_n_step': np.float32(4.0), 'buffer_size': 54208} @ step loss: {'critic_loss': np.float64(0.14788179248571395), 'actor_loss': np.float64(-1.0048039197921752), 'hyper_actor_loss': np.float64(0.0652521938085556), 'behavior_loss': np.float64(0.8436655223369598)}
step: 1640 @ episode report: {'average_total_reward': np.float32(3.417778), 'reward_variance': np.float32(1.1401532), 'max_total_reward': np.float32(5.288889), 'min_total_reward': np.float32(2.0444446), 'average_n_step': np.float32(5.3), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(4.0), 'buffer_size': 54528} @ step loss: {'critic_loss': np.float64(0.13100543096661568), 'actor_loss': np.float64(-0.9168185293674469), 'hyper_actor_loss': np.float64(0.0646838515996933), 'behavior_loss': np.float64(0.8767375409603119)}
step: 1650 @ episode report: {'average_total_reward': np.float32(3.2888894), 'reward_variance': np.float32(0.19049387), 'max_total_reward': np.float32(4.166667), 'min_total_reward': np.float32(2.288889), 'average_n_step': np.float32(5.0), 'max_n_step': np.float32(6.0), 'min_n_step': np.float32(4.0), 'buffer_size': 54848} @ step loss: {'critic_loss': np.float64(0.12798314541578293), 'actor_loss': np.float64(-0.9308613896369934), 'hyper_actor_loss': np.float64(0.06368694454431534), 'behavior_loss': np.float64(0.9120724081993103)}
step: 1660 @ episode report: {'average_total_reward': np.float32(3.3033333), 'reward_variance': np.float32(1.2144456), 'max_total_reward': np.float32(5.411111), 'min_total_reward': np.float32(1.8), 'average_n_step': np.float32(5.1), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(4.0), 'buffer_size': 55168} @ step loss: {'critic_loss': np.float64(0.1225882314145565), 'actor_loss': np.float64(-0.95435711145401), 'hyper_actor_loss': np.float64(0.06309513002634048), 'behavior_loss': np.float64(0.9238826036453247)}
step: 1670 @ episode report: {'average_total_reward': np.float32(3.44), 'reward_variance': np.float32(0.7746223), 'max_total_reward': np.float32(4.5333333), 'min_total_reward': np.float32(1.6777778), 'average_n_step': np.float32(5.2), 'max_n_step': np.float32(6.0), 'min_n_step': np.float32(4.0), 'buffer_size': 55488} @ step loss: {'critic_loss': np.float64(0.12481576427817345), 'actor_loss': np.float64(-0.9667093873023986), 'hyper_actor_loss': np.float64(0.06283417940139771), 'behavior_loss': np.float64(0.9236033916473388)}
step: 1680 @ episode report: {'average_total_reward': np.float32(3.266667), 'reward_variance': np.float32(0.5837038), 'max_total_reward': np.float32(4.166667), 'min_total_reward': np.float32(1.6777779), 'average_n_step': np.float32(5.1), 'max_n_step': np.float32(6.0), 'min_n_step': np.float32(4.0), 'buffer_size': 55808} @ step loss: {'critic_loss': np.float64(0.1261641077697277), 'actor_loss': np.float64(-1.035962426662445), 'hyper_actor_loss': np.float64(0.06262880116701126), 'behavior_loss': np.float64(0.9043260037899017)}
step: 1690 @ episode report: {'average_total_reward': np.float32(2.5277781), 'reward_variance': np.float32(0.20449999), 'max_total_reward': np.float32(3.2888887), 'min_total_reward': np.float32(2.0444443), 'average_n_step': np.float32(4.3), 'max_n_step': np.float32(5.0), 'min_n_step': np.float32(4.0), 'buffer_size': 56128} @ step loss: {'critic_loss': np.float64(0.13024672567844392), 'actor_loss': np.float64(-0.9640595614910126), 'hyper_actor_loss': np.float64(0.06237973496317863), 'behavior_loss': np.float64(0.9283713817596435)}
step: 1700 @ episode report: {'average_total_reward': np.float32(2.22), 'reward_variance': np.float32(0.2982914), 'max_total_reward': np.float32(3.0444448), 'min_total_reward': np.float32(1.1666667), 'average_n_step': np.float32(4.2), 'max_n_step': np.float32(5.0), 'min_n_step': np.float32(3.0), 'buffer_size': 56448} @ step loss: {'critic_loss': np.float64(0.1322885550558567), 'actor_loss': np.float64(-1.0413134217262268), 'hyper_actor_loss': np.float64(0.06196601837873459), 'behavior_loss': np.float64(0.9200897336006164)}
step: 1710 @ episode report: {'average_total_reward': np.float32(2.4322221), 'reward_variance': np.float32(0.3557889), 'max_total_reward': np.float32(3.8), 'min_total_reward': np.float32(1.8), 'average_n_step': np.float32(4.4), 'max_n_step': np.float32(6.0), 'min_n_step': np.float32(4.0), 'buffer_size': 56768} @ step loss: {'critic_loss': np.float64(0.1266123943030834), 'actor_loss': np.float64(-0.9726266682147979), 'hyper_actor_loss': np.float64(0.061768009513616565), 'behavior_loss': np.float64(0.9205081224441528)}
step: 1720 @ episode report: {'average_total_reward': np.float32(1.9588888), 'reward_variance': np.float32(0.25447038), 'max_total_reward': np.float32(3.1666667), 'min_total_reward': np.float32(1.0444446), 'average_n_step': np.float32(4.0), 'max_n_step': np.float32(5.0), 'min_n_step': np.float32(3.0), 'buffer_size': 57088} @ step loss: {'critic_loss': np.float64(0.11538924425840377), 'actor_loss': np.float64(-1.0404803156852722), 'hyper_actor_loss': np.float64(0.0621916513890028), 'behavior_loss': np.float64(1.0198444306850434)}
step: 1730 @ episode report: {'average_total_reward': np.float32(1.72), 'reward_variance': np.float32(0.51940256), 'max_total_reward': np.float32(3.166667), 'min_total_reward': np.float32(0.79999995), 'average_n_step': np.float32(3.7), 'max_n_step': np.float32(5.0), 'min_n_step': np.float32(3.0), 'buffer_size': 57408} @ step loss: {'critic_loss': np.float64(0.11968760788440705), 'actor_loss': np.float64(-1.1183519601821899), 'hyper_actor_loss': np.float64(0.06205957680940628), 'behavior_loss': np.float64(0.982478803396225)}
step: 1740 @ episode report: {'average_total_reward': np.float32(1.0955555), 'reward_variance': np.float32(0.066424705), 'max_total_reward': np.float32(1.8000001), 'min_total_reward': np.float32(0.8), 'average_n_step': np.float32(3.1), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 57728} @ step loss: {'critic_loss': np.float64(0.12477253898978233), 'actor_loss': np.float64(-1.1208660304546356), 'hyper_actor_loss': np.float64(0.06183453015983105), 'behavior_loss': np.float64(1.0547059535980225)}
step: 1750 @ episode report: {'average_total_reward': np.float32(1.5488889), 'reward_variance': np.float32(0.2692642), 'max_total_reward': np.float32(2.1666667), 'min_total_reward': np.float32(0.6777778), 'average_n_step': np.float32(3.7), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 58048} @ step loss: {'critic_loss': np.float64(0.1301190122961998), 'actor_loss': np.float64(-0.9159998297691345), 'hyper_actor_loss': np.float64(0.061774886399507525), 'behavior_loss': np.float64(1.0907983481884003)}
step: 1760 @ episode report: {'average_total_reward': np.float32(2.02), 'reward_variance': np.float32(0.12552597), 'max_total_reward': np.float32(2.677778), 'min_total_reward': np.float32(1.1666667), 'average_n_step': np.float32(4.0), 'max_n_step': np.float32(5.0), 'min_n_step': np.float32(3.0), 'buffer_size': 58368} @ step loss: {'critic_loss': np.float64(0.1272615075111389), 'actor_loss': np.float64(-0.9208194673061371), 'hyper_actor_loss': np.float64(0.06115924678742886), 'behavior_loss': np.float64(1.0556856155395509)}
step: 1770 @ episode report: {'average_total_reward': np.float32(1.8733333), 'reward_variance': np.float32(0.036449395), 'max_total_reward': np.float32(2.288889), 'min_total_reward': np.float32(1.5555556), 'average_n_step': np.float32(4.0), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(4.0), 'buffer_size': 58688} @ step loss: {'critic_loss': np.float64(0.12143982946872711), 'actor_loss': np.float64(-0.928116774559021), 'hyper_actor_loss': np.float64(0.060728348791599274), 'behavior_loss': np.float64(1.144535207748413)}
step: 1780 @ episode report: {'average_total_reward': np.float32(2.181111), 'reward_variance': np.float32(0.48526055), 'max_total_reward': np.float32(3.166667), 'min_total_reward': np.float32(1.1666667), 'average_n_step': np.float32(4.1), 'max_n_step': np.float32(5.0), 'min_n_step': np.float32(3.0), 'buffer_size': 59008} @ step loss: {'critic_loss': np.float64(0.12336539775133133), 'actor_loss': np.float64(-0.927590012550354), 'hyper_actor_loss': np.float64(0.06028868295252323), 'behavior_loss': np.float64(1.1170696020126343)}
step: 1790 @ episode report: {'average_total_reward': np.float32(1.8344444), 'reward_variance': np.float32(0.08672719), 'max_total_reward': np.float32(2.166667), 'min_total_reward': np.float32(1.1666667), 'average_n_step': np.float32(3.9), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 59328} @ step loss: {'critic_loss': np.float64(0.11044640839099884), 'actor_loss': np.float64(-0.8934359312057495), 'hyper_actor_loss': np.float64(0.05964840054512024), 'behavior_loss': np.float64(1.114350813627243)}
step: 1800 @ episode report: {'average_total_reward': np.float32(2.02), 'reward_variance': np.float32(0.32552594), 'max_total_reward': np.float32(3.0444446), 'min_total_reward': np.float32(1.1666666), 'average_n_step': np.float32(4.0), 'max_n_step': np.float32(5.0), 'min_n_step': np.float32(3.0), 'buffer_size': 59648} @ step loss: {'critic_loss': np.float64(0.13243651688098906), 'actor_loss': np.float64(-0.9423709273338318), 'hyper_actor_loss': np.float64(0.05873299725353718), 'behavior_loss': np.float64(1.2162353456020356)}
step: 1810 @ episode report: {'average_total_reward': np.float32(1.8222221), 'reward_variance': np.float32(0.3736543), 'max_total_reward': np.float32(3.0444446), 'min_total_reward': np.float32(0.8), 'average_n_step': np.float32(3.9), 'max_n_step': np.float32(5.0), 'min_n_step': np.float32(3.0), 'buffer_size': 59968} @ step loss: {'critic_loss': np.float64(0.10685045272111893), 'actor_loss': np.float64(-0.8959798097610474), 'hyper_actor_loss': np.float64(0.057635863125324246), 'behavior_loss': np.float64(1.1861202120780945)}
step: 1820 @ episode report: {'average_total_reward': np.float32(2.0444446), 'reward_variance': np.float32(0.035851866), 'max_total_reward': np.float32(2.2888892), 'min_total_reward': np.float32(1.8000001), 'average_n_step': np.float32(4.0), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(4.0), 'buffer_size': 60288} @ step loss: {'critic_loss': np.float64(0.12023888751864434), 'actor_loss': np.float64(-0.9075864315032959), 'hyper_actor_loss': np.float64(0.05701662115752697), 'behavior_loss': np.float64(1.318400502204895)}
step: 1830 @ episode report: {'average_total_reward': np.float32(1.82), 'reward_variance': np.float32(0.17950127), 'max_total_reward': np.float32(2.288889), 'min_total_reward': np.float32(0.9222223), 'average_n_step': np.float32(3.8), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 60608} @ step loss: {'critic_loss': np.float64(0.10444430932402611), 'actor_loss': np.float64(-0.8924096167087555), 'hyper_actor_loss': np.float64(0.05690288245677948), 'behavior_loss': np.float64(1.243919551372528)}
step: 1840 @ episode report: {'average_total_reward': np.float32(1.9200001), 'reward_variance': np.float32(0.37967414), 'max_total_reward': np.float32(3.0444446), 'min_total_reward': np.float32(1.0444444), 'average_n_step': np.float32(3.9), 'max_n_step': np.float32(5.0), 'min_n_step': np.float32(3.0), 'buffer_size': 60928} @ step loss: {'critic_loss': np.float64(0.11005515083670617), 'actor_loss': np.float64(-0.8944991409778595), 'hyper_actor_loss': np.float64(0.05692809410393238), 'behavior_loss': np.float64(1.3387646436691285)}
step: 1850 @ episode report: {'average_total_reward': np.float32(2.3833334), 'reward_variance': np.float32(0.40082103), 'max_total_reward': np.float32(3.0444446), 'min_total_reward': np.float32(1.0444446), 'average_n_step': np.float32(4.4), 'max_n_step': np.float32(5.0), 'min_n_step': np.float32(3.0), 'buffer_size': 61248} @ step loss: {'critic_loss': np.float64(0.11186228469014167), 'actor_loss': np.float64(-0.8884937584400177), 'hyper_actor_loss': np.float64(0.056905566900968554), 'behavior_loss': np.float64(1.354737138748169)}
step: 1860 @ episode report: {'average_total_reward': np.float32(1.9444447), 'reward_variance': np.float32(0.41612354), 'max_total_reward': np.float32(3.0444448), 'min_total_reward': np.float32(1.0444444), 'average_n_step': np.float32(3.9), 'max_n_step': np.float32(5.0), 'min_n_step': np.float32(3.0), 'buffer_size': 61568} @ step loss: {'critic_loss': np.float64(0.11416937336325646), 'actor_loss': np.float64(-0.9052496492862702), 'hyper_actor_loss': np.float64(0.056768960878252984), 'behavior_loss': np.float64(1.2743561744689942)}
step: 1870 @ episode report: {'average_total_reward': np.float32(2.1444447), 'reward_variance': np.float32(0.3014074), 'max_total_reward': np.float32(3.166667), 'min_total_reward': np.float32(1.1666667), 'average_n_step': np.float32(4.1), 'max_n_step': np.float32(5.0), 'min_n_step': np.float32(3.0), 'buffer_size': 61888} @ step loss: {'critic_loss': np.float64(0.11371674165129661), 'actor_loss': np.float64(-0.9234718322753906), 'hyper_actor_loss': np.float64(0.057558974251151085), 'behavior_loss': np.float64(1.242739701271057)}
step: 1880 @ episode report: {'average_total_reward': np.float32(2.6177778), 'reward_variance': np.float32(0.2989432), 'max_total_reward': np.float32(3.288889), 'min_total_reward': np.float32(1.9222224), 'average_n_step': np.float32(4.5), 'max_n_step': np.float32(5.0), 'min_n_step': np.float32(4.0), 'buffer_size': 62208} @ step loss: {'critic_loss': np.float64(0.12962031960487366), 'actor_loss': np.float64(-0.9300172388553619), 'hyper_actor_loss': np.float64(0.05835817828774452), 'behavior_loss': np.float64(1.2741232514381409)}
step: 1890 @ episode report: {'average_total_reward': np.float32(3.268889), 'reward_variance': np.float32(0.9864643), 'max_total_reward': np.float32(5.166667), 'min_total_reward': np.float32(1.9222224), 'average_n_step': np.float32(5.2), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(4.0), 'buffer_size': 62528} @ step loss: {'critic_loss': np.float64(0.11624840423464775), 'actor_loss': np.float64(-0.9407837986946106), 'hyper_actor_loss': np.float64(0.059309064596891406), 'behavior_loss': np.float64(1.219559872150421)}
step: 1900 @ episode report: {'average_total_reward': np.float32(4.2011113), 'reward_variance': np.float32(1.051863), 'max_total_reward': np.float32(6.6555557), 'min_total_reward': np.float32(3.1666667), 'average_n_step': np.float32(5.9), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(5.0), 'buffer_size': 62848} @ step loss: {'critic_loss': np.float64(0.10716530755162239), 'actor_loss': np.float64(-0.8980162501335144), 'hyper_actor_loss': np.float64(0.05968076512217522), 'behavior_loss': np.float64(1.160148823261261)}
step: 1910 @ episode report: {'average_total_reward': np.float32(3.7888894), 'reward_variance': np.float32(1.0509877), 'max_total_reward': np.float32(5.4111114), 'min_total_reward': np.float32(1.9222224), 'average_n_step': np.float32(5.5), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(4.0), 'buffer_size': 63168} @ step loss: {'critic_loss': np.float64(0.11425493136048318), 'actor_loss': np.float64(-0.9379426598548889), 'hyper_actor_loss': np.float64(0.05919554978609085), 'behavior_loss': np.float64(1.141563594341278)}
step: 1920 @ episode report: {'average_total_reward': np.float32(4.511111), 'reward_variance': np.float32(0.8745183), 'max_total_reward': np.float32(6.411111), 'min_total_reward': np.float32(3.288889), 'average_n_step': np.float32(6.1), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(5.0), 'buffer_size': 63488} @ step loss: {'critic_loss': np.float64(0.11448942646384239), 'actor_loss': np.float64(-0.8980252146720886), 'hyper_actor_loss': np.float64(0.05860581956803799), 'behavior_loss': np.float64(1.131355309486389)}
step: 1930 @ episode report: {'average_total_reward': np.float32(4.037778), 'reward_variance': np.float32(0.74161), 'max_total_reward': np.float32(5.4111114), 'min_total_reward': np.float32(2.288889), 'average_n_step': np.float32(5.7), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(4.0), 'buffer_size': 63808} @ step loss: {'critic_loss': np.float64(0.10905285403132439), 'actor_loss': np.float64(-0.9389427959918976), 'hyper_actor_loss': np.float64(0.05825975015759468), 'behavior_loss': np.float64(1.0618271470069884)}
step: 1940 @ episode report: {'average_total_reward': np.float32(4.498889), 'reward_variance': np.float32(1.340678), 'max_total_reward': np.float32(5.6555557), 'min_total_reward': np.float32(2.1666667), 'average_n_step': np.float32(6.1), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(4.0), 'buffer_size': 64128} @ step loss: {'critic_loss': np.float64(0.12008479684591293), 'actor_loss': np.float64(-0.9477187335491181), 'hyper_actor_loss': np.float64(0.057966163754463194), 'behavior_loss': np.float64(1.0836361706256867)}
step: 1950 @ episode report: {'average_total_reward': np.float32(4.5600004), 'reward_variance': np.float32(1.5431902), 'max_total_reward': np.float32(6.6555557), 'min_total_reward': np.float32(2.288889), 'average_n_step': np.float32(6.1), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(4.0), 'buffer_size': 64448} @ step loss: {'critic_loss': np.float64(0.10724797695875168), 'actor_loss': np.float64(-0.9269739866256714), 'hyper_actor_loss': np.float64(0.0581328172236681), 'behavior_loss': np.float64(0.9537643611431121)}
step: 1960 @ episode report: {'average_total_reward': np.float32(4.8477783), 'reward_variance': np.float32(1.8652111), 'max_total_reward': np.float32(7.7777777), 'min_total_reward': np.float32(3.166667), 'average_n_step': np.float32(6.4), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(5.0), 'buffer_size': 64768} @ step loss: {'critic_loss': np.float64(0.10600480511784553), 'actor_loss': np.float64(-0.9384749293327331), 'hyper_actor_loss': np.float64(0.057999420538544656), 'behavior_loss': np.float64(0.9629403591156006)}
step: 1970 @ episode report: {'average_total_reward': np.float32(4.9722223), 'reward_variance': np.float32(0.7238088), 'max_total_reward': np.float32(6.655556), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(6.5), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(6.0), 'buffer_size': 65088} @ step loss: {'critic_loss': np.float64(0.11722481474280358), 'actor_loss': np.float64(-0.9269642353057861), 'hyper_actor_loss': np.float64(0.058370545506477356), 'behavior_loss': np.float64(0.9805149793624878)}
step: 1980 @ episode report: {'average_total_reward': np.float32(5.223334), 'reward_variance': np.float32(0.9851468), 'max_total_reward': np.float32(7.655556), 'min_total_reward': np.float32(4.044445), 'average_n_step': np.float32(6.8), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 65408} @ step loss: {'critic_loss': np.float64(0.10902479737997055), 'actor_loss': np.float64(-0.969264668226242), 'hyper_actor_loss': np.float64(0.058670812845230104), 'behavior_loss': np.float64(0.9728838682174683)}
step: 1990 @ episode report: {'average_total_reward': np.float32(5.347778), 'reward_variance': np.float32(1.2859769), 'max_total_reward': np.float32(7.7777786), 'min_total_reward': np.float32(3.4111114), 'average_n_step': np.float32(6.9), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(5.0), 'buffer_size': 65728} @ step loss: {'critic_loss': np.float64(0.1273512452840805), 'actor_loss': np.float64(-0.9987354457378388), 'hyper_actor_loss': np.float64(0.059180884063243865), 'behavior_loss': np.float64(0.9668432354927063)}
step: 2000 @ episode report: {'average_total_reward': np.float32(5.123334), 'reward_variance': np.float32(1.2411222), 'max_total_reward': np.float32(6.6555557), 'min_total_reward': np.float32(3.288889), 'average_n_step': np.float32(6.7), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(5.0), 'buffer_size': 66048} @ step loss: {'critic_loss': np.float64(0.11760059520602226), 'actor_loss': np.float64(-1.00610870718956), 'hyper_actor_loss': np.float64(0.05994746685028076), 'behavior_loss': np.float64(0.9325786352157592)}
step: 2010 @ episode report: {'average_total_reward': np.float32(6.3700004), 'reward_variance': np.float32(3.4751124), 'max_total_reward': np.float32(8.777778), 'min_total_reward': np.float32(3.288889), 'average_n_step': np.float32(7.8), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(5.0), 'buffer_size': 66368} @ step loss: {'critic_loss': np.float64(0.12171093299984932), 'actor_loss': np.float64(-1.0001587390899658), 'hyper_actor_loss': np.float64(0.06085318960249424), 'behavior_loss': np.float64(0.949582040309906)}
step: 2020 @ episode report: {'average_total_reward': np.float32(5.2333336), 'reward_variance': np.float32(0.864864), 'max_total_reward': np.float32(6.6555557), 'min_total_reward': np.float32(3.4111114), 'average_n_step': np.float32(6.7), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(5.0), 'buffer_size': 66688} @ step loss: {'critic_loss': np.float64(0.12049582526087761), 'actor_loss': np.float64(-1.0222251176834107), 'hyper_actor_loss': np.float64(0.06141192838549614), 'behavior_loss': np.float64(0.8817253589630127)}
step: 2030 @ episode report: {'average_total_reward': np.float32(6.0577774), 'reward_variance': np.float32(2.3332295), 'max_total_reward': np.float32(8.777778), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.5), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 67008} @ step loss: {'critic_loss': np.float64(0.11828462630510331), 'actor_loss': np.float64(-1.0648486733436584), 'hyper_actor_loss': np.float64(0.06302323751151562), 'behavior_loss': np.float64(0.8848832368850708)}
step: 2040 @ episode report: {'average_total_reward': np.float32(6.2822227), 'reward_variance': np.float32(4.0380054), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(3.4111114), 'average_n_step': np.float32(7.7), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(5.0), 'buffer_size': 67328} @ step loss: {'critic_loss': np.float64(0.12917297706007957), 'actor_loss': np.float64(-1.066592514514923), 'hyper_actor_loss': np.float64(0.06398903653025627), 'behavior_loss': np.float64(0.8534786999225616)}
step: 2050 @ episode report: {'average_total_reward': np.float32(6.1944447), 'reward_variance': np.float32(1.8178327), 'max_total_reward': np.float32(7.6555557), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.6), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 67648} @ step loss: {'critic_loss': np.float64(0.1343573309481144), 'actor_loss': np.float64(-1.0408676147460938), 'hyper_actor_loss': np.float64(0.0643252708017826), 'behavior_loss': np.float64(0.8555146515369415)}
step: 2060 @ episode report: {'average_total_reward': np.float32(6.494445), 'reward_variance': np.float32(3.2202048), 'max_total_reward': np.float32(9.900002), 'min_total_reward': np.float32(3.2888892), 'average_n_step': np.float32(7.9), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(5.0), 'buffer_size': 67968} @ step loss: {'critic_loss': np.float64(0.13180167973041534), 'actor_loss': np.float64(-1.083421540260315), 'hyper_actor_loss': np.float64(0.0648369163274765), 'behavior_loss': np.float64(0.8414643347263336)}
step: 2070 @ episode report: {'average_total_reward': np.float32(6.1966667), 'reward_variance': np.float32(1.410594), 'max_total_reward': np.float32(7.777778), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(7.7), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 68288} @ step loss: {'critic_loss': np.float64(0.14145674481987952), 'actor_loss': np.float64(-1.0990034937858582), 'hyper_actor_loss': np.float64(0.06434719637036324), 'behavior_loss': np.float64(0.815870600938797)}
step: 2080 @ episode report: {'average_total_reward': np.float32(5.784445), 'reward_variance': np.float32(2.4070425), 'max_total_reward': np.float32(7.7777786), 'min_total_reward': np.float32(4.0444446), 'average_n_step': np.float32(7.3), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 68608} @ step loss: {'critic_loss': np.float64(0.12708347514271737), 'actor_loss': np.float64(-1.0292720437049865), 'hyper_actor_loss': np.float64(0.06342497393488884), 'behavior_loss': np.float64(0.8460204005241394)}
step: 2090 @ episode report: {'average_total_reward': np.float32(6.457778), 'reward_variance': np.float32(1.147156), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.288889), 'average_n_step': np.float32(7.9), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 68928} @ step loss: {'critic_loss': np.float64(0.15392922461032868), 'actor_loss': np.float64(-1.0403966903686523), 'hyper_actor_loss': np.float64(0.06291311159729958), 'behavior_loss': np.float64(0.8563884437084198)}
step: 2100 @ episode report: {'average_total_reward': np.float32(6.1333337), 'reward_variance': np.float32(1.5970862), 'max_total_reward': np.float32(7.6555557), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(7.6), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 69248} @ step loss: {'critic_loss': np.float64(0.13010629042983055), 'actor_loss': np.float64(-1.0095984637737274), 'hyper_actor_loss': np.float64(0.061840837076306346), 'behavior_loss': np.float64(0.8139242768287659)}
step: 2110 @ episode report: {'average_total_reward': np.float32(6.331111), 'reward_variance': np.float32(0.92293346), 'max_total_reward': np.float32(7.7777777), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(7.7), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 69568} @ step loss: {'critic_loss': np.float64(0.12446799725294114), 'actor_loss': np.float64(-0.9493712842464447), 'hyper_actor_loss': np.float64(0.061361901462078094), 'behavior_loss': np.float64(0.8036917686462403)}
step: 2120 @ episode report: {'average_total_reward': np.float32(6.1333337), 'reward_variance': np.float32(2.3083456), 'max_total_reward': np.float32(8.777778), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(7.6), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 69888} @ step loss: {'critic_loss': np.float64(0.14407659322023392), 'actor_loss': np.float64(-1.0132602512836457), 'hyper_actor_loss': np.float64(0.060644886642694476), 'behavior_loss': np.float64(0.8440067768096924)}
step: 2130 @ episode report: {'average_total_reward': np.float32(5.296667), 'reward_variance': np.float32(0.85521114), 'max_total_reward': np.float32(6.6555567), 'min_total_reward': np.float32(4.2888894), 'average_n_step': np.float32(6.8), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(6.0), 'buffer_size': 70208} @ step loss: {'critic_loss': np.float64(0.1416337512433529), 'actor_loss': np.float64(-1.0077206492424011), 'hyper_actor_loss': np.float64(0.060396114364266396), 'behavior_loss': np.float64(0.8116600632667541)}
step: 2140 @ episode report: {'average_total_reward': np.float32(6.0088897), 'reward_variance': np.float32(1.2444153), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(7.5), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 70528} @ step loss: {'critic_loss': np.float64(0.12582507058978082), 'actor_loss': np.float64(-0.9803492665290833), 'hyper_actor_loss': np.float64(0.060813446342945096), 'behavior_loss': np.float64(0.8311022520065308)}
step: 2150 @ episode report: {'average_total_reward': np.float32(5.1333337), 'reward_variance': np.float32(1.5053583), 'max_total_reward': np.float32(7.7777786), 'min_total_reward': np.float32(3.4111114), 'average_n_step': np.float32(6.6), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(5.0), 'buffer_size': 70848} @ step loss: {'critic_loss': np.float64(0.12525070011615752), 'actor_loss': np.float64(-1.0319798648357392), 'hyper_actor_loss': np.float64(0.06090528033673763), 'behavior_loss': np.float64(0.8287118315696717)}
step: 2160 @ episode report: {'average_total_reward': np.float32(4.137778), 'reward_variance': np.float32(0.66489387), 'max_total_reward': np.float32(5.6555557), 'min_total_reward': np.float32(3.0444448), 'average_n_step': np.float32(5.8), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(5.0), 'buffer_size': 71168} @ step loss: {'critic_loss': np.float64(0.1160230040550232), 'actor_loss': np.float64(-1.0148234128952027), 'hyper_actor_loss': np.float64(0.05980498716235161), 'behavior_loss': np.float64(0.8327938258647919)}
step: 2170 @ episode report: {'average_total_reward': np.float32(4.0622225), 'reward_variance': np.float32(0.91244954), 'max_total_reward': np.float32(5.4111114), 'min_total_reward': np.float32(2.288889), 'average_n_step': np.float32(5.7), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(4.0), 'buffer_size': 71488} @ step loss: {'critic_loss': np.float64(0.1176795057952404), 'actor_loss': np.float64(-0.9524244129657745), 'hyper_actor_loss': np.float64(0.058618148788809776), 'behavior_loss': np.float64(0.9316366195678711)}
step: 2180 @ episode report: {'average_total_reward': np.float32(4.3988886), 'reward_variance': np.float32(0.9355172), 'max_total_reward': np.float32(5.533334), 'min_total_reward': np.float32(3.166667), 'average_n_step': np.float32(6.0), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(5.0), 'buffer_size': 71808} @ step loss: {'critic_loss': np.float64(0.1363238587975502), 'actor_loss': np.float64(-1.0355576813220977), 'hyper_actor_loss': np.float64(0.05750029534101486), 'behavior_loss': np.float64(0.8747193574905395)}
step: 2190 @ episode report: {'average_total_reward': np.float32(4.1011114), 'reward_variance': np.float32(0.32630745), 'max_total_reward': np.float32(5.166667), 'min_total_reward': np.float32(3.2888892), 'average_n_step': np.float32(5.8), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(5.0), 'buffer_size': 72128} @ step loss: {'critic_loss': np.float64(0.1323771946132183), 'actor_loss': np.float64(-1.051649558544159), 'hyper_actor_loss': np.float64(0.0562645822763443), 'behavior_loss': np.float64(0.8647021770477294)}
step: 2200 @ episode report: {'average_total_reward': np.float32(4.0644445), 'reward_variance': np.float32(1.2144396), 'max_total_reward': np.float32(6.4111114), 'min_total_reward': np.float32(2.8000002), 'average_n_step': np.float32(5.8), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(5.0), 'buffer_size': 72448} @ step loss: {'critic_loss': np.float64(0.13066384196281433), 'actor_loss': np.float64(-0.9732765853404999), 'hyper_actor_loss': np.float64(0.05524692460894585), 'behavior_loss': np.float64(0.9218967258930206)}
step: 2210 @ episode report: {'average_total_reward': np.float32(3.4011111), 'reward_variance': np.float32(0.8016162), 'max_total_reward': np.float32(4.4111114), 'min_total_reward': np.float32(2.0444446), 'average_n_step': np.float32(5.1), 'max_n_step': np.float32(6.0), 'min_n_step': np.float32(4.0), 'buffer_size': 72768} @ step loss: {'critic_loss': np.float64(0.1341255523264408), 'actor_loss': np.float64(-0.993244856595993), 'hyper_actor_loss': np.float64(0.053814608976244925), 'behavior_loss': np.float64(0.9300445675849914)}
step: 2220 @ episode report: {'average_total_reward': np.float32(3.0400002), 'reward_variance': np.float32(0.5175854), 'max_total_reward': np.float32(4.533334), 'min_total_reward': np.float32(1.9222223), 'average_n_step': np.float32(4.8), 'max_n_step': np.float32(6.0), 'min_n_step': np.float32(4.0), 'buffer_size': 73088} @ step loss: {'critic_loss': np.float64(0.1322969302535057), 'actor_loss': np.float64(-0.9806553304195404), 'hyper_actor_loss': np.float64(0.052496602013707164), 'behavior_loss': np.float64(0.976815277338028)}
step: 2230 @ episode report: {'average_total_reward': np.float32(2.817778), 'reward_variance': np.float32(0.40760994), 'max_total_reward': np.float32(3.9222224), 'min_total_reward': np.float32(1.9222224), 'average_n_step': np.float32(4.7), 'max_n_step': np.float32(6.0), 'min_n_step': np.float32(4.0), 'buffer_size': 73408} @ step loss: {'critic_loss': np.float64(0.13093168139457703), 'actor_loss': np.float64(-0.916029816865921), 'hyper_actor_loss': np.float64(0.05132207423448563), 'behavior_loss': np.float64(1.0082427620887757)}
step: 2240 @ episode report: {'average_total_reward': np.float32(2.6688888), 'reward_variance': np.float32(0.24592102), 'max_total_reward': np.float32(3.2888892), 'min_total_reward': np.float32(1.8000001), 'average_n_step': np.float32(4.6), 'max_n_step': np.float32(5.0), 'min_n_step': np.float32(4.0), 'buffer_size': 73728} @ step loss: {'critic_loss': np.float64(0.12287167906761169), 'actor_loss': np.float64(-0.9493444383144378), 'hyper_actor_loss': np.float64(0.05045277215540409), 'behavior_loss': np.float64(1.0177005529403687)}
step: 2250 @ episode report: {'average_total_reward': np.float32(2.4955556), 'reward_variance': np.float32(0.24054818), 'max_total_reward': np.float32(3.288889), 'min_total_reward': np.float32(1.9222223), 'average_n_step': np.float32(4.5), 'max_n_step': np.float32(5.0), 'min_n_step': np.float32(4.0), 'buffer_size': 74048} @ step loss: {'critic_loss': np.float64(0.13847400844097138), 'actor_loss': np.float64(-0.9199648976325989), 'hyper_actor_loss': np.float64(0.049433665722608565), 'behavior_loss': np.float64(0.9860843062400818)}
step: 2260 @ episode report: {'average_total_reward': np.float32(2.1688893), 'reward_variance': np.float32(0.52987164), 'max_total_reward': np.float32(3.166667), 'min_total_reward': np.float32(0.92222226), 'average_n_step': np.float32(4.1), 'max_n_step': np.float32(5.0), 'min_n_step': np.float32(3.0), 'buffer_size': 74368} @ step loss: {'critic_loss': np.float64(0.11879692673683166), 'actor_loss': np.float64(-0.9347039878368377), 'hyper_actor_loss': np.float64(0.04868319034576416), 'behavior_loss': np.float64(1.0692884743213653)}
step: 2270 @ episode report: {'average_total_reward': np.float32(2.4933333), 'reward_variance': np.float32(0.2677581), 'max_total_reward': np.float32(3.4111116), 'min_total_reward': np.float32(1.8000002), 'average_n_step': np.float32(4.4), 'max_n_step': np.float32(5.0), 'min_n_step': np.float32(4.0), 'buffer_size': 74688} @ step loss: {'critic_loss': np.float64(0.11632300838828087), 'actor_loss': np.float64(-0.9092784225940704), 'hyper_actor_loss': np.float64(0.04783574342727661), 'behavior_loss': np.float64(1.0175266027450562)}
step: 2280 @ episode report: {'average_total_reward': np.float32(2.3544447), 'reward_variance': np.float32(0.4330482), 'max_total_reward': np.float32(3.4111114), 'min_total_reward': np.float32(1.1666667), 'average_n_step': np.float32(4.2), 'max_n_step': np.float32(5.0), 'min_n_step': np.float32(3.0), 'buffer_size': 75008} @ step loss: {'critic_loss': np.float64(0.13026246950030326), 'actor_loss': np.float64(-0.9493135511875153), 'hyper_actor_loss': np.float64(0.047048314660787585), 'behavior_loss': np.float64(1.0604610085487365)}
step: 2290 @ episode report: {'average_total_reward': np.float32(2.2322223), 'reward_variance': np.float32(0.19610992), 'max_total_reward': np.float32(3.1666667), 'min_total_reward': np.float32(1.8), 'average_n_step': np.float32(4.2), 'max_n_step': np.float32(5.0), 'min_n_step': np.float32(4.0), 'buffer_size': 75328} @ step loss: {'critic_loss': np.float64(0.1272871471941471), 'actor_loss': np.float64(-0.9176594018936157), 'hyper_actor_loss': np.float64(0.046165190264582635), 'behavior_loss': np.float64(1.079918909072876)}
step: 2300 @ episode report: {'average_total_reward': np.float32(3.0155559), 'reward_variance': np.float32(0.48037535), 'max_total_reward': np.float32(4.288889), 'min_total_reward': np.float32(1.9222223), 'average_n_step': np.float32(4.8), 'max_n_step': np.float32(6.0), 'min_n_step': np.float32(4.0), 'buffer_size': 75648} @ step loss: {'critic_loss': np.float64(0.12070812210440636), 'actor_loss': np.float64(-0.9310201823711395), 'hyper_actor_loss': np.float64(0.0447179552167654), 'behavior_loss': np.float64(1.060957008600235)}
step: 2310 @ episode report: {'average_total_reward': np.float32(3.5400002), 'reward_variance': np.float32(0.78551096), 'max_total_reward': np.float32(4.5333333), 'min_total_reward': np.float32(1.8000002), 'average_n_step': np.float32(5.3), 'max_n_step': np.float32(6.0), 'min_n_step': np.float32(4.0), 'buffer_size': 75968} @ step loss: {'critic_loss': np.float64(0.11301153376698495), 'actor_loss': np.float64(-0.9069272398948669), 'hyper_actor_loss': np.float64(0.042932097986340526), 'behavior_loss': np.float64(1.1080190420150757)}
step: 2320 @ episode report: {'average_total_reward': np.float32(3.225556), 'reward_variance': np.float32(0.60721105), 'max_total_reward': np.float32(4.5333333), 'min_total_reward': np.float32(2.1666665), 'average_n_step': np.float32(4.9), 'max_n_step': np.float32(6.0), 'min_n_step': np.float32(4.0), 'buffer_size': 76288} @ step loss: {'critic_loss': np.float64(0.11920368745923042), 'actor_loss': np.float64(-0.9052174925804138), 'hyper_actor_loss': np.float64(0.0413416426628828), 'behavior_loss': np.float64(1.1647603511810303)}
step: 2330 @ episode report: {'average_total_reward': np.float32(3.8400002), 'reward_variance': np.float32(0.5565728), 'max_total_reward': np.float32(5.4111114), 'min_total_reward': np.float32(2.9222221), 'average_n_step': np.float32(5.6), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(5.0), 'buffer_size': 76608} @ step loss: {'critic_loss': np.float64(0.12135111466050148), 'actor_loss': np.float64(-0.9053200721740723), 'hyper_actor_loss': np.float64(0.03995014950633049), 'behavior_loss': np.float64(1.2185524582862854)}
step: 2340 @ episode report: {'average_total_reward': np.float32(4.423333), 'reward_variance': np.float32(0.68364084), 'max_total_reward': np.float32(5.655556), 'min_total_reward': np.float32(3.2888892), 'average_n_step': np.float32(6.0), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(5.0), 'buffer_size': 76928} @ step loss: {'critic_loss': np.float64(0.11423730328679085), 'actor_loss': np.float64(-0.918761545419693), 'hyper_actor_loss': np.float64(0.03878768607974052), 'behavior_loss': np.float64(1.2055898189544678)}
step: 2350 @ episode report: {'average_total_reward': np.float32(4.2500005), 'reward_variance': np.float32(0.5149198), 'max_total_reward': np.float32(5.4111114), 'min_total_reward': np.float32(3.2888892), 'average_n_step': np.float32(5.9), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(5.0), 'buffer_size': 77248} @ step loss: {'critic_loss': np.float64(0.11265119686722755), 'actor_loss': np.float64(-0.9502141356468201), 'hyper_actor_loss': np.float64(0.03778894655406475), 'behavior_loss': np.float64(1.2463275909423828)}
step: 2360 @ episode report: {'average_total_reward': np.float32(4.5622225), 'reward_variance': np.float32(0.9901037), 'max_total_reward': np.float32(6.5333333), 'min_total_reward': np.float32(3.1666667), 'average_n_step': np.float32(6.2), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(5.0), 'buffer_size': 77568} @ step loss: {'critic_loss': np.float64(0.12235894724726677), 'actor_loss': np.float64(-0.9161453127861023), 'hyper_actor_loss': np.float64(0.03691379576921463), 'behavior_loss': np.float64(1.323500967025757)}
step: 2370 @ episode report: {'average_total_reward': np.float32(4.7599998), 'reward_variance': np.float32(0.5398816), 'max_total_reward': np.float32(6.655556), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(6.3), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(6.0), 'buffer_size': 77888} @ step loss: {'critic_loss': np.float64(0.112334256619215), 'actor_loss': np.float64(-0.928941136598587), 'hyper_actor_loss': np.float64(0.03610042184591293), 'behavior_loss': np.float64(1.3493748664855958)}
step: 2380 @ episode report: {'average_total_reward': np.float32(4.9111114), 'reward_variance': np.float32(0.2524445), 'max_total_reward': np.float32(5.533334), 'min_total_reward': np.float32(4.166667), 'average_n_step': np.float32(6.5), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(6.0), 'buffer_size': 78208} @ step loss: {'critic_loss': np.float64(0.1223772868514061), 'actor_loss': np.float64(-0.9603433907032013), 'hyper_actor_loss': np.float64(0.03552234284579754), 'behavior_loss': np.float64(1.2645027875900268)}
step: 2390 @ episode report: {'average_total_reward': np.float32(4.535556), 'reward_variance': np.float32(0.2690321), 'max_total_reward': np.float32(5.4111114), 'min_total_reward': np.float32(3.4111114), 'average_n_step': np.float32(6.1), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(5.0), 'buffer_size': 78528} @ step loss: {'critic_loss': np.float64(0.11124405264854431), 'actor_loss': np.float64(-0.9299152374267579), 'hyper_actor_loss': np.float64(0.03476792573928833), 'behavior_loss': np.float64(1.3034056544303894)}
step: 2400 @ episode report: {'average_total_reward': np.float32(5.533334), 'reward_variance': np.float32(2.3386924), 'max_total_reward': np.float32(8.77778), 'min_total_reward': np.float32(3.4111114), 'average_n_step': np.float32(7.0), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(5.0), 'buffer_size': 78848} @ step loss: {'critic_loss': np.float64(0.11056759431958199), 'actor_loss': np.float64(-0.9085335969924927), 'hyper_actor_loss': np.float64(0.034237489476799964), 'behavior_loss': np.float64(1.366631543636322)}
step: 2410 @ episode report: {'average_total_reward': np.float32(4.5622225), 'reward_variance': np.float32(0.54321486), 'max_total_reward': np.float32(6.2888894), 'min_total_reward': np.float32(3.2888892), 'average_n_step': np.float32(6.2), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(5.0), 'buffer_size': 79168} @ step loss: {'critic_loss': np.float64(0.11673926562070847), 'actor_loss': np.float64(-0.9236276328563691), 'hyper_actor_loss': np.float64(0.033793560788035394), 'behavior_loss': np.float64(1.4357552647590637)}
step: 2420 @ episode report: {'average_total_reward': np.float32(4.7233334), 'reward_variance': np.float32(0.18554191), 'max_total_reward': np.float32(5.4111114), 'min_total_reward': np.float32(4.2888894), 'average_n_step': np.float32(6.3), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(6.0), 'buffer_size': 79488} @ step loss: {'critic_loss': np.float64(0.11830135732889176), 'actor_loss': np.float64(-0.9314057767391205), 'hyper_actor_loss': np.float64(0.03343815691769123), 'behavior_loss': np.float64(1.3364117980003356)}
step: 2430 @ episode report: {'average_total_reward': np.float32(4.9111114), 'reward_variance': np.float32(0.5532099), 'max_total_reward': np.float32(5.6555557), 'min_total_reward': np.float32(3.4111114), 'average_n_step': np.float32(6.5), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(5.0), 'buffer_size': 79808} @ step loss: {'critic_loss': np.float64(0.11408650279045104), 'actor_loss': np.float64(-0.9047096610069275), 'hyper_actor_loss': np.float64(0.03294864855706692), 'behavior_loss': np.float64(1.3852940320968627)}
step: 2440 @ episode report: {'average_total_reward': np.float32(5.0233335), 'reward_variance': np.float32(1.1852953), 'max_total_reward': np.float32(7.5333343), 'min_total_reward': np.float32(3.288889), 'average_n_step': np.float32(6.6), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(5.0), 'buffer_size': 80128} @ step loss: {'critic_loss': np.float64(0.11551918089389801), 'actor_loss': np.float64(-0.9359049141407013), 'hyper_actor_loss': np.float64(0.03245339021086693), 'behavior_loss': np.float64(1.3045710444450378)}
step: 2450 @ episode report: {'average_total_reward': np.float32(4.6477776), 'reward_variance': np.float32(0.60034704), 'max_total_reward': np.float32(5.533334), 'min_total_reward': np.float32(3.4111109), 'average_n_step': np.float32(6.2), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(5.0), 'buffer_size': 80448} @ step loss: {'critic_loss': np.float64(0.11373234540224075), 'actor_loss': np.float64(-0.9703447580337524), 'hyper_actor_loss': np.float64(0.03227594904601574), 'behavior_loss': np.float64(1.3693935751914978)}
step: 2460 @ episode report: {'average_total_reward': np.float32(5.3333335), 'reward_variance': np.float32(0.39041975), 'max_total_reward': np.float32(6.6555557), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(6.8), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(6.0), 'buffer_size': 80768} @ step loss: {'critic_loss': np.float64(0.12306777015328407), 'actor_loss': np.float64(-0.9408521592617035), 'hyper_actor_loss': np.float64(0.03207617923617363), 'behavior_loss': np.float64(1.3114898800849915)}
step: 2470 @ episode report: {'average_total_reward': np.float32(5.660001), 'reward_variance': np.float32(1.9316099), 'max_total_reward': np.float32(7.6555557), 'min_total_reward': np.float32(3.1666665), 'average_n_step': np.float32(7.2), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(5.0), 'buffer_size': 81088} @ step loss: {'critic_loss': np.float64(0.10636549070477486), 'actor_loss': np.float64(-0.940278023481369), 'hyper_actor_loss': np.float64(0.032031891494989397), 'behavior_loss': np.float64(1.3745633125305177)}
step: 2480 @ episode report: {'average_total_reward': np.float32(5.5477777), 'reward_variance': np.float32(0.5192112), 'max_total_reward': np.float32(6.6555557), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(7.1), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(6.0), 'buffer_size': 81408} @ step loss: {'critic_loss': np.float64(0.11123853176832199), 'actor_loss': np.float64(-0.9315622508525848), 'hyper_actor_loss': np.float64(0.03161003086715937), 'behavior_loss': np.float64(1.3722504258155823)}
step: 2490 @ episode report: {'average_total_reward': np.float32(5.4722223), 'reward_variance': np.float32(0.98526555), 'max_total_reward': np.float32(7.2888894), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.0), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 81728} @ step loss: {'critic_loss': np.float64(0.11353496089577675), 'actor_loss': np.float64(-0.9247730851173401), 'hyper_actor_loss': np.float64(0.03129623811691999), 'behavior_loss': np.float64(1.4252323031425476)}
step: 2500 @ episode report: {'average_total_reward': np.float32(5.4455557), 'reward_variance': np.float32(0.62497413), 'max_total_reward': np.float32(6.6555567), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(6.9), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(6.0), 'buffer_size': 82048} @ step loss: {'critic_loss': np.float64(0.13065300658345222), 'actor_loss': np.float64(-0.9585657119750977), 'hyper_actor_loss': np.float64(0.03057099673897028), 'behavior_loss': np.float64(1.4582764387130738)}
step: 2510 @ episode report: {'average_total_reward': np.float32(5.633333), 'reward_variance': np.float32(1.7004942), 'max_total_reward': np.float32(7.6555557), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(7.1), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 82368} @ step loss: {'critic_loss': np.float64(0.11797091364860535), 'actor_loss': np.float64(-0.9395618736743927), 'hyper_actor_loss': np.float64(0.030077259801328183), 'behavior_loss': np.float64(1.3980273604393005)}
step: 2520 @ episode report: {'average_total_reward': np.float32(5.272222), 'reward_variance': np.float32(2.7602787), 'max_total_reward': np.float32(7.5333343), 'min_total_reward': np.float32(3.0444446), 'average_n_step': np.float32(6.8), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(5.0), 'buffer_size': 82688} @ step loss: {'critic_loss': np.float64(0.12356618791818619), 'actor_loss': np.float64(-0.953196668624878), 'hyper_actor_loss': np.float64(0.02970536779612303), 'behavior_loss': np.float64(1.499699354171753)}
step: 2530 @ episode report: {'average_total_reward': np.float32(6.096667), 'reward_variance': np.float32(2.013335), 'max_total_reward': np.float32(8.900002), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(7.6), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 83008} @ step loss: {'critic_loss': np.float64(0.12044441625475884), 'actor_loss': np.float64(-0.9617627084255218), 'hyper_actor_loss': np.float64(0.029637000150978567), 'behavior_loss': np.float64(1.3769710063934326)}
step: 2540 @ episode report: {'average_total_reward': np.float32(5.845556), 'reward_variance': np.float32(3.13174), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(3.288889), 'average_n_step': np.float32(7.3), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(5.0), 'buffer_size': 83328} @ step loss: {'critic_loss': np.float64(0.12716367095708847), 'actor_loss': np.float64(-0.9769594192504882), 'hyper_actor_loss': np.float64(0.029437537863850595), 'behavior_loss': np.float64(1.5360989928245545)}
step: 2550 @ episode report: {'average_total_reward': np.float32(6.0944448), 'reward_variance': np.float32(1.0490186), 'max_total_reward': np.float32(7.7777786), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.5), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 83648} @ step loss: {'critic_loss': np.float64(0.11857822239398956), 'actor_loss': np.float64(-0.8898955285549164), 'hyper_actor_loss': np.float64(0.029263451881706714), 'behavior_loss': np.float64(1.423262083530426)}
step: 2560 @ episode report: {'average_total_reward': np.float32(6.3455553), 'reward_variance': np.float32(2.24853), 'max_total_reward': np.float32(8.411111), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.8), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 83968} @ step loss: {'critic_loss': np.float64(0.10986970216035843), 'actor_loss': np.float64(-0.9629064440727234), 'hyper_actor_loss': np.float64(0.029190383851528168), 'behavior_loss': np.float64(1.4256958365440369)}
step: 2570 @ episode report: {'average_total_reward': np.float32(7.055556), 'reward_variance': np.float32(2.751259), 'max_total_reward': np.float32(9.777778), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 84288} @ step loss: {'critic_loss': np.float64(0.10622457787394524), 'actor_loss': np.float64(-0.9273974418640136), 'hyper_actor_loss': np.float64(0.02952987216413021), 'behavior_loss': np.float64(1.4182985186576844)}
step: 2580 @ episode report: {'average_total_reward': np.float32(7.967778), 'reward_variance': np.float32(0.82048017), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(6.4111114), 'average_n_step': np.float32(9.3), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(8.0), 'buffer_size': 84608} @ step loss: {'critic_loss': np.float64(0.11310441866517067), 'actor_loss': np.float64(-0.9251865983009339), 'hyper_actor_loss': np.float64(0.029331801831722258), 'behavior_loss': np.float64(1.436233353614807)}
step: 2590 @ episode report: {'average_total_reward': np.float32(6.594445), 'reward_variance': np.float32(2.1913154), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(8.0), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 84928} @ step loss: {'critic_loss': np.float64(0.10397378355264664), 'actor_loss': np.float64(-0.9350311756134033), 'hyper_actor_loss': np.float64(0.029115261882543562), 'behavior_loss': np.float64(1.43721684217453)}
step: 2600 @ episode report: {'average_total_reward': np.float32(8.32889), 'reward_variance': np.float32(2.920252), 'max_total_reward': np.float32(11.900001), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(9.6), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 85248} @ step loss: {'critic_loss': np.float64(0.11847943365573883), 'actor_loss': np.float64(-0.9325350046157836), 'hyper_actor_loss': np.float64(0.029184651933610438), 'behavior_loss': np.float64(1.4092382192611694)}
step: 2610 @ episode report: {'average_total_reward': np.float32(7.2188888), 'reward_variance': np.float32(1.9006189), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(5.288889), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 85568} @ step loss: {'critic_loss': np.float64(0.1052391104400158), 'actor_loss': np.float64(-0.9687100052833557), 'hyper_actor_loss': np.float64(0.028961307555437087), 'behavior_loss': np.float64(1.3899147987365723)}
step: 2620 @ episode report: {'average_total_reward': np.float32(7.0922227), 'reward_variance': np.float32(3.9919515), 'max_total_reward': np.float32(12.266666), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 85888} @ step loss: {'critic_loss': np.float64(0.10607737675309181), 'actor_loss': np.float64(-0.937759953737259), 'hyper_actor_loss': np.float64(0.02898626569658518), 'behavior_loss': np.float64(1.3835393071174622)}
step: 2630 @ episode report: {'average_total_reward': np.float32(6.9433336), 'reward_variance': np.float32(3.9982827), 'max_total_reward': np.float32(12.144444), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(6.0), 'buffer_size': 86208} @ step loss: {'critic_loss': np.float64(0.11578012332320213), 'actor_loss': np.float64(-0.9716809988021851), 'hyper_actor_loss': np.float64(0.02918267883360386), 'behavior_loss': np.float64(1.4341760277748108)}
step: 2640 @ episode report: {'average_total_reward': np.float32(8.553334), 'reward_variance': np.float32(4.1701436), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(9.8), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 86528} @ step loss: {'critic_loss': np.float64(0.12375179454684257), 'actor_loss': np.float64(-0.961487090587616), 'hyper_actor_loss': np.float64(0.02917307708412409), 'behavior_loss': np.float64(1.4333772659301758)}
step: 2650 @ episode report: {'average_total_reward': np.float32(8.128889), 'reward_variance': np.float32(4.7705727), 'max_total_reward': np.float32(11.0222225), 'min_total_reward': np.float32(5.288889), 'average_n_step': np.float32(9.4), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 86848} @ step loss: {'critic_loss': np.float64(0.12860831543803214), 'actor_loss': np.float64(-1.005249136686325), 'hyper_actor_loss': np.float64(0.0295422799885273), 'behavior_loss': np.float64(1.4418240308761596)}
step: 2660 @ episode report: {'average_total_reward': np.float32(8.02889), 'reward_variance': np.float32(3.3557098), 'max_total_reward': np.float32(11.022223), 'min_total_reward': np.float32(5.411111), 'average_n_step': np.float32(9.3), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 87168} @ step loss: {'critic_loss': np.float64(0.11337782591581344), 'actor_loss': np.float64(-0.9716742932796478), 'hyper_actor_loss': np.float64(0.030169720016419887), 'behavior_loss': np.float64(1.3686438202857971)}
step: 2670 @ episode report: {'average_total_reward': np.float32(7.828889), 'reward_variance': np.float32(1.7078817), 'max_total_reward': np.float32(10.022222), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.1), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 87488} @ step loss: {'critic_loss': np.float64(0.1019580140709877), 'actor_loss': np.float64(-0.9680467844009399), 'hyper_actor_loss': np.float64(0.03069437127560377), 'behavior_loss': np.float64(1.3555695772171021)}
step: 2680 @ episode report: {'average_total_reward': np.float32(7.5311112), 'reward_variance': np.float32(2.1498718), 'max_total_reward': np.float32(9.777778), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.9), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 87808} @ step loss: {'critic_loss': np.float64(0.11711247339844703), 'actor_loss': np.float64(-0.9859416484832764), 'hyper_actor_loss': np.float64(0.03121491950005293), 'behavior_loss': np.float64(1.4070697546005249)}
step: 2690 @ episode report: {'average_total_reward': np.float32(8.826667), 'reward_variance': np.float32(2.7527704), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.0), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 88128} @ step loss: {'critic_loss': np.float64(0.1034113883972168), 'actor_loss': np.float64(-0.9560985863208771), 'hyper_actor_loss': np.float64(0.03171659708023071), 'behavior_loss': np.float64(1.3123900532722472)}
step: 2700 @ episode report: {'average_total_reward': np.float32(7.816667), 'reward_variance': np.float32(1.4067224), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(9.1), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 88448} @ step loss: {'critic_loss': np.float64(0.1146602489054203), 'actor_loss': np.float64(-0.9330815970897675), 'hyper_actor_loss': np.float64(0.03197403475642204), 'behavior_loss': np.float64(1.3765299916267395)}
step: 2710 @ episode report: {'average_total_reward': np.float32(8.590001), 'reward_variance': np.float32(0.20561597), 'max_total_reward': np.float32(8.900002), 'min_total_reward': np.float32(7.655556), 'average_n_step': np.float32(9.8), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(9.0), 'buffer_size': 88768} @ step loss: {'critic_loss': np.float64(0.12949065193533899), 'actor_loss': np.float64(-0.9937438011169434), 'hyper_actor_loss': np.float64(0.03195982277393341), 'behavior_loss': np.float64(1.3981531381607055)}
step: 2720 @ episode report: {'average_total_reward': np.float32(8.641111), 'reward_variance': np.float32(1.5955323), 'max_total_reward': np.float32(10.777779), 'min_total_reward': np.float32(6.6555552), 'average_n_step': np.float32(9.9), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(8.0), 'buffer_size': 89088} @ step loss: {'critic_loss': np.float64(0.11983596608042717), 'actor_loss': np.float64(-0.9611847639083863), 'hyper_actor_loss': np.float64(0.03170827887952328), 'behavior_loss': np.float64(1.313206946849823)}
step: 2730 @ episode report: {'average_total_reward': np.float32(7.3166666), 'reward_variance': np.float32(3.3839574), 'max_total_reward': np.float32(11.0222225), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 89408} @ step loss: {'critic_loss': np.float64(0.11214619874954224), 'actor_loss': np.float64(-0.9838933944702148), 'hyper_actor_loss': np.float64(0.03176141530275345), 'behavior_loss': np.float64(1.275551199913025)}
step: 2740 @ episode report: {'average_total_reward': np.float32(7.7288895), 'reward_variance': np.float32(4.888475), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.0), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(7.0), 'buffer_size': 89728} @ step loss: {'critic_loss': np.float64(0.10716423280537128), 'actor_loss': np.float64(-0.9448747754096984), 'hyper_actor_loss': np.float64(0.03132018595933914), 'behavior_loss': np.float64(1.3355792880058288)}
step: 2750 @ episode report: {'average_total_reward': np.float32(7.467778), 'reward_variance': np.float32(1.2041594), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(8.8), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 90048} @ step loss: {'critic_loss': np.float64(0.1327056899666786), 'actor_loss': np.float64(-1.0070292234420777), 'hyper_actor_loss': np.float64(0.030859277956187724), 'behavior_loss': np.float64(1.3157789826393127)}
step: 2760 @ episode report: {'average_total_reward': np.float32(7.267778), 'reward_variance': np.float32(2.8661344), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(3.411111), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(5.0), 'buffer_size': 90368} @ step loss: {'critic_loss': np.float64(0.1207636259496212), 'actor_loss': np.float64(-0.9444805681705475), 'hyper_actor_loss': np.float64(0.03010421209037304), 'behavior_loss': np.float64(1.3865292429924012)}
step: 2770 @ episode report: {'average_total_reward': np.float32(7.1800003), 'reward_variance': np.float32(3.2339954), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(3.411111), 'average_n_step': np.float32(8.5), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(5.0), 'buffer_size': 90688} @ step loss: {'critic_loss': np.float64(0.10935204029083252), 'actor_loss': np.float64(-0.95847247838974), 'hyper_actor_loss': np.float64(0.02930881567299366), 'behavior_loss': np.float64(1.3576523423194886)}
step: 2780 @ episode report: {'average_total_reward': np.float32(7.055556), 'reward_variance': np.float32(2.0749378), 'max_total_reward': np.float32(9.655555), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 91008} @ step loss: {'critic_loss': np.float64(0.11584864482283593), 'actor_loss': np.float64(-0.9199716567993164), 'hyper_actor_loss': np.float64(0.028489244543015955), 'behavior_loss': np.float64(1.408287727832794)}
step: 2790 @ episode report: {'average_total_reward': np.float32(6.418889), 'reward_variance': np.float32(1.3285449), 'max_total_reward': np.float32(8.655556), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(7.8), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 91328} @ step loss: {'critic_loss': np.float64(0.11348721906542777), 'actor_loss': np.float64(-0.9652386486530304), 'hyper_actor_loss': np.float64(0.028250923939049245), 'behavior_loss': np.float64(1.3997246980667115)}
step: 2800 @ episode report: {'average_total_reward': np.float32(7.8555555), 'reward_variance': np.float32(1.2572347), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.2), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 91648} @ step loss: {'critic_loss': np.float64(0.11804479360580444), 'actor_loss': np.float64(-0.9285771071910858), 'hyper_actor_loss': np.float64(0.027864081785082817), 'behavior_loss': np.float64(1.4532278180122375)}
step: 2810 @ episode report: {'average_total_reward': np.float32(7.28), 'reward_variance': np.float32(4.2430816), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 91968} @ step loss: {'critic_loss': np.float64(0.11749935150146484), 'actor_loss': np.float64(-1.010441243648529), 'hyper_actor_loss': np.float64(0.027977925166487692), 'behavior_loss': np.float64(1.411731445789337)}
step: 2820 @ episode report: {'average_total_reward': np.float32(7.167778), 'reward_variance': np.float32(2.2052464), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.5), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 92288} @ step loss: {'critic_loss': np.float64(0.11767651587724685), 'actor_loss': np.float64(-0.9749851644039154), 'hyper_actor_loss': np.float64(0.02791748456656933), 'behavior_loss': np.float64(1.2809831142425536)}
step: 2830 @ episode report: {'average_total_reward': np.float32(7.6800003), 'reward_variance': np.float32(3.0418472), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(9.0), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 92608} @ step loss: {'critic_loss': np.float64(0.10643796995282173), 'actor_loss': np.float64(-0.9806787550449372), 'hyper_actor_loss': np.float64(0.028440847247838973), 'behavior_loss': np.float64(1.3237024068832397)}
step: 2840 @ episode report: {'average_total_reward': np.float32(7.928889), 'reward_variance': np.float32(1.7662017), 'max_total_reward': np.float32(10.022222), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.2), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 92928} @ step loss: {'critic_loss': np.float64(0.10940276682376862), 'actor_loss': np.float64(-0.9408160150051117), 'hyper_actor_loss': np.float64(0.028887290693819522), 'behavior_loss': np.float64(1.3473971366882325)}
step: 2850 @ episode report: {'average_total_reward': np.float32(7.492223), 'reward_variance': np.float32(2.516496), 'max_total_reward': np.float32(11.022223), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(8.8), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 93248} @ step loss: {'critic_loss': np.float64(0.11992989555001259), 'actor_loss': np.float64(-0.9971895456314087), 'hyper_actor_loss': np.float64(0.028968650847673416), 'behavior_loss': np.float64(1.3942396879196166)}
step: 2860 @ episode report: {'average_total_reward': np.float32(6.9800005), 'reward_variance': np.float32(3.9594033), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(3.4111114), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(5.0), 'buffer_size': 93568} @ step loss: {'critic_loss': np.float64(0.12379366457462311), 'actor_loss': np.float64(-0.9908772587776185), 'hyper_actor_loss': np.float64(0.028424414806067944), 'behavior_loss': np.float64(1.3027055382728576)}
step: 2870 @ episode report: {'average_total_reward': np.float32(7.3433332), 'reward_variance': np.float32(1.8968014), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.7), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 93888} @ step loss: {'critic_loss': np.float64(0.12147376388311386), 'actor_loss': np.float64(-0.9305514097213745), 'hyper_actor_loss': np.float64(0.02776126340031624), 'behavior_loss': np.float64(1.357430100440979)}
step: 2880 @ episode report: {'average_total_reward': np.float32(6.4822226), 'reward_variance': np.float32(2.6235855), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.9), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 94208} @ step loss: {'critic_loss': np.float64(0.12557579204440117), 'actor_loss': np.float64(-0.9940993010997772), 'hyper_actor_loss': np.float64(0.027218043431639673), 'behavior_loss': np.float64(1.3768962979316712)}
step: 2890 @ episode report: {'average_total_reward': np.float32(6.306667), 'reward_variance': np.float32(1.9748195), 'max_total_reward': np.float32(8.9), 'min_total_reward': np.float32(4.411111), 'average_n_step': np.float32(7.7), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 94528} @ step loss: {'critic_loss': np.float64(0.1255062997341156), 'actor_loss': np.float64(-0.949719887971878), 'hyper_actor_loss': np.float64(0.026932599395513533), 'behavior_loss': np.float64(1.3198248386383056)}
step: 2900 @ episode report: {'average_total_reward': np.float32(5.845556), 'reward_variance': np.float32(2.7611718), 'max_total_reward': np.float32(8.777778), 'min_total_reward': np.float32(3.411111), 'average_n_step': np.float32(7.3), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(5.0), 'buffer_size': 94848} @ step loss: {'critic_loss': np.float64(0.11209127977490425), 'actor_loss': np.float64(-0.994501394033432), 'hyper_actor_loss': np.float64(0.026589673943817616), 'behavior_loss': np.float64(1.359328842163086)}
step: 2910 @ episode report: {'average_total_reward': np.float32(7.604445), 'reward_variance': np.float32(2.0420547), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(8.9), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 95168} @ step loss: {'critic_loss': np.float64(0.11458728983998298), 'actor_loss': np.float64(-0.9628147840499878), 'hyper_actor_loss': np.float64(0.02611854877322912), 'behavior_loss': np.float64(1.285640501976013)}
step: 2920 @ episode report: {'average_total_reward': np.float32(6.582223), 'reward_variance': np.float32(1.5347704), 'max_total_reward': np.float32(7.7777786), 'min_total_reward': np.float32(3.4111114), 'average_n_step': np.float32(8.0), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(5.0), 'buffer_size': 95488} @ step loss: {'critic_loss': np.float64(0.11372323855757713), 'actor_loss': np.float64(-0.9786547660827637), 'hyper_actor_loss': np.float64(0.025573867745697497), 'behavior_loss': np.float64(1.300009310245514)}
step: 2930 @ episode report: {'average_total_reward': np.float32(6.082223), 'reward_variance': np.float32(2.0366478), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(7.5), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 95808} @ step loss: {'critic_loss': np.float64(0.11085422486066818), 'actor_loss': np.float64(-0.9552857220172882), 'hyper_actor_loss': np.float64(0.025177172757685183), 'behavior_loss': np.float64(1.4807110667228698)}
step: 2940 @ episode report: {'average_total_reward': np.float32(6.0577784), 'reward_variance': np.float32(2.3392053), 'max_total_reward': np.float32(8.655556), 'min_total_reward': np.float32(3.411111), 'average_n_step': np.float32(7.5), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(5.0), 'buffer_size': 96128} @ step loss: {'critic_loss': np.float64(0.11938479766249657), 'actor_loss': np.float64(-0.978114926815033), 'hyper_actor_loss': np.float64(0.024746598862111568), 'behavior_loss': np.float64(1.4814425468444825)}
step: 2950 @ episode report: {'average_total_reward': np.float32(5.9333334), 'reward_variance': np.float32(1.5741732), 'max_total_reward': np.float32(8.655556), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.4), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 96448} @ step loss: {'critic_loss': np.float64(0.11691146567463875), 'actor_loss': np.float64(-0.9763832092285156), 'hyper_actor_loss': np.float64(0.02463793959468603), 'behavior_loss': np.float64(1.3791382551193236)}
step: 2960 @ episode report: {'average_total_reward': np.float32(5.8700004), 'reward_variance': np.float32(2.6505194), 'max_total_reward': np.float32(8.9), 'min_total_reward': np.float32(3.4111114), 'average_n_step': np.float32(7.3), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(5.0), 'buffer_size': 96768} @ step loss: {'critic_loss': np.float64(0.12211677432060242), 'actor_loss': np.float64(-1.0036380469799042), 'hyper_actor_loss': np.float64(0.024769046157598496), 'behavior_loss': np.float64(1.364120888710022)}
step: 2970 @ episode report: {'average_total_reward': np.float32(6.3700004), 'reward_variance': np.float32(0.60822374), 'max_total_reward': np.float32(7.7777786), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(7.8), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(7.0), 'buffer_size': 97088} @ step loss: {'critic_loss': np.float64(0.1211940474808216), 'actor_loss': np.float64(-0.9712122678756714), 'hyper_actor_loss': np.float64(0.02532186731696129), 'behavior_loss': np.float64(1.4163204431533813)}
step: 2980 @ episode report: {'average_total_reward': np.float32(6.2188888), 'reward_variance': np.float32(2.422841), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.6), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 97408} @ step loss: {'critic_loss': np.float64(0.11131098121404648), 'actor_loss': np.float64(-0.9884893238544464), 'hyper_actor_loss': np.float64(0.025914025865495204), 'behavior_loss': np.float64(1.4533331155776978)}
step: 2990 @ episode report: {'average_total_reward': np.float32(6.494445), 'reward_variance': np.float32(3.0336852), 'max_total_reward': np.float32(11.0222225), 'min_total_reward': np.float32(4.166667), 'average_n_step': np.float32(7.9), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(6.0), 'buffer_size': 97728} @ step loss: {'critic_loss': np.float64(0.11093606129288673), 'actor_loss': np.float64(-0.9811088979244232), 'hyper_actor_loss': np.float64(0.02678609937429428), 'behavior_loss': np.float64(1.3427056908607482)}
step: 3000 @ episode report: {'average_total_reward': np.float32(5.596667), 'reward_variance': np.float32(1.4865196), 'max_total_reward': np.float32(7.6555552), 'min_total_reward': np.float32(3.288889), 'average_n_step': np.float32(7.1), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(5.0), 'buffer_size': 98048} @ step loss: {'critic_loss': np.float64(0.12074626311659813), 'actor_loss': np.float64(-0.9908698499202728), 'hyper_actor_loss': np.float64(0.027134263701736928), 'behavior_loss': np.float64(1.444931721687317)}
step: 3010 @ episode report: {'average_total_reward': np.float32(5.3966665), 'reward_variance': np.float32(0.87032205), 'max_total_reward': np.float32(7.4111114), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(6.9), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 98368} @ step loss: {'critic_loss': np.float64(0.12163991332054139), 'actor_loss': np.float64(-0.9906300663948059), 'hyper_actor_loss': np.float64(0.02692617829889059), 'behavior_loss': np.float64(1.4554650902748107)}
step: 3020 @ episode report: {'average_total_reward': np.float32(4.9477777), 'reward_variance': np.float32(0.86634696), 'max_total_reward': np.float32(6.655556), 'min_total_reward': np.float32(3.4111116), 'average_n_step': np.float32(6.5), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(5.0), 'buffer_size': 98688} @ step loss: {'critic_loss': np.float64(0.11436471790075302), 'actor_loss': np.float64(-0.9522143840789795), 'hyper_actor_loss': np.float64(0.026217076927423477), 'behavior_loss': np.float64(1.4011476755142211)}
step: 3030 @ episode report: {'average_total_reward': np.float32(5.408889), 'reward_variance': np.float32(2.2720938), 'max_total_reward': np.float32(8.777778), 'min_total_reward': np.float32(3.2888892), 'average_n_step': np.float32(6.9), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(5.0), 'buffer_size': 99008} @ step loss: {'critic_loss': np.float64(0.1259591296315193), 'actor_loss': np.float64(-0.9879396438598633), 'hyper_actor_loss': np.float64(0.025040063448250292), 'behavior_loss': np.float64(1.408583974838257)}
step: 3040 @ episode report: {'average_total_reward': np.float32(4.8477774), 'reward_variance': np.float32(0.31755686), 'max_total_reward': np.float32(5.533334), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(6.4), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(6.0), 'buffer_size': 99328} @ step loss: {'critic_loss': np.float64(0.11790560558438301), 'actor_loss': np.float64(-0.962435919046402), 'hyper_actor_loss': np.float64(0.023713708110153674), 'behavior_loss': np.float64(1.4023601770401002)}
step: 3050 @ episode report: {'average_total_reward': np.float32(5.6700006), 'reward_variance': np.float32(2.8429651), 'max_total_reward': np.float32(7.7777786), 'min_total_reward': np.float32(2.288889), 'average_n_step': np.float32(7.1), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(4.0), 'buffer_size': 99648} @ step loss: {'critic_loss': np.float64(0.12225362733006477), 'actor_loss': np.float64(-0.9454716742038727), 'hyper_actor_loss': np.float64(0.02282653860747814), 'behavior_loss': np.float64(1.467245304584503)}
step: 3060 @ episode report: {'average_total_reward': np.float32(6.045556), 'reward_variance': np.float32(2.4326785), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(3.411111), 'average_n_step': np.float32(7.5), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(5.0), 'buffer_size': 99968} @ step loss: {'critic_loss': np.float64(0.11925323829054832), 'actor_loss': np.float64(-0.9553357481956481), 'hyper_actor_loss': np.float64(0.022084563598036767), 'behavior_loss': np.float64(1.4645419001579285)}
step: 3070 @ episode report: {'average_total_reward': np.float32(6.7066665), 'reward_variance': np.float32(2.0864255), 'max_total_reward': np.float32(8.900002), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.1), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.11865822449326516), 'actor_loss': np.float64(-0.9606812775135041), 'hyper_actor_loss': np.float64(0.021559022925794126), 'behavior_loss': np.float64(1.4947909474372865)}
step: 3080 @ episode report: {'average_total_reward': np.float32(5.845556), 'reward_variance': np.float32(0.99151754), 'max_total_reward': np.float32(7.6555567), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.3), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.12580062225461006), 'actor_loss': np.float64(-0.993611854314804), 'hyper_actor_loss': np.float64(0.021074405498802663), 'behavior_loss': np.float64(1.3904338955879212)}
step: 3090 @ episode report: {'average_total_reward': np.float32(6.5066667), 'reward_variance': np.float32(2.4254873), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.2888894), 'average_n_step': np.float32(7.9), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.12011706158518791), 'actor_loss': np.float64(-0.9490566670894622), 'hyper_actor_loss': np.float64(0.020639857836067678), 'behavior_loss': np.float64(1.5110806465148925)}
step: 3100 @ episode report: {'average_total_reward': np.float32(6.208889), 'reward_variance': np.float32(2.2905145), 'max_total_reward': np.float32(8.655557), 'min_total_reward': np.float32(4.1666665), 'average_n_step': np.float32(7.7), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10889115780591965), 'actor_loss': np.float64(-0.9494619965553284), 'hyper_actor_loss': np.float64(0.020225037634372712), 'behavior_loss': np.float64(1.4793744206428527)}
step: 3110 @ episode report: {'average_total_reward': np.float32(5.508889), 'reward_variance': np.float32(1.4921932), 'max_total_reward': np.float32(7.7777786), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(7.0), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.11360745653510093), 'actor_loss': np.float64(-0.9663132190704345), 'hyper_actor_loss': np.float64(0.019846809469163416), 'behavior_loss': np.float64(1.4466369986534118)}
step: 3120 @ episode report: {'average_total_reward': np.float32(6.457778), 'reward_variance': np.float32(1.9322169), 'max_total_reward': np.float32(8.655555), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(7.9), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10748732239007949), 'actor_loss': np.float64(-0.9495836019515991), 'hyper_actor_loss': np.float64(0.019385290518403053), 'behavior_loss': np.float64(1.4252403855323792)}
step: 3130 @ episode report: {'average_total_reward': np.float32(6.357778), 'reward_variance': np.float32(2.5108597), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(7.8), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.1302650071680546), 'actor_loss': np.float64(-0.9669942319393158), 'hyper_actor_loss': np.float64(0.0191716343164444), 'behavior_loss': np.float64(1.4599551439285279)}
step: 3140 @ episode report: {'average_total_reward': np.float32(5.6211114), 'reward_variance': np.float32(1.0997641), 'max_total_reward': np.float32(7.533334), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.1), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.12180460169911385), 'actor_loss': np.float64(-0.9542173683643341), 'hyper_actor_loss': np.float64(0.018559109047055246), 'behavior_loss': np.float64(1.5260980367660522)}
step: 3150 @ episode report: {'average_total_reward': np.float32(6.2333336), 'reward_variance': np.float32(3.409062), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(3.0444446), 'average_n_step': np.float32(7.7), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.11197188720107079), 'actor_loss': np.float64(-0.9563564658164978), 'hyper_actor_loss': np.float64(0.017800178937613965), 'behavior_loss': np.float64(1.481863272190094)}
step: 3160 @ episode report: {'average_total_reward': np.float32(6.5311112), 'reward_variance': np.float32(2.6446614), 'max_total_reward': np.float32(9.777778), 'min_total_reward': np.float32(3.288889), 'average_n_step': np.float32(7.9), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.11134387776255608), 'actor_loss': np.float64(-0.9551308214664459), 'hyper_actor_loss': np.float64(0.01733121518045664), 'behavior_loss': np.float64(1.4888096928596497)}
step: 3170 @ episode report: {'average_total_reward': np.float32(6.8066664), 'reward_variance': np.float32(1.5662034), 'max_total_reward': np.float32(8.900002), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.2), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.12550045996904374), 'actor_loss': np.float64(-0.9937607765197753), 'hyper_actor_loss': np.float64(0.01701852735131979), 'behavior_loss': np.float64(1.4909001469612122)}
step: 3180 @ episode report: {'average_total_reward': np.float32(6.5188894), 'reward_variance': np.float32(4.2474823), 'max_total_reward': np.float32(9.777778), 'min_total_reward': np.float32(3.2888892), 'average_n_step': np.float32(7.9), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.11855214685201645), 'actor_loss': np.float64(-0.9557173609733581), 'hyper_actor_loss': np.float64(0.01676121409982443), 'behavior_loss': np.float64(1.5415449619293213)}
step: 3190 @ episode report: {'average_total_reward': np.float32(5.957778), 'reward_variance': np.float32(5.0802917), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(3.411111), 'average_n_step': np.float32(7.4), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10241163596510887), 'actor_loss': np.float64(-0.9513785541057587), 'hyper_actor_loss': np.float64(0.016680551506578923), 'behavior_loss': np.float64(1.4862898349761964)}
step: 3200 @ episode report: {'average_total_reward': np.float32(6.955556), 'reward_variance': np.float32(2.3516796), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.11007621064782143), 'actor_loss': np.float64(-0.9621604442596435), 'hyper_actor_loss': np.float64(0.01661008931696415), 'behavior_loss': np.float64(1.461902904510498)}
step: 3210 @ episode report: {'average_total_reward': np.float32(6.8433332), 'reward_variance': np.float32(3.4849994), 'max_total_reward': np.float32(8.900002), 'min_total_reward': np.float32(3.4111116), 'average_n_step': np.float32(8.2), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.11217959076166154), 'actor_loss': np.float64(-0.9489650785923004), 'hyper_actor_loss': np.float64(0.015963877830654383), 'behavior_loss': np.float64(1.5590610027313232)}
step: 3220 @ episode report: {'average_total_reward': np.float32(6.321111), 'reward_variance': np.float32(1.6751473), 'max_total_reward': np.float32(8.777778), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.8), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10566566810011864), 'actor_loss': np.float64(-0.9747955977916718), 'hyper_actor_loss': np.float64(0.015632953122258188), 'behavior_loss': np.float64(1.4183656692504882)}
step: 3230 @ episode report: {'average_total_reward': np.float32(6.2822227), 'reward_variance': np.float32(1.6259804), 'max_total_reward': np.float32(7.7777786), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.7), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.1042795829474926), 'actor_loss': np.float64(-0.9369294106960296), 'hyper_actor_loss': np.float64(0.015148654859513045), 'behavior_loss': np.float64(1.6202530145645142)}
step: 3240 @ episode report: {'average_total_reward': np.float32(6.1211114), 'reward_variance': np.float32(1.739295), 'max_total_reward': np.float32(8.655556), 'min_total_reward': np.float32(4.0444446), 'average_n_step': np.float32(7.6), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09956090599298477), 'actor_loss': np.float64(-0.9165685832500458), 'hyper_actor_loss': np.float64(0.01448963638395071), 'behavior_loss': np.float64(1.5103099346160889)}
step: 3250 @ episode report: {'average_total_reward': np.float32(6.7333326), 'reward_variance': np.float32(2.9211352), 'max_total_reward': np.float32(9.655556), 'min_total_reward': np.float32(4.2888894), 'average_n_step': np.float32(8.2), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10189294032752513), 'actor_loss': np.float64(-0.9399263918399811), 'hyper_actor_loss': np.float64(0.014257857296615838), 'behavior_loss': np.float64(1.7127798080444336)}
step: 3260 @ episode report: {'average_total_reward': np.float32(7.067778), 'reward_variance': np.float32(1.9124066), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09488463178277015), 'actor_loss': np.float64(-0.9106863260269165), 'hyper_actor_loss': np.float64(0.01381978215649724), 'behavior_loss': np.float64(1.6113911986351013)}
step: 3270 @ episode report: {'average_total_reward': np.float32(6.8700004), 'reward_variance': np.float32(1.629063), 'max_total_reward': np.float32(8.777778), 'min_total_reward': np.float32(4.411111), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.11323291659355164), 'actor_loss': np.float64(-0.9308052659034729), 'hyper_actor_loss': np.float64(0.013729412667453289), 'behavior_loss': np.float64(1.715693199634552)}
step: 3280 @ episode report: {'average_total_reward': np.float32(7.1800003), 'reward_variance': np.float32(1.2598964), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(8.5), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10701677799224854), 'actor_loss': np.float64(-0.9501792788505554), 'hyper_actor_loss': np.float64(0.013136651273816824), 'behavior_loss': np.float64(1.531034529209137)}
step: 3290 @ episode report: {'average_total_reward': np.float32(6.1433334), 'reward_variance': np.float32(0.93988764), 'max_total_reward': np.float32(7.777778), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(7.5), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.1028354026377201), 'actor_loss': np.float64(-0.9101447343826294), 'hyper_actor_loss': np.float64(0.012927928008139133), 'behavior_loss': np.float64(1.6122668862342835)}
step: 3300 @ episode report: {'average_total_reward': np.float32(7.6433344), 'reward_variance': np.float32(1.4452457), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(9.0), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10703677535057068), 'actor_loss': np.float64(-0.9211052060127258), 'hyper_actor_loss': np.float64(0.012692197598516941), 'behavior_loss': np.float64(1.6465009093284606)}
step: 3310 @ episode report: {'average_total_reward': np.float32(6.5311117), 'reward_variance': np.float32(2.1409092), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(3.4111114), 'average_n_step': np.float32(7.9), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10108672231435775), 'actor_loss': np.float64(-0.9499699115753174), 'hyper_actor_loss': np.float64(0.01258218865841627), 'behavior_loss': np.float64(1.6246408462524413)}
step: 3320 @ episode report: {'average_total_reward': np.float32(7.1433334), 'reward_variance': np.float32(1.3867768), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.288889), 'average_n_step': np.float32(8.5), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10634309127926826), 'actor_loss': np.float64(-0.945727926492691), 'hyper_actor_loss': np.float64(0.012716557458043098), 'behavior_loss': np.float64(1.5596556901931762)}
step: 3330 @ episode report: {'average_total_reward': np.float32(7.267778), 'reward_variance': np.float32(0.7364062), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.655556), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09326599091291428), 'actor_loss': np.float64(-0.9612459063529968), 'hyper_actor_loss': np.float64(0.012787662539631128), 'behavior_loss': np.float64(1.6506685376167298)}
step: 3340 @ episode report: {'average_total_reward': np.float32(6.4455557), 'reward_variance': np.float32(1.6933196), 'max_total_reward': np.float32(7.777778), 'min_total_reward': np.float32(4.166667), 'average_n_step': np.float32(7.9), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09656369648873805), 'actor_loss': np.float64(-0.9080411911010742), 'hyper_actor_loss': np.float64(0.012559275794774293), 'behavior_loss': np.float64(1.6485820412635803)}
step: 3350 @ episode report: {'average_total_reward': np.float32(6.682223), 'reward_variance': np.float32(1.7950672), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(8.1), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09888423308730125), 'actor_loss': np.float64(-0.9102816760540009), 'hyper_actor_loss': np.float64(0.01206801738590002), 'behavior_loss': np.float64(1.6374873280525208)}
step: 3360 @ episode report: {'average_total_reward': np.float32(6.145556), 'reward_variance': np.float32(0.51494944), 'max_total_reward': np.float32(7.6555557), 'min_total_reward': np.float32(5.288889), 'average_n_step': np.float32(7.6), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09720731973648071), 'actor_loss': np.float64(-0.918950480222702), 'hyper_actor_loss': np.float64(0.011267486680299043), 'behavior_loss': np.float64(1.643638801574707)}
step: 3370 @ episode report: {'average_total_reward': np.float32(6.2944446), 'reward_variance': np.float32(2.3127723), 'max_total_reward': np.float32(8.900002), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(7.7), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10489671006798744), 'actor_loss': np.float64(-0.9346432983875275), 'hyper_actor_loss': np.float64(0.01113807549700141), 'behavior_loss': np.float64(1.8397605895996094)}
step: 3380 @ episode report: {'average_total_reward': np.float32(6.2822223), 'reward_variance': np.float32(1.6733382), 'max_total_reward': np.float32(8.533333), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(7.7), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10174028277397155), 'actor_loss': np.float64(-0.9360570907592773), 'hyper_actor_loss': np.float64(0.010691321082413196), 'behavior_loss': np.float64(1.8103615283966064)}
step: 3390 @ episode report: {'average_total_reward': np.float32(6.321111), 'reward_variance': np.float32(1.6691717), 'max_total_reward': np.float32(8.655556), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(7.8), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10939762517809867), 'actor_loss': np.float64(-0.9621552348136901), 'hyper_actor_loss': np.float64(0.01087065041065216), 'behavior_loss': np.float64(1.8839013218879699)}
step: 3400 @ episode report: {'average_total_reward': np.float32(7.0944443), 'reward_variance': np.float32(2.5418086), 'max_total_reward': np.float32(9.9), 'min_total_reward': np.float32(5.2888885), 'average_n_step': np.float32(8.5), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09685591012239456), 'actor_loss': np.float64(-0.9530457258224487), 'hyper_actor_loss': np.float64(0.011069837119430303), 'behavior_loss': np.float64(1.7386348962783813)}
step: 3410 @ episode report: {'average_total_reward': np.float32(6.3066664), 'reward_variance': np.float32(2.735437), 'max_total_reward': np.float32(9.777778), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.7), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08288772255182267), 'actor_loss': np.float64(-0.9228837311267852), 'hyper_actor_loss': np.float64(0.01145491497591138), 'behavior_loss': np.float64(1.7659491181373597)}
step: 3420 @ episode report: {'average_total_reward': np.float32(6.9311113), 'reward_variance': np.float32(3.537847), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(3.4111114), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.1081812970340252), 'actor_loss': np.float64(-0.9527904450893402), 'hyper_actor_loss': np.float64(0.011591962818056346), 'behavior_loss': np.float64(1.6773830771446228)}
step: 3430 @ episode report: {'average_total_reward': np.float32(6.6700006), 'reward_variance': np.float32(2.142199), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(8.1), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09779067188501359), 'actor_loss': np.float64(-0.9263197183609009), 'hyper_actor_loss': np.float64(0.011660492047667503), 'behavior_loss': np.float64(1.8647297143936157)}
step: 3440 @ episode report: {'average_total_reward': np.float32(6.794445), 'reward_variance': np.float32(1.9557594), 'max_total_reward': np.float32(9.655557), 'min_total_reward': np.float32(5.288889), 'average_n_step': np.float32(8.2), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08997727185487747), 'actor_loss': np.float64(-0.9412630319595336), 'hyper_actor_loss': np.float64(0.011730899568647146), 'behavior_loss': np.float64(1.683675730228424)}
step: 3450 @ episode report: {'average_total_reward': np.float32(7.055556), 'reward_variance': np.float32(2.3542473), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08755319751799107), 'actor_loss': np.float64(-0.9527000665664673), 'hyper_actor_loss': np.float64(0.012041037995368242), 'behavior_loss': np.float64(1.569700050354004)}
step: 3460 @ episode report: {'average_total_reward': np.float32(7.667779), 'reward_variance': np.float32(3.224851), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(9.0), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10009824559092521), 'actor_loss': np.float64(-0.9661704182624817), 'hyper_actor_loss': np.float64(0.012284009717404842), 'behavior_loss': np.float64(1.7246853351593017)}
step: 3470 @ episode report: {'average_total_reward': np.float32(7.316667), 'reward_variance': np.float32(1.2756851), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10767882689833641), 'actor_loss': np.float64(-0.9541949987411499), 'hyper_actor_loss': np.float64(0.01269629243761301), 'behavior_loss': np.float64(1.7121493816375732)}
step: 3480 @ episode report: {'average_total_reward': np.float32(7.1800003), 'reward_variance': np.float32(0.9561434), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(8.5), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.1016418308019638), 'actor_loss': np.float64(-0.9462600469589233), 'hyper_actor_loss': np.float64(0.012959011737257243), 'behavior_loss': np.float64(1.6778053402900697)}
step: 3490 @ episode report: {'average_total_reward': np.float32(6.3944445), 'reward_variance': np.float32(1.2261049), 'max_total_reward': np.float32(7.777778), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(7.8), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10911628156900406), 'actor_loss': np.float64(-0.9167653620243073), 'hyper_actor_loss': np.float64(0.013151604402810334), 'behavior_loss': np.float64(1.8070833921432494)}
step: 3500 @ episode report: {'average_total_reward': np.float32(6.7188897), 'reward_variance': np.float32(3.0117302), 'max_total_reward': np.float32(9.900002), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.1), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10469367280602455), 'actor_loss': np.float64(-0.9557181835174561), 'hyper_actor_loss': np.float64(0.013330927304923534), 'behavior_loss': np.float64(1.8383395314216613)}
step: 3510 @ episode report: {'average_total_reward': np.float32(6.467778), 'reward_variance': np.float32(2.0256162), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(7.8), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10957811549305915), 'actor_loss': np.float64(-0.9388185799121856), 'hyper_actor_loss': np.float64(0.012993668671697378), 'behavior_loss': np.float64(1.814522886276245)}
step: 3520 @ episode report: {'average_total_reward': np.float32(7.0311112), 'reward_variance': np.float32(1.9871557), 'max_total_reward': np.float32(8.777778), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09958667233586312), 'actor_loss': np.float64(-0.9466268122196198), 'hyper_actor_loss': np.float64(0.01254446543753147), 'behavior_loss': np.float64(1.7835349798202516)}
step: 3530 @ episode report: {'average_total_reward': np.float32(6.518889), 'reward_variance': np.float32(2.5362232), 'max_total_reward': np.float32(9.777778), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.9), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10616127923130989), 'actor_loss': np.float64(-0.9715279638767242), 'hyper_actor_loss': np.float64(0.01204102486371994), 'behavior_loss': np.float64(1.762698245048523)}
step: 3540 @ episode report: {'average_total_reward': np.float32(6.6066666), 'reward_variance': np.float32(1.1896347), 'max_total_reward': np.float32(7.777778), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.0), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.1124176800251007), 'actor_loss': np.float64(-0.9702205181121826), 'hyper_actor_loss': np.float64(0.011866080854088069), 'behavior_loss': np.float64(1.6712029576301575)}
step: 3550 @ episode report: {'average_total_reward': np.float32(7.055556), 'reward_variance': np.float32(1.574173), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09886038154363633), 'actor_loss': np.float64(-0.9810581505298615), 'hyper_actor_loss': np.float64(0.011620242055505514), 'behavior_loss': np.float64(1.735885000228882)}
step: 3560 @ episode report: {'average_total_reward': np.float32(6.4433336), 'reward_variance': np.float32(1.7854191), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.8), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09209963604807854), 'actor_loss': np.float64(-0.9034643530845642), 'hyper_actor_loss': np.float64(0.012045438773930073), 'behavior_loss': np.float64(1.8214439511299134)}
step: 3570 @ episode report: {'average_total_reward': np.float32(7.492223), 'reward_variance': np.float32(1.5364206), 'max_total_reward': np.float32(9.777778), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(8.8), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09565875753760338), 'actor_loss': np.float64(-0.906687980890274), 'hyper_actor_loss': np.float64(0.011877212207764387), 'behavior_loss': np.float64(1.8256433606147766)}
step: 3580 @ episode report: {'average_total_reward': np.float32(6.6066666), 'reward_variance': np.float32(1.1806719), 'max_total_reward': np.float32(7.7777786), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.0), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10094833150506019), 'actor_loss': np.float64(-0.9376501619815827), 'hyper_actor_loss': np.float64(0.011575668770819902), 'behavior_loss': np.float64(1.9142463088035584)}
step: 3590 @ episode report: {'average_total_reward': np.float32(5.857778), 'reward_variance': np.float32(1.063082), 'max_total_reward': np.float32(7.7777786), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(7.3), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10210254862904548), 'actor_loss': np.float64(-0.8944116473197937), 'hyper_actor_loss': np.float64(0.011198758520185948), 'behavior_loss': np.float64(1.7428508758544923)}
step: 3600 @ episode report: {'average_total_reward': np.float32(6.27), 'reward_variance': np.float32(2.425705), 'max_total_reward': np.float32(8.777778), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(7.7), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10207372009754181), 'actor_loss': np.float64(-0.9372596800327301), 'hyper_actor_loss': np.float64(0.010744328796863555), 'behavior_loss': np.float64(1.8853995680809021)}
step: 3610 @ episode report: {'average_total_reward': np.float32(6.1211114), 'reward_variance': np.float32(3.7443557), 'max_total_reward': np.float32(9.777777), 'min_total_reward': np.float32(3.411111), 'average_n_step': np.float32(7.6), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10991686582565308), 'actor_loss': np.float64(-0.9275790810585022), 'hyper_actor_loss': np.float64(0.010356789175420999), 'behavior_loss': np.float64(1.9055718421936034)}
step: 3620 @ episode report: {'average_total_reward': np.float32(7.0311112), 'reward_variance': np.float32(0.9472294), 'max_total_reward': np.float32(8.655556), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10291747003793716), 'actor_loss': np.float64(-0.9781077384948731), 'hyper_actor_loss': np.float64(0.010207338444888591), 'behavior_loss': np.float64(1.7248695969581604)}
step: 3630 @ episode report: {'average_total_reward': np.float32(5.9822226), 'reward_variance': np.float32(1.3296843), 'max_total_reward': np.float32(7.777778), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(7.4), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10687037110328675), 'actor_loss': np.float64(-0.9130025625228881), 'hyper_actor_loss': np.float64(0.010559391789138317), 'behavior_loss': np.float64(1.7933650493621827)}
step: 3640 @ episode report: {'average_total_reward': np.float32(6.7066665), 'reward_variance': np.float32(1.5108693), 'max_total_reward': np.float32(8.655556), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.1), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09928165897727012), 'actor_loss': np.float64(-0.9651824474334717), 'hyper_actor_loss': np.float64(0.011129019036889076), 'behavior_loss': np.float64(1.8900224447250367)}
step: 3650 @ episode report: {'average_total_reward': np.float32(6.1577783), 'reward_variance': np.float32(0.49834076), 'max_total_reward': np.float32(7.777778), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(7.6), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09176231622695923), 'actor_loss': np.float64(-0.9064579427242279), 'hyper_actor_loss': np.float64(0.011805720906704665), 'behavior_loss': np.float64(1.8761938095092774)}
step: 3660 @ episode report: {'average_total_reward': np.float32(7.194444), 'reward_variance': np.float32(2.8128464), 'max_total_reward': np.float32(11.022223), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07950348369777202), 'actor_loss': np.float64(-0.9296350598335266), 'hyper_actor_loss': np.float64(0.012236387748271228), 'behavior_loss': np.float64(1.8801252841949463)}
step: 3670 @ episode report: {'average_total_reward': np.float32(7.0700006), 'reward_variance': np.float32(2.7107925), 'max_total_reward': np.float32(9.900002), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.5), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09768772348761559), 'actor_loss': np.float64(-0.9447811722755433), 'hyper_actor_loss': np.float64(0.012772602122277021), 'behavior_loss': np.float64(1.842496132850647)}
step: 3680 @ episode report: {'average_total_reward': np.float32(7.443334), 'reward_variance': np.float32(1.818826), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(8.8), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.11123507395386696), 'actor_loss': np.float64(-0.9879153072834015), 'hyper_actor_loss': np.float64(0.01348033370450139), 'behavior_loss': np.float64(1.960041606426239)}
step: 3690 @ episode report: {'average_total_reward': np.float32(7.1433334), 'reward_variance': np.float32(2.12095), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(5.288889), 'average_n_step': np.float32(8.5), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09783496633172035), 'actor_loss': np.float64(-0.9540544927120209), 'hyper_actor_loss': np.float64(0.014421585761010648), 'behavior_loss': np.float64(1.7118605852127076)}
step: 3700 @ episode report: {'average_total_reward': np.float32(7.2555556), 'reward_variance': np.float32(2.1327903), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08818217664957047), 'actor_loss': np.float64(-0.9499906659126282), 'hyper_actor_loss': np.float64(0.014968611020594835), 'behavior_loss': np.float64(1.8439070582389832)}
step: 3710 @ episode report: {'average_total_reward': np.float32(7.2555556), 'reward_variance': np.float32(2.0914083), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(5.2888885), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10303376093506814), 'actor_loss': np.float64(-0.9546579480171203), 'hyper_actor_loss': np.float64(0.015062970481812954), 'behavior_loss': np.float64(1.8334047079086304)}
step: 3720 @ episode report: {'average_total_reward': np.float32(6.918889), 'reward_variance': np.float32(1.2486184), 'max_total_reward': np.float32(8.9), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.1098415769636631), 'actor_loss': np.float64(-1.0051311135292054), 'hyper_actor_loss': np.float64(0.014940571039915085), 'behavior_loss': np.float64(1.768101978302002)}
step: 3730 @ episode report: {'average_total_reward': np.float32(7.9411116), 'reward_variance': np.float32(3.6142726), 'max_total_reward': np.float32(10.900001), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(9.2), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.1077342040836811), 'actor_loss': np.float64(-0.9518525183200837), 'hyper_actor_loss': np.float64(0.014280109480023385), 'behavior_loss': np.float64(1.8274929404258728)}
step: 3740 @ episode report: {'average_total_reward': np.float32(6.7211113), 'reward_variance': np.float32(1.6240852), 'max_total_reward': np.float32(8.533334), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.2), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09710652977228165), 'actor_loss': np.float64(-0.9307234883308411), 'hyper_actor_loss': np.float64(0.013385837618261575), 'behavior_loss': np.float64(1.9669955611228942)}
step: 3750 @ episode report: {'average_total_reward': np.float32(7.1922226), 'reward_variance': np.float32(1.6424452), 'max_total_reward': np.float32(9.9), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(8.5), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09654879495501519), 'actor_loss': np.float64(-0.9316401541233063), 'hyper_actor_loss': np.float64(0.012808927334845066), 'behavior_loss': np.float64(1.90042964220047)}
step: 3760 @ episode report: {'average_total_reward': np.float32(7.78), 'reward_variance': np.float32(2.4291804), 'max_total_reward': np.float32(10.9), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.1), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10026921406388282), 'actor_loss': np.float64(-0.9602168321609497), 'hyper_actor_loss': np.float64(0.012686486076563596), 'behavior_loss': np.float64(2.149006116390228)}
step: 3770 @ episode report: {'average_total_reward': np.float32(7.0800004), 'reward_variance': np.float32(2.18597), 'max_total_reward': np.float32(9.9), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10151400417089462), 'actor_loss': np.float64(-0.9088052392005921), 'hyper_actor_loss': np.float64(0.01258367756381631), 'behavior_loss': np.float64(2.050432229042053)}
step: 3780 @ episode report: {'average_total_reward': np.float32(6.2822223), 'reward_variance': np.float32(1.580079), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(7.7), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10633886605501175), 'actor_loss': np.float64(-0.9644688189029693), 'hyper_actor_loss': np.float64(0.012985457945615054), 'behavior_loss': np.float64(2.201034462451935)}
step: 3790 @ episode report: {'average_total_reward': np.float32(7.1066675), 'reward_variance': np.float32(2.6241531), 'max_total_reward': np.float32(9.777779), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.5), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09753255620598793), 'actor_loss': np.float64(-0.9453819811344146), 'hyper_actor_loss': np.float64(0.012693012040108443), 'behavior_loss': np.float64(1.9284406900405884)}
step: 3800 @ episode report: {'average_total_reward': np.float32(7.4044447), 'reward_variance': np.float32(4.0928683), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(8.7), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10322174429893494), 'actor_loss': np.float64(-0.9708306908607482), 'hyper_actor_loss': np.float64(0.012828746624290944), 'behavior_loss': np.float64(1.8841200947761536)}
step: 3810 @ episode report: {'average_total_reward': np.float32(7.8044443), 'reward_variance': np.float32(1.346178), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(5.411111), 'average_n_step': np.float32(9.1), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08935541659593582), 'actor_loss': np.float64(-0.9195713937282562), 'hyper_actor_loss': np.float64(0.01275159902870655), 'behavior_loss': np.float64(2.093666434288025)}
step: 3820 @ episode report: {'average_total_reward': np.float32(6.4944444), 'reward_variance': np.float32(1.9578333), 'max_total_reward': np.float32(8.533333), 'min_total_reward': np.float32(3.411111), 'average_n_step': np.float32(7.9), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10550491139292717), 'actor_loss': np.float64(-0.9519269526004791), 'hyper_actor_loss': np.float64(0.012782469484955072), 'behavior_loss': np.float64(1.973112905025482)}
step: 3830 @ episode report: {'average_total_reward': np.float32(6.257778), 'reward_variance': np.float32(2.1872053), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(7.7), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09835689961910248), 'actor_loss': np.float64(-0.9271777391433715), 'hyper_actor_loss': np.float64(0.01256299577653408), 'behavior_loss': np.float64(2.1051852345466613)}
step: 3840 @ episode report: {'average_total_reward': np.float32(6.406667), 'reward_variance': np.float32(1.7241039), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.8), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10631690695881843), 'actor_loss': np.float64(-0.9835103929042817), 'hyper_actor_loss': np.float64(0.012697675079107285), 'behavior_loss': np.float64(1.9754111170768738)}
step: 3850 @ episode report: {'average_total_reward': np.float32(6.8944445), 'reward_variance': np.float32(1.2074878), 'max_total_reward': np.float32(7.7777777), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09679218642413616), 'actor_loss': np.float64(-0.9614261507987976), 'hyper_actor_loss': np.float64(0.012751005031168461), 'behavior_loss': np.float64(2.0031798124313354)}
step: 3860 @ episode report: {'average_total_reward': np.float32(6.8433332), 'reward_variance': np.float32(2.6450734), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(8.2), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10761672034859657), 'actor_loss': np.float64(-1.003825694322586), 'hyper_actor_loss': np.float64(0.013079501129686833), 'behavior_loss': np.float64(1.9599796772003173)}
step: 3870 @ episode report: {'average_total_reward': np.float32(6.406667), 'reward_variance': np.float32(1.1285483), 'max_total_reward': np.float32(8.655556), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(7.8), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09601248651742936), 'actor_loss': np.float64(-0.9463086545467376), 'hyper_actor_loss': np.float64(0.012742174882441759), 'behavior_loss': np.float64(2.0068376302719115)}
step: 3880 @ episode report: {'average_total_reward': np.float32(7.067778), 'reward_variance': np.float32(1.8420607), 'max_total_reward': np.float32(8.900002), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10066491365432739), 'actor_loss': np.float64(-0.9221215665340423), 'hyper_actor_loss': np.float64(0.013012906443327666), 'behavior_loss': np.float64(1.9580352663993836)}
step: 3890 @ episode report: {'average_total_reward': np.float32(7.455556), 'reward_variance': np.float32(2.611408), 'max_total_reward': np.float32(9.900002), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(8.8), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10587713345885277), 'actor_loss': np.float64(-0.9747801303863526), 'hyper_actor_loss': np.float64(0.012447815481573343), 'behavior_loss': np.float64(2.11003041267395)}
step: 3900 @ episode report: {'average_total_reward': np.float32(6.9433336), 'reward_variance': np.float32(3.291542), 'max_total_reward': np.float32(9.777778), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08678979948163032), 'actor_loss': np.float64(-0.940639442205429), 'hyper_actor_loss': np.float64(0.012056405842304229), 'behavior_loss': np.float64(1.9471355199813842)}
step: 3910 @ episode report: {'average_total_reward': np.float32(7.4800005), 'reward_variance': np.float32(1.8864149), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.8), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09759869500994682), 'actor_loss': np.float64(-0.969790643453598), 'hyper_actor_loss': np.float64(0.012108115572482347), 'behavior_loss': np.float64(2.1053018450736998)}
step: 3920 @ episode report: {'average_total_reward': np.float32(7.0311117), 'reward_variance': np.float32(3.0964153), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09929735362529754), 'actor_loss': np.float64(-0.9575856626033783), 'hyper_actor_loss': np.float64(0.012316887080669404), 'behavior_loss': np.float64(2.043703520298004)}
step: 3930 @ episode report: {'average_total_reward': np.float32(7.3433332), 'reward_variance': np.float32(2.0604055), 'max_total_reward': np.float32(8.777778), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.7), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10278294160962105), 'actor_loss': np.float64(-0.9770667910575866), 'hyper_actor_loss': np.float64(0.012361844722181558), 'behavior_loss': np.float64(2.051603841781616)}
step: 3940 @ episode report: {'average_total_reward': np.float32(6.231111), 'reward_variance': np.float32(1.3206124), 'max_total_reward': np.float32(7.6555557), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(7.6), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10093010514974594), 'actor_loss': np.float64(-0.9504400968551636), 'hyper_actor_loss': np.float64(0.012130493763834238), 'behavior_loss': np.float64(2.2507097482681275)}
step: 3950 @ episode report: {'average_total_reward': np.float32(6.967778), 'reward_variance': np.float32(1.8085301), 'max_total_reward': np.float32(9.777778), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09393704049289227), 'actor_loss': np.float64(-0.9371017873287201), 'hyper_actor_loss': np.float64(0.012209896743297578), 'behavior_loss': np.float64(2.1989560604095457)}
step: 3960 @ episode report: {'average_total_reward': np.float32(6.6922226), 'reward_variance': np.float32(3.7648158), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(3.4111114), 'average_n_step': np.float32(8.0), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09003214538097382), 'actor_loss': np.float64(-0.9383653342723847), 'hyper_actor_loss': np.float64(0.012299723085016012), 'behavior_loss': np.float64(2.1407353401184084)}
step: 3970 @ episode report: {'average_total_reward': np.float32(7.455556), 'reward_variance': np.float32(2.2957041), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(8.8), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10502601936459541), 'actor_loss': np.float64(-0.9542508780956268), 'hyper_actor_loss': np.float64(0.0122163200750947), 'behavior_loss': np.float64(2.1458826065063477)}
step: 3980 @ episode report: {'average_total_reward': np.float32(6.7822227), 'reward_variance': np.float32(0.73751146), 'max_total_reward': np.float32(7.7777786), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(8.2), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09131437242031097), 'actor_loss': np.float64(-0.9233269691467285), 'hyper_actor_loss': np.float64(0.012932796496897936), 'behavior_loss': np.float64(2.233921205997467)}
step: 3990 @ episode report: {'average_total_reward': np.float32(6.8188896), 'reward_variance': np.float32(3.1484466), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.2), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10462269335985183), 'actor_loss': np.float64(-0.9831256926059723), 'hyper_actor_loss': np.float64(0.01345239169895649), 'behavior_loss': np.float64(2.237104618549347)}
step: 4000 @ episode report: {'average_total_reward': np.float32(6.545556), 'reward_variance': np.float32(1.9903822), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.0), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09734714403748512), 'actor_loss': np.float64(-0.9076876640319824), 'hyper_actor_loss': np.float64(0.0128969794139266), 'behavior_loss': np.float64(2.263696014881134)}
step: 4010 @ episode report: {'average_total_reward': np.float32(6.8822227), 'reward_variance': np.float32(3.2725976), 'max_total_reward': np.float32(9.9), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10584346912801265), 'actor_loss': np.float64(-0.9879575550556183), 'hyper_actor_loss': np.float64(0.012422244343906642), 'behavior_loss': np.float64(2.243857181072235)}
step: 4020 @ episode report: {'average_total_reward': np.float32(6.9944444), 'reward_variance': np.float32(1.906105), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.411111), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09022896103560925), 'actor_loss': np.float64(-0.903047513961792), 'hyper_actor_loss': np.float64(0.011327620130032301), 'behavior_loss': np.float64(2.201269268989563)}
step: 4030 @ episode report: {'average_total_reward': np.float32(6.37), 'reward_variance': np.float32(1.0386436), 'max_total_reward': np.float32(7.655556), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(7.8), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09542313292622566), 'actor_loss': np.float64(-0.9744322240352631), 'hyper_actor_loss': np.float64(0.010496775712817907), 'behavior_loss': np.float64(2.123712694644928)}
step: 4040 @ episode report: {'average_total_reward': np.float32(6.594445), 'reward_variance': np.float32(1.5593641), 'max_total_reward': np.float32(8.777778), 'min_total_reward': np.float32(4.411112), 'average_n_step': np.float32(8.0), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08882136158645153), 'actor_loss': np.float64(-0.9505168735980988), 'hyper_actor_loss': np.float64(0.00917108291760087), 'behavior_loss': np.float64(2.2492119431495667)}
step: 4050 @ episode report: {'average_total_reward': np.float32(6.745556), 'reward_variance': np.float32(2.786406), 'max_total_reward': np.float32(8.9), 'min_total_reward': np.float32(3.288889), 'average_n_step': np.float32(8.2), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10101454220712185), 'actor_loss': np.float64(-0.9388625383377075), 'hyper_actor_loss': np.float64(0.009006747417151928), 'behavior_loss': np.float64(2.2659266352653504)}
step: 4060 @ episode report: {'average_total_reward': np.float32(6.8188887), 'reward_variance': np.float32(6.655261), 'max_total_reward': np.float32(11.022223), 'min_total_reward': np.float32(3.4111114), 'average_n_step': np.float32(8.2), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10192016288638114), 'actor_loss': np.float64(-0.9723938584327698), 'hyper_actor_loss': np.float64(0.008701580297201871), 'behavior_loss': np.float64(2.2056081295013428)}
step: 4070 @ episode report: {'average_total_reward': np.float32(7.3922224), 'reward_variance': np.float32(2.5434089), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(8.7), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0997992530465126), 'actor_loss': np.float64(-0.9466830968856812), 'hyper_actor_loss': np.float64(0.00866908933967352), 'behavior_loss': np.float64(2.21013799905777)}
step: 4080 @ episode report: {'average_total_reward': np.float32(6.8333335), 'reward_variance': np.float32(2.7880745), 'max_total_reward': np.float32(9.777778), 'min_total_reward': np.float32(4.1666665), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09281901195645333), 'actor_loss': np.float64(-0.9671257376670838), 'hyper_actor_loss': np.float64(0.009311403427273036), 'behavior_loss': np.float64(2.3383276224136353)}
step: 4090 @ episode report: {'average_total_reward': np.float32(6.8677773), 'reward_variance': np.float32(2.3440356), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.2), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10229086354374886), 'actor_loss': np.float64(-0.9593328952789306), 'hyper_actor_loss': np.float64(0.010137540102005006), 'behavior_loss': np.float64(2.2992671251297)}
step: 4100 @ episode report: {'average_total_reward': np.float32(8.202223), 'reward_variance': np.float32(3.8009834), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.4), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09376278482377529), 'actor_loss': np.float64(-0.9978220403194428), 'hyper_actor_loss': np.float64(0.01135683637112379), 'behavior_loss': np.float64(2.2787046790122987)}
step: 4110 @ episode report: {'average_total_reward': np.float32(7.9677787), 'reward_variance': np.float32(4.1008515), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(5.288889), 'average_n_step': np.float32(9.3), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09442805051803589), 'actor_loss': np.float64(-0.9430685758590698), 'hyper_actor_loss': np.float64(0.01280400026589632), 'behavior_loss': np.float64(2.285397481918335)}
step: 4120 @ episode report: {'average_total_reward': np.float32(7.38), 'reward_variance': np.float32(2.2864408), 'max_total_reward': np.float32(11.022224), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(8.7), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10017073675990104), 'actor_loss': np.float64(-0.9958623766899108), 'hyper_actor_loss': np.float64(0.014002441056072712), 'behavior_loss': np.float64(2.232887363433838)}
step: 4130 @ episode report: {'average_total_reward': np.float32(6.6433334), 'reward_variance': np.float32(2.4163568), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(3.2888892), 'average_n_step': np.float32(8.0), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10023289993405342), 'actor_loss': np.float64(-0.9721092164516449), 'hyper_actor_loss': np.float64(0.014717854745686054), 'behavior_loss': np.float64(2.269693684577942)}
step: 4140 @ episode report: {'average_total_reward': np.float32(6.6066666), 'reward_variance': np.float32(1.0065728), 'max_total_reward': np.float32(8.655556), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(8.0), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10323721319437026), 'actor_loss': np.float64(-0.9605162560939788), 'hyper_actor_loss': np.float64(0.015868019964545965), 'behavior_loss': np.float64(2.0891300201416017)}
step: 4150 @ episode report: {'average_total_reward': np.float32(7.2555556), 'reward_variance': np.float32(1.6075798), 'max_total_reward': np.float32(10.022222), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10381081104278564), 'actor_loss': np.float64(-1.0083229780197143), 'hyper_actor_loss': np.float64(0.017655358463525773), 'behavior_loss': np.float64(2.402464199066162)}
step: 4160 @ episode report: {'average_total_reward': np.float32(5.335555), 'reward_variance': np.float32(1.1715999), 'max_total_reward': np.float32(7.7777777), 'min_total_reward': np.float32(3.288889), 'average_n_step': np.float32(6.9), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10612455829977989), 'actor_loss': np.float64(-1.080329704284668), 'hyper_actor_loss': np.float64(0.02211693823337555), 'behavior_loss': np.float64(2.1065141558647156)}
step: 4170 @ episode report: {'average_total_reward': np.float32(3.4500003), 'reward_variance': np.float32(0.30894446), 'max_total_reward': np.float32(4.4111114), 'min_total_reward': np.float32(2.288889), 'average_n_step': np.float32(5.1), 'max_n_step': np.float32(6.0), 'min_n_step': np.float32(4.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10236390456557273), 'actor_loss': np.float64(-1.3671956419944764), 'hyper_actor_loss': np.float64(0.03033082578331232), 'behavior_loss': np.float64(1.6649402141571046)}
step: 4180 @ episode report: {'average_total_reward': np.float32(4.1744447), 'reward_variance': np.float32(0.65521127), 'max_total_reward': np.float32(5.533334), 'min_total_reward': np.float32(3.288889), 'average_n_step': np.float32(5.8), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10233928523957729), 'actor_loss': np.float64(-1.5386653184890746), 'hyper_actor_loss': np.float64(0.04067598059773445), 'behavior_loss': np.float64(1.5404892683029174)}
step: 4190 @ episode report: {'average_total_reward': np.float32(3.8622222), 'reward_variance': np.float32(1.0271409), 'max_total_reward': np.float32(5.6555557), 'min_total_reward': np.float32(2.0444446), 'average_n_step': np.float32(5.5), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(4.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10116417109966278), 'actor_loss': np.float64(-1.4476410031318665), 'hyper_actor_loss': np.float64(0.049252279475331305), 'behavior_loss': np.float64(1.476413869857788)}
step: 4200 @ episode report: {'average_total_reward': np.float32(3.7155557), 'reward_variance': np.float32(0.3427705), 'max_total_reward': np.float32(5.166667), 'min_total_reward': np.float32(3.1666667), 'average_n_step': np.float32(5.5), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.1087893195450306), 'actor_loss': np.float64(-1.3752469301223755), 'hyper_actor_loss': np.float64(0.05728829316794872), 'behavior_loss': np.float64(1.211335289478302)}
step: 4210 @ episode report: {'average_total_reward': np.float32(2.5544443), 'reward_variance': np.float32(0.15578893), 'max_total_reward': np.float32(3.288889), 'min_total_reward': np.float32(2.1666665), 'average_n_step': np.float32(4.4), 'max_n_step': np.float32(5.0), 'min_n_step': np.float32(4.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10716996043920517), 'actor_loss': np.float64(-1.467644500732422), 'hyper_actor_loss': np.float64(0.06407138966023922), 'behavior_loss': np.float64(0.9764006018638611)}
step: 4220 @ episode report: {'average_total_reward': np.float32(1.5344445), 'reward_variance': np.float32(0.1677395), 'max_total_reward': np.float32(2.288889), 'min_total_reward': np.float32(1.0444444), 'average_n_step': np.float32(3.6), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08658047467470169), 'actor_loss': np.float64(-1.5279937148094178), 'hyper_actor_loss': np.float64(0.065849918872118), 'behavior_loss': np.float64(0.8482878863811493)}
step: 4230 @ episode report: {'average_total_reward': np.float32(0.87333333), 'reward_variance': np.float32(0.03644939), 'max_total_reward': np.float32(1.1666667), 'min_total_reward': np.float32(0.5555556), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(3.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10627427399158478), 'actor_loss': np.float64(-1.4414923191070557), 'hyper_actor_loss': np.float64(0.06480872705578804), 'behavior_loss': np.float64(0.7361684024333954)}
step: 4240 @ episode report: {'average_total_reward': np.float32(0.16555554), 'reward_variance': np.float32(0.043838274), 'max_total_reward': np.float32(0.5555556), 'min_total_reward': np.float32(-0.20000002), 'average_n_step': np.float32(2.5), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.13052943274378775), 'actor_loss': np.float64(-1.2573691964149476), 'hyper_actor_loss': np.float64(0.06343553811311722), 'behavior_loss': np.float64(0.6790271997451782)}
step: 4250 @ episode report: {'average_total_reward': np.float32(0.23888886), 'reward_variance': np.float32(0.08370988), 'max_total_reward': np.float32(0.79999995), 'min_total_reward': np.float32(-0.07777779), 'average_n_step': np.float32(2.5), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.12716061547398566), 'actor_loss': np.float64(-0.5936624974012374), 'hyper_actor_loss': np.float64(0.0631713043898344), 'behavior_loss': np.float64(0.6112317442893982)}
step: 4260 @ episode report: {'average_total_reward': np.float32(0.64111114), 'reward_variance': np.float32(0.08380372), 'max_total_reward': np.float32(1.0444446), 'min_total_reward': np.float32(0.3111111), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(3.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09874292947351933), 'actor_loss': np.float64(-0.8043553471565247), 'hyper_actor_loss': np.float64(0.060813768208026885), 'behavior_loss': np.float64(0.6321784853935242)}
step: 4270 @ episode report: {'average_total_reward': np.float32(1.2466667), 'reward_variance': np.float32(0.23955064), 'max_total_reward': np.float32(2.2888892), 'min_total_reward': np.float32(0.6777779), 'average_n_step': np.float32(3.3), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0897217832505703), 'actor_loss': np.float64(-0.8921907365322113), 'hyper_actor_loss': np.float64(0.058610791340470314), 'behavior_loss': np.float64(0.6216698408126831)}
step: 4280 @ episode report: {'average_total_reward': np.float32(1.2488891), 'reward_variance': np.float32(0.1949679), 'max_total_reward': np.float32(1.9222223), 'min_total_reward': np.float32(0.79999995), 'average_n_step': np.float32(3.4), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08967634290456772), 'actor_loss': np.float64(-0.827280443906784), 'hyper_actor_loss': np.float64(0.05662606842815876), 'behavior_loss': np.float64(0.6292793214321136)}
step: 4290 @ episode report: {'average_total_reward': np.float32(1.958889), 'reward_variance': np.float32(0.5916308), 'max_total_reward': np.float32(3.4111109), 'min_total_reward': np.float32(0.6777778), 'average_n_step': np.float32(4.0), 'max_n_step': np.float32(5.0), 'min_n_step': np.float32(3.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08870884478092193), 'actor_loss': np.float64(-0.8496049106121063), 'hyper_actor_loss': np.float64(0.05453013144433498), 'behavior_loss': np.float64(0.6794405043125152)}
step: 4300 @ episode report: {'average_total_reward': np.float32(2.766667), 'reward_variance': np.float32(0.48834568), 'max_total_reward': np.float32(4.288889), 'min_total_reward': np.float32(2.0444446), 'average_n_step': np.float32(4.6), 'max_n_step': np.float32(6.0), 'min_n_step': np.float32(4.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08764345347881317), 'actor_loss': np.float64(-0.9223357796669006), 'hyper_actor_loss': np.float64(0.05266254059970379), 'behavior_loss': np.float64(0.7058583319187164)}
step: 4310 @ episode report: {'average_total_reward': np.float32(2.3422225), 'reward_variance': np.float32(0.17760003), 'max_total_reward': np.float32(3.4111114), 'min_total_reward': np.float32(1.9222223), 'average_n_step': np.float32(4.2), 'max_n_step': np.float32(5.0), 'min_n_step': np.float32(4.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09814826026558876), 'actor_loss': np.float64(-0.9535131573677063), 'hyper_actor_loss': np.float64(0.05111182704567909), 'behavior_loss': np.float64(0.7977591693401337)}
step: 4320 @ episode report: {'average_total_reward': np.float32(2.5688891), 'reward_variance': np.float32(0.8832544), 'max_total_reward': np.float32(4.288889), 'min_total_reward': np.float32(0.8), 'average_n_step': np.float32(4.5), 'max_n_step': np.float32(6.0), 'min_n_step': np.float32(3.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07828943431377411), 'actor_loss': np.float64(-0.9106605648994446), 'hyper_actor_loss': np.float64(0.05055606067180633), 'behavior_loss': np.float64(0.8617164969444275)}
step: 4330 @ episode report: {'average_total_reward': np.float32(2.5811114), 'reward_variance': np.float32(0.4618284), 'max_total_reward': np.float32(4.0444446), 'min_total_reward': np.float32(1.9222223), 'average_n_step': np.float32(4.5), 'max_n_step': np.float32(6.0), 'min_n_step': np.float32(4.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09658264294266701), 'actor_loss': np.float64(-0.9445956885814667), 'hyper_actor_loss': np.float64(0.050174951925873755), 'behavior_loss': np.float64(0.9264850735664367)}
step: 4340 @ episode report: {'average_total_reward': np.float32(3.676667), 'reward_variance': np.float32(0.3054433), 'max_total_reward': np.float32(4.533334), 'min_total_reward': np.float32(3.0444446), 'average_n_step': np.float32(5.4), 'max_n_step': np.float32(6.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08621414825320244), 'actor_loss': np.float64(-0.8980744659900666), 'hyper_actor_loss': np.float64(0.05018735937774181), 'behavior_loss': np.float64(0.994108647108078)}
step: 4350 @ episode report: {'average_total_reward': np.float32(4.186667), 'reward_variance': np.float32(0.39199513), 'max_total_reward': np.float32(5.533334), 'min_total_reward': np.float32(3.411111), 'average_n_step': np.float32(5.8), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08671423345804215), 'actor_loss': np.float64(-0.9483416855335236), 'hyper_actor_loss': np.float64(0.051302208378911016), 'behavior_loss': np.float64(1.018638050556183)}
step: 4360 @ episode report: {'average_total_reward': np.float32(5.9577775), 'reward_variance': np.float32(1.5370817), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.4), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09432843849062919), 'actor_loss': np.float64(-0.9195187389850616), 'hyper_actor_loss': np.float64(0.05111732594668865), 'behavior_loss': np.float64(1.149388349056244)}
step: 4370 @ episode report: {'average_total_reward': np.float32(8.265556), 'reward_variance': np.float32(3.5713692), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(9.5), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09663445949554443), 'actor_loss': np.float64(-0.9329168736934662), 'hyper_actor_loss': np.float64(0.048585842922329904), 'behavior_loss': np.float64(1.2268148183822631)}
step: 4380 @ episode report: {'average_total_reward': np.float32(8.887778), 'reward_variance': np.float32(3.2512956), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.0), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09528054445981979), 'actor_loss': np.float64(-0.9239796936511994), 'hyper_actor_loss': np.float64(0.04449036121368408), 'behavior_loss': np.float64(1.3819907784461976)}
step: 4390 @ episode report: {'average_total_reward': np.float32(8.204445), 'reward_variance': np.float32(1.1189435), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(6.5333333), 'average_n_step': np.float32(9.5), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08815336301922798), 'actor_loss': np.float64(-0.9078457355499268), 'hyper_actor_loss': np.float64(0.0400348786264658), 'behavior_loss': np.float64(1.3975378751754761)}
step: 4400 @ episode report: {'average_total_reward': np.float32(8.1044445), 'reward_variance': np.float32(3.3676095), 'max_total_reward': np.float32(10.777778), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(9.4), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08455256298184395), 'actor_loss': np.float64(-0.933534836769104), 'hyper_actor_loss': np.float64(0.0352848544716835), 'behavior_loss': np.float64(1.452060091495514)}
step: 4410 @ episode report: {'average_total_reward': np.float32(8.153334), 'reward_variance': np.float32(2.1058476), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(9.4), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08774136342108249), 'actor_loss': np.float64(-0.9293901860713959), 'hyper_actor_loss': np.float64(0.03090268075466156), 'behavior_loss': np.float64(1.6527408361434937)}
step: 4420 @ episode report: {'average_total_reward': np.float32(9.451112), 'reward_variance': np.float32(4.4070673), 'max_total_reward': np.float32(13.144444), 'min_total_reward': np.float32(6.5333333), 'average_n_step': np.float32(10.6), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.095327477902174), 'actor_loss': np.float64(-0.9368855237960816), 'hyper_actor_loss': np.float64(0.027881213277578355), 'behavior_loss': np.float64(1.6623038291931151)}
step: 4430 @ episode report: {'average_total_reward': np.float32(8.204445), 'reward_variance': np.float32(0.93289393), 'max_total_reward': np.float32(9.777779), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(9.5), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10228797867894172), 'actor_loss': np.float64(-0.9454318165779114), 'hyper_actor_loss': np.float64(0.025805096514523028), 'behavior_loss': np.float64(1.703144097328186)}
step: 4440 @ episode report: {'average_total_reward': np.float32(8.777779), 'reward_variance': np.float32(2.840445), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.0), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09407705441117287), 'actor_loss': np.float64(-0.9634635865688324), 'hyper_actor_loss': np.float64(0.023888576962053775), 'behavior_loss': np.float64(1.7225586533546449)}
step: 4450 @ episode report: {'average_total_reward': np.float32(8.714445), 'reward_variance': np.float32(2.0391622), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(9.9), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0819141186773777), 'actor_loss': np.float64(-0.8944907486438751), 'hyper_actor_loss': np.float64(0.022445685975253583), 'behavior_loss': np.float64(1.8331543684005738)}
step: 4460 @ episode report: {'average_total_reward': np.float32(8.875555), 'reward_variance': np.float32(2.4662914), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.0), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0972585417330265), 'actor_loss': np.float64(-0.9679140448570251), 'hyper_actor_loss': np.float64(0.02118565794080496), 'behavior_loss': np.float64(1.853458285331726)}
step: 4470 @ episode report: {'average_total_reward': np.float32(8.016667), 'reward_variance': np.float32(2.4195125), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(9.3), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08453030623495579), 'actor_loss': np.float64(-0.9265939354896545), 'hyper_actor_loss': np.float64(0.019787408411502838), 'behavior_loss': np.float64(1.8127821326255797)}
step: 4480 @ episode report: {'average_total_reward': np.float32(7.928889), 'reward_variance': np.float32(1.1113379), 'max_total_reward': np.float32(9.9), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(9.2), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09110616520047188), 'actor_loss': np.float64(-0.9216897130012512), 'hyper_actor_loss': np.float64(0.017838801629841326), 'behavior_loss': np.float64(1.8395151138305663)}
step: 4490 @ episode report: {'average_total_reward': np.float32(8.4388895), 'reward_variance': np.float32(3.8877113), 'max_total_reward': np.float32(12.266668), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.6), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10076583251357078), 'actor_loss': np.float64(-0.9811138808727264), 'hyper_actor_loss': np.float64(0.016052223462611436), 'behavior_loss': np.float64(1.893499529361725)}
step: 4500 @ episode report: {'average_total_reward': np.float32(7.9411116), 'reward_variance': np.float32(1.7469151), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(9.2), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08863478973507881), 'actor_loss': np.float64(-0.9246405303478241), 'hyper_actor_loss': np.float64(0.014497632067650557), 'behavior_loss': np.float64(1.9188524961471558)}
step: 4510 @ episode report: {'average_total_reward': np.float32(8.626667), 'reward_variance': np.float32(1.5033628), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(6.655556), 'average_n_step': np.float32(9.8), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09375023394823075), 'actor_loss': np.float64(-0.9714014232158661), 'hyper_actor_loss': np.float64(0.013347030431032181), 'behavior_loss': np.float64(1.9657287001609802)}
step: 4520 @ episode report: {'average_total_reward': np.float32(7.1800003), 'reward_variance': np.float32(0.98357505), 'max_total_reward': np.float32(8.9), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(8.5), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.1033881239593029), 'actor_loss': np.float64(-0.9291890442371369), 'hyper_actor_loss': np.float64(0.012166780047118663), 'behavior_loss': np.float64(2.0339904189109803)}
step: 4530 @ episode report: {'average_total_reward': np.float32(7.2555556), 'reward_variance': np.float32(1.4839004), 'max_total_reward': np.float32(10.022222), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0959940031170845), 'actor_loss': np.float64(-0.9469612538814545), 'hyper_actor_loss': np.float64(0.011709072068333626), 'behavior_loss': np.float64(2.04833208322525)}
step: 4540 @ episode report: {'average_total_reward': np.float32(7.9800005), 'reward_variance': np.float32(2.2461433), 'max_total_reward': np.float32(11.022223), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(9.3), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09076762571930885), 'actor_loss': np.float64(-0.9077489256858826), 'hyper_actor_loss': np.float64(0.01092075351625681), 'behavior_loss': np.float64(2.1432384252548218)}
step: 4550 @ episode report: {'average_total_reward': np.float32(7.4288893), 'reward_variance': np.float32(4.7534375), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(3.4111114), 'average_n_step': np.float32(8.7), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0808191180229187), 'actor_loss': np.float64(-0.9646200001239776), 'hyper_actor_loss': np.float64(0.01072116643190384), 'behavior_loss': np.float64(2.0076420068740846)}
step: 4560 @ episode report: {'average_total_reward': np.float32(7.8288894), 'reward_variance': np.float32(3.2525487), 'max_total_reward': np.float32(11.022223), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(9.1), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09270388633012772), 'actor_loss': np.float64(-0.9537958264350891), 'hyper_actor_loss': np.float64(0.010268368013203143), 'behavior_loss': np.float64(2.057032859325409)}
step: 4570 @ episode report: {'average_total_reward': np.float32(7.0166674), 'reward_variance': np.float32(4.9921556), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(3.4111114), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10425925105810166), 'actor_loss': np.float64(-0.958416473865509), 'hyper_actor_loss': np.float64(0.009984381031244993), 'behavior_loss': np.float64(2.447680687904358)}
step: 4580 @ episode report: {'average_total_reward': np.float32(8.1044445), 'reward_variance': np.float32(2.1157322), 'max_total_reward': np.float32(11.022222), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.4), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09266477525234222), 'actor_loss': np.float64(-0.9425197005271911), 'hyper_actor_loss': np.float64(0.009971248731017113), 'behavior_loss': np.float64(2.2548773527145385)}
step: 4590 @ episode report: {'average_total_reward': np.float32(7.5166674), 'reward_variance': np.float32(5.409241), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.8), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08536890670657157), 'actor_loss': np.float64(-0.9511505603790283), 'hyper_actor_loss': np.float64(0.009883857984095811), 'behavior_loss': np.float64(2.184362518787384)}
step: 4600 @ episode report: {'average_total_reward': np.float32(7.6922235), 'reward_variance': np.float32(1.3019025), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(6.2888894), 'average_n_step': np.float32(9.0), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0993525356054306), 'actor_loss': np.float64(-0.9902603507041932), 'hyper_actor_loss': np.float64(0.009839963167905807), 'behavior_loss': np.float64(2.21732382774353)}
step: 4610 @ episode report: {'average_total_reward': np.float32(8.341112), 'reward_variance': np.float32(3.208891), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(9.6), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.11105536818504333), 'actor_loss': np.float64(-0.9660284459590912), 'hyper_actor_loss': np.float64(0.009500935953110457), 'behavior_loss': np.float64(2.17423529624939)}
step: 4620 @ episode report: {'average_total_reward': np.float32(6.6433334), 'reward_variance': np.float32(1.3050973), 'max_total_reward': np.float32(8.777778), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(8.0), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08932631462812424), 'actor_loss': np.float64(-0.927755069732666), 'hyper_actor_loss': np.float64(0.009482892230153084), 'behavior_loss': np.float64(2.3247575044631956)}
step: 4630 @ episode report: {'average_total_reward': np.float32(7.5433335), 'reward_variance': np.float32(1.5816902), 'max_total_reward': np.float32(9.655556), 'min_total_reward': np.float32(5.288889), 'average_n_step': np.float32(8.9), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08741684630513191), 'actor_loss': np.float64(-0.934154611825943), 'hyper_actor_loss': np.float64(0.009409698750823736), 'behavior_loss': np.float64(2.359821248054504)}
step: 4640 @ episode report: {'average_total_reward': np.float32(6.967778), 'reward_variance': np.float32(4.8036165), 'max_total_reward': np.float32(11.0222225), 'min_total_reward': np.float32(4.411112), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09531694054603576), 'actor_loss': np.float64(-0.9539050757884979), 'hyper_actor_loss': np.float64(0.009257206693291664), 'behavior_loss': np.float64(2.3504693269729615)}
step: 4650 @ episode report: {'average_total_reward': np.float32(7.6800013), 'reward_variance': np.float32(3.400465), 'max_total_reward': np.float32(11.0222225), 'min_total_reward': np.float32(5.411111), 'average_n_step': np.float32(9.0), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0791063578799367), 'actor_loss': np.float64(-0.9157944977283478), 'hyper_actor_loss': np.float64(0.009576385095715522), 'behavior_loss': np.float64(2.3041127800941466)}
step: 4660 @ episode report: {'average_total_reward': np.float32(8.177778), 'reward_variance': np.float32(2.7068896), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.4), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10395648404955864), 'actor_loss': np.float64(-0.9922063946723938), 'hyper_actor_loss': np.float64(0.009721554908901453), 'behavior_loss': np.float64(2.150192129611969)}
step: 4670 @ episode report: {'average_total_reward': np.float32(7.9655557), 'reward_variance': np.float32(2.6989484), 'max_total_reward': np.float32(11.022222), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.2), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08528936542570591), 'actor_loss': np.float64(-0.9793677270412445), 'hyper_actor_loss': np.float64(0.00961155453696847), 'behavior_loss': np.float64(2.185708236694336)}
step: 4680 @ episode report: {'average_total_reward': np.float32(7.304445), 'reward_variance': np.float32(1.6413136), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10556772202253342), 'actor_loss': np.float64(-0.9865764498710632), 'hyper_actor_loss': np.float64(0.009604998771101237), 'behavior_loss': np.float64(2.2633816957473756)}
step: 4690 @ episode report: {'average_total_reward': np.float32(7.204444), 'reward_variance': np.float32(2.8286717), 'max_total_reward': np.float32(10.022222), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.5), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09158833883702755), 'actor_loss': np.float64(-0.9399330615997314), 'hyper_actor_loss': np.float64(0.009603017941117287), 'behavior_loss': np.float64(2.369928503036499)}
step: 4700 @ episode report: {'average_total_reward': np.float32(7.1555557), 'reward_variance': np.float32(2.870988), 'max_total_reward': np.float32(9.777778), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(8.5), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.1052088513970375), 'actor_loss': np.float64(-0.9626002013683319), 'hyper_actor_loss': np.float64(0.009869437478482724), 'behavior_loss': np.float64(2.4101229190826414)}
step: 4710 @ episode report: {'average_total_reward': np.float32(7.5800004), 'reward_variance': np.float32(3.1486871), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(8.9), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08836750090122222), 'actor_loss': np.float64(-0.9403839707374573), 'hyper_actor_loss': np.float64(0.009850827697664499), 'behavior_loss': np.float64(2.267162036895752)}
step: 4720 @ episode report: {'average_total_reward': np.float32(7.0800004), 'reward_variance': np.float32(1.199921), 'max_total_reward': np.float32(8.9), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07963314652442932), 'actor_loss': np.float64(-0.9156887292861938), 'hyper_actor_loss': np.float64(0.009609358571469783), 'behavior_loss': np.float64(2.2618597030639647)}
step: 4730 @ episode report: {'average_total_reward': np.float32(6.9311113), 'reward_variance': np.float32(0.79011875), 'max_total_reward': np.float32(7.7777786), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.1041012778878212), 'actor_loss': np.float64(-0.9749060094356536), 'hyper_actor_loss': np.float64(0.009436630923300982), 'behavior_loss': np.float64(2.1327061891555785)}
step: 4740 @ episode report: {'average_total_reward': np.float32(7.967778), 'reward_variance': np.float32(2.8798623), 'max_total_reward': np.float32(9.9), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(9.3), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08923860006034375), 'actor_loss': np.float64(-0.9363182604312896), 'hyper_actor_loss': np.float64(0.009161569830030202), 'behavior_loss': np.float64(2.2236571431159975)}
step: 4750 @ episode report: {'average_total_reward': np.float32(7.2922225), 'reward_variance': np.float32(0.8585197), 'max_total_reward': np.float32(8.9), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09499431774020195), 'actor_loss': np.float64(-0.9619360864162445), 'hyper_actor_loss': np.float64(0.009036448784172535), 'behavior_loss': np.float64(2.4109049081802367)}
step: 4760 @ episode report: {'average_total_reward': np.float32(6.9311113), 'reward_variance': np.float32(2.0450568), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08231346830725669), 'actor_loss': np.float64(-0.9556121170520783), 'hyper_actor_loss': np.float64(0.008920655120164156), 'behavior_loss': np.float64(2.310381555557251)}
step: 4770 @ episode report: {'average_total_reward': np.float32(7.0922227), 'reward_variance': np.float32(1.415335), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08662466369569302), 'actor_loss': np.float64(-0.9508047580718995), 'hyper_actor_loss': np.float64(0.008834791462868452), 'behavior_loss': np.float64(2.182893443107605)}
step: 4780 @ episode report: {'average_total_reward': np.float32(6.3700004), 'reward_variance': np.float32(0.6630878), 'max_total_reward': np.float32(7.6555567), 'min_total_reward': np.float32(5.288889), 'average_n_step': np.float32(7.8), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09786761105060578), 'actor_loss': np.float64(-0.9871228039264679), 'hyper_actor_loss': np.float64(0.008933070860803128), 'behavior_loss': np.float64(2.294252407550812)}
step: 4790 @ episode report: {'average_total_reward': np.float32(7.492223), 'reward_variance': np.float32(2.7683713), 'max_total_reward': np.float32(10.9), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(8.8), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08176215924322605), 'actor_loss': np.float64(-0.9748595476150512), 'hyper_actor_loss': np.float64(0.009020519908517599), 'behavior_loss': np.float64(2.1543057203292846)}
step: 4800 @ episode report: {'average_total_reward': np.float32(7.504445), 'reward_variance': np.float32(4.1782274), 'max_total_reward': np.float32(12.144444), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.8), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09240080267190934), 'actor_loss': np.float64(-0.9320030331611633), 'hyper_actor_loss': np.float64(0.009210899006575346), 'behavior_loss': np.float64(2.3082958102226256)}
step: 4810 @ episode report: {'average_total_reward': np.float32(6.4066668), 'reward_variance': np.float32(1.7545239), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(7.8), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08924246951937675), 'actor_loss': np.float64(-0.9782218337059021), 'hyper_actor_loss': np.float64(0.009481625352054834), 'behavior_loss': np.float64(2.2529278993606567)}
step: 4820 @ episode report: {'average_total_reward': np.float32(7.1555557), 'reward_variance': np.float32(3.4206417), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.5), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09340493381023407), 'actor_loss': np.float64(-0.9512404561042785), 'hyper_actor_loss': np.float64(0.009425495378673076), 'behavior_loss': np.float64(2.200134539604187)}
step: 4830 @ episode report: {'average_total_reward': np.float32(7.2555556), 'reward_variance': np.float32(1.948272), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09216374009847642), 'actor_loss': np.float64(-0.9861165404319763), 'hyper_actor_loss': np.float64(0.009357935842126608), 'behavior_loss': np.float64(2.3046958208084107)}
step: 4840 @ episode report: {'average_total_reward': np.float32(6.9944444), 'reward_variance': np.float32(1.7424997), 'max_total_reward': np.float32(8.9), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08782911747694015), 'actor_loss': np.float64(-0.9361362516880035), 'hyper_actor_loss': np.float64(0.009430419933050872), 'behavior_loss': np.float64(2.1908345222473145)}
step: 4850 @ episode report: {'average_total_reward': np.float32(7.182223), 'reward_variance': np.float32(1.6777089), 'max_total_reward': np.float32(9.777778), 'min_total_reward': np.float32(5.288889), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10135288909077644), 'actor_loss': np.float64(-0.9923248887062073), 'hyper_actor_loss': np.float64(0.009412035346031189), 'behavior_loss': np.float64(2.190815496444702)}
step: 4860 @ episode report: {'average_total_reward': np.float32(6.4333334), 'reward_variance': np.float32(0.7812592), 'max_total_reward': np.float32(7.777778), 'min_total_reward': np.float32(5.288889), 'average_n_step': np.float32(7.9), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09784755222499371), 'actor_loss': np.float64(-0.9531318008899688), 'hyper_actor_loss': np.float64(0.009069743007421494), 'behavior_loss': np.float64(2.215849959850311)}
step: 4870 @ episode report: {'average_total_reward': np.float32(7.204445), 'reward_variance': np.float32(1.9618574), 'max_total_reward': np.float32(8.900002), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.5), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08958167061209679), 'actor_loss': np.float64(-0.9307655394077301), 'hyper_actor_loss': np.float64(0.009292559698224068), 'behavior_loss': np.float64(2.2850651502609254)}
step: 4880 @ episode report: {'average_total_reward': np.float32(7.38), 'reward_variance': np.float32(1.1123412), 'max_total_reward': np.float32(8.9), 'min_total_reward': np.float32(5.533333), 'average_n_step': np.float32(8.7), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09083211272954941), 'actor_loss': np.float64(-0.9847256004810333), 'hyper_actor_loss': np.float64(0.009342050086706877), 'behavior_loss': np.float64(2.2254660725593567)}
step: 4890 @ episode report: {'average_total_reward': np.float32(6.8822227), 'reward_variance': np.float32(2.498499), 'max_total_reward': np.float32(9.9), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10247440859675408), 'actor_loss': np.float64(-0.9538584768772125), 'hyper_actor_loss': np.float64(0.009483123011887074), 'behavior_loss': np.float64(2.37701735496521)}
step: 4900 @ episode report: {'average_total_reward': np.float32(7.0555563), 'reward_variance': np.float32(1.3771609), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08749728687107564), 'actor_loss': np.float64(-0.9693285584449768), 'hyper_actor_loss': np.float64(0.009532917104661465), 'behavior_loss': np.float64(2.1343676686286925)}
step: 4910 @ episode report: {'average_total_reward': np.float32(7.216667), 'reward_variance': np.float32(4.106945), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.5), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10366158038377762), 'actor_loss': np.float64(-0.9644304513931274), 'hyper_actor_loss': np.float64(0.009578893892467022), 'behavior_loss': np.float64(2.2579703450202944)}
step: 4920 @ episode report: {'average_total_reward': np.float32(6.482222), 'reward_variance': np.float32(3.7104015), 'max_total_reward': np.float32(11.022223), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(7.9), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08971863649785519), 'actor_loss': np.float64(-0.9576635897159577), 'hyper_actor_loss': np.float64(0.009320820774883031), 'behavior_loss': np.float64(2.321039307117462)}
step: 4930 @ episode report: {'average_total_reward': np.float32(6.6211114), 'reward_variance': np.float32(1.3820604), 'max_total_reward': np.float32(7.777778), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.1), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09257758036255836), 'actor_loss': np.float64(-0.9338232755661011), 'hyper_actor_loss': np.float64(0.00890228347852826), 'behavior_loss': np.float64(2.0069863557815553)}
step: 4940 @ episode report: {'average_total_reward': np.float32(7.767778), 'reward_variance': np.float32(0.8230729), 'max_total_reward': np.float32(8.900002), 'min_total_reward': np.float32(6.533334), 'average_n_step': np.float32(9.1), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09041729792952538), 'actor_loss': np.float64(-0.9655650734901429), 'hyper_actor_loss': np.float64(0.008491757418960333), 'behavior_loss': np.float64(2.2436669945716856)}
step: 4950 @ episode report: {'average_total_reward': np.float32(6.494445), 'reward_variance': np.float32(2.7847962), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(3.2888892), 'average_n_step': np.float32(7.9), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08310501500964165), 'actor_loss': np.float64(-0.9438883900642395), 'hyper_actor_loss': np.float64(0.008353145606815816), 'behavior_loss': np.float64(2.1218374609947204)}
step: 4960 @ episode report: {'average_total_reward': np.float32(8.031111), 'reward_variance': np.float32(0.9686861), 'max_total_reward': np.float32(9.777778), 'min_total_reward': np.float32(6.533334), 'average_n_step': np.float32(9.4), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08198372125625611), 'actor_loss': np.float64(-0.944393390417099), 'hyper_actor_loss': np.float64(0.008192900568246841), 'behavior_loss': np.float64(2.2991034984588623)}
step: 4970 @ episode report: {'average_total_reward': np.float32(7.3433332), 'reward_variance': np.float32(1.3870736), 'max_total_reward': np.float32(9.900002), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(8.7), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09024928137660027), 'actor_loss': np.float64(-0.9474231243133545), 'hyper_actor_loss': np.float64(0.008096609916538), 'behavior_loss': np.float64(2.105288290977478)}
step: 4980 @ episode report: {'average_total_reward': np.float32(7.4800005), 'reward_variance': np.float32(2.5323162), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.8), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09295142441987991), 'actor_loss': np.float64(-0.9795817613601685), 'hyper_actor_loss': np.float64(0.007892247708514332), 'behavior_loss': np.float64(2.203853416442871)}
step: 4990 @ episode report: {'average_total_reward': np.float32(7.0311112), 'reward_variance': np.float32(1.3028595), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(5.288889), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09951476082205772), 'actor_loss': np.float64(-0.9709925472736358), 'hyper_actor_loss': np.float64(0.007833837484940886), 'behavior_loss': np.float64(2.2644250273704527)}
step: 5000 @ episode report: {'average_total_reward': np.float32(7.9555564), 'reward_variance': np.float32(3.141704), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(5.2888894), 'average_n_step': np.float32(9.3), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09837659709155559), 'actor_loss': np.float64(-0.9671863973140716), 'hyper_actor_loss': np.float64(0.00780714894644916), 'behavior_loss': np.float64(2.2533801317214968)}
step: 5010 @ episode report: {'average_total_reward': np.float32(6.7066665), 'reward_variance': np.float32(1.4375359), 'max_total_reward': np.float32(7.7777786), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.1), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08880983628332614), 'actor_loss': np.float64(-0.9712605476379395), 'hyper_actor_loss': np.float64(0.008025831682607532), 'behavior_loss': np.float64(2.3337872982025147)}
step: 5020 @ episode report: {'average_total_reward': np.float32(7.804445), 'reward_variance': np.float32(1.3521534), 'max_total_reward': np.float32(9.9), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(9.1), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0972595602273941), 'actor_loss': np.float64(-1.0030785083770752), 'hyper_actor_loss': np.float64(0.007985912542790175), 'behavior_loss': np.float64(2.0493743896484373)}
step: 5030 @ episode report: {'average_total_reward': np.float32(6.406667), 'reward_variance': np.float32(3.6488438), 'max_total_reward': np.float32(10.022222), 'min_total_reward': np.float32(4.2888894), 'average_n_step': np.float32(7.8), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0867395255714655), 'actor_loss': np.float64(-0.9417831659317016), 'hyper_actor_loss': np.float64(0.00802228688262403), 'behavior_loss': np.float64(2.29699649810791)}
step: 5040 @ episode report: {'average_total_reward': np.float32(7.767778), 'reward_variance': np.float32(2.085443), 'max_total_reward': np.float32(9.9), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(9.1), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09156254529953003), 'actor_loss': np.float64(-0.9579882562160492), 'hyper_actor_loss': np.float64(0.00817216276191175), 'behavior_loss': np.float64(2.2432274341583254)}
step: 5050 @ episode report: {'average_total_reward': np.float32(8.004445), 'reward_variance': np.float32(1.7259312), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.3), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08726256005465985), 'actor_loss': np.float64(-0.9570637881755829), 'hyper_actor_loss': np.float64(0.00809858194552362), 'behavior_loss': np.float64(2.241141378879547)}
step: 5060 @ episode report: {'average_total_reward': np.float32(6.967778), 'reward_variance': np.float32(1.1870726), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08878805935382843), 'actor_loss': np.float64(-0.94573974609375), 'hyper_actor_loss': np.float64(0.007949027698487043), 'behavior_loss': np.float64(2.2161449790000916)}
step: 5070 @ episode report: {'average_total_reward': np.float32(7.231112), 'reward_variance': np.float32(4.212933), 'max_total_reward': np.float32(11.0222225), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09165254049003124), 'actor_loss': np.float64(-0.975087147951126), 'hyper_actor_loss': np.float64(0.0078105215914547445), 'behavior_loss': np.float64(2.2268995523452757)}
step: 5080 @ episode report: {'average_total_reward': np.float32(7.2555556), 'reward_variance': np.float32(2.8500247), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(4.166667), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08633729070425034), 'actor_loss': np.float64(-0.9407809257507325), 'hyper_actor_loss': np.float64(0.007682247646152973), 'behavior_loss': np.float64(2.2846311688423158)}
step: 5090 @ episode report: {'average_total_reward': np.float32(7.167778), 'reward_variance': np.float32(1.0251718), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(8.5), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0815892443060875), 'actor_loss': np.float64(-0.9591027796268463), 'hyper_actor_loss': np.float64(0.007425494538620114), 'behavior_loss': np.float64(2.2234209775924683)}
step: 5100 @ episode report: {'average_total_reward': np.float32(7.5922227), 'reward_variance': np.float32(3.243681), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(8.9), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0824727799743414), 'actor_loss': np.float64(-0.893687903881073), 'hyper_actor_loss': np.float64(0.007373525202274323), 'behavior_loss': np.float64(2.4584221839904785)}
step: 5110 @ episode report: {'average_total_reward': np.float32(7.492223), 'reward_variance': np.float32(0.8326683), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(8.8), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08257106728851796), 'actor_loss': np.float64(-0.9582851886749267), 'hyper_actor_loss': np.float64(0.007150418683886528), 'behavior_loss': np.float64(2.22859468460083)}
step: 5120 @ episode report: {'average_total_reward': np.float32(7.3433332), 'reward_variance': np.float32(3.7287517), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.7), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08745074570178986), 'actor_loss': np.float64(-0.9475855648517608), 'hyper_actor_loss': np.float64(0.006845340179279446), 'behavior_loss': np.float64(2.1371578931808473)}
step: 5130 @ episode report: {'average_total_reward': np.float32(8.626668), 'reward_variance': np.float32(2.6285732), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.8), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09693792909383774), 'actor_loss': np.float64(-0.9787240743637085), 'hyper_actor_loss': np.float64(0.006844258867204189), 'behavior_loss': np.float64(2.1597466826438905)}
step: 5140 @ episode report: {'average_total_reward': np.float32(7.731111), 'reward_variance': np.float32(1.5077732), 'max_total_reward': np.float32(9.777779), 'min_total_reward': np.float32(6.411112), 'average_n_step': np.float32(9.1), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09801902398467063), 'actor_loss': np.float64(-0.9787960946559906), 'hyper_actor_loss': np.float64(0.006690349150449038), 'behavior_loss': np.float64(2.1262477159500124)}
step: 5150 @ episode report: {'average_total_reward': np.float32(6.694444), 'reward_variance': np.float32(1.2979815), 'max_total_reward': np.float32(8.9), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(8.1), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.1014115571975708), 'actor_loss': np.float64(-0.9703691303730011), 'hyper_actor_loss': np.float64(0.006645349226891995), 'behavior_loss': np.float64(2.190416693687439)}
step: 5160 @ episode report: {'average_total_reward': np.float32(6.6433334), 'reward_variance': np.float32(2.454752), 'max_total_reward': np.float32(8.655556), 'min_total_reward': np.float32(3.4111114), 'average_n_step': np.float32(8.0), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09116137847304344), 'actor_loss': np.float64(-0.9860096931457519), 'hyper_actor_loss': np.float64(0.0067615334410220385), 'behavior_loss': np.float64(2.181508457660675)}
step: 5170 @ episode report: {'average_total_reward': np.float32(7.406667), 'reward_variance': np.float32(2.6473138), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.8), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0829742819070816), 'actor_loss': np.float64(-0.9289034843444824), 'hyper_actor_loss': np.float64(0.006969090038910508), 'behavior_loss': np.float64(2.225834381580353)}
step: 5180 @ episode report: {'average_total_reward': np.float32(6.9311113), 'reward_variance': np.float32(2.4285884), 'max_total_reward': np.float32(10.777779), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09303383901715279), 'actor_loss': np.float64(-0.9755825340747833), 'hyper_actor_loss': np.float64(0.0069811788853257895), 'behavior_loss': np.float64(2.1834095239639284)}
step: 5190 @ episode report: {'average_total_reward': np.float32(6.6433334), 'reward_variance': np.float32(2.1096158), 'max_total_reward': np.float32(8.9), 'min_total_reward': np.float32(3.4111114), 'average_n_step': np.float32(8.0), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07631616890430451), 'actor_loss': np.float64(-0.9508253812789917), 'hyper_actor_loss': np.float64(0.006906062783673406), 'behavior_loss': np.float64(2.08651340007782)}
step: 5200 @ episode report: {'average_total_reward': np.float32(7.267778), 'reward_variance': np.float32(2.7848263), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0776911959052086), 'actor_loss': np.float64(-0.9318839192390442), 'hyper_actor_loss': np.float64(0.007037172187119722), 'behavior_loss': np.float64(2.3141022682189942)}
step: 5210 @ episode report: {'average_total_reward': np.float32(7.567778), 'reward_variance': np.float32(1.9177644), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.2888885), 'average_n_step': np.float32(8.9), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09908500984311104), 'actor_loss': np.float64(-0.9632302343845367), 'hyper_actor_loss': np.float64(0.007023813435807824), 'behavior_loss': np.float64(2.290378451347351)}
step: 5220 @ episode report: {'average_total_reward': np.float32(5.908889), 'reward_variance': np.float32(0.7197977), 'max_total_reward': np.float32(7.533334), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.4), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08094923943281174), 'actor_loss': np.float64(-0.9878319084644318), 'hyper_actor_loss': np.float64(0.0072452562861144544), 'behavior_loss': np.float64(2.152928555011749)}
step: 5230 @ episode report: {'average_total_reward': np.float32(5.957778), 'reward_variance': np.float32(2.7231307), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.4), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0912245538085699), 'actor_loss': np.float64(-0.9496020972728729), 'hyper_actor_loss': np.float64(0.0075304304715245966), 'behavior_loss': np.float64(2.15970139503479)}
step: 5240 @ episode report: {'average_total_reward': np.float32(6.5944443), 'reward_variance': np.float32(1.5653397), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.0), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09772785417735577), 'actor_loss': np.float64(-1.0041091799736024), 'hyper_actor_loss': np.float64(0.007916902005672456), 'behavior_loss': np.float64(2.1446119785308837)}
step: 5250 @ episode report: {'average_total_reward': np.float32(6.131111), 'reward_variance': np.float32(2.836983), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(3.4111114), 'average_n_step': np.float32(7.5), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.1089427188038826), 'actor_loss': np.float64(-0.9750523924827575), 'hyper_actor_loss': np.float64(0.007978110667318105), 'behavior_loss': np.float64(2.0648785829544067)}
step: 5260 @ episode report: {'average_total_reward': np.float32(5.7966666), 'reward_variance': np.float32(1.778273), 'max_total_reward': np.float32(8.655557), 'min_total_reward': np.float32(4.411112), 'average_n_step': np.float32(7.3), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08619283325970173), 'actor_loss': np.float64(-0.9787283778190613), 'hyper_actor_loss': np.float64(0.007410433329641819), 'behavior_loss': np.float64(2.081016421318054)}
step: 5270 @ episode report: {'average_total_reward': np.float32(5.608889), 'reward_variance': np.float32(2.6329832), 'max_total_reward': np.float32(8.655556), 'min_total_reward': np.float32(3.2888892), 'average_n_step': np.float32(7.1), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09212172329425812), 'actor_loss': np.float64(-0.9455339312553406), 'hyper_actor_loss': np.float64(0.006993946991860867), 'behavior_loss': np.float64(2.106428587436676)}
step: 5280 @ episode report: {'average_total_reward': np.float32(7.3922224), 'reward_variance': np.float32(1.1388901), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.655556), 'average_n_step': np.float32(8.7), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09458834230899811), 'actor_loss': np.float64(-0.9826349318027496), 'hyper_actor_loss': np.float64(0.006739474786445499), 'behavior_loss': np.float64(2.298987329006195)}
step: 5290 @ episode report: {'average_total_reward': np.float32(7.4044447), 'reward_variance': np.float32(2.5571666), 'max_total_reward': np.float32(11.022223), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(8.7), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09349721893668175), 'actor_loss': np.float64(-0.9538196146488189), 'hyper_actor_loss': np.float64(0.006631285045295953), 'behavior_loss': np.float64(2.2710883021354675)}
step: 5300 @ episode report: {'average_total_reward': np.float32(7.5800004), 'reward_variance': np.float32(1.5411808), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(8.9), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09898583739995956), 'actor_loss': np.float64(-0.9921302735805512), 'hyper_actor_loss': np.float64(0.006731851911172271), 'behavior_loss': np.float64(2.1919861316680906)}
step: 5310 @ episode report: {'average_total_reward': np.float32(8.041112), 'reward_variance': np.float32(2.483557), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(9.3), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08550203703343869), 'actor_loss': np.float64(-0.965691864490509), 'hyper_actor_loss': np.float64(0.006787934899330139), 'behavior_loss': np.float64(2.3436213731765747)}
step: 5320 @ episode report: {'average_total_reward': np.float32(7.1800003), 'reward_variance': np.float32(3.6858718), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.5), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08859035298228264), 'actor_loss': np.float64(-0.9704318284988404), 'hyper_actor_loss': np.float64(0.006977139273658395), 'behavior_loss': np.float64(2.066022515296936)}
step: 5330 @ episode report: {'average_total_reward': np.float32(6.831111), 'reward_variance': np.float32(2.562736), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(4.411111), 'average_n_step': np.float32(8.2), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09085589274764061), 'actor_loss': np.float64(-0.9566067516803741), 'hyper_actor_loss': np.float64(0.0069053396582603455), 'behavior_loss': np.float64(2.169937551021576)}
step: 5340 @ episode report: {'average_total_reward': np.float32(5.8333335), 'reward_variance': np.float32(1.3656303), 'max_total_reward': np.float32(7.6555567), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.3), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09016365557909012), 'actor_loss': np.float64(-0.9783848226070404), 'hyper_actor_loss': np.float64(0.00694528422318399), 'behavior_loss': np.float64(2.218833565711975)}
step: 5350 @ episode report: {'average_total_reward': np.float32(6.082223), 'reward_variance': np.float32(0.7328941), 'max_total_reward': np.float32(7.7777786), 'min_total_reward': np.float32(5.411111), 'average_n_step': np.float32(7.5), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08932600729167461), 'actor_loss': np.float64(-0.9552706420421601), 'hyper_actor_loss': np.float64(0.0068514843005687), 'behavior_loss': np.float64(2.2511242032051086)}
step: 5360 @ episode report: {'average_total_reward': np.float32(6.3966665), 'reward_variance': np.float32(2.3845692), 'max_total_reward': np.float32(9.533334), 'min_total_reward': np.float32(4.0444446), 'average_n_step': np.float32(7.9), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09678107500076294), 'actor_loss': np.float64(-0.976602965593338), 'hyper_actor_loss': np.float64(0.006709908787161112), 'behavior_loss': np.float64(2.1912918210029604)}
step: 5370 @ episode report: {'average_total_reward': np.float32(6.406667), 'reward_variance': np.float32(1.4936842), 'max_total_reward': np.float32(7.6555567), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.8), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.1030995074659586), 'actor_loss': np.float64(-0.984239250421524), 'hyper_actor_loss': np.float64(0.006505842320621014), 'behavior_loss': np.float64(2.3934963583946227)}
step: 5380 @ episode report: {'average_total_reward': np.float32(6.6433334), 'reward_variance': np.float32(2.0058627), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.0), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08648150712251663), 'actor_loss': np.float64(-0.9483369052410126), 'hyper_actor_loss': np.float64(0.0062213285826146604), 'behavior_loss': np.float64(2.212599277496338)}
step: 5390 @ episode report: {'average_total_reward': np.float32(7.4433336), 'reward_variance': np.float32(2.295147), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.8), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09559364169836045), 'actor_loss': np.float64(-0.9715105831623078), 'hyper_actor_loss': np.float64(0.006254346761852503), 'behavior_loss': np.float64(2.3804135799407957)}
step: 5400 @ episode report: {'average_total_reward': np.float32(6.3333335), 'reward_variance': np.float32(1.6881977), 'max_total_reward': np.float32(7.6555557), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.8), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08765761330723762), 'actor_loss': np.float64(-0.9671577155590058), 'hyper_actor_loss': np.float64(0.006090768286958337), 'behavior_loss': np.float64(2.292309749126434)}
step: 5410 @ episode report: {'average_total_reward': np.float32(6.731111), 'reward_variance': np.float32(4.365699), 'max_total_reward': np.float32(11.0222225), 'min_total_reward': np.float32(2.288889), 'average_n_step': np.float32(8.1), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(4.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08973409980535507), 'actor_loss': np.float64(-0.9614705860614776), 'hyper_actor_loss': np.float64(0.006081239040941), 'behavior_loss': np.float64(2.271225893497467)}
step: 5420 @ episode report: {'average_total_reward': np.float32(6.4066668), 'reward_variance': np.float32(2.9256344), 'max_total_reward': np.float32(8.9), 'min_total_reward': np.float32(3.4111114), 'average_n_step': np.float32(7.8), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09383098594844341), 'actor_loss': np.float64(-0.9744564890861511), 'hyper_actor_loss': np.float64(0.006238578213378787), 'behavior_loss': np.float64(2.2253623604774475)}
step: 5430 @ episode report: {'average_total_reward': np.float32(6.2844443), 'reward_variance': np.float32(2.251758), 'max_total_reward': np.float32(9.777778), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.8), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07880300134420395), 'actor_loss': np.float64(-0.9296978771686554), 'hyper_actor_loss': np.float64(0.006372451549395919), 'behavior_loss': np.float64(2.096859538555145)}
step: 5440 @ episode report: {'average_total_reward': np.float32(6.967778), 'reward_variance': np.float32(3.3197892), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08983958289027213), 'actor_loss': np.float64(-0.9924758493900299), 'hyper_actor_loss': np.float64(0.006078005535528064), 'behavior_loss': np.float64(2.189024496078491)}
step: 5450 @ episode report: {'average_total_reward': np.float32(6.418889), 'reward_variance': np.float32(1.2412611), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.288889), 'average_n_step': np.float32(7.8), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08302700519561768), 'actor_loss': np.float64(-0.9106320202350616), 'hyper_actor_loss': np.float64(0.005960480310022831), 'behavior_loss': np.float64(2.2834051847457886)}
step: 5460 @ episode report: {'average_total_reward': np.float32(6.257778), 'reward_variance': np.float32(1.4390074), 'max_total_reward': np.float32(8.411111), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(7.7), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09125111252069473), 'actor_loss': np.float64(-0.9583502948284149), 'hyper_actor_loss': np.float64(0.005499674286693334), 'behavior_loss': np.float64(2.2806552410125733)}
step: 5470 @ episode report: {'average_total_reward': np.float32(5.9700003), 'reward_variance': np.float32(1.5859028), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.166667), 'average_n_step': np.float32(7.4), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08977479562163353), 'actor_loss': np.float64(-0.9516400992870331), 'hyper_actor_loss': np.float64(0.005329895112663507), 'behavior_loss': np.float64(2.222796368598938)}
step: 5480 @ episode report: {'average_total_reward': np.float32(6.7433333), 'reward_variance': np.float32(2.2384562), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.1), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07747179232537746), 'actor_loss': np.float64(-0.9502037167549133), 'hyper_actor_loss': np.float64(0.005153182614594698), 'behavior_loss': np.float64(2.269876742362976)}
step: 5490 @ episode report: {'average_total_reward': np.float32(6.9822226), 'reward_variance': np.float32(1.6254618), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.2888894), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08525740653276444), 'actor_loss': np.float64(-0.9422394156455993), 'hyper_actor_loss': np.float64(0.005017212172970176), 'behavior_loss': np.float64(2.2372521996498107)}
step: 5500 @ episode report: {'average_total_reward': np.float32(5.496667), 'reward_variance': np.float32(2.0051124), 'max_total_reward': np.float32(7.7777777), 'min_total_reward': np.float32(2.288889), 'average_n_step': np.float32(7.0), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(4.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0852238267660141), 'actor_loss': np.float64(-0.955973482131958), 'hyper_actor_loss': np.float64(0.005095080705359578), 'behavior_loss': np.float64(2.099990200996399)}
step: 5510 @ episode report: {'average_total_reward': np.float32(6.782222), 'reward_variance': np.float32(2.6996593), 'max_total_reward': np.float32(8.655556), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.2), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09188246689736843), 'actor_loss': np.float64(-0.9772739470005035), 'hyper_actor_loss': np.float64(0.00526029928587377), 'behavior_loss': np.float64(2.2350746750831605)}
step: 5520 @ episode report: {'average_total_reward': np.float32(6.457778), 'reward_variance': np.float32(2.1930568), 'max_total_reward': np.float32(8.777778), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(7.9), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08773175850510598), 'actor_loss': np.float64(-0.9524102151393891), 'hyper_actor_loss': np.float64(0.005450737057253718), 'behavior_loss': np.float64(2.3260183811187742)}
step: 5530 @ episode report: {'average_total_reward': np.float32(6.594445), 'reward_variance': np.float32(1.4067225), 'max_total_reward': np.float32(8.533334), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.0), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08642537221312523), 'actor_loss': np.float64(-0.9750611543655395), 'hyper_actor_loss': np.float64(0.005565695697441697), 'behavior_loss': np.float64(2.043013834953308)}
step: 5540 @ episode report: {'average_total_reward': np.float32(6.382222), 'reward_variance': np.float32(0.6943261), 'max_total_reward': np.float32(7.6555557), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(7.8), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08627176657319069), 'actor_loss': np.float64(-0.9693216860294342), 'hyper_actor_loss': np.float64(0.0057006315793842076), 'behavior_loss': np.float64(2.1380730271339417)}
step: 5550 @ episode report: {'average_total_reward': np.float32(6.145556), 'reward_variance': np.float32(1.3364064), 'max_total_reward': np.float32(7.6555567), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(7.6), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08885550945997238), 'actor_loss': np.float64(-0.9454927146434784), 'hyper_actor_loss': np.float64(0.005546657415106892), 'behavior_loss': np.float64(2.2406410336494447)}
step: 5560 @ episode report: {'average_total_reward': np.float32(5.821111), 'reward_variance': np.float32(1.3174431), 'max_total_reward': np.float32(7.777778), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.3), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0791895866394043), 'actor_loss': np.float64(-0.9289752125740052), 'hyper_actor_loss': np.float64(0.005329330824315548), 'behavior_loss': np.float64(2.2819417834281923)}
step: 5570 @ episode report: {'average_total_reward': np.float32(6.582223), 'reward_variance': np.float32(1.8689436), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.0), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08824007138609886), 'actor_loss': np.float64(-0.9444720625877381), 'hyper_actor_loss': np.float64(0.0051097681280225515), 'behavior_loss': np.float64(2.2262492775917053)}
step: 5580 @ episode report: {'average_total_reward': np.float32(6.645556), 'reward_variance': np.float32(1.6594679), 'max_total_reward': np.float32(8.411111), 'min_total_reward': np.float32(4.1666665), 'average_n_step': np.float32(8.1), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0820144072175026), 'actor_loss': np.float64(-0.9698609232902526), 'hyper_actor_loss': np.float64(0.004953892761841416), 'behavior_loss': np.float64(2.0327292680740356)}
step: 5590 @ episode report: {'average_total_reward': np.float32(6.318889), 'reward_variance': np.float32(1.6320512), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(7.7), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08617504462599754), 'actor_loss': np.float64(-0.9444082200527191), 'hyper_actor_loss': np.float64(0.005026012845337391), 'behavior_loss': np.float64(2.021641397476196)}
step: 5600 @ episode report: {'average_total_reward': np.float32(5.708889), 'reward_variance': np.float32(0.95071095), 'max_total_reward': np.float32(7.4111114), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.2), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0829305112361908), 'actor_loss': np.float64(-0.9521668732166291), 'hyper_actor_loss': np.float64(0.005140419257804752), 'behavior_loss': np.float64(2.188681995868683)}
step: 5610 @ episode report: {'average_total_reward': np.float32(5.296667), 'reward_variance': np.float32(0.6796557), 'max_total_reward': np.float32(6.6555567), 'min_total_reward': np.float32(4.2888894), 'average_n_step': np.float32(6.8), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08365161791443824), 'actor_loss': np.float64(-0.9309264838695526), 'hyper_actor_loss': np.float64(0.005238878075033426), 'behavior_loss': np.float64(2.176192510128021)}
step: 5620 @ episode report: {'average_total_reward': np.float32(5.7188888), 'reward_variance': np.float32(0.32790253), 'max_total_reward': np.float32(6.6555557), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.1), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0917057916522026), 'actor_loss': np.float64(-0.9728740632534028), 'hyper_actor_loss': np.float64(0.0051691918168216945), 'behavior_loss': np.float64(2.110115575790405)}
step: 5630 @ episode report: {'average_total_reward': np.float32(6.682223), 'reward_variance': np.float32(1.442425), 'max_total_reward': np.float32(7.7777786), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.1), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08239961043000221), 'actor_loss': np.float64(-0.9565509974956512), 'hyper_actor_loss': np.float64(0.005003121308982372), 'behavior_loss': np.float64(1.999183750152588)}
step: 5640 @ episode report: {'average_total_reward': np.float32(6.4700003), 'reward_variance': np.float32(0.8680507), 'max_total_reward': np.float32(7.7777786), 'min_total_reward': np.float32(5.2888894), 'average_n_step': np.float32(7.9), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08662856370210648), 'actor_loss': np.float64(-0.9649881541728973), 'hyper_actor_loss': np.float64(0.004820520058274269), 'behavior_loss': np.float64(1.9268993973731994)}
step: 5650 @ episode report: {'average_total_reward': np.float32(6.231111), 'reward_variance': np.float32(2.7495756), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(3.4111114), 'average_n_step': np.float32(7.6), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08922635838389396), 'actor_loss': np.float64(-0.9380671918392182), 'hyper_actor_loss': np.float64(0.0044971406925469635), 'behavior_loss': np.float64(2.1987165212631226)}
step: 5660 @ episode report: {'average_total_reward': np.float32(6.533334), 'reward_variance': np.float32(1.6498772), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(8.0), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07637921385467053), 'actor_loss': np.float64(-0.9526778578758239), 'hyper_actor_loss': np.float64(0.0043823675252497194), 'behavior_loss': np.float64(2.1295435667037963)}
step: 5670 @ episode report: {'average_total_reward': np.float32(7.094445), 'reward_variance': np.float32(3.7034125), 'max_total_reward': np.float32(11.022222), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.5), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08508246429264546), 'actor_loss': np.float64(-0.9475288331508637), 'hyper_actor_loss': np.float64(0.0041986019117757675), 'behavior_loss': np.float64(2.0183654546737673)}
step: 5680 @ episode report: {'average_total_reward': np.float32(7.204445), 'reward_variance': np.float32(3.002771), 'max_total_reward': np.float32(8.900002), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.5), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09233426600694657), 'actor_loss': np.float64(-0.9569909751415253), 'hyper_actor_loss': np.float64(0.0040361058665439485), 'behavior_loss': np.float64(2.126510727405548)}
step: 5690 @ episode report: {'average_total_reward': np.float32(6.8822227), 'reward_variance': np.float32(2.107462), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07390958070755005), 'actor_loss': np.float64(-0.925040864944458), 'hyper_actor_loss': np.float64(0.0040093837305903435), 'behavior_loss': np.float64(2.1175561428070067)}
step: 5700 @ episode report: {'average_total_reward': np.float32(6.533334), 'reward_variance': np.float32(1.3341727), 'max_total_reward': np.float32(7.777778), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.0), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09151088073849678), 'actor_loss': np.float64(-0.9689819574356079), 'hyper_actor_loss': np.float64(0.003943489282391965), 'behavior_loss': np.float64(1.9928755283355712)}
step: 5710 @ episode report: {'average_total_reward': np.float32(6.243334), 'reward_variance': np.float32(1.8909496), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.6), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0807251401245594), 'actor_loss': np.float64(-0.9581614434719086), 'hyper_actor_loss': np.float64(0.003984529455192387), 'behavior_loss': np.float64(2.0371548414230345)}
step: 5720 @ episode report: {'average_total_reward': np.float32(7.0311112), 'reward_variance': np.float32(1.2923654), 'max_total_reward': np.float32(8.533334), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08312689550220967), 'actor_loss': np.float64(-0.9320751667022705), 'hyper_actor_loss': np.float64(0.004032028908841312), 'behavior_loss': np.float64(2.030181336402893)}
step: 5730 @ episode report: {'average_total_reward': np.float32(5.9844446), 'reward_variance': np.float32(1.227141), 'max_total_reward': np.float32(7.7777786), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(7.5), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08340068981051445), 'actor_loss': np.float64(-0.9620253503322601), 'hyper_actor_loss': np.float64(0.004185187933035195), 'behavior_loss': np.float64(2.0001346349716185)}
step: 5740 @ episode report: {'average_total_reward': np.float32(6.7333336), 'reward_variance': np.float32(1.6727165), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.2), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0819462589919567), 'actor_loss': np.float64(-0.9527538120746613), 'hyper_actor_loss': np.float64(0.004211443266831339), 'behavior_loss': np.float64(2.008778476715088)}
step: 5750 @ episode report: {'average_total_reward': np.float32(6.406667), 'reward_variance': np.float32(1.5241044), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.8), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07966665849089623), 'actor_loss': np.float64(-0.9340883374214173), 'hyper_actor_loss': np.float64(0.004563892632722855), 'behavior_loss': np.float64(2.1550004363059996)}
step: 5760 @ episode report: {'average_total_reward': np.float32(6.5311117), 'reward_variance': np.float32(2.0625875), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(7.9), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08305701985955238), 'actor_loss': np.float64(-0.9688861489295959), 'hyper_actor_loss': np.float64(0.0044960238505154845), 'behavior_loss': np.float64(2.053130030632019)}
step: 5770 @ episode report: {'average_total_reward': np.float32(6.906667), 'reward_variance': np.float32(1.2194617), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08383656069636344), 'actor_loss': np.float64(-0.9570197463035583), 'hyper_actor_loss': np.float64(0.004569369228556752), 'behavior_loss': np.float64(2.1128663659095763)}
step: 5780 @ episode report: {'average_total_reward': np.float32(6.033334), 'reward_variance': np.float32(1.9761978), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(7.5), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08781050741672516), 'actor_loss': np.float64(-0.9612394630908966), 'hyper_actor_loss': np.float64(0.004828242352232337), 'behavior_loss': np.float64(2.0605407834053038)}
step: 5790 @ episode report: {'average_total_reward': np.float32(5.7822227), 'reward_variance': np.float32(0.66923964), 'max_total_reward': np.float32(7.7777786), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(7.2), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07978450283408164), 'actor_loss': np.float64(-0.9440804362297058), 'hyper_actor_loss': np.float64(0.004947475623339415), 'behavior_loss': np.float64(2.041679322719574)}
step: 5800 @ episode report: {'average_total_reward': np.float32(6.257778), 'reward_variance': np.float32(1.7168596), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.7), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0925930853933096), 'actor_loss': np.float64(-0.9526438653469086), 'hyper_actor_loss': np.float64(0.004722251230850816), 'behavior_loss': np.float64(2.064115595817566)}
step: 5810 @ episode report: {'average_total_reward': np.float32(6.518889), 'reward_variance': np.float32(2.9417307), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.9), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08146094158291817), 'actor_loss': np.float64(-0.9391099274158478), 'hyper_actor_loss': np.float64(0.004493002220988274), 'behavior_loss': np.float64(2.063182008266449)}
step: 5820 @ episode report: {'average_total_reward': np.float32(6.1700006), 'reward_variance': np.float32(1.3497794), 'max_total_reward': np.float32(7.7777786), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(7.6), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09562838971614837), 'actor_loss': np.float64(-0.9591685712337494), 'hyper_actor_loss': np.float64(0.004369884356856346), 'behavior_loss': np.float64(2.1208778023719788)}
step: 5830 @ episode report: {'average_total_reward': np.float32(5.7333336), 'reward_variance': np.float32(2.2498028), 'max_total_reward': np.float32(7.7777786), 'min_total_reward': np.float32(3.288889), 'average_n_step': np.float32(7.2), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07882576994597912), 'actor_loss': np.float64(-0.9158123016357422), 'hyper_actor_loss': np.float64(0.004160639457404613), 'behavior_loss': np.float64(2.0931683778762817)}
step: 5840 @ episode report: {'average_total_reward': np.float32(5.6333337), 'reward_variance': np.float32(2.402247), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(3.0444448), 'average_n_step': np.float32(7.1), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08487588614225387), 'actor_loss': np.float64(-0.9565603852272033), 'hyper_actor_loss': np.float64(0.004174009920097888), 'behavior_loss': np.float64(1.9614891767501832)}
step: 5850 @ episode report: {'average_total_reward': np.float32(6.0211115), 'reward_variance': np.float32(4.341937), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(3.4111114), 'average_n_step': np.float32(7.5), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07333366237580777), 'actor_loss': np.float64(-0.9492475628852844), 'hyper_actor_loss': np.float64(0.004154999321326613), 'behavior_loss': np.float64(1.9777090191841125)}
step: 5860 @ episode report: {'average_total_reward': np.float32(6.131111), 'reward_variance': np.float32(2.3880947), 'max_total_reward': np.float32(8.900002), 'min_total_reward': np.float32(3.4111114), 'average_n_step': np.float32(7.5), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08715599924325942), 'actor_loss': np.float64(-0.9369706690311432), 'hyper_actor_loss': np.float64(0.004286689404398203), 'behavior_loss': np.float64(1.9789098143577575)}
step: 5870 @ episode report: {'average_total_reward': np.float32(6.4822226), 'reward_variance': np.float32(1.3307952), 'max_total_reward': np.float32(8.655556), 'min_total_reward': np.float32(5.411111), 'average_n_step': np.float32(7.9), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08857291787862778), 'actor_loss': np.float64(-0.977774703502655), 'hyper_actor_loss': np.float64(0.004545774636790156), 'behavior_loss': np.float64(2.0106889724731447)}
step: 5880 @ episode report: {'average_total_reward': np.float32(6.4455557), 'reward_variance': np.float32(2.0229747), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.9), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08582240082323551), 'actor_loss': np.float64(-0.9214090228080749), 'hyper_actor_loss': np.float64(0.0046723420731723305), 'behavior_loss': np.float64(1.9886287331581116)}
step: 5890 @ episode report: {'average_total_reward': np.float32(5.957778), 'reward_variance': np.float32(1.057773), 'max_total_reward': np.float32(7.7777786), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.4), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09020584300160409), 'actor_loss': np.float64(-0.9728929281234742), 'hyper_actor_loss': np.float64(0.004836708540096879), 'behavior_loss': np.float64(2.0966653704643248)}
step: 5900 @ episode report: {'average_total_reward': np.float32(6.8188887), 'reward_variance': np.float32(1.005236), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(8.2), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08246035948395729), 'actor_loss': np.float64(-0.9417062640190125), 'hyper_actor_loss': np.float64(0.00484966984950006), 'behavior_loss': np.float64(1.9392626881599426)}
step: 5910 @ episode report: {'average_total_reward': np.float32(5.347778), 'reward_variance': np.float32(1.9658283), 'max_total_reward': np.float32(7.6555557), 'min_total_reward': np.float32(3.166667), 'average_n_step': np.float32(6.9), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07859190814197063), 'actor_loss': np.float64(-0.9564604341983796), 'hyper_actor_loss': np.float64(0.004758657934144139), 'behavior_loss': np.float64(1.8612584352493287)}
step: 5920 @ episode report: {'average_total_reward': np.float32(5.0600004), 'reward_variance': np.float32(0.7435358), 'max_total_reward': np.float32(6.4111114), 'min_total_reward': np.float32(3.166667), 'average_n_step': np.float32(6.6), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07804952375590801), 'actor_loss': np.float64(-0.9492721855640411), 'hyper_actor_loss': np.float64(0.004688967578113079), 'behavior_loss': np.float64(2.0157754182815553)}
step: 5930 @ episode report: {'average_total_reward': np.float32(6.482222), 'reward_variance': np.float32(2.2694862), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.9), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07824990637600422), 'actor_loss': np.float64(-0.9418822228908539), 'hyper_actor_loss': np.float64(0.00450286683626473), 'behavior_loss': np.float64(1.9483339071273804)}
step: 5940 @ episode report: {'average_total_reward': np.float32(6.7188897), 'reward_variance': np.float32(2.417705), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.1), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07979284040629864), 'actor_loss': np.float64(-0.9169614970684051), 'hyper_actor_loss': np.float64(0.004314958839677275), 'behavior_loss': np.float64(1.8415107727050781)}
step: 5950 @ episode report: {'average_total_reward': np.float32(5.508889), 'reward_variance': np.float32(0.9914273), 'max_total_reward': np.float32(7.777778), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.0), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08504058122634887), 'actor_loss': np.float64(-0.9603163301944733), 'hyper_actor_loss': np.float64(0.004145659157074988), 'behavior_loss': np.float64(1.897892916202545)}
step: 5960 @ episode report: {'average_total_reward': np.float32(5.7333336), 'reward_variance': np.float32(2.632864), 'max_total_reward': np.float32(7.7777786), 'min_total_reward': np.float32(3.2888892), 'average_n_step': np.float32(7.2), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08508810810744763), 'actor_loss': np.float64(-0.9539443016052246), 'hyper_actor_loss': np.float64(0.004045216762460768), 'behavior_loss': np.float64(1.8782601833343506)}
step: 5970 @ episode report: {'average_total_reward': np.float32(6.2333336), 'reward_variance': np.float32(1.295284), 'max_total_reward': np.float32(7.7777786), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(7.7), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08021969608962536), 'actor_loss': np.float64(-0.9366717338562012), 'hyper_actor_loss': np.float64(0.003896730113774538), 'behavior_loss': np.float64(1.8999629259109496)}
step: 5980 @ episode report: {'average_total_reward': np.float32(5.982222), 'reward_variance': np.float32(0.82891876), 'max_total_reward': np.float32(7.5333333), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(7.4), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0847790315747261), 'actor_loss': np.float64(-0.9510019421577454), 'hyper_actor_loss': np.float64(0.0038322087377309797), 'behavior_loss': np.float64(1.8885716199874878)}
step: 5990 @ episode report: {'average_total_reward': np.float32(6.9311113), 'reward_variance': np.float32(2.0864398), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09362647011876106), 'actor_loss': np.float64(-0.9505051493644714), 'hyper_actor_loss': np.float64(0.0034064326202496885), 'behavior_loss': np.float64(1.8543343424797059)}
step: 6000 @ episode report: {'average_total_reward': np.float32(7.0433335), 'reward_variance': np.float32(1.1852953), 'max_total_reward': np.float32(7.7777786), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08713319040834903), 'actor_loss': np.float64(-0.949985933303833), 'hyper_actor_loss': np.float64(0.003503702930174768), 'behavior_loss': np.float64(1.8100667238235473)}
step: 6010 @ episode report: {'average_total_reward': np.float32(6.4700003), 'reward_variance': np.float32(1.8147173), 'max_total_reward': np.float32(7.777778), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.9), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08104923330247402), 'actor_loss': np.float64(-0.9560278713703155), 'hyper_actor_loss': np.float64(0.003334742970764637), 'behavior_loss': np.float64(1.7473866105079652)}
step: 6020 @ episode report: {'average_total_reward': np.float32(8.053334), 'reward_variance': np.float32(1.4619949), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(9.3), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08125850893557071), 'actor_loss': np.float64(-0.9409199953079224), 'hyper_actor_loss': np.float64(0.0034769224002957344), 'behavior_loss': np.float64(1.7860454440116882)}
step: 6030 @ episode report: {'average_total_reward': np.float32(6.5577784), 'reward_variance': np.float32(3.075255), 'max_total_reward': np.float32(9.777779), 'min_total_reward': np.float32(3.166667), 'average_n_step': np.float32(8.0), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07442545257508755), 'actor_loss': np.float64(-0.9223981559276581), 'hyper_actor_loss': np.float64(0.003424443467520177), 'behavior_loss': np.float64(1.7931470990180969)}
step: 6040 @ episode report: {'average_total_reward': np.float32(6.37), 'reward_variance': np.float32(0.9513594), 'max_total_reward': np.float32(7.777778), 'min_total_reward': np.float32(5.288889), 'average_n_step': np.float32(7.8), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08799347914755344), 'actor_loss': np.float64(-0.9382426023483277), 'hyper_actor_loss': np.float64(0.003539059543982148), 'behavior_loss': np.float64(1.820992887020111)}
step: 6050 @ episode report: {'average_total_reward': np.float32(7.3555555), 'reward_variance': np.float32(2.0858517), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.7), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07823806218802928), 'actor_loss': np.float64(-0.9575972437858582), 'hyper_actor_loss': np.float64(0.003636205545626581), 'behavior_loss': np.float64(1.8875873684883118)}
step: 6060 @ episode report: {'average_total_reward': np.float32(7.3188887), 'reward_variance': np.float32(2.0230873), 'max_total_reward': np.float32(9.655556), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.7), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07898322679102421), 'actor_loss': np.float64(-0.9037366926670074), 'hyper_actor_loss': np.float64(0.0035726889735087754), 'behavior_loss': np.float64(1.7280647516250611)}
step: 6070 @ episode report: {'average_total_reward': np.float32(8.02889), 'reward_variance': np.float32(2.3706474), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(9.3), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08300923630595207), 'actor_loss': np.float64(-0.9465907156467438), 'hyper_actor_loss': np.float64(0.0036501169903203844), 'behavior_loss': np.float64(1.8066850423812866)}
step: 6080 @ episode report: {'average_total_reward': np.float32(7.0944443), 'reward_variance': np.float32(1.1098579), 'max_total_reward': np.float32(7.7777786), 'min_total_reward': np.float32(4.166667), 'average_n_step': np.float32(8.5), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07467529028654099), 'actor_loss': np.float64(-0.954192864894867), 'hyper_actor_loss': np.float64(0.0037479571532458068), 'behavior_loss': np.float64(1.6295790195465087)}
step: 6090 @ episode report: {'average_total_reward': np.float32(6.9433336), 'reward_variance': np.float32(1.9693199), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07951728887856006), 'actor_loss': np.float64(-0.927648514509201), 'hyper_actor_loss': np.float64(0.0037420398788526655), 'behavior_loss': np.float64(1.7489485383033752)}
step: 6100 @ episode report: {'average_total_reward': np.float32(7.082223), 'reward_variance': np.float32(1.0456096), 'max_total_reward': np.float32(8.777778), 'min_total_reward': np.float32(5.655556), 'average_n_step': np.float32(8.5), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08740295022726059), 'actor_loss': np.float64(-0.9559547543525696), 'hyper_actor_loss': np.float64(0.003775868797674775), 'behavior_loss': np.float64(1.783736789226532)}
step: 6110 @ episode report: {'average_total_reward': np.float32(6.6555557), 'reward_variance': np.float32(2.253408), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.0), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08242275416851044), 'actor_loss': np.float64(-0.9398721694946289), 'hyper_actor_loss': np.float64(0.003994857566431165), 'behavior_loss': np.float64(1.7091133832931518)}
step: 6120 @ episode report: {'average_total_reward': np.float32(7.194445), 'reward_variance': np.float32(0.90158653), 'max_total_reward': np.float32(8.655556), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09232026860117912), 'actor_loss': np.float64(-0.961484694480896), 'hyper_actor_loss': np.float64(0.0039680162211880084), 'behavior_loss': np.float64(1.7424882531166077)}
step: 6130 @ episode report: {'average_total_reward': np.float32(7.1433334), 'reward_variance': np.float32(1.151839), 'max_total_reward': np.float32(8.900002), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(8.5), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0813524067401886), 'actor_loss': np.float64(-0.9345965683460236), 'hyper_actor_loss': np.float64(0.00407592193223536), 'behavior_loss': np.float64(1.737312376499176)}
step: 6140 @ episode report: {'average_total_reward': np.float32(6.2211113), 'reward_variance': np.float32(2.3486784), 'max_total_reward': np.float32(8.655557), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.7), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07566231116652489), 'actor_loss': np.float64(-0.9597396612167358), 'hyper_actor_loss': np.float64(0.0038683365099132063), 'behavior_loss': np.float64(1.605344784259796)}
step: 6150 @ episode report: {'average_total_reward': np.float32(6.018889), 'reward_variance': np.float32(0.7547668), 'max_total_reward': np.float32(7.6555557), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(7.4), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08220902942121029), 'actor_loss': np.float64(-0.944608348608017), 'hyper_actor_loss': np.float64(0.003604648471809924), 'behavior_loss': np.float64(1.7009376168251038)}
step: 6160 @ episode report: {'average_total_reward': np.float32(7.2433333), 'reward_variance': np.float32(4.057074), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0713475577533245), 'actor_loss': np.float64(-0.9256049692630768), 'hyper_actor_loss': np.float64(0.0037469367729499937), 'behavior_loss': np.float64(1.731199526786804)}
step: 6170 @ episode report: {'average_total_reward': np.float32(6.2822227), 'reward_variance': np.float32(2.8010676), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(4.166667), 'average_n_step': np.float32(7.7), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08336858227849006), 'actor_loss': np.float64(-0.9333442270755767), 'hyper_actor_loss': np.float64(0.003804656444117427), 'behavior_loss': np.float64(1.8494885325431825)}
step: 6180 @ episode report: {'average_total_reward': np.float32(6.894445), 'reward_variance': np.float32(1.7646482), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07856708168983459), 'actor_loss': np.float64(-0.9584500968456269), 'hyper_actor_loss': np.float64(0.0037091482896357774), 'behavior_loss': np.float64(1.6824502825737)}
step: 6190 @ episode report: {'average_total_reward': np.float32(6.357778), 'reward_variance': np.float32(2.3333042), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(4.0444446), 'average_n_step': np.float32(7.8), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07408305220305919), 'actor_loss': np.float64(-0.9301782965660095), 'hyper_actor_loss': np.float64(0.003782689105719328), 'behavior_loss': np.float64(1.746748447418213)}
step: 6200 @ episode report: {'average_total_reward': np.float32(6.1944447), 'reward_variance': np.float32(2.437291), 'max_total_reward': np.float32(8.900002), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.6), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08082752674818039), 'actor_loss': np.float64(-0.9241255760192871), 'hyper_actor_loss': np.float64(0.003847273695282638), 'behavior_loss': np.float64(1.8295675039291381)}
step: 6210 @ episode report: {'average_total_reward': np.float32(6.145556), 'reward_variance': np.float32(2.0097396), 'max_total_reward': np.float32(8.777778), 'min_total_reward': np.float32(4.411111), 'average_n_step': np.float32(7.6), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07486737109720706), 'actor_loss': np.float64(-0.9431750476360321), 'hyper_actor_loss': np.float64(0.003914294205605984), 'behavior_loss': np.float64(1.79258291721344)}
step: 6220 @ episode report: {'average_total_reward': np.float32(6.118889), 'reward_variance': np.float32(0.96612465), 'max_total_reward': np.float32(7.6555557), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.5), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08326088674366475), 'actor_loss': np.float64(-0.922753369808197), 'hyper_actor_loss': np.float64(0.003882257151417434), 'behavior_loss': np.float64(1.7284404516220093)}
step: 6230 @ episode report: {'average_total_reward': np.float32(6.6577783), 'reward_variance': np.float32(1.5942422), 'max_total_reward': np.float32(9.533334), 'min_total_reward': np.float32(5.411111), 'average_n_step': np.float32(8.1), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08506311252713203), 'actor_loss': np.float64(-0.9609788656234741), 'hyper_actor_loss': np.float64(0.003876619762741029), 'behavior_loss': np.float64(1.736106538772583)}
step: 6240 @ episode report: {'average_total_reward': np.float32(6.6700006), 'reward_variance': np.float32(2.3935328), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.1), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07846985869109631), 'actor_loss': np.float64(-0.9466214299201965), 'hyper_actor_loss': np.float64(0.004061325266957283), 'behavior_loss': np.float64(1.6706887841224671)}
step: 6250 @ episode report: {'average_total_reward': np.float32(6.731111), 'reward_variance': np.float32(3.3063157), 'max_total_reward': np.float32(9.655556), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.1), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07837613373994827), 'actor_loss': np.float64(-0.9486506104469299), 'hyper_actor_loss': np.float64(0.004162055905908346), 'behavior_loss': np.float64(1.6723329663276671)}
step: 6260 @ episode report: {'average_total_reward': np.float32(6.582223), 'reward_variance': np.float32(1.4444987), 'max_total_reward': np.float32(8.777778), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.0), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07898905985057354), 'actor_loss': np.float64(-0.9324303805828095), 'hyper_actor_loss': np.float64(0.004113614512607455), 'behavior_loss': np.float64(1.6949028968811035)}
step: 6270 @ episode report: {'average_total_reward': np.float32(6.8944445), 'reward_variance': np.float32(1.7297096), 'max_total_reward': np.float32(8.655556), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0772991806268692), 'actor_loss': np.float64(-0.9532258212566376), 'hyper_actor_loss': np.float64(0.003939580707810819), 'behavior_loss': np.float64(1.7760692358016967)}
step: 6280 @ episode report: {'average_total_reward': np.float32(5.7944446), 'reward_variance': np.float32(0.36373454), 'max_total_reward': np.float32(6.6555557), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(7.2), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07922192253172397), 'actor_loss': np.float64(-0.94754079580307), 'hyper_actor_loss': np.float64(0.004154242994263768), 'behavior_loss': np.float64(1.762460172176361)}
step: 6290 @ episode report: {'average_total_reward': np.float32(6.9822226), 'reward_variance': np.float32(3.5995617), 'max_total_reward': np.float32(9.900002), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08709247820079327), 'actor_loss': np.float64(-0.9543025135993958), 'hyper_actor_loss': np.float64(0.004377402970567346), 'behavior_loss': np.float64(1.6989207863807678)}
step: 6300 @ episode report: {'average_total_reward': np.float32(5.6966667), 'reward_variance': np.float32(2.7164953), 'max_total_reward': np.float32(8.655556), 'min_total_reward': np.float32(3.2888892), 'average_n_step': np.float32(7.2), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08792076073586941), 'actor_loss': np.float64(-0.953009557723999), 'hyper_actor_loss': np.float64(0.004047225508838892), 'behavior_loss': np.float64(1.7118379473686218)}
step: 6310 @ episode report: {'average_total_reward': np.float32(5.857778), 'reward_variance': np.float32(1.3777974), 'max_total_reward': np.float32(7.6555557), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.3), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08080680929124355), 'actor_loss': np.float64(-0.9394097924232483), 'hyper_actor_loss': np.float64(0.003594368346966803), 'behavior_loss': np.float64(1.6395784974098206)}
step: 6320 @ episode report: {'average_total_reward': np.float32(6.1700006), 'reward_variance': np.float32(1.1607419), 'max_total_reward': np.float32(8.777778), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(7.6), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0752036951482296), 'actor_loss': np.float64(-0.9192028105258941), 'hyper_actor_loss': np.float64(0.003509992780163884), 'behavior_loss': np.float64(1.7314822554588318)}
step: 6330 @ episode report: {'average_total_reward': np.float32(6.7188888), 'reward_variance': np.float32(3.1124957), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.1), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08538518100976944), 'actor_loss': np.float64(-0.958254587650299), 'hyper_actor_loss': np.float64(0.003455294296145439), 'behavior_loss': np.float64(1.7269465565681457)}
step: 6340 @ episode report: {'average_total_reward': np.float32(7.853334), 'reward_variance': np.float32(5.4634767), 'max_total_reward': np.float32(12.144444), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(9.1), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08576157167553902), 'actor_loss': np.float64(-0.9248569011688232), 'hyper_actor_loss': np.float64(0.003495649341493845), 'behavior_loss': np.float64(1.6810469388961793)}
step: 6350 @ episode report: {'average_total_reward': np.float32(6.0577784), 'reward_variance': np.float32(1.600045), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.166667), 'average_n_step': np.float32(7.5), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07222747337073088), 'actor_loss': np.float64(-0.9371949791908264), 'hyper_actor_loss': np.float64(0.003309135069139302), 'behavior_loss': np.float64(1.6910485982894898)}
step: 6360 @ episode report: {'average_total_reward': np.float32(6.955556), 'reward_variance': np.float32(2.162643), 'max_total_reward': np.float32(8.77778), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09289520420134068), 'actor_loss': np.float64(-0.9519884288311005), 'hyper_actor_loss': np.float64(0.0031766530591994524), 'behavior_loss': np.float64(1.653260588645935)}
step: 6370 @ episode report: {'average_total_reward': np.float32(6.7433333), 'reward_variance': np.float32(1.4768507), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.1), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08490849733352661), 'actor_loss': np.float64(-0.9549538969993592), 'hyper_actor_loss': np.float64(0.003066745586693287), 'behavior_loss': np.float64(1.6396399974822997)}
step: 6380 @ episode report: {'average_total_reward': np.float32(7.304445), 'reward_variance': np.float32(4.1845245), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08493765629827976), 'actor_loss': np.float64(-0.9624160945415496), 'hyper_actor_loss': np.float64(0.0031599072273820637), 'behavior_loss': np.float64(1.5644001007080077)}
step: 6390 @ episode report: {'average_total_reward': np.float32(7.3555555), 'reward_variance': np.float32(1.2813336), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(8.7), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0837907038629055), 'actor_loss': np.float64(-0.9504002928733826), 'hyper_actor_loss': np.float64(0.003023244487121701), 'behavior_loss': np.float64(1.678110408782959)}
step: 6400 @ episode report: {'average_total_reward': np.float32(7.067778), 'reward_variance': np.float32(3.0710235), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08169969394803048), 'actor_loss': np.float64(-0.9317435920238495), 'hyper_actor_loss': np.float64(0.0029296670341864227), 'behavior_loss': np.float64(1.6019200801849365)}
step: 6410 @ episode report: {'average_total_reward': np.float32(7.182222), 'reward_variance': np.float32(1.3644497), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09157225675880909), 'actor_loss': np.float64(-0.9365453481674194), 'hyper_actor_loss': np.float64(0.0029013169929385184), 'behavior_loss': np.float64(1.695589017868042)}
step: 6420 @ episode report: {'average_total_reward': np.float32(7.1066666), 'reward_variance': np.float32(1.9767954), 'max_total_reward': np.float32(8.9), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(8.5), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09677378684282303), 'actor_loss': np.float64(-0.9683932602405548), 'hyper_actor_loss': np.float64(0.0028764873975887896), 'behavior_loss': np.float64(1.62280775308609)}
step: 6430 @ episode report: {'average_total_reward': np.float32(7.0800004), 'reward_variance': np.float32(1.8273531), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0912021353840828), 'actor_loss': np.float64(-0.9796888649463653), 'hyper_actor_loss': np.float64(0.0028843072475865485), 'behavior_loss': np.float64(1.5919393181800843)}
step: 6440 @ episode report: {'average_total_reward': np.float32(6.694444), 'reward_variance': np.float32(2.0401292), 'max_total_reward': np.float32(9.777778), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.1), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07134460844099522), 'actor_loss': np.float64(-0.920603585243225), 'hyper_actor_loss': np.float64(0.003026243392378092), 'behavior_loss': np.float64(1.6057318091392516)}
step: 6450 @ episode report: {'average_total_reward': np.float32(6.4822226), 'reward_variance': np.float32(1.7108688), 'max_total_reward': np.float32(8.777778), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.9), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08516477458178998), 'actor_loss': np.float64(-0.9428671717643737), 'hyper_actor_loss': np.float64(0.003036212408915162), 'behavior_loss': np.float64(1.6016168355941773)}
step: 6460 @ episode report: {'average_total_reward': np.float32(5.7700005), 'reward_variance': np.float32(0.82479125), 'max_total_reward': np.float32(7.6555557), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(7.2), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07763360403478145), 'actor_loss': np.float64(-0.958332622051239), 'hyper_actor_loss': np.float64(0.002967742271721363), 'behavior_loss': np.float64(1.5816607356071473)}
step: 6470 @ episode report: {'average_total_reward': np.float32(7.055556), 'reward_variance': np.float32(1.4809139), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07284559160470963), 'actor_loss': np.float64(-0.89320148229599), 'hyper_actor_loss': np.float64(0.0028345081023871898), 'behavior_loss': np.float64(1.6850934028625488)}
step: 6480 @ episode report: {'average_total_reward': np.float32(7.043334), 'reward_variance': np.float32(0.70897424), 'max_total_reward': np.float32(7.7777786), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07978737205266953), 'actor_loss': np.float64(-0.9251655220985413), 'hyper_actor_loss': np.float64(0.002639067289419472), 'behavior_loss': np.float64(1.6457783818244933)}
step: 6490 @ episode report: {'average_total_reward': np.float32(7.416667), 'reward_variance': np.float32(3.0838828), 'max_total_reward': np.float32(11.0222225), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.7), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0864452674984932), 'actor_loss': np.float64(-0.9598463773727417), 'hyper_actor_loss': np.float64(0.002491032215766609), 'behavior_loss': np.float64(1.6845531821250916)}
step: 6500 @ episode report: {'average_total_reward': np.float32(7.1433334), 'reward_variance': np.float32(2.353369), 'max_total_reward': np.float32(10.777778), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(8.5), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07833321802318097), 'actor_loss': np.float64(-0.927919453382492), 'hyper_actor_loss': np.float64(0.002453926461748779), 'behavior_loss': np.float64(1.6899697422981261)}
step: 6510 @ episode report: {'average_total_reward': np.float32(6.457778), 'reward_variance': np.float32(1.8932794), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(7.9), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0772510427981615), 'actor_loss': np.float64(-0.9310140192508698), 'hyper_actor_loss': np.float64(0.002641733968630433), 'behavior_loss': np.float64(1.568954837322235)}
step: 6520 @ episode report: {'average_total_reward': np.float32(5.347778), 'reward_variance': np.float32(1.3827667), 'max_total_reward': np.float32(7.533334), 'min_total_reward': np.float32(3.4111114), 'average_n_step': np.float32(6.9), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0769072998315096), 'actor_loss': np.float64(-0.9304221093654632), 'hyper_actor_loss': np.float64(0.002664332673884928), 'behavior_loss': np.float64(1.6722654938697814)}
step: 6530 @ episode report: {'average_total_reward': np.float32(7.006667), 'reward_variance': np.float32(2.1695113), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08535660281777382), 'actor_loss': np.float64(-0.9315541744232178), 'hyper_actor_loss': np.float64(0.002667963784188032), 'behavior_loss': np.float64(1.7789608597755433)}
step: 6540 @ episode report: {'average_total_reward': np.float32(7.131111), 'reward_variance': np.float32(2.7008102), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.5), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0875104546546936), 'actor_loss': np.float64(-0.9231427788734436), 'hyper_actor_loss': np.float64(0.0025554083986207843), 'behavior_loss': np.float64(1.688754963874817)}
step: 6550 @ episode report: {'average_total_reward': np.float32(6.506667), 'reward_variance': np.float32(0.9386719), 'max_total_reward': np.float32(7.777778), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(7.9), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0866036742925644), 'actor_loss': np.float64(-0.9702169716358184), 'hyper_actor_loss': np.float64(0.002509218850173056), 'behavior_loss': np.float64(1.5445552229881288)}
step: 6560 @ episode report: {'average_total_reward': np.float32(7.0433335), 'reward_variance': np.float32(1.9928017), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06808455232530833), 'actor_loss': np.float64(-0.9228640615940094), 'hyper_actor_loss': np.float64(0.0025058771949261426), 'behavior_loss': np.float64(1.6242899298667908)}
step: 6570 @ episode report: {'average_total_reward': np.float32(6.1577783), 'reward_variance': np.float32(1.3028593), 'max_total_reward': np.float32(7.7777777), 'min_total_reward': np.float32(4.166667), 'average_n_step': np.float32(7.6), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08113153092563152), 'actor_loss': np.float64(-0.9038101613521576), 'hyper_actor_loss': np.float64(0.0027282208669930697), 'behavior_loss': np.float64(1.6892623543739318)}
step: 6580 @ episode report: {'average_total_reward': np.float32(6.8555555), 'reward_variance': np.float32(3.6268888), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(3.4111114), 'average_n_step': np.float32(8.2), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07939234003424644), 'actor_loss': np.float64(-0.9683944642543793), 'hyper_actor_loss': np.float64(0.002698238403536379), 'behavior_loss': np.float64(1.5951856970787048)}
step: 6590 @ episode report: {'average_total_reward': np.float32(7.7922225), 'reward_variance': np.float32(1.9940752), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(9.1), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08551147282123565), 'actor_loss': np.float64(-0.9159683406352996), 'hyper_actor_loss': np.float64(0.002659062738530338), 'behavior_loss': np.float64(1.6199774384498595)}
step: 6600 @ episode report: {'average_total_reward': np.float32(6.8066664), 'reward_variance': np.float32(2.7432895), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.2), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07603064924478531), 'actor_loss': np.float64(-0.9225102126598358), 'hyper_actor_loss': np.float64(0.002616290468722582), 'behavior_loss': np.float64(1.6255162715911866)}
step: 6610 @ episode report: {'average_total_reward': np.float32(7.5288887), 'reward_variance': np.float32(1.8493135), 'max_total_reward': np.float32(9.9), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(8.8), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08047209978103638), 'actor_loss': np.float64(-0.9359367489814758), 'hyper_actor_loss': np.float64(0.002565258997492492), 'behavior_loss': np.float64(1.5683825492858887)}
step: 6620 @ episode report: {'average_total_reward': np.float32(6.794445), 'reward_variance': np.float32(2.1113896), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(5.288889), 'average_n_step': np.float32(8.2), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0714311458170414), 'actor_loss': np.float64(-0.9139411985874176), 'hyper_actor_loss': np.float64(0.0025834348052740097), 'behavior_loss': np.float64(1.5972664833068848)}
step: 6630 @ episode report: {'average_total_reward': np.float32(6.555556), 'reward_variance': np.float32(2.2531362), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(7.9), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08878740705549718), 'actor_loss': np.float64(-0.9469842731952667), 'hyper_actor_loss': np.float64(0.002526400797069073), 'behavior_loss': np.float64(1.5635652661323547)}
step: 6640 @ episode report: {'average_total_reward': np.float32(6.918889), 'reward_variance': np.float32(1.4625694), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08517402857542038), 'actor_loss': np.float64(-0.9615567088127136), 'hyper_actor_loss': np.float64(0.002483878913335502), 'behavior_loss': np.float64(1.6101219415664674)}
step: 6650 @ episode report: {'average_total_reward': np.float32(7.653334), 'reward_variance': np.float32(3.5698714), 'max_total_reward': np.float32(10.022222), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.9), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09830271452665329), 'actor_loss': np.float64(-0.9310138523578644), 'hyper_actor_loss': np.float64(0.0024259394500404595), 'behavior_loss': np.float64(1.5667455196380615)}
step: 6660 @ episode report: {'average_total_reward': np.float32(6.457778), 'reward_variance': np.float32(1.1306866), 'max_total_reward': np.float32(7.6555567), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.9), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06854421198368073), 'actor_loss': np.float64(-0.9533687829971313), 'hyper_actor_loss': np.float64(0.002419176371768117), 'behavior_loss': np.float64(1.5033405303955079)}
step: 6670 @ episode report: {'average_total_reward': np.float32(7.3822227), 'reward_variance': np.float32(0.82849884), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(8.8), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08795698955655099), 'actor_loss': np.float64(-0.9321662485599518), 'hyper_actor_loss': np.float64(0.002337569766677916), 'behavior_loss': np.float64(1.5904634118080139)}
step: 6680 @ episode report: {'average_total_reward': np.float32(6.8188896), 'reward_variance': np.float32(1.6217048), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(8.2), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09226985648274422), 'actor_loss': np.float64(-0.9536315202713013), 'hyper_actor_loss': np.float64(0.002277002017945051), 'behavior_loss': np.float64(1.5723379969596862)}
step: 6690 @ episode report: {'average_total_reward': np.float32(6.6066675), 'reward_variance': np.float32(2.3637338), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(3.4111114), 'average_n_step': np.float32(8.0), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08792351223528386), 'actor_loss': np.float64(-0.969122713804245), 'hyper_actor_loss': np.float64(0.002345317369326949), 'behavior_loss': np.float64(1.6127564907073975)}
step: 6700 @ episode report: {'average_total_reward': np.float32(7.006667), 'reward_variance': np.float32(1.9021537), 'max_total_reward': np.float32(9.900002), 'min_total_reward': np.float32(5.288889), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07572519481182098), 'actor_loss': np.float64(-0.9206283330917359), 'hyper_actor_loss': np.float64(0.0023354959208518266), 'behavior_loss': np.float64(1.5741572260856629)}
step: 6710 @ episode report: {'average_total_reward': np.float32(7.0944443), 'reward_variance': np.float32(2.238056), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(8.5), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08548747263848781), 'actor_loss': np.float64(-0.9344744384288788), 'hyper_actor_loss': np.float64(0.0023138696793466806), 'behavior_loss': np.float64(1.6054954648017883)}
step: 6720 @ episode report: {'average_total_reward': np.float32(6.6066675), 'reward_variance': np.float32(4.091462), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(4.166667), 'average_n_step': np.float32(8.0), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08598513044416904), 'actor_loss': np.float64(-0.940605241060257), 'hyper_actor_loss': np.float64(0.0022039343137294056), 'behavior_loss': np.float64(1.5393415808677673)}
step: 6730 @ episode report: {'average_total_reward': np.float32(6.955556), 'reward_variance': np.float32(2.0968156), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(4.411111), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08219434656202793), 'actor_loss': np.float64(-0.9299614310264588), 'hyper_actor_loss': np.float64(0.0022964116651564837), 'behavior_loss': np.float64(1.6607617259025573)}
step: 6740 @ episode report: {'average_total_reward': np.float32(6.6577783), 'reward_variance': np.float32(1.1423656), 'max_total_reward': np.float32(7.6555557), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.1), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08063228614628315), 'actor_loss': np.float64(-0.9333797812461853), 'hyper_actor_loss': np.float64(0.0022213713731616736), 'behavior_loss': np.float64(1.5958290219306945)}
step: 6750 @ episode report: {'average_total_reward': np.float32(7.006667), 'reward_variance': np.float32(2.64882), 'max_total_reward': np.float32(9.777779), 'min_total_reward': np.float32(4.411112), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07942320294678211), 'actor_loss': np.float64(-0.927688467502594), 'hyper_actor_loss': np.float64(0.0021518196212127806), 'behavior_loss': np.float64(1.4696560025215148)}
step: 6760 @ episode report: {'average_total_reward': np.float32(7.5433335), 'reward_variance': np.float32(1.2719624), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(8.9), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08040993139147759), 'actor_loss': np.float64(-0.9440622448921203), 'hyper_actor_loss': np.float64(0.002122935594525188), 'behavior_loss': np.float64(1.5898969531059266)}
step: 6770 @ episode report: {'average_total_reward': np.float32(7.3433332), 'reward_variance': np.float32(3.044455), 'max_total_reward': np.float32(10.022222), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.7), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07966960817575455), 'actor_loss': np.float64(-0.9307383060455322), 'hyper_actor_loss': np.float64(0.00211920291185379), 'behavior_loss': np.float64(1.5582931518554688)}
step: 6780 @ episode report: {'average_total_reward': np.float32(7.5433335), 'reward_variance': np.float32(1.8260605), 'max_total_reward': np.float32(9.533334), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.9), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07100027240812778), 'actor_loss': np.float64(-0.919745284318924), 'hyper_actor_loss': np.float64(0.0021688987384550274), 'behavior_loss': np.float64(1.5653134346008302)}
step: 6790 @ episode report: {'average_total_reward': np.float32(7.0922227), 'reward_variance': np.float32(3.1629894), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08274263553321362), 'actor_loss': np.float64(-0.9474092423915863), 'hyper_actor_loss': np.float64(0.0022411096142604947), 'behavior_loss': np.float64(1.4907719135284423)}
step: 6800 @ episode report: {'average_total_reward': np.float32(6.4066668), 'reward_variance': np.float32(1.4966718), 'max_total_reward': np.float32(7.7777786), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.8), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07587117552757264), 'actor_loss': np.float64(-0.9515030264854432), 'hyper_actor_loss': np.float64(0.002384384791366756), 'behavior_loss': np.float64(1.442084300518036)}
step: 6810 @ episode report: {'average_total_reward': np.float32(6.8433332), 'reward_variance': np.float32(3.2545788), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.2), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08437321707606316), 'actor_loss': np.float64(-0.9640346884727478), 'hyper_actor_loss': np.float64(0.0024601839715614913), 'behavior_loss': np.float64(1.4898008584976197)}
step: 6820 @ episode report: {'average_total_reward': np.float32(6.794445), 'reward_variance': np.float32(1.6949196), 'max_total_reward': np.float32(8.655556), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.2), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07639151252806187), 'actor_loss': np.float64(-0.9358811557292939), 'hyper_actor_loss': np.float64(0.002672007703222334), 'behavior_loss': np.float64(1.5132575035095215)}
step: 6830 @ episode report: {'average_total_reward': np.float32(6.3944445), 'reward_variance': np.float32(2.0749938), 'max_total_reward': np.float32(8.655556), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.8), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08343214839696884), 'actor_loss': np.float64(-0.9319647192955017), 'hyper_actor_loss': np.float64(0.002744705183431506), 'behavior_loss': np.float64(1.488589358329773)}
step: 6840 @ episode report: {'average_total_reward': np.float32(6.1211114), 'reward_variance': np.float32(1.3627526), 'max_total_reward': np.float32(7.6555567), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.6), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06973450146615505), 'actor_loss': np.float64(-0.9514043092727661), 'hyper_actor_loss': np.float64(0.002714412659406662), 'behavior_loss': np.float64(1.486984956264496)}
step: 6850 @ episode report: {'average_total_reward': np.float32(7.167778), 'reward_variance': np.float32(1.3289245), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(8.5), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07399322241544723), 'actor_loss': np.float64(-0.9326090216636658), 'hyper_actor_loss': np.float64(0.002740586828440428), 'behavior_loss': np.float64(1.4466266989707948)}
step: 6860 @ episode report: {'average_total_reward': np.float32(6.0700006), 'reward_variance': np.float32(1.4209893), 'max_total_reward': np.float32(7.7777786), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.5), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09008942693471908), 'actor_loss': np.float64(-0.941270512342453), 'hyper_actor_loss': np.float64(0.0027768971864134072), 'behavior_loss': np.float64(1.5589379668235779)}
step: 6870 @ episode report: {'average_total_reward': np.float32(7.216667), 'reward_variance': np.float32(3.123883), 'max_total_reward': np.float32(11.022223), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.5), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08366400934755802), 'actor_loss': np.float64(-0.9462777674198151), 'hyper_actor_loss': np.float64(0.002725730394013226), 'behavior_loss': np.float64(1.5064684987068175)}
step: 6880 @ episode report: {'average_total_reward': np.float32(6.8944445), 'reward_variance': np.float32(3.0579076), 'max_total_reward': np.float32(9.777777), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09268875792622566), 'actor_loss': np.float64(-0.9669570624828339), 'hyper_actor_loss': np.float64(0.0027891613775864244), 'behavior_loss': np.float64(1.496764588356018)}
step: 6890 @ episode report: {'average_total_reward': np.float32(6.967778), 'reward_variance': np.float32(2.2938135), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09122188724577426), 'actor_loss': np.float64(-0.9560551822185517), 'hyper_actor_loss': np.float64(0.0029021968832239507), 'behavior_loss': np.float64(1.6215412855148315)}
step: 6900 @ episode report: {'average_total_reward': np.float32(6.5700006), 'reward_variance': np.float32(2.1861987), 'max_total_reward': np.float32(8.777777), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.0), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0875798773020506), 'actor_loss': np.float64(-0.9369306445121766), 'hyper_actor_loss': np.float64(0.002797027654014528), 'behavior_loss': np.float64(1.5052292346954346)}
step: 6910 @ episode report: {'average_total_reward': np.float32(7.553334), 'reward_variance': np.float32(3.4928355), 'max_total_reward': np.float32(11.022223), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(8.8), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07457046844065189), 'actor_loss': np.float64(-0.9381175398826599), 'hyper_actor_loss': np.float64(0.0028939530020579696), 'behavior_loss': np.float64(1.5237828016281127)}
step: 6920 @ episode report: {'average_total_reward': np.float32(6.7433333), 'reward_variance': np.float32(1.7012951), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.1), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07696146480739116), 'actor_loss': np.float64(-0.9385694324970245), 'hyper_actor_loss': np.float64(0.0028690536972135307), 'behavior_loss': np.float64(1.533750319480896)}
step: 6930 @ episode report: {'average_total_reward': np.float32(6.8944445), 'reward_variance': np.float32(2.0853395), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08052680753171444), 'actor_loss': np.float64(-0.9340933859348297), 'hyper_actor_loss': np.float64(0.0029848183039575815), 'behavior_loss': np.float64(1.5038007736206054)}
step: 6940 @ episode report: {'average_total_reward': np.float32(6.845556), 'reward_variance': np.float32(1.7107513), 'max_total_reward': np.float32(8.655555), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0912768855690956), 'actor_loss': np.float64(-0.9546037971973419), 'hyper_actor_loss': np.float64(0.002945767599157989), 'behavior_loss': np.float64(1.5123824596405029)}
step: 6950 @ episode report: {'average_total_reward': np.float32(6.994446), 'reward_variance': np.float32(3.4068706), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(3.4111114), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08918774239718914), 'actor_loss': np.float64(-0.9640079021453858), 'hyper_actor_loss': np.float64(0.0032605775399133564), 'behavior_loss': np.float64(1.4446858406066894)}
step: 6960 @ episode report: {'average_total_reward': np.float32(6.7555556), 'reward_variance': np.float32(1.2989633), 'max_total_reward': np.float32(8.655556), 'min_total_reward': np.float32(5.6555552), 'average_n_step': np.float32(8.1), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08555595017969608), 'actor_loss': np.float64(-0.9446036577224731), 'hyper_actor_loss': np.float64(0.0032523143803700806), 'behavior_loss': np.float64(1.493762743473053)}
step: 6970 @ episode report: {'average_total_reward': np.float32(6.767779), 'reward_variance': np.float32(1.7178634), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.1), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09253194630146026), 'actor_loss': np.float64(-0.9257271528244019), 'hyper_actor_loss': np.float64(0.0030598206678405402), 'behavior_loss': np.float64(1.5709229469299317)}
step: 6980 @ episode report: {'average_total_reward': np.float32(7.3188887), 'reward_variance': np.float32(1.2674582), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(8.7), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08427500016987324), 'actor_loss': np.float64(-0.9267981171607971), 'hyper_actor_loss': np.float64(0.0026490038493648172), 'behavior_loss': np.float64(1.4755684733390808)}
step: 6990 @ episode report: {'average_total_reward': np.float32(6.37), 'reward_variance': np.float32(1.7823219), 'max_total_reward': np.float32(8.777778), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.8), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08307171165943146), 'actor_loss': np.float64(-0.9434019505977631), 'hyper_actor_loss': np.float64(0.0025784449884667993), 'behavior_loss': np.float64(1.4529431223869325)}
step: 7000 @ episode report: {'average_total_reward': np.float32(6.5577784), 'reward_variance': np.float32(0.8477481), 'max_total_reward': np.float32(7.777778), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(8.0), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09320274740457535), 'actor_loss': np.float64(-0.9545873284339905), 'hyper_actor_loss': np.float64(0.0026243885746225714), 'behavior_loss': np.float64(1.468838882446289)}
step: 7010 @ episode report: {'average_total_reward': np.float32(6.3066664), 'reward_variance': np.float32(2.2541296), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(7.7), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0845850482583046), 'actor_loss': np.float64(-0.9545534908771515), 'hyper_actor_loss': np.float64(0.0027574783889576793), 'behavior_loss': np.float64(1.442973554134369)}
step: 7020 @ episode report: {'average_total_reward': np.float32(6.2822223), 'reward_variance': np.float32(1.4000051), 'max_total_reward': np.float32(7.7777786), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(7.7), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0960854422301054), 'actor_loss': np.float64(-0.9359963536262512), 'hyper_actor_loss': np.float64(0.002915485552512109), 'behavior_loss': np.float64(1.4751718878746032)}
step: 7030 @ episode report: {'average_total_reward': np.float32(6.6433344), 'reward_variance': np.float32(3.431839), 'max_total_reward': np.float32(9.900002), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.0), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08745091259479523), 'actor_loss': np.float64(-0.969609797000885), 'hyper_actor_loss': np.float64(0.0026017355266958475), 'behavior_loss': np.float64(1.4559133172035217)}
step: 7040 @ episode report: {'average_total_reward': np.float32(7.4800005), 'reward_variance': np.float32(2.628563), 'max_total_reward': np.float32(9.777778), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.8), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08655079938471318), 'actor_loss': np.float64(-0.9289288401603699), 'hyper_actor_loss': np.float64(0.002348418557085097), 'behavior_loss': np.float64(1.4352633118629456)}
step: 7050 @ episode report: {'average_total_reward': np.float32(7.131112), 'reward_variance': np.float32(2.694835), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.5), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08200975023210048), 'actor_loss': np.float64(-0.9409618973731995), 'hyper_actor_loss': np.float64(0.0022207419155165554), 'behavior_loss': np.float64(1.471003484725952)}
step: 7060 @ episode report: {'average_total_reward': np.float32(8.216667), 'reward_variance': np.float32(1.8016608), 'max_total_reward': np.float32(9.900002), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(9.5), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07261033579707146), 'actor_loss': np.float64(-0.9200477242469788), 'hyper_actor_loss': np.float64(0.0020634432206861676), 'behavior_loss': np.float64(1.4414787769317627)}
step: 7070 @ episode report: {'average_total_reward': np.float32(7.0800004), 'reward_variance': np.float32(1.9889584), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07863140925765037), 'actor_loss': np.float64(-0.930216783285141), 'hyper_actor_loss': np.float64(0.0019127741223201155), 'behavior_loss': np.float64(1.464398241043091)}
step: 7080 @ episode report: {'average_total_reward': np.float32(6.555556), 'reward_variance': np.float32(1.9463953), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.9), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07890638932585717), 'actor_loss': np.float64(-0.9267039120197296), 'hyper_actor_loss': np.float64(0.0019426562823355198), 'behavior_loss': np.float64(1.4253109693527222)}
step: 7090 @ episode report: {'average_total_reward': np.float32(7.2066674), 'reward_variance': np.float32(1.387536), 'max_total_reward': np.float32(8.655556), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0870641078799963), 'actor_loss': np.float64(-0.9507809996604919), 'hyper_actor_loss': np.float64(0.0018840072792954744), 'behavior_loss': np.float64(1.3391396403312683)}
step: 7100 @ episode report: {'average_total_reward': np.float32(7.455556), 'reward_variance': np.float32(2.5535557), 'max_total_reward': np.float32(11.0222225), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(8.8), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0782908894121647), 'actor_loss': np.float64(-0.9279293119907379), 'hyper_actor_loss': np.float64(0.0019028490060009062), 'behavior_loss': np.float64(1.5367399215698243)}
step: 7110 @ episode report: {'average_total_reward': np.float32(6.2211113), 'reward_variance': np.float32(1.1990238), 'max_total_reward': np.float32(7.7777786), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.7), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08580510951578617), 'actor_loss': np.float64(-0.9316536664962769), 'hyper_actor_loss': np.float64(0.0019612999400123953), 'behavior_loss': np.float64(1.4187119126319885)}
step: 7120 @ episode report: {'average_total_reward': np.float32(7.1555557), 'reward_variance': np.float32(2.4799502), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.5), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07841957174241543), 'actor_loss': np.float64(-0.9517110645771026), 'hyper_actor_loss': np.float64(0.0021396742318756878), 'behavior_loss': np.float64(1.442241406440735)}
step: 7130 @ episode report: {'average_total_reward': np.float32(6.931112), 'reward_variance': np.float32(0.6604644), 'max_total_reward': np.float32(7.7777786), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07897849716246128), 'actor_loss': np.float64(-0.9280101716518402), 'hyper_actor_loss': np.float64(0.0021045703324489295), 'behavior_loss': np.float64(1.438575553894043)}
step: 7140 @ episode report: {'average_total_reward': np.float32(8.428889), 'reward_variance': np.float32(1.3917578), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.7), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07935207262635231), 'actor_loss': np.float64(-0.9398455202579499), 'hyper_actor_loss': np.float64(0.002160880947485566), 'behavior_loss': np.float64(1.4237018942832946)}
step: 7150 @ episode report: {'average_total_reward': np.float32(7.367778), 'reward_variance': np.float32(2.7907763), 'max_total_reward': np.float32(10.022222), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.7), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08043591566383838), 'actor_loss': np.float64(-0.9304251790046691), 'hyper_actor_loss': np.float64(0.002125613042153418), 'behavior_loss': np.float64(1.4984500408172607)}
step: 7160 @ episode report: {'average_total_reward': np.float32(6.918889), 'reward_variance': np.float32(3.326469), 'max_total_reward': np.float32(10.022222), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0733161572366953), 'actor_loss': np.float64(-0.9139583826065063), 'hyper_actor_loss': np.float64(0.0021212431252934038), 'behavior_loss': np.float64(1.4794217109680177)}
step: 7170 @ episode report: {'average_total_reward': np.float32(7.816667), 'reward_variance': np.float32(1.8476362), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.1), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08058828413486481), 'actor_loss': np.float64(-0.924136620759964), 'hyper_actor_loss': np.float64(0.001987604517489672), 'behavior_loss': np.float64(1.3711765885353089)}
step: 7180 @ episode report: {'average_total_reward': np.float32(7.4188895), 'reward_variance': np.float32(1.8671618), 'max_total_reward': np.float32(9.777778), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(8.8), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07632996588945389), 'actor_loss': np.float64(-0.9679055988788605), 'hyper_actor_loss': np.float64(0.0019711356027983127), 'behavior_loss': np.float64(1.3803898215293884)}
step: 7190 @ episode report: {'average_total_reward': np.float32(7.741111), 'reward_variance': np.float32(1.9388406), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(9.0), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08170965015888214), 'actor_loss': np.float64(-0.9116537988185882), 'hyper_actor_loss': np.float64(0.001993380219209939), 'behavior_loss': np.float64(1.4521001696586608)}
step: 7200 @ episode report: {'average_total_reward': np.float32(6.667778), 'reward_variance': np.float32(1.6851723), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.0), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0879086934030056), 'actor_loss': np.float64(-0.9493279695510864), 'hyper_actor_loss': np.float64(0.0019840741879306734), 'behavior_loss': np.float64(1.4831209063529969)}
step: 7210 @ episode report: {'average_total_reward': np.float32(7.2433333), 'reward_variance': np.float32(2.7044303), 'max_total_reward': np.float32(9.777777), 'min_total_reward': np.float32(5.288889), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08071686774492264), 'actor_loss': np.float64(-0.9350801706314087), 'hyper_actor_loss': np.float64(0.0019344129716046155), 'behavior_loss': np.float64(1.4377331495285035)}
step: 7220 @ episode report: {'average_total_reward': np.float32(7.6800003), 'reward_variance': np.float32(2.8064404), 'max_total_reward': np.float32(11.022223), 'min_total_reward': np.float32(5.288889), 'average_n_step': np.float32(9.0), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09219900891184807), 'actor_loss': np.float64(-0.9367620050907135), 'hyper_actor_loss': np.float64(0.0019084953120909632), 'behavior_loss': np.float64(1.3701034188270569)}
step: 7230 @ episode report: {'average_total_reward': np.float32(7.492223), 'reward_variance': np.float32(3.3868415), 'max_total_reward': np.float32(11.022223), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.8), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08371357843279839), 'actor_loss': np.float64(-0.9689578652381897), 'hyper_actor_loss': np.float64(0.0019511418882757424), 'behavior_loss': np.float64(1.4453572750091552)}
step: 7240 @ episode report: {'average_total_reward': np.float32(7.267778), 'reward_variance': np.float32(0.28452963), 'max_total_reward': np.float32(7.7777786), 'min_total_reward': np.float32(6.533334), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07893924899399281), 'actor_loss': np.float64(-0.9233153581619262), 'hyper_actor_loss': np.float64(0.001982057257555425), 'behavior_loss': np.float64(1.3648921012878419)}
step: 7250 @ episode report: {'average_total_reward': np.float32(7.28), 'reward_variance': np.float32(3.1532788), 'max_total_reward': np.float32(10.022222), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07597609311342239), 'actor_loss': np.float64(-0.9417365312576294), 'hyper_actor_loss': np.float64(0.0019985427148640155), 'behavior_loss': np.float64(1.4207019329071044)}
step: 7260 @ episode report: {'average_total_reward': np.float32(8.102223), 'reward_variance': np.float32(5.826293), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(9.3), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08138019032776356), 'actor_loss': np.float64(-0.9474249899387359), 'hyper_actor_loss': np.float64(0.0020344145712442698), 'behavior_loss': np.float64(1.3499382138252258)}
step: 7270 @ episode report: {'average_total_reward': np.float32(6.618889), 'reward_variance': np.float32(1.7832115), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.0), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08469093330204487), 'actor_loss': np.float64(-0.9701078176498413), 'hyper_actor_loss': np.float64(0.002170868287794292), 'behavior_loss': np.float64(1.313052487373352)}
step: 7280 @ episode report: {'average_total_reward': np.float32(6.857778), 'reward_variance': np.float32(1.890514), 'max_total_reward': np.float32(8.655557), 'min_total_reward': np.float32(5.166667), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07867163419723511), 'actor_loss': np.float64(-0.9371107339859008), 'hyper_actor_loss': np.float64(0.0022218353115022182), 'behavior_loss': np.float64(1.3742369890213013)}
step: 7290 @ episode report: {'average_total_reward': np.float32(6.294444), 'reward_variance': np.float32(1.8195127), 'max_total_reward': np.float32(7.7777786), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(7.7), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0859658695757389), 'actor_loss': np.float64(-0.9365881264209748), 'hyper_actor_loss': np.float64(0.0022148176562041045), 'behavior_loss': np.float64(1.3670651197433472)}
step: 7300 @ episode report: {'average_total_reward': np.float32(7.3188896), 'reward_variance': np.float32(1.2948903), 'max_total_reward': np.float32(9.777779), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(8.7), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07277193032205105), 'actor_loss': np.float64(-0.9227044820785523), 'hyper_actor_loss': np.float64(0.002199305989779532), 'behavior_loss': np.float64(1.4083208918571473)}
step: 7310 @ episode report: {'average_total_reward': np.float32(7.88), 'reward_variance': np.float32(1.3815755), 'max_total_reward': np.float32(9.9), 'min_total_reward': np.float32(6.5333333), 'average_n_step': np.float32(9.2), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07770035304129123), 'actor_loss': np.float64(-0.9493153393268585), 'hyper_actor_loss': np.float64(0.002134432038292289), 'behavior_loss': np.float64(1.343965971469879)}
step: 7320 @ episode report: {'average_total_reward': np.float32(7.2922225), 'reward_variance': np.float32(3.8126926), 'max_total_reward': np.float32(12.144444), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07110352367162705), 'actor_loss': np.float64(-0.9284038066864013), 'hyper_actor_loss': np.float64(0.0020875427406281235), 'behavior_loss': np.float64(1.353051447868347)}
step: 7330 @ episode report: {'average_total_reward': np.float32(6.4700003), 'reward_variance': np.float32(2.0087423), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.9), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07351105958223343), 'actor_loss': np.float64(-0.9145283877849579), 'hyper_actor_loss': np.float64(0.0021070656832307575), 'behavior_loss': np.float64(1.390434741973877)}
step: 7340 @ episode report: {'average_total_reward': np.float32(6.994445), 'reward_variance': np.float32(3.0143769), 'max_total_reward': np.float32(9.777779), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07505549304187298), 'actor_loss': np.float64(-0.9381196439266205), 'hyper_actor_loss': np.float64(0.002162147220224142), 'behavior_loss': np.float64(1.289625310897827)}
step: 7350 @ episode report: {'average_total_reward': np.float32(6.5700006), 'reward_variance': np.float32(2.5034337), 'max_total_reward': np.float32(7.7777786), 'min_total_reward': np.float32(3.1666667), 'average_n_step': np.float32(8.0), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0800836008042097), 'actor_loss': np.float64(-0.9434945046901703), 'hyper_actor_loss': np.float64(0.0021654476411640646), 'behavior_loss': np.float64(1.4447375655174255)}
step: 7360 @ episode report: {'average_total_reward': np.float32(7.78), 'reward_variance': np.float32(2.4655752), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.1), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08520877361297607), 'actor_loss': np.float64(-0.9528742015361786), 'hyper_actor_loss': np.float64(0.0021514538675546646), 'behavior_loss': np.float64(1.3122025847434997)}
step: 7370 @ episode report: {'average_total_reward': np.float32(6.9433336), 'reward_variance': np.float32(2.8062577), 'max_total_reward': np.float32(9.777778), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08116782829165459), 'actor_loss': np.float64(-0.9434822142124176), 'hyper_actor_loss': np.float64(0.00224637349601835), 'behavior_loss': np.float64(1.409874439239502)}
step: 7380 @ episode report: {'average_total_reward': np.float32(7.4800005), 'reward_variance': np.float32(2.072934), 'max_total_reward': np.float32(9.777779), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(8.8), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08674179017543793), 'actor_loss': np.float64(-0.934486573934555), 'hyper_actor_loss': np.float64(0.0021831321530044077), 'behavior_loss': np.float64(1.3512590408325196)}
step: 7390 @ episode report: {'average_total_reward': np.float32(7.2433333), 'reward_variance': np.float32(1.7901833), 'max_total_reward': np.float32(9.777778), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08174838945269584), 'actor_loss': np.float64(-0.9509908735752106), 'hyper_actor_loss': np.float64(0.002340694284066558), 'behavior_loss': np.float64(1.3551798343658448)}
step: 7400 @ episode report: {'average_total_reward': np.float32(7.716667), 'reward_variance': np.float32(2.6247222), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.0), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08259453997015953), 'actor_loss': np.float64(-0.9500950872898102), 'hyper_actor_loss': np.float64(0.0022515275282785296), 'behavior_loss': np.float64(1.3679479241371155)}
step: 7410 @ episode report: {'average_total_reward': np.float32(8.08), 'reward_variance': np.float32(1.7675011), 'max_total_reward': np.float32(10.9), 'min_total_reward': np.float32(6.411111), 'average_n_step': np.float32(9.4), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0834351010620594), 'actor_loss': np.float64(-0.9554527282714844), 'hyper_actor_loss': np.float64(0.002131566684693098), 'behavior_loss': np.float64(1.345589029788971)}
step: 7420 @ episode report: {'average_total_reward': np.float32(7.1800003), 'reward_variance': np.float32(1.2324643), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(8.5), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07504984699189662), 'actor_loss': np.float64(-0.9272607266902924), 'hyper_actor_loss': np.float64(0.0021923773689195513), 'behavior_loss': np.float64(1.2454666256904603)}
step: 7430 @ episode report: {'average_total_reward': np.float32(7.104445), 'reward_variance': np.float32(3.117264), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0825983215123415), 'actor_loss': np.float64(-0.94517862200737), 'hyper_actor_loss': np.float64(0.002242793212644756), 'behavior_loss': np.float64(1.3575780749320985)}
step: 7440 @ episode report: {'average_total_reward': np.float32(7.0433335), 'reward_variance': np.float32(2.326974), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(5.288889), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06819181069731713), 'actor_loss': np.float64(-0.9486665070056916), 'hyper_actor_loss': np.float64(0.0021131324232555927), 'behavior_loss': np.float64(1.2906592965126038)}
step: 7450 @ episode report: {'average_total_reward': np.float32(6.894445), 'reward_variance': np.float32(3.1890924), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(3.4111114), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08057598359882831), 'actor_loss': np.float64(-0.9441778898239136), 'hyper_actor_loss': np.float64(0.0021138665382750333), 'behavior_loss': np.float64(1.2874330043792725)}
step: 7460 @ episode report: {'average_total_reward': np.float32(7.804445), 'reward_variance': np.float32(2.567635), 'max_total_reward': np.float32(11.0222225), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(9.1), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06436010859906674), 'actor_loss': np.float64(-0.9444490671157837), 'hyper_actor_loss': np.float64(0.002181840850971639), 'behavior_loss': np.float64(1.232052755355835)}
step: 7470 @ episode report: {'average_total_reward': np.float32(7.131111), 'reward_variance': np.float32(3.3956008), 'max_total_reward': np.float32(11.022223), 'min_total_reward': np.float32(4.411112), 'average_n_step': np.float32(8.5), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07527323924005032), 'actor_loss': np.float64(-0.9364901781082153), 'hyper_actor_loss': np.float64(0.0023038648534566162), 'behavior_loss': np.float64(1.3202396988868714)}
step: 7480 @ episode report: {'average_total_reward': np.float32(7.78), 'reward_variance': np.float32(0.80021733), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.1), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08117552772164345), 'actor_loss': np.float64(-0.955870759487152), 'hyper_actor_loss': np.float64(0.002501825662329793), 'behavior_loss': np.float64(1.34191392660141)}
step: 7490 @ episode report: {'average_total_reward': np.float32(8.192223), 'reward_variance': np.float32(1.5277292), 'max_total_reward': np.float32(10.9), 'min_total_reward': np.float32(6.411112), 'average_n_step': np.float32(9.5), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08463969714939594), 'actor_loss': np.float64(-0.9457032740116119), 'hyper_actor_loss': np.float64(0.0026351137319579722), 'behavior_loss': np.float64(1.341895830631256)}
step: 7500 @ episode report: {'average_total_reward': np.float32(6.7188888), 'reward_variance': np.float32(2.9104958), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.1), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08455687575042248), 'actor_loss': np.float64(-0.961236834526062), 'hyper_actor_loss': np.float64(0.002792111085727811), 'behavior_loss': np.float64(1.3235575675964355)}
step: 7510 @ episode report: {'average_total_reward': np.float32(6.918889), 'reward_variance': np.float32(2.149383), 'max_total_reward': np.float32(9.9), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08714264482259751), 'actor_loss': np.float64(-0.9593706727027893), 'hyper_actor_loss': np.float64(0.0030919664539396765), 'behavior_loss': np.float64(1.3185951113700867)}
step: 7520 @ episode report: {'average_total_reward': np.float32(6.5577784), 'reward_variance': np.float32(2.2343411), 'max_total_reward': np.float32(9.777779), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.0), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08471729829907418), 'actor_loss': np.float64(-0.9519361555576324), 'hyper_actor_loss': np.float64(0.003155720978975296), 'behavior_loss': np.float64(1.2681036233901977)}
step: 7530 @ episode report: {'average_total_reward': np.float32(6.8433332), 'reward_variance': np.float32(1.437566), 'max_total_reward': np.float32(8.9), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(8.2), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07501922808587551), 'actor_loss': np.float64(-0.9448244452476502), 'hyper_actor_loss': np.float64(0.003169018146581948), 'behavior_loss': np.float64(1.322211492061615)}
step: 7540 @ episode report: {'average_total_reward': np.float32(7.1800003), 'reward_variance': np.float32(1.5940695), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(8.5), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08148523345589638), 'actor_loss': np.float64(-0.9504079997539521), 'hyper_actor_loss': np.float64(0.003147838031873107), 'behavior_loss': np.float64(1.2383058786392211)}
step: 7550 @ episode report: {'average_total_reward': np.float32(7.3433332), 'reward_variance': np.float32(2.170135), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(8.7), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0773948922753334), 'actor_loss': np.float64(-0.946315324306488), 'hyper_actor_loss': np.float64(0.002842647535726428), 'behavior_loss': np.float64(1.2922605991363525)}
step: 7560 @ episode report: {'average_total_reward': np.float32(6.631111), 'reward_variance': np.float32(2.4587855), 'max_total_reward': np.float32(8.9), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.0), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09300102926790714), 'actor_loss': np.float64(-0.9548996746540069), 'hyper_actor_loss': np.float64(0.0024316397495567797), 'behavior_loss': np.float64(1.3016246914863587)}
step: 7570 @ episode report: {'average_total_reward': np.float32(6.37), 'reward_variance': np.float32(1.3483719), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(7.8), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07764810398221016), 'actor_loss': np.float64(-0.953756433725357), 'hyper_actor_loss': np.float64(0.0023122367914766074), 'behavior_loss': np.float64(1.2926472902297974)}
step: 7580 @ episode report: {'average_total_reward': np.float32(7.2555556), 'reward_variance': np.float32(1.8335555), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07536462768912315), 'actor_loss': np.float64(-0.9116234958171845), 'hyper_actor_loss': np.float64(0.002088252210523933), 'behavior_loss': np.float64(1.2247411847114562)}
step: 7590 @ episode report: {'average_total_reward': np.float32(6.27), 'reward_variance': np.float32(2.8745942), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(3.2888892), 'average_n_step': np.float32(7.7), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07641706988215446), 'actor_loss': np.float64(-0.9494184732437134), 'hyper_actor_loss': np.float64(0.002078649157192558), 'behavior_loss': np.float64(1.365816342830658)}
step: 7600 @ episode report: {'average_total_reward': np.float32(6.8066664), 'reward_variance': np.float32(1.1477336), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(5.411112), 'average_n_step': np.float32(8.2), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06921694539487362), 'actor_loss': np.float64(-0.9236363351345063), 'hyper_actor_loss': np.float64(0.0021330187446437776), 'behavior_loss': np.float64(1.2752962470054627)}
step: 7610 @ episode report: {'average_total_reward': np.float32(6.955556), 'reward_variance': np.float32(1.3257042), 'max_total_reward': np.float32(8.655556), 'min_total_reward': np.float32(5.411111), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0900486458092928), 'actor_loss': np.float64(-0.9427785575389862), 'hyper_actor_loss': np.float64(0.0020693040336482228), 'behavior_loss': np.float64(1.291795790195465)}
step: 7620 @ episode report: {'average_total_reward': np.float32(7.055556), 'reward_variance': np.float32(1.7053587), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08045794144272804), 'actor_loss': np.float64(-0.9421642780303955), 'hyper_actor_loss': np.float64(0.0019687210442498326), 'behavior_loss': np.float64(1.2652066349983215)}
step: 7630 @ episode report: {'average_total_reward': np.float32(6.61889), 'reward_variance': np.float32(1.8869644), 'max_total_reward': np.float32(7.7777777), 'min_total_reward': np.float32(3.288889), 'average_n_step': np.float32(8.0), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07906125895678998), 'actor_loss': np.float64(-0.9362079083919526), 'hyper_actor_loss': np.float64(0.0020328154088929294), 'behavior_loss': np.float64(1.3822776317596435)}
step: 7640 @ episode report: {'average_total_reward': np.float32(7.467778), 'reward_variance': np.float32(1.2210977), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(8.8), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08082284815609456), 'actor_loss': np.float64(-0.958230060338974), 'hyper_actor_loss': np.float64(0.0022521797101944683), 'behavior_loss': np.float64(1.3047385454177856)}
step: 7650 @ episode report: {'average_total_reward': np.float32(6.631111), 'reward_variance': np.float32(1.2787113), 'max_total_reward': np.float32(8.655556), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.0), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0699489589780569), 'actor_loss': np.float64(-0.9209155738353729), 'hyper_actor_loss': np.float64(0.002404858241789043), 'behavior_loss': np.float64(1.291377955675125)}
step: 7660 @ episode report: {'average_total_reward': np.float32(6.618889), 'reward_variance': np.float32(2.9767668), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(8.0), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08299838826060295), 'actor_loss': np.float64(-0.9482555210590362), 'hyper_actor_loss': np.float64(0.0023637416772544382), 'behavior_loss': np.float64(1.2962664842605591)}
step: 7670 @ episode report: {'average_total_reward': np.float32(6.5433335), 'reward_variance': np.float32(1.6659863), 'max_total_reward': np.float32(8.777778), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(7.9), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09211908504366875), 'actor_loss': np.float64(-0.9779296338558197), 'hyper_actor_loss': np.float64(0.0025928381131961943), 'behavior_loss': np.float64(1.2845232367515564)}
step: 7680 @ episode report: {'average_total_reward': np.float32(5.2233334), 'reward_variance': np.float32(1.0340359), 'max_total_reward': np.float32(6.655556), 'min_total_reward': np.float32(3.0444446), 'average_n_step': np.float32(6.8), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08167489096522332), 'actor_loss': np.float64(-0.9503757059574127), 'hyper_actor_loss': np.float64(0.0030034645926207302), 'behavior_loss': np.float64(1.2545311808586121)}
step: 7690 @ episode report: {'average_total_reward': np.float32(4.574445), 'reward_variance': np.float32(0.38676667), 'max_total_reward': np.float32(5.533334), 'min_total_reward': np.float32(3.4111114), 'average_n_step': np.float32(6.2), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07952312976121903), 'actor_loss': np.float64(-0.956906658411026), 'hyper_actor_loss': np.float64(0.003544225404039025), 'behavior_loss': np.float64(1.3722638130187987)}
step: 7700 @ episode report: {'average_total_reward': np.float32(4.511111), 'reward_variance': np.float32(0.8605679), 'max_total_reward': np.float32(5.6555557), 'min_total_reward': np.float32(3.288889), 'average_n_step': np.float32(6.1), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0748790055513382), 'actor_loss': np.float64(-0.9400401711463928), 'hyper_actor_loss': np.float64(0.004152320837602019), 'behavior_loss': np.float64(1.1768009424209596)}
step: 7710 @ episode report: {'average_total_reward': np.float32(4.362222), 'reward_variance': np.float32(0.49783197), 'max_total_reward': np.float32(5.5333333), 'min_total_reward': np.float32(3.2888892), 'average_n_step': np.float32(6.0), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07687093727290631), 'actor_loss': np.float64(-0.971148407459259), 'hyper_actor_loss': np.float64(0.004355753352865577), 'behavior_loss': np.float64(1.2649492740631103)}
step: 7720 @ episode report: {'average_total_reward': np.float32(4.45), 'reward_variance': np.float32(1.7657839), 'max_total_reward': np.float32(7.7777777), 'min_total_reward': np.float32(2.9222221), 'average_n_step': np.float32(6.1), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08560257367789745), 'actor_loss': np.float64(-0.9333321869373321), 'hyper_actor_loss': np.float64(0.004617839679121971), 'behavior_loss': np.float64(1.337581253051758)}
step: 7730 @ episode report: {'average_total_reward': np.float32(4.462222), 'reward_variance': np.float32(1.4041287), 'max_total_reward': np.float32(6.411112), 'min_total_reward': np.float32(2.288889), 'average_n_step': np.float32(6.1), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(4.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07742273360490799), 'actor_loss': np.float64(-0.9733146071434021), 'hyper_actor_loss': np.float64(0.004787151422351599), 'behavior_loss': np.float64(1.3134035110473632)}
step: 7740 @ episode report: {'average_total_reward': np.float32(4.05), 'reward_variance': np.float32(1.3581295), 'max_total_reward': np.float32(5.6555557), 'min_total_reward': np.float32(2.0444446), 'average_n_step': np.float32(5.7), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(4.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07889779135584832), 'actor_loss': np.float64(-0.9334339499473572), 'hyper_actor_loss': np.float64(0.005133018083870411), 'behavior_loss': np.float64(1.4251275062561035)}
step: 7750 @ episode report: {'average_total_reward': np.float32(4.2644444), 'reward_variance': np.float32(1.8522669), 'max_total_reward': np.float32(6.4111114), 'min_total_reward': np.float32(2.0444446), 'average_n_step': np.float32(6.0), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(4.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06839714422821999), 'actor_loss': np.float64(-0.9205886423587799), 'hyper_actor_loss': np.float64(0.005700027896091342), 'behavior_loss': np.float64(1.3406970500946045)}
step: 7760 @ episode report: {'average_total_reward': np.float32(3.8255553), 'reward_variance': np.float32(1.150643), 'max_total_reward': np.float32(6.411111), 'min_total_reward': np.float32(2.288889), 'average_n_step': np.float32(5.5), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(4.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07359554395079612), 'actor_loss': np.float64(-0.9697410464286804), 'hyper_actor_loss': np.float64(0.009350175177678466), 'behavior_loss': np.float64(1.3305208683013916)}
step: 7770 @ episode report: {'average_total_reward': np.float32(3.376667), 'reward_variance': np.float32(0.5850483), 'max_total_reward': np.float32(4.533334), 'min_total_reward': np.float32(2.1666667), 'average_n_step': np.float32(5.1), 'max_n_step': np.float32(6.0), 'min_n_step': np.float32(4.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08274171575903892), 'actor_loss': np.float64(-1.0710469841957093), 'hyper_actor_loss': np.float64(0.016916575934737922), 'behavior_loss': np.float64(1.2017223477363586)}
step: 7780 @ episode report: {'average_total_reward': np.float32(2.9155557), 'reward_variance': np.float32(0.20896792), 'max_total_reward': np.float32(3.4111114), 'min_total_reward': np.float32(2.1666667), 'average_n_step': np.float32(4.7), 'max_n_step': np.float32(5.0), 'min_n_step': np.float32(4.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08236129246652127), 'actor_loss': np.float64(-1.3836332321166993), 'hyper_actor_loss': np.float64(0.02554207816720009), 'behavior_loss': np.float64(1.141423338651657)}
step: 7790 @ episode report: {'average_total_reward': np.float32(2.64), 'reward_variance': np.float32(0.37541243), 'max_total_reward': np.float32(3.9222224), 'min_total_reward': np.float32(2.0444446), 'average_n_step': np.float32(4.4), 'max_n_step': np.float32(6.0), 'min_n_step': np.float32(4.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0812775868922472), 'actor_loss': np.float64(-1.6847392678260804), 'hyper_actor_loss': np.float64(0.031783543340861795), 'behavior_loss': np.float64(0.9157538890838623)}
step: 7800 @ episode report: {'average_total_reward': np.float32(2.978889), 'reward_variance': np.float32(0.3197889), 'max_total_reward': np.float32(3.9222224), 'min_total_reward': np.float32(2.1666667), 'average_n_step': np.float32(4.8), 'max_n_step': np.float32(6.0), 'min_n_step': np.float32(4.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07901670075953007), 'actor_loss': np.float64(-1.707111668586731), 'hyper_actor_loss': np.float64(0.03623822256922722), 'behavior_loss': np.float64(0.885971587896347)}
step: 7810 @ episode report: {'average_total_reward': np.float32(2.8055558), 'reward_variance': np.float32(0.31368524), 'max_total_reward': np.float32(3.4111114), 'min_total_reward': np.float32(1.9222223), 'average_n_step': np.float32(4.7), 'max_n_step': np.float32(5.0), 'min_n_step': np.float32(4.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07988579347729682), 'actor_loss': np.float64(-1.6038694620132445), 'hyper_actor_loss': np.float64(0.040794627368450166), 'behavior_loss': np.float64(0.8082641065120697)}
step: 7820 @ episode report: {'average_total_reward': np.float32(2.3833337), 'reward_variance': np.float32(0.86563605), 'max_total_reward': np.float32(4.411112), 'min_total_reward': np.float32(1.0444444), 'average_n_step': np.float32(4.4), 'max_n_step': np.float32(6.0), 'min_n_step': np.float32(3.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09093399941921235), 'actor_loss': np.float64(-1.6271621942520142), 'hyper_actor_loss': np.float64(0.04420210011303425), 'behavior_loss': np.float64(0.7100207090377808)}
step: 7830 @ episode report: {'average_total_reward': np.float32(1.8322222), 'reward_variance': np.float32(0.36786294), 'max_total_reward': np.float32(2.9222221), 'min_total_reward': np.float32(0.9222222), 'average_n_step': np.float32(3.8), 'max_n_step': np.float32(5.0), 'min_n_step': np.float32(3.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08264359980821609), 'actor_loss': np.float64(-1.700101613998413), 'hyper_actor_loss': np.float64(0.046860430389642715), 'behavior_loss': np.float64(0.6482280850410461)}
step: 7840 @ episode report: {'average_total_reward': np.float32(1.5711112), 'reward_variance': np.float32(0.14444938), 'max_total_reward': np.float32(2.1666667), 'min_total_reward': np.float32(1.0444446), 'average_n_step': np.float32(3.6), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08620215207338333), 'actor_loss': np.float64(-1.7752591133117677), 'hyper_actor_loss': np.float64(0.047703180462121964), 'behavior_loss': np.float64(0.6055885016918182)}
step: 7850 @ episode report: {'average_total_reward': np.float32(0.7244445), 'reward_variance': np.float32(0.12661235), 'max_total_reward': np.float32(1.1666667), 'min_total_reward': np.float32(-0.07777779), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07887751869857311), 'actor_loss': np.float64(-1.8186341285705567), 'hyper_actor_loss': np.float64(0.04759136289358139), 'behavior_loss': np.float64(0.5811181128025055)}
step: 7860 @ episode report: {'average_total_reward': np.float32(0.62666667), 'reward_variance': np.float32(0.13714077), 'max_total_reward': np.float32(1.3111112), 'min_total_reward': np.float32(0.044444427), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(2.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08542764596641064), 'actor_loss': np.float64(-1.8656151652336121), 'hyper_actor_loss': np.float64(0.04702444337308407), 'behavior_loss': np.float64(0.5992808640003204)}
step: 7870 @ episode report: {'average_total_reward': np.float32(0.4122222), 'reward_variance': np.float32(0.18566544), 'max_total_reward': np.float32(1.0444444), 'min_total_reward': np.float32(-0.20000002), 'average_n_step': np.float32(2.6), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08835969492793083), 'actor_loss': np.float64(-1.5945686459541322), 'hyper_actor_loss': np.float64(0.04698940478265286), 'behavior_loss': np.float64(0.5800110578536988)}
step: 7880 @ episode report: {'average_total_reward': np.float32(0.1511111), 'reward_variance': np.float32(0.07790616), 'max_total_reward': np.float32(0.92222226), 'min_total_reward': np.float32(-0.077777795), 'average_n_step': np.float32(2.4), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0923998299986124), 'actor_loss': np.float64(-1.283584177494049), 'hyper_actor_loss': np.float64(0.0482290543615818), 'behavior_loss': np.float64(0.5627928793430328)}
step: 7890 @ episode report: {'average_total_reward': np.float32(0.028888876), 'reward_variance': np.float32(0.029017285), 'max_total_reward': np.float32(0.3111111), 'min_total_reward': np.float32(-0.20000002), 'average_n_step': np.float32(2.4), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09527052864432335), 'actor_loss': np.float64(-1.1647470235824584), 'hyper_actor_loss': np.float64(0.05076683647930622), 'behavior_loss': np.float64(0.5567857027053833)}
step: 7900 @ episode report: {'average_total_reward': np.float32(-0.01444446), 'reward_variance': np.float32(0.0141), 'max_total_reward': np.float32(0.3111111), 'min_total_reward': np.float32(-0.077777795), 'average_n_step': np.float32(2.1), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09292948171496392), 'actor_loss': np.float64(-0.97024205327034), 'hyper_actor_loss': np.float64(0.05261695645749569), 'behavior_loss': np.float64(0.5910641252994537)}
step: 7910 @ episode report: {'average_total_reward': np.float32(0.28999996), 'reward_variance': np.float32(0.07783828), 'max_total_reward': np.float32(0.92222226), 'min_total_reward': np.float32(-0.07777779), 'average_n_step': np.float32(2.6), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09557691998779774), 'actor_loss': np.float64(-0.8932525336742401), 'hyper_actor_loss': np.float64(0.05437569320201874), 'behavior_loss': np.float64(0.6011911034584045)}
step: 7920 @ episode report: {'average_total_reward': np.float32(0.56777775), 'reward_variance': np.float32(0.025245678), 'max_total_reward': np.float32(0.9222222), 'min_total_reward': np.float32(0.43333328), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(3.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07449878379702568), 'actor_loss': np.float64(-0.8668286144733429), 'hyper_actor_loss': np.float64(0.05639020018279552), 'behavior_loss': np.float64(0.5998601913452148)}
step: 7930 @ episode report: {'average_total_reward': np.float32(1.0633335), 'reward_variance': np.float32(0.5496556), 'max_total_reward': np.float32(2.288889), 'min_total_reward': np.float32(0.3111111), 'average_n_step': np.float32(3.3), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09748476631939411), 'actor_loss': np.float64(-0.8039120495319366), 'hyper_actor_loss': np.float64(0.054911117628216745), 'behavior_loss': np.float64(0.5155501157045365)}
step: 7940 @ episode report: {'average_total_reward': np.float32(2.442222), 'reward_variance': np.float32(0.22352593), 'max_total_reward': np.float32(3.4111114), 'min_total_reward': np.float32(1.9222224), 'average_n_step': np.float32(4.3), 'max_n_step': np.float32(5.0), 'min_n_step': np.float32(4.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09491148963570595), 'actor_loss': np.float64(-0.9501174569129944), 'hyper_actor_loss': np.float64(0.04989586025476456), 'behavior_loss': np.float64(0.4855256944894791)}
step: 7950 @ episode report: {'average_total_reward': np.float32(2.891111), 'reward_variance': np.float32(0.4783903), 'max_total_reward': np.float32(4.533334), 'min_total_reward': np.float32(2.1666665), 'average_n_step': np.float32(4.7), 'max_n_step': np.float32(6.0), 'min_n_step': np.float32(4.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09270181581377983), 'actor_loss': np.float64(-0.8841767609119415), 'hyper_actor_loss': np.float64(0.044521146640181544), 'behavior_loss': np.float64(0.4886768668889999)}
step: 7960 @ episode report: {'average_total_reward': np.float32(4.1011114), 'reward_variance': np.float32(1.4465297), 'max_total_reward': np.float32(5.533334), 'min_total_reward': np.float32(1.9222223), 'average_n_step': np.float32(5.8), 'max_n_step': np.float32(7.0), 'min_n_step': np.float32(4.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0786640491336584), 'actor_loss': np.float64(-0.9434862673282624), 'hyper_actor_loss': np.float64(0.040015192702412605), 'behavior_loss': np.float64(0.5336963564157486)}
step: 7970 @ episode report: {'average_total_reward': np.float32(5.362222), 'reward_variance': np.float32(0.83644944), 'max_total_reward': np.float32(7.4111114), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(7.0), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07558320350944996), 'actor_loss': np.float64(-0.9154781401157379), 'hyper_actor_loss': np.float64(0.03742838837206364), 'behavior_loss': np.float64(0.5412117719650269)}
step: 7980 @ episode report: {'average_total_reward': np.float32(4.5744452), 'reward_variance': np.float32(1.2326679), 'max_total_reward': np.float32(6.288889), 'min_total_reward': np.float32(2.288889), 'average_n_step': np.float32(6.2), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(4.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07642856575548648), 'actor_loss': np.float64(-0.9248868286609649), 'hyper_actor_loss': np.float64(0.0352908480912447), 'behavior_loss': np.float64(0.554415512084961)}
step: 7990 @ episode report: {'average_total_reward': np.float32(5.7577777), 'reward_variance': np.float32(1.2573532), 'max_total_reward': np.float32(7.777778), 'min_total_reward': np.float32(4.0444446), 'average_n_step': np.float32(7.2), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0862686812877655), 'actor_loss': np.float64(-0.9563333988189697), 'hyper_actor_loss': np.float64(0.033060988411307335), 'behavior_loss': np.float64(0.5752000480890274)}
step: 8000 @ episode report: {'average_total_reward': np.float32(5.7211113), 'reward_variance': np.float32(1.6974188), 'max_total_reward': np.float32(7.6555557), 'min_total_reward': np.float32(3.411111), 'average_n_step': np.float32(7.2), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09332210868597031), 'actor_loss': np.float64(-0.9569154202938079), 'hyper_actor_loss': np.float64(0.030795313976705076), 'behavior_loss': np.float64(0.6065957546234131)}
step: 8010 @ episode report: {'average_total_reward': np.float32(6.5699997), 'reward_variance': np.float32(1.8929398), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(8.0), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08823434226214885), 'actor_loss': np.float64(-0.927470600605011), 'hyper_actor_loss': np.float64(0.028857885301113127), 'behavior_loss': np.float64(0.6642845809459687)}
step: 8020 @ episode report: {'average_total_reward': np.float32(7.9800005), 'reward_variance': np.float32(2.2296734), 'max_total_reward': np.float32(9.777778), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(9.3), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07647630758583546), 'actor_loss': np.float64(-0.933326804637909), 'hyper_actor_loss': np.float64(0.026649737544357777), 'behavior_loss': np.float64(0.6465918004512787)}
step: 8030 @ episode report: {'average_total_reward': np.float32(7.2555556), 'reward_variance': np.float32(0.9986173), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08719597160816192), 'actor_loss': np.float64(-0.9360850393772125), 'hyper_actor_loss': np.float64(0.024552847631275652), 'behavior_loss': np.float64(0.7089761018753051)}
step: 8040 @ episode report: {'average_total_reward': np.float32(8.055555), 'reward_variance': np.float32(1.0379999), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(6.411111), 'average_n_step': np.float32(9.4), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08757631927728653), 'actor_loss': np.float64(-0.9374770939350128), 'hyper_actor_loss': np.float64(0.022399157099425793), 'behavior_loss': np.float64(0.7454923033714295)}
step: 8050 @ episode report: {'average_total_reward': np.float32(8.265556), 'reward_variance': np.float32(1.7503815), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(6.533334), 'average_n_step': np.float32(9.5), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0840641051530838), 'actor_loss': np.float64(-0.9127404987812042), 'hyper_actor_loss': np.float64(0.02074712924659252), 'behavior_loss': np.float64(0.7478928327560425)}
step: 8060 @ episode report: {'average_total_reward': np.float32(8.902223), 'reward_variance': np.float32(2.2655752), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.1), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09159669578075409), 'actor_loss': np.float64(-0.9593078434467316), 'hyper_actor_loss': np.float64(0.01876054350286722), 'behavior_loss': np.float64(0.7820374548435212)}
step: 8070 @ episode report: {'average_total_reward': np.float32(8.265556), 'reward_variance': np.float32(2.0601096), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(9.5), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08228562138974667), 'actor_loss': np.float64(-0.9371067643165588), 'hyper_actor_loss': np.float64(0.01682712957262993), 'behavior_loss': np.float64(0.793720155954361)}
step: 8080 @ episode report: {'average_total_reward': np.float32(8.002222), 'reward_variance': np.float32(2.3616498), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(9.2), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0906555786728859), 'actor_loss': np.float64(-0.9279606878757477), 'hyper_actor_loss': np.float64(0.01540944203734398), 'behavior_loss': np.float64(0.8286051571369171)}
step: 8090 @ episode report: {'average_total_reward': np.float32(8.665556), 'reward_variance': np.float32(1.8580115), 'max_total_reward': np.float32(11.0222225), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(9.9), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08314025439321995), 'actor_loss': np.float64(-0.9419726371765137), 'hyper_actor_loss': np.float64(0.014157859887927771), 'behavior_loss': np.float64(0.8716020822525025)}
step: 8100 @ episode report: {'average_total_reward': np.float32(8.838889), 'reward_variance': np.float32(7.373983), 'max_total_reward': np.float32(15.511112), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.0), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07886469140648841), 'actor_loss': np.float64(-0.9099715769290924), 'hyper_actor_loss': np.float64(0.013032056111842393), 'behavior_loss': np.float64(0.8542706429958343)}
step: 8110 @ episode report: {'average_total_reward': np.float32(7.1922226), 'reward_variance': np.float32(1.7247422), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(8.5), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09171632751822471), 'actor_loss': np.float64(-0.9412951469421387), 'hyper_actor_loss': np.float64(0.012213442381471396), 'behavior_loss': np.float64(0.8587231576442719)}
step: 8120 @ episode report: {'average_total_reward': np.float32(8.765556), 'reward_variance': np.float32(5.4717402), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(10.0), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08711728192865849), 'actor_loss': np.float64(-0.9479233026504517), 'hyper_actor_loss': np.float64(0.011102058831602335), 'behavior_loss': np.float64(0.924716341495514)}
step: 8130 @ episode report: {'average_total_reward': np.float32(7.416667), 'reward_variance': np.float32(2.5586739), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.7), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08211425729095936), 'actor_loss': np.float64(-0.8997036695480347), 'hyper_actor_loss': np.float64(0.010227077640593052), 'behavior_loss': np.float64(0.960884815454483)}
step: 8140 @ episode report: {'average_total_reward': np.float32(7.2922225), 'reward_variance': np.float32(1.4310877), 'max_total_reward': np.float32(8.9), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07942057810723782), 'actor_loss': np.float64(-0.9277037978172302), 'hyper_actor_loss': np.float64(0.009483206178992986), 'behavior_loss': np.float64(0.9467580020427704)}
step: 8150 @ episode report: {'average_total_reward': np.float32(8.690001), 'reward_variance': np.float32(2.0050483), 'max_total_reward': np.float32(10.900001), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(9.9), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08555099219083787), 'actor_loss': np.float64(-0.9372351229190826), 'hyper_actor_loss': np.float64(0.009142582491040229), 'behavior_loss': np.float64(0.8871634721755981)}
step: 8160 @ episode report: {'average_total_reward': np.float32(9.026668), 'reward_variance': np.float32(3.4687703), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.2), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08148143962025642), 'actor_loss': np.float64(-0.9403381526470185), 'hyper_actor_loss': np.float64(0.008317280653864145), 'behavior_loss': np.float64(0.9209548175334931)}
step: 8170 @ episode report: {'average_total_reward': np.float32(7.804445), 'reward_variance': np.float32(1.2943017), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(5.6555552), 'average_n_step': np.float32(9.1), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0904230758547783), 'actor_loss': np.float64(-0.9601936101913452), 'hyper_actor_loss': np.float64(0.008176254108548164), 'behavior_loss': np.float64(0.954550588130951)}
step: 8180 @ episode report: {'average_total_reward': np.float32(8.602223), 'reward_variance': np.float32(3.3457985), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.8), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08568054474890233), 'actor_loss': np.float64(-0.9070743560791016), 'hyper_actor_loss': np.float64(0.007576035289093852), 'behavior_loss': np.float64(0.934012258052826)}
step: 8190 @ episode report: {'average_total_reward': np.float32(9.002222), 'reward_variance': np.float32(3.82002), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(6.288889), 'average_n_step': np.float32(10.2), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08693314641714096), 'actor_loss': np.float64(-0.9479590594768524), 'hyper_actor_loss': np.float64(0.007154346304014325), 'behavior_loss': np.float64(0.9490565359592438)}
step: 8200 @ episode report: {'average_total_reward': np.float32(9.090001), 'reward_variance': np.float32(1.1960357), 'max_total_reward': np.float32(10.777779), 'min_total_reward': np.float32(7.533334), 'average_n_step': np.float32(10.3), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08661431893706321), 'actor_loss': np.float64(-0.9599708259105683), 'hyper_actor_loss': np.float64(0.00702998205088079), 'behavior_loss': np.float64(0.898559284210205)}
step: 8210 @ episode report: {'average_total_reward': np.float32(7.79), 'reward_variance': np.float32(2.3859363), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.0), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08563161864876748), 'actor_loss': np.float64(-0.9321312308311462), 'hyper_actor_loss': np.float64(0.0064330262131989), 'behavior_loss': np.float64(0.9744560241699218)}
step: 8220 @ episode report: {'average_total_reward': np.float32(7.953334), 'reward_variance': np.float32(2.6420445), 'max_total_reward': np.float32(11.0222225), 'min_total_reward': np.float32(5.655556), 'average_n_step': np.float32(9.2), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08248960636556149), 'actor_loss': np.float64(-0.9416399955749511), 'hyper_actor_loss': np.float64(0.0062651438638567924), 'behavior_loss': np.float64(0.9812381386756897)}
step: 8230 @ episode report: {'average_total_reward': np.float32(7.816667), 'reward_variance': np.float32(1.56534), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(9.1), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08951848931610584), 'actor_loss': np.float64(-0.9401101171970367), 'hyper_actor_loss': np.float64(0.005807935213670135), 'behavior_loss': np.float64(0.9851021111011505)}
step: 8240 @ episode report: {'average_total_reward': np.float32(9.487778), 'reward_variance': np.float32(1.6251224), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(10.6), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08450719825923443), 'actor_loss': np.float64(-0.9314984500408172), 'hyper_actor_loss': np.float64(0.006044891104102135), 'behavior_loss': np.float64(0.9757353127002716)}
step: 8250 @ episode report: {'average_total_reward': np.float32(8.602222), 'reward_variance': np.float32(2.9841924), 'max_total_reward': np.float32(11.0222225), 'min_total_reward': np.float32(6.533334), 'average_n_step': np.float32(9.8), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08168275877833367), 'actor_loss': np.float64(-0.9478240668773651), 'hyper_actor_loss': np.float64(0.0054727612063288685), 'behavior_loss': np.float64(0.9697552502155304)}
step: 8260 @ episode report: {'average_total_reward': np.float32(8.628889), 'reward_variance': np.float32(3.8270175), 'max_total_reward': np.float32(12.144444), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(9.9), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07618021331727505), 'actor_loss': np.float64(-0.9202334821224213), 'hyper_actor_loss': np.float64(0.005243422882631421), 'behavior_loss': np.float64(0.9684603929519653)}
step: 8270 @ episode report: {'average_total_reward': np.float32(8.951112), 'reward_variance': np.float32(4.0051904), 'max_total_reward': np.float32(12.266666), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(10.1), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08726937398314476), 'actor_loss': np.float64(-0.9358502566814423), 'hyper_actor_loss': np.float64(0.005072512617334724), 'behavior_loss': np.float64(0.982651311159134)}
step: 8280 @ episode report: {'average_total_reward': np.float32(8.714445), 'reward_variance': np.float32(1.0805442), 'max_total_reward': np.float32(10.022222), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(9.9), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07547554187476635), 'actor_loss': np.float64(-0.9413616240024567), 'hyper_actor_loss': np.float64(0.005357410991564393), 'behavior_loss': np.float64(0.9466539204120636)}
step: 8290 @ episode report: {'average_total_reward': np.float32(8.677778), 'reward_variance': np.float32(1.1064695), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(9.9), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08205470368266106), 'actor_loss': np.float64(-0.9484294533729554), 'hyper_actor_loss': np.float64(0.005346616031602025), 'behavior_loss': np.float64(0.9799585163593292)}
step: 8300 @ episode report: {'average_total_reward': np.float32(7.8922224), 'reward_variance': np.float32(1.9145943), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(9.2), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08901977315545082), 'actor_loss': np.float64(-0.9525625050067902), 'hyper_actor_loss': np.float64(0.005583854159340262), 'behavior_loss': np.float64(0.9026840627193451)}
step: 8310 @ episode report: {'average_total_reward': np.float32(8.802223), 'reward_variance': np.float32(2.7575495), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(10.0), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0931909054517746), 'actor_loss': np.float64(-0.9778836011886597), 'hyper_actor_loss': np.float64(0.005605871556326747), 'behavior_loss': np.float64(0.9324635207653046)}
step: 8320 @ episode report: {'average_total_reward': np.float32(7.8655562), 'reward_variance': np.float32(2.284357), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(9.1), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0740048997104168), 'actor_loss': np.float64(-0.9408991992473602), 'hyper_actor_loss': np.float64(0.005573696969076991), 'behavior_loss': np.float64(0.9276615619659424)}
step: 8330 @ episode report: {'average_total_reward': np.float32(8.914445), 'reward_variance': np.float32(2.164644), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(6.5333333), 'average_n_step': np.float32(10.1), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08731724992394448), 'actor_loss': np.float64(-0.9367772579193115), 'hyper_actor_loss': np.float64(0.005620808387175202), 'behavior_loss': np.float64(0.9392008125782013)}
step: 8340 @ episode report: {'average_total_reward': np.float32(8.990001), 'reward_variance': np.float32(1.6158378), 'max_total_reward': np.float32(12.022222), 'min_total_reward': np.float32(7.5333333), 'average_n_step': np.float32(10.2), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09347614794969558), 'actor_loss': np.float64(-0.9907333552837372), 'hyper_actor_loss': np.float64(0.005502485809847713), 'behavior_loss': np.float64(0.9217837989330292)}
step: 8350 @ episode report: {'average_total_reward': np.float32(8.653334), 'reward_variance': np.float32(1.3972294), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.9), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09250702410936355), 'actor_loss': np.float64(-0.9565145194530487), 'hyper_actor_loss': np.float64(0.005318799940869212), 'behavior_loss': np.float64(0.9394216775894165)}
step: 8360 @ episode report: {'average_total_reward': np.float32(9.226667), 'reward_variance': np.float32(2.2479057), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(6.4111114), 'average_n_step': np.float32(10.4), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08585165739059449), 'actor_loss': np.float64(-0.9217336714267731), 'hyper_actor_loss': np.float64(0.004928301181644201), 'behavior_loss': np.float64(0.9704863846302032)}
step: 8370 @ episode report: {'average_total_reward': np.float32(8.614445), 'reward_variance': np.float32(2.9928164), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.8), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08801486641168595), 'actor_loss': np.float64(-0.9310264229774475), 'hyper_actor_loss': np.float64(0.004894663253799081), 'behavior_loss': np.float64(0.9562688648700715)}
step: 8380 @ episode report: {'average_total_reward': np.float32(8.826668), 'reward_variance': np.float32(2.3637328), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(5.655556), 'average_n_step': np.float32(10.0), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08476265780627727), 'actor_loss': np.float64(-0.9465616405010223), 'hyper_actor_loss': np.float64(0.004679128993302584), 'behavior_loss': np.float64(0.9642850935459137)}
step: 8390 @ episode report: {'average_total_reward': np.float32(7.267778), 'reward_variance': np.float32(1.4097391), 'max_total_reward': np.float32(8.777778), 'min_total_reward': np.float32(5.411111), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09015626162290573), 'actor_loss': np.float64(-0.9543553113937377), 'hyper_actor_loss': np.float64(0.004515831544995308), 'behavior_loss': np.float64(0.9781114399433136)}
step: 8400 @ episode report: {'average_total_reward': np.float32(7.4044447), 'reward_variance': np.float32(2.79808), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.7), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07230235263705254), 'actor_loss': np.float64(-0.9029051840305329), 'hyper_actor_loss': np.float64(0.004451892198994755), 'behavior_loss': np.float64(0.9824372947216033)}
step: 8410 @ episode report: {'average_total_reward': np.float32(9.500001), 'reward_variance': np.float32(3.1507907), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(7.533334), 'average_n_step': np.float32(10.6), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07875635251402854), 'actor_loss': np.float64(-0.9296219229698182), 'hyper_actor_loss': np.float64(0.004279147181659937), 'behavior_loss': np.float64(0.9743058621883393)}
step: 8420 @ episode report: {'average_total_reward': np.float32(8.93889), 'reward_variance': np.float32(1.6750677), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(10.1), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08676631450653076), 'actor_loss': np.float64(-0.9679409146308899), 'hyper_actor_loss': np.float64(0.004081415268592537), 'behavior_loss': np.float64(0.9145429313182831)}
step: 8430 @ episode report: {'average_total_reward': np.float32(9.014445), 'reward_variance': np.float32(3.932595), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(5.411111), 'average_n_step': np.float32(10.2), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09747124835848808), 'actor_loss': np.float64(-0.9388955891132355), 'hyper_actor_loss': np.float64(0.004050886421464383), 'behavior_loss': np.float64(0.961816668510437)}
step: 8440 @ episode report: {'average_total_reward': np.float32(7.8411117), 'reward_variance': np.float32(2.091038), 'max_total_reward': np.float32(11.022222), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(9.1), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09068805053830147), 'actor_loss': np.float64(-0.9526096820831299), 'hyper_actor_loss': np.float64(0.004075276060029864), 'behavior_loss': np.float64(0.9698756396770477)}
step: 8450 @ episode report: {'average_total_reward': np.float32(8.914446), 'reward_variance': np.float32(1.348174), 'max_total_reward': np.float32(11.0222225), 'min_total_reward': np.float32(7.5333333), 'average_n_step': np.float32(10.1), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07803487069904805), 'actor_loss': np.float64(-0.9511931717395783), 'hyper_actor_loss': np.float64(0.003867568029090762), 'behavior_loss': np.float64(0.914363706111908)}
step: 8460 @ episode report: {'average_total_reward': np.float32(7.916667), 'reward_variance': np.float32(1.568253), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(9.2), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08552868850529194), 'actor_loss': np.float64(-0.9561276376247406), 'hyper_actor_loss': np.float64(0.004002620349638164), 'behavior_loss': np.float64(0.90162872672081)}
step: 8470 @ episode report: {'average_total_reward': np.float32(8.790001), 'reward_variance': np.float32(3.8737388), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(10.0), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08298855423927307), 'actor_loss': np.float64(-0.9288220643997193), 'hyper_actor_loss': np.float64(0.0040651008021086454), 'behavior_loss': np.float64(0.9586542427539826)}
step: 8480 @ episode report: {'average_total_reward': np.float32(8.79), 'reward_variance': np.float32(1.2667027), 'max_total_reward': np.float32(11.0222225), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.0), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09215282052755355), 'actor_loss': np.float64(-0.9478739321231842), 'hyper_actor_loss': np.float64(0.003947601653635502), 'behavior_loss': np.float64(0.9341112375259399)}
step: 8490 @ episode report: {'average_total_reward': np.float32(8.128889), 'reward_variance': np.float32(2.8164005), 'max_total_reward': np.float32(11.0222225), 'min_total_reward': np.float32(5.1666665), 'average_n_step': np.float32(9.4), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09110298380255699), 'actor_loss': np.float64(-0.9689895629882812), 'hyper_actor_loss': np.float64(0.0038494949927553534), 'behavior_loss': np.float64(0.9450661897659302)}
step: 8500 @ episode report: {'average_total_reward': np.float32(9.114446), 'reward_variance': np.float32(2.8884454), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.655556), 'average_n_step': np.float32(10.3), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09957242906093597), 'actor_loss': np.float64(-0.9467479348182678), 'hyper_actor_loss': np.float64(0.0038366654189303517), 'behavior_loss': np.float64(0.9663146495819092)}
step: 8510 @ episode report: {'average_total_reward': np.float32(8.141111), 'reward_variance': np.float32(2.7179036), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(9.4), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08313994705677033), 'actor_loss': np.float64(-0.9554761826992035), 'hyper_actor_loss': np.float64(0.0036679649027064444), 'behavior_loss': np.float64(0.9512260913848877)}
step: 8520 @ episode report: {'average_total_reward': np.float32(8.402223), 'reward_variance': np.float32(3.1014028), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(9.6), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08507048040628433), 'actor_loss': np.float64(-0.9210342705249787), 'hyper_actor_loss': np.float64(0.0036551473662257195), 'behavior_loss': np.float64(0.9925390839576721)}
step: 8530 @ episode report: {'average_total_reward': np.float32(8.465556), 'reward_variance': np.float32(1.4968017), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(6.533334), 'average_n_step': np.float32(9.7), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09368515908718109), 'actor_loss': np.float64(-0.956112265586853), 'hyper_actor_loss': np.float64(0.003777135699056089), 'behavior_loss': np.float64(0.9817956268787384)}
step: 8540 @ episode report: {'average_total_reward': np.float32(7.916667), 'reward_variance': np.float32(1.6919329), 'max_total_reward': np.float32(9.900002), 'min_total_reward': np.float32(5.655556), 'average_n_step': np.float32(9.2), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07700619548559189), 'actor_loss': np.float64(-0.9205702424049378), 'hyper_actor_loss': np.float64(0.00402428915258497), 'behavior_loss': np.float64(0.9734546661376953)}
step: 8550 @ episode report: {'average_total_reward': np.float32(9.275556), 'reward_variance': np.float32(3.4904385), 'max_total_reward': np.float32(13.388888), 'min_total_reward': np.float32(7.655556), 'average_n_step': np.float32(10.4), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08465459272265434), 'actor_loss': np.float64(-0.9196008384227753), 'hyper_actor_loss': np.float64(0.004256076063029468), 'behavior_loss': np.float64(0.8781394302845001)}
step: 8560 @ episode report: {'average_total_reward': np.float32(9.051111), 'reward_variance': np.float32(2.5991416), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.411111), 'average_n_step': np.float32(10.2), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09037004858255386), 'actor_loss': np.float64(-0.9656065881252289), 'hyper_actor_loss': np.float64(0.004634433984756469), 'behavior_loss': np.float64(0.8970476865768433)}
step: 8570 @ episode report: {'average_total_reward': np.float32(8.638889), 'reward_variance': np.float32(1.223117), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(6.655556), 'average_n_step': np.float32(9.8), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09921281337738037), 'actor_loss': np.float64(-0.9540633141994477), 'hyper_actor_loss': np.float64(0.004646945372223854), 'behavior_loss': np.float64(0.8705642819404602)}
step: 8580 @ episode report: {'average_total_reward': np.float32(8.165556), 'reward_variance': np.float32(1.4586285), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(9.4), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08655139803886414), 'actor_loss': np.float64(-0.9752188205718995), 'hyper_actor_loss': np.float64(0.004595746193081141), 'behavior_loss': np.float64(0.8364892959594726)}
step: 8590 @ episode report: {'average_total_reward': np.float32(9.177778), 'reward_variance': np.float32(1.626049), 'max_total_reward': np.float32(12.0222225), 'min_total_reward': np.float32(7.655556), 'average_n_step': np.float32(10.4), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08305708542466164), 'actor_loss': np.float64(-0.9318110883235932), 'hyper_actor_loss': np.float64(0.004307076521217823), 'behavior_loss': np.float64(0.8992704093456269)}
step: 8600 @ episode report: {'average_total_reward': np.float32(8.004445), 'reward_variance': np.float32(0.239116), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(7.5333333), 'average_n_step': np.float32(9.3), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07661356665194034), 'actor_loss': np.float64(-0.9445165455341339), 'hyper_actor_loss': np.float64(0.004235869063995779), 'behavior_loss': np.float64(0.9218395292758942)}
step: 8610 @ episode report: {'average_total_reward': np.float32(9.263334), 'reward_variance': np.float32(1.1986679), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(7.5333343), 'average_n_step': np.float32(10.4), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09436394944787026), 'actor_loss': np.float64(-0.9466013014316559), 'hyper_actor_loss': np.float64(0.004116766736842692), 'behavior_loss': np.float64(0.9729871153831482)}
step: 8620 @ episode report: {'average_total_reward': np.float32(8.141111), 'reward_variance': np.float32(1.5682485), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(6.6555552), 'average_n_step': np.float32(9.4), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07513515166938305), 'actor_loss': np.float64(-0.9393498063087463), 'hyper_actor_loss': np.float64(0.004243923397734761), 'behavior_loss': np.float64(0.897911137342453)}
step: 8630 @ episode report: {'average_total_reward': np.float32(7.553334), 'reward_variance': np.float32(2.6409588), 'max_total_reward': np.float32(11.144446), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.8), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08218755424022675), 'actor_loss': np.float64(-0.9271309316158295), 'hyper_actor_loss': np.float64(0.0039747243514284495), 'behavior_loss': np.float64(0.9412541031837464)}
step: 8640 @ episode report: {'average_total_reward': np.float32(8.165556), 'reward_variance': np.float32(0.785295), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(6.533334), 'average_n_step': np.float32(9.4), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08359919562935829), 'actor_loss': np.float64(-0.9383468687534332), 'hyper_actor_loss': np.float64(0.004009204055182636), 'behavior_loss': np.float64(0.9226345002651215)}
step: 8650 @ episode report: {'average_total_reward': np.float32(7.0433335), 'reward_variance': np.float32(2.6526535), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07848054766654969), 'actor_loss': np.float64(-0.9484059274196625), 'hyper_actor_loss': np.float64(0.004116077930666507), 'behavior_loss': np.float64(0.8782227516174317)}
step: 8660 @ episode report: {'average_total_reward': np.float32(9.038889), 'reward_variance': np.float32(1.9278581), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(6.411111), 'average_n_step': np.float32(10.2), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08037892803549766), 'actor_loss': np.float64(-0.9381108999252319), 'hyper_actor_loss': np.float64(0.004026551567949355), 'behavior_loss': np.float64(0.9012430310249329)}
step: 8670 @ episode report: {'average_total_reward': np.float32(9.3144455), 'reward_variance': np.float32(3.6220512), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(6.4111114), 'average_n_step': np.float32(10.5), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08531731851398945), 'actor_loss': np.float64(-0.9428202867507934), 'hyper_actor_loss': np.float64(0.004032414243556559), 'behavior_loss': np.float64(0.904601228237152)}
step: 8680 @ episode report: {'average_total_reward': np.float32(9.087778), 'reward_variance': np.float32(5.294036), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(10.2), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09935502260923386), 'actor_loss': np.float64(-0.9876718759536743), 'hyper_actor_loss': np.float64(0.003943315218202769), 'behavior_loss': np.float64(0.9098688960075378)}
step: 8690 @ episode report: {'average_total_reward': np.float32(7.816667), 'reward_variance': np.float32(2.8062534), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(9.1), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09083790369331837), 'actor_loss': np.float64(-0.9364534854888916), 'hyper_actor_loss': np.float64(0.004201732762157917), 'behavior_loss': np.float64(0.9093936204910278)}
step: 8700 @ episode report: {'average_total_reward': np.float32(8.714445), 'reward_variance': np.float32(1.8636059), 'max_total_reward': np.float32(11.022223), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(9.9), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09262505397200585), 'actor_loss': np.float64(-0.9696845889091492), 'hyper_actor_loss': np.float64(0.004295417037792504), 'behavior_loss': np.float64(0.9011753559112549)}
step: 8710 @ episode report: {'average_total_reward': np.float32(7.853334), 'reward_variance': np.float32(4.6758966), 'max_total_reward': np.float32(11.900001), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.1), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07997026406228543), 'actor_loss': np.float64(-0.9504653573036194), 'hyper_actor_loss': np.float64(0.004387086816132068), 'behavior_loss': np.float64(0.8984532535076142)}
step: 8720 @ episode report: {'average_total_reward': np.float32(8.041111), 'reward_variance': np.float32(1.5064704), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.3), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08705216646194458), 'actor_loss': np.float64(-0.9503005564212799), 'hyper_actor_loss': np.float64(0.00474409987218678), 'behavior_loss': np.float64(0.8858416557312012)}
step: 8730 @ episode report: {'average_total_reward': np.float32(7.8922224), 'reward_variance': np.float32(2.1694589), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(5.411111), 'average_n_step': np.float32(9.2), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.10238264054059983), 'actor_loss': np.float64(-0.9865638673305511), 'hyper_actor_loss': np.float64(0.004668173100799322), 'behavior_loss': np.float64(0.8658865690231323)}
step: 8740 @ episode report: {'average_total_reward': np.float32(7.8288903), 'reward_variance': np.float32(1.2295609), 'max_total_reward': np.float32(8.900002), 'min_total_reward': np.float32(6.288889), 'average_n_step': np.float32(9.1), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09018085300922393), 'actor_loss': np.float64(-0.9770546734333039), 'hyper_actor_loss': np.float64(0.00454892567358911), 'behavior_loss': np.float64(0.9071537494659424)}
step: 8750 @ episode report: {'average_total_reward': np.float32(7.916667), 'reward_variance': np.float32(1.226105), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(6.411112), 'average_n_step': np.float32(9.2), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07478931695222854), 'actor_loss': np.float64(-0.9169838309288025), 'hyper_actor_loss': np.float64(0.004426311561837792), 'behavior_loss': np.float64(0.9314041852951049)}
step: 8760 @ episode report: {'average_total_reward': np.float32(7.8166666), 'reward_variance': np.float32(2.2261791), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.1), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09946382492780685), 'actor_loss': np.float64(-0.9542945265769959), 'hyper_actor_loss': np.float64(0.004475820949301124), 'behavior_loss': np.float64(0.9056975305080414)}
step: 8770 @ episode report: {'average_total_reward': np.float32(7.7411118), 'reward_variance': np.float32(1.7068905), 'max_total_reward': np.float32(9.655556), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.0), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09146614857017994), 'actor_loss': np.float64(-0.981693035364151), 'hyper_actor_loss': np.float64(0.004528468986973166), 'behavior_loss': np.float64(0.9215309500694275)}
step: 8780 @ episode report: {'average_total_reward': np.float32(7.0433335), 'reward_variance': np.float32(2.523987), 'max_total_reward': np.float32(9.900002), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07498314455151558), 'actor_loss': np.float64(-0.9162554502487182), 'hyper_actor_loss': np.float64(0.00436592516489327), 'behavior_loss': np.float64(0.89277583360672)}
step: 8790 @ episode report: {'average_total_reward': np.float32(7.5555563), 'reward_variance': np.float32(1.958346), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(8.9), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08747557774186135), 'actor_loss': np.float64(-0.9605490803718567), 'hyper_actor_loss': np.float64(0.004185446840710938), 'behavior_loss': np.float64(0.8740319550037384)}
step: 8800 @ episode report: {'average_total_reward': np.float32(7.2433333), 'reward_variance': np.float32(0.76872694), 'max_total_reward': np.float32(8.9), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08561794683337212), 'actor_loss': np.float64(-0.9547263145446777), 'hyper_actor_loss': np.float64(0.004050205531530082), 'behavior_loss': np.float64(0.9181414008140564)}
step: 8810 @ episode report: {'average_total_reward': np.float32(7.5922227), 'reward_variance': np.float32(3.6406932), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(3.4111114), 'average_n_step': np.float32(8.9), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08434564024209976), 'actor_loss': np.float64(-0.912674343585968), 'hyper_actor_loss': np.float64(0.003947626939043403), 'behavior_loss': np.float64(0.9327066123485566)}
step: 8820 @ episode report: {'average_total_reward': np.float32(7.941111), 'reward_variance': np.float32(3.4965692), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(9.2), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08936869576573372), 'actor_loss': np.float64(-0.9605623364448548), 'hyper_actor_loss': np.float64(0.0038519931957125665), 'behavior_loss': np.float64(0.9297106087207794)}
step: 8830 @ episode report: {'average_total_reward': np.float32(7.4188895), 'reward_variance': np.float32(4.299187), 'max_total_reward': np.float32(11.022223), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(8.8), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08634404018521309), 'actor_loss': np.float64(-0.9502381443977356), 'hyper_actor_loss': np.float64(0.00404464490711689), 'behavior_loss': np.float64(0.9469222307205201)}
step: 8840 @ episode report: {'average_total_reward': np.float32(8.016667), 'reward_variance': np.float32(1.4090188), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.3), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08462138697504998), 'actor_loss': np.float64(-0.9583985209465027), 'hyper_actor_loss': np.float64(0.004019729024730623), 'behavior_loss': np.float64(0.8868846297264099)}
step: 8850 @ episode report: {'average_total_reward': np.float32(8.016667), 'reward_variance': np.float32(3.94771), 'max_total_reward': np.float32(12.0222225), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(9.3), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0760639451444149), 'actor_loss': np.float64(-0.9461505889892579), 'hyper_actor_loss': np.float64(0.0038734253961592914), 'behavior_loss': np.float64(0.8650954842567444)}
step: 8860 @ episode report: {'average_total_reward': np.float32(7.2433333), 'reward_variance': np.float32(2.8111718), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09391377717256547), 'actor_loss': np.float64(-0.959618866443634), 'hyper_actor_loss': np.float64(0.003936070878989994), 'behavior_loss': np.float64(0.9010872662067413)}
step: 8870 @ episode report: {'average_total_reward': np.float32(8.39), 'reward_variance': np.float32(3.4875913), 'max_total_reward': np.float32(13.144444), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.6), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08773578330874443), 'actor_loss': np.float64(-0.9933564782142639), 'hyper_actor_loss': np.float64(0.00410393769852817), 'behavior_loss': np.float64(0.8480838656425476)}
step: 8880 @ episode report: {'average_total_reward': np.float32(7.0433335), 'reward_variance': np.float32(1.8995432), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(5.411111), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08915451113134623), 'actor_loss': np.float64(-0.9641964852809906), 'hyper_actor_loss': np.float64(0.00423086246009916), 'behavior_loss': np.float64(0.8746010065078735)}
step: 8890 @ episode report: {'average_total_reward': np.float32(7.6288886), 'reward_variance': np.float32(2.101807), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(8.9), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08095297440886498), 'actor_loss': np.float64(-0.963003259897232), 'hyper_actor_loss': np.float64(0.00418570009060204), 'behavior_loss': np.float64(0.8093094885349273)}
step: 8900 @ episode report: {'average_total_reward': np.float32(8.553334), 'reward_variance': np.float32(2.1217232), 'max_total_reward': np.float32(11.0222225), 'min_total_reward': np.float32(6.533334), 'average_n_step': np.float32(9.8), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07445553429424763), 'actor_loss': np.float64(-0.9439847886562347), 'hyper_actor_loss': np.float64(0.004626411711797118), 'behavior_loss': np.float64(0.8536859929561615)}
step: 8910 @ episode report: {'average_total_reward': np.float32(7.404444), 'reward_variance': np.float32(3.3217576), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(8.7), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07994698099792004), 'actor_loss': np.float64(-0.9519420564174652), 'hyper_actor_loss': np.float64(0.004564188700169325), 'behavior_loss': np.float64(0.822707349061966)}
step: 8920 @ episode report: {'average_total_reward': np.float32(7.0800004), 'reward_variance': np.float32(4.0119452), 'max_total_reward': np.float32(11.0222225), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09787717908620834), 'actor_loss': np.float64(-0.9627824544906616), 'hyper_actor_loss': np.float64(0.0045814862009137865), 'behavior_loss': np.float64(0.887857186794281)}
step: 8930 @ episode report: {'average_total_reward': np.float32(7.216667), 'reward_variance': np.float32(3.2964509), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.5), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08522078394889832), 'actor_loss': np.float64(-0.9596444547176362), 'hyper_actor_loss': np.float64(0.004556991532444954), 'behavior_loss': np.float64(0.8294771254062653)}
step: 8940 @ episode report: {'average_total_reward': np.float32(8.316668), 'reward_variance': np.float32(2.2267969), 'max_total_reward': np.float32(10.777779), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.6), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07661797590553761), 'actor_loss': np.float64(-0.9307156026363372), 'hyper_actor_loss': np.float64(0.004198700468987226), 'behavior_loss': np.float64(0.8655489563941956)}
step: 8950 @ episode report: {'average_total_reward': np.float32(7.5922227), 'reward_variance': np.float32(1.3443717), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.411111), 'average_n_step': np.float32(8.9), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08365408107638359), 'actor_loss': np.float64(-0.941589993238449), 'hyper_actor_loss': np.float64(0.0040514797670766715), 'behavior_loss': np.float64(0.8732366442680359)}
step: 8960 @ episode report: {'average_total_reward': np.float32(7.9044447), 'reward_variance': np.float32(1.4886963), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(6.533334), 'average_n_step': np.float32(9.2), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09020182453095912), 'actor_loss': np.float64(-0.9607394278049469), 'hyper_actor_loss': np.float64(0.0038257412845268844), 'behavior_loss': np.float64(0.8454605281352997)}
step: 8970 @ episode report: {'average_total_reward': np.float32(7.804445), 'reward_variance': np.float32(3.7965991), 'max_total_reward': np.float32(9.900002), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(9.1), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08344817161560059), 'actor_loss': np.float64(-0.9597777128219604), 'hyper_actor_loss': np.float64(0.0036276815924793484), 'behavior_loss': np.float64(0.8872319996356964)}
step: 8980 @ episode report: {'average_total_reward': np.float32(6.6577783), 'reward_variance': np.float32(0.97876054), 'max_total_reward': np.float32(8.777778), 'min_total_reward': np.float32(5.288889), 'average_n_step': np.float32(8.1), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07914703413844108), 'actor_loss': np.float64(-0.9206079006195068), 'hyper_actor_loss': np.float64(0.003757041390053928), 'behavior_loss': np.float64(0.9090380012989044)}
step: 8990 @ episode report: {'average_total_reward': np.float32(7.8288894), 'reward_variance': np.float32(2.0664997), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(9.1), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08458730317652226), 'actor_loss': np.float64(-0.9566921055316925), 'hyper_actor_loss': np.float64(0.0036383148515596988), 'behavior_loss': np.float64(0.8712773740291595)}
step: 9000 @ episode report: {'average_total_reward': np.float32(7.555556), 'reward_variance': np.float32(1.4850119), 'max_total_reward': np.float32(8.9), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(8.9), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07783906906843185), 'actor_loss': np.float64(-0.9559838235378265), 'hyper_actor_loss': np.float64(0.003549638530239463), 'behavior_loss': np.float64(0.8583997249603271)}
step: 9010 @ episode report: {'average_total_reward': np.float32(7.6655555), 'reward_variance': np.float32(1.772727), 'max_total_reward': np.float32(10.022222), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(8.9), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08605059459805489), 'actor_loss': np.float64(-0.9282675445079803), 'hyper_actor_loss': np.float64(0.003462353069335222), 'behavior_loss': np.float64(0.912070918083191)}
step: 9020 @ episode report: {'average_total_reward': np.float32(7.231111), 'reward_variance': np.float32(3.3291068), 'max_total_reward': np.float32(10.777779), 'min_total_reward': np.float32(5.411111), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08399633578956127), 'actor_loss': np.float64(-0.9545731723308564), 'hyper_actor_loss': np.float64(0.0034385302104055883), 'behavior_loss': np.float64(0.848753696680069)}
step: 9030 @ episode report: {'average_total_reward': np.float32(7.5800004), 'reward_variance': np.float32(0.78853834), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(8.9), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08270020484924316), 'actor_loss': np.float64(-0.9469351530075073), 'hyper_actor_loss': np.float64(0.0033364590955898164), 'behavior_loss': np.float64(0.8724275827407837)}
step: 9040 @ episode report: {'average_total_reward': np.float32(8.428889), 'reward_variance': np.float32(2.5912888), 'max_total_reward': np.float32(12.144444), 'min_total_reward': np.float32(6.5333333), 'average_n_step': np.float32(9.7), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08102116659283638), 'actor_loss': np.float64(-0.9452169001102447), 'hyper_actor_loss': np.float64(0.0033189105335623024), 'behavior_loss': np.float64(0.8296408832073212)}
step: 9050 @ episode report: {'average_total_reward': np.float32(7.8922224), 'reward_variance': np.float32(2.8702233), 'max_total_reward': np.float32(11.022222), 'min_total_reward': np.float32(5.288889), 'average_n_step': np.float32(9.2), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07669190615415573), 'actor_loss': np.float64(-0.9580693006515503), 'hyper_actor_loss': np.float64(0.003206804394721985), 'behavior_loss': np.float64(0.8477695524692536)}
step: 9060 @ episode report: {'average_total_reward': np.float32(8.43889), 'reward_variance': np.float32(3.515142), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.6), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09431065171957016), 'actor_loss': np.float64(-0.9390763223171235), 'hyper_actor_loss': np.float64(0.0031673386925831436), 'behavior_loss': np.float64(0.885505735874176)}
step: 9070 @ episode report: {'average_total_reward': np.float32(8.02889), 'reward_variance': np.float32(2.8160052), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.3), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08352051600813866), 'actor_loss': np.float64(-0.9711349964141845), 'hyper_actor_loss': np.float64(0.003197363903746009), 'behavior_loss': np.float64(0.8379431128501892)}
step: 9080 @ episode report: {'average_total_reward': np.float32(7.653334), 'reward_variance': np.float32(2.6446617), 'max_total_reward': np.float32(9.9), 'min_total_reward': np.float32(5.6555552), 'average_n_step': np.float32(8.9), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07290152199566365), 'actor_loss': np.float64(-0.9288536190986634), 'hyper_actor_loss': np.float64(0.00298791176173836), 'behavior_loss': np.float64(0.8408417522907257)}
step: 9090 @ episode report: {'average_total_reward': np.float32(7.816667), 'reward_variance': np.float32(2.9129944), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(9.1), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08520007096230983), 'actor_loss': np.float64(-0.9290568590164184), 'hyper_actor_loss': np.float64(0.0030304827261716126), 'behavior_loss': np.float64(0.8646861493587494)}
step: 9100 @ episode report: {'average_total_reward': np.float32(8.177778), 'reward_variance': np.float32(2.5098774), 'max_total_reward': np.float32(10.900001), 'min_total_reward': np.float32(5.411111), 'average_n_step': np.float32(9.4), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07892908304929733), 'actor_loss': np.float64(-0.9731210887432098), 'hyper_actor_loss': np.float64(0.0031842801719903944), 'behavior_loss': np.float64(0.8171316504478454)}
step: 9110 @ episode report: {'average_total_reward': np.float32(7.716667), 'reward_variance': np.float32(1.6720806), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.0), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07360221296548844), 'actor_loss': np.float64(-0.9376999318599701), 'hyper_actor_loss': np.float64(0.00308519066311419), 'behavior_loss': np.float64(0.8061502695083618)}
step: 9120 @ episode report: {'average_total_reward': np.float32(8.6044445), 'reward_variance': np.float32(2.570252), 'max_total_reward': np.float32(12.0222225), 'min_total_reward': np.float32(6.5333333), 'average_n_step': np.float32(9.9), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08562247753143311), 'actor_loss': np.float64(-0.9409342408180237), 'hyper_actor_loss': np.float64(0.0030397762777283786), 'behavior_loss': np.float64(0.8533157348632813)}
step: 9130 @ episode report: {'average_total_reward': np.float32(8.241112), 'reward_variance': np.float32(0.7476562), 'max_total_reward': np.float32(9.900002), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(9.5), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08328860402107238), 'actor_loss': np.float64(-0.9586253762245178), 'hyper_actor_loss': np.float64(0.002944006724283099), 'behavior_loss': np.float64(0.8381946206092834)}
step: 9140 @ episode report: {'average_total_reward': np.float32(8.714445), 'reward_variance': np.float32(3.0800757), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.9), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0787055492401123), 'actor_loss': np.float64(-0.9572662591934205), 'hyper_actor_loss': np.float64(0.003049516142345965), 'behavior_loss': np.float64(0.8466326534748078)}
step: 9150 @ episode report: {'average_total_reward': np.float32(8.526668), 'reward_variance': np.float32(4.1143265), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(9.7), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0827356033027172), 'actor_loss': np.float64(-0.9611030399799347), 'hyper_actor_loss': np.float64(0.0029847325524315236), 'behavior_loss': np.float64(0.7971889317035675)}
step: 9160 @ episode report: {'average_total_reward': np.float32(8.702223), 'reward_variance': np.float32(2.0968103), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.9), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0822503238916397), 'actor_loss': np.float64(-0.9532118976116181), 'hyper_actor_loss': np.float64(0.0031249335035681723), 'behavior_loss': np.float64(0.8375212848186493)}
step: 9170 @ episode report: {'average_total_reward': np.float32(8.565557), 'reward_variance': np.float32(2.5529983), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(5.655556), 'average_n_step': np.float32(9.8), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07598213590681553), 'actor_loss': np.float64(-0.9213889956474304), 'hyper_actor_loss': np.float64(0.0029559060232713817), 'behavior_loss': np.float64(0.7732444047927857)}
step: 9180 @ episode report: {'average_total_reward': np.float32(7.567778), 'reward_variance': np.float32(0.82796156), 'max_total_reward': np.float32(8.9), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(8.9), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08288598209619522), 'actor_loss': np.float64(-0.9925580680370331), 'hyper_actor_loss': np.float64(0.0031985812122002242), 'behavior_loss': np.float64(0.8146574378013611)}
step: 9190 @ episode report: {'average_total_reward': np.float32(8.777779), 'reward_variance': np.float32(5.145729), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.0), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08581583369523287), 'actor_loss': np.float64(-0.9514204323291778), 'hyper_actor_loss': np.float64(0.0033528519095852973), 'behavior_loss': np.float64(0.8235555231571198)}
step: 9200 @ episode report: {'average_total_reward': np.float32(7.9777784), 'reward_variance': np.float32(1.0941732), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.2), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07727577388286591), 'actor_loss': np.float64(-0.9651066303253174), 'hyper_actor_loss': np.float64(0.0034416363574564456), 'behavior_loss': np.float64(0.8380513727664948)}
step: 9210 @ episode report: {'average_total_reward': np.float32(8.204445), 'reward_variance': np.float32(0.5663015), 'max_total_reward': np.float32(8.900002), 'min_total_reward': np.float32(6.533334), 'average_n_step': np.float32(9.5), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08925709202885627), 'actor_loss': np.float64(-0.9647869110107422), 'hyper_actor_loss': np.float64(0.0037171161035075783), 'behavior_loss': np.float64(0.8495608627796173)}
step: 9220 @ episode report: {'average_total_reward': np.float32(6.88), 'reward_variance': np.float32(2.60602), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.2), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08163236491382123), 'actor_loss': np.float64(-0.9685440838336945), 'hyper_actor_loss': np.float64(0.004000942525453866), 'behavior_loss': np.float64(0.8436554312705994)}
step: 9230 @ episode report: {'average_total_reward': np.float32(7.4800005), 'reward_variance': np.float32(2.2894025), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.8), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07911895699799061), 'actor_loss': np.float64(-0.9599605321884155), 'hyper_actor_loss': np.float64(0.0038388109067454936), 'behavior_loss': np.float64(0.8480135142803192)}
step: 9240 @ episode report: {'average_total_reward': np.float32(6.594445), 'reward_variance': np.float32(1.1667968), 'max_total_reward': np.float32(8.28889), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(8.0), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08065813444554806), 'actor_loss': np.float64(-0.9653375804424286), 'hyper_actor_loss': np.float64(0.004324227757751942), 'behavior_loss': np.float64(0.8477986872196197)}
step: 9250 @ episode report: {'average_total_reward': np.float32(6.5700006), 'reward_variance': np.float32(2.268495), 'max_total_reward': np.float32(8.900002), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.0), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07774880453944207), 'actor_loss': np.float64(-0.952988350391388), 'hyper_actor_loss': np.float64(0.004300802852958441), 'behavior_loss': np.float64(0.875578647851944)}
step: 9260 @ episode report: {'average_total_reward': np.float32(6.594445), 'reward_variance': np.float32(1.9424263), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.0), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0769001729786396), 'actor_loss': np.float64(-0.9521912753582), 'hyper_actor_loss': np.float64(0.0045480668079108), 'behavior_loss': np.float64(0.8965614914894104)}
step: 9270 @ episode report: {'average_total_reward': np.float32(7.331111), 'reward_variance': np.float32(0.45258775), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(6.533334), 'average_n_step': np.float32(8.7), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08345169015228748), 'actor_loss': np.float64(-0.9734833359718322), 'hyper_actor_loss': np.float64(0.0046155612450093034), 'behavior_loss': np.float64(0.8611172795295715)}
step: 9280 @ episode report: {'average_total_reward': np.float32(6.418889), 'reward_variance': np.float32(0.6492359), 'max_total_reward': np.float32(7.777778), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(7.8), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08077803328633308), 'actor_loss': np.float64(-0.9893288671970367), 'hyper_actor_loss': np.float64(0.004807645920664072), 'behavior_loss': np.float64(0.8849696755409241)}
step: 9290 @ episode report: {'average_total_reward': np.float32(5.821111), 'reward_variance': np.float32(1.2136902), 'max_total_reward': np.float32(7.6555557), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.3), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0808281160891056), 'actor_loss': np.float64(-0.9734871804714202), 'hyper_actor_loss': np.float64(0.005056704627349973), 'behavior_loss': np.float64(0.8794178545475007)}
step: 9300 @ episode report: {'average_total_reward': np.float32(7.2922225), 'reward_variance': np.float32(2.1897044), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09334641695022583), 'actor_loss': np.float64(-0.9653002440929412), 'hyper_actor_loss': np.float64(0.005200109770521521), 'behavior_loss': np.float64(0.9074012994766235)}
step: 9310 @ episode report: {'average_total_reward': np.float32(6.4822226), 'reward_variance': np.float32(1.0345482), 'max_total_reward': np.float32(7.777778), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.9), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08748486451804638), 'actor_loss': np.float64(-0.9880782902240753), 'hyper_actor_loss': np.float64(0.005239908304065466), 'behavior_loss': np.float64(0.8668652176856995)}
step: 9320 @ episode report: {'average_total_reward': np.float32(6.9822226), 'reward_variance': np.float32(1.048376), 'max_total_reward': np.float32(8.900002), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07973224185407161), 'actor_loss': np.float64(-0.9728887856006623), 'hyper_actor_loss': np.float64(0.005272743245586753), 'behavior_loss': np.float64(0.8619780838489532)}
step: 9330 @ episode report: {'average_total_reward': np.float32(6.7700005), 'reward_variance': np.float32(0.62777925), 'max_total_reward': np.float32(7.6555567), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(8.2), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08372986167669297), 'actor_loss': np.float64(-0.9557581543922424), 'hyper_actor_loss': np.float64(0.005301766889169812), 'behavior_loss': np.float64(0.9356844365596771)}
step: 9340 @ episode report: {'average_total_reward': np.float32(5.4722223), 'reward_variance': np.float32(0.9912408), 'max_total_reward': np.float32(7.4111114), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.0), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08731045126914978), 'actor_loss': np.float64(-0.9485481917858124), 'hyper_actor_loss': np.float64(0.005280730547383428), 'behavior_loss': np.float64(0.919064736366272)}
step: 9350 @ episode report: {'average_total_reward': np.float32(5.708889), 'reward_variance': np.float32(1.5382173), 'max_total_reward': np.float32(7.4111114), 'min_total_reward': np.float32(3.4111114), 'average_n_step': np.float32(7.2), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08320301920175552), 'actor_loss': np.float64(-0.9950380146503448), 'hyper_actor_loss': np.float64(0.005213321186602116), 'behavior_loss': np.float64(0.8704954266548157)}
step: 9360 @ episode report: {'average_total_reward': np.float32(5.672222), 'reward_variance': np.float32(1.2854135), 'max_total_reward': np.float32(7.6555557), 'min_total_reward': np.float32(4.166667), 'average_n_step': np.float32(7.2), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08967594802379608), 'actor_loss': np.float64(-0.9491537868976593), 'hyper_actor_loss': np.float64(0.005245398357510566), 'behavior_loss': np.float64(0.8643221080303192)}
step: 9370 @ episode report: {'average_total_reward': np.float32(6.8944445), 'reward_variance': np.float32(2.0758328), 'max_total_reward': np.float32(9.777777), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08623547255992889), 'actor_loss': np.float64(-0.9843678295612335), 'hyper_actor_loss': np.float64(0.005456356145441532), 'behavior_loss': np.float64(0.9174573361873627)}
step: 9380 @ episode report: {'average_total_reward': np.float32(6.321111), 'reward_variance': np.float32(1.4736904), 'max_total_reward': np.float32(7.777778), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(7.8), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07102028056979179), 'actor_loss': np.float64(-0.9571068823337555), 'hyper_actor_loss': np.float64(0.005303916055709124), 'behavior_loss': np.float64(0.819723653793335)}
step: 9390 @ episode report: {'average_total_reward': np.float32(6.0700006), 'reward_variance': np.float32(1.2269641), 'max_total_reward': np.float32(7.7777777), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(7.5), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09373234622180462), 'actor_loss': np.float64(-0.9759251117706299), 'hyper_actor_loss': np.float64(0.004968860791996122), 'behavior_loss': np.float64(0.8837027728557587)}
step: 9400 @ episode report: {'average_total_reward': np.float32(5.921111), 'reward_variance': np.float32(2.4675918), 'max_total_reward': np.float32(7.7777777), 'min_total_reward': np.float32(3.288889), 'average_n_step': np.float32(7.4), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09702569544315338), 'actor_loss': np.float64(-0.9635277509689331), 'hyper_actor_loss': np.float64(0.004809920117259026), 'behavior_loss': np.float64(0.9168595373630524)}
step: 9410 @ episode report: {'average_total_reward': np.float32(6.46), 'reward_variance': np.float32(0.9317831), 'max_total_reward': np.float32(7.6555557), 'min_total_reward': np.float32(5.288889), 'average_n_step': np.float32(8.0), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08231383860111237), 'actor_loss': np.float64(-0.9593446433544159), 'hyper_actor_loss': np.float64(0.0045852117706090215), 'behavior_loss': np.float64(0.8777965486049653)}
step: 9420 @ episode report: {'average_total_reward': np.float32(6.045556), 'reward_variance': np.float32(1.3593447), 'max_total_reward': np.float32(7.7777786), 'min_total_reward': np.float32(4.2888894), 'average_n_step': np.float32(7.5), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08922876417636871), 'actor_loss': np.float64(-0.9597473621368409), 'hyper_actor_loss': np.float64(0.004271055362187326), 'behavior_loss': np.float64(0.8591603755950927)}
step: 9430 @ episode report: {'average_total_reward': np.float32(6.4188895), 'reward_variance': np.float32(1.3589649), 'max_total_reward': np.float32(8.900002), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(7.8), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0968651868402958), 'actor_loss': np.float64(-0.9980828583240509), 'hyper_actor_loss': np.float64(0.004061472648754716), 'behavior_loss': np.float64(0.8993810474872589)}
step: 9440 @ episode report: {'average_total_reward': np.float32(6.033334), 'reward_variance': np.float32(1.4879258), 'max_total_reward': np.float32(7.7777777), 'min_total_reward': np.float32(3.288889), 'average_n_step': np.float32(7.5), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08053594641387463), 'actor_loss': np.float64(-0.9369712710380554), 'hyper_actor_loss': np.float64(0.003998568351380527), 'behavior_loss': np.float64(0.8778670430183411)}
step: 9450 @ episode report: {'average_total_reward': np.float32(5.9822226), 'reward_variance': np.float32(4.00408), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(7.4), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08883581310510635), 'actor_loss': np.float64(-0.9501386046409607), 'hyper_actor_loss': np.float64(0.0038721650140359997), 'behavior_loss': np.float64(0.8561046898365021)}
step: 9460 @ episode report: {'average_total_reward': np.float32(6.3700004), 'reward_variance': np.float32(2.626224), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(4.166667), 'average_n_step': np.float32(7.8), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08800982609391213), 'actor_loss': np.float64(-0.9611591994762421), 'hyper_actor_loss': np.float64(0.003654341143555939), 'behavior_loss': np.float64(0.8854170441627502)}
step: 9470 @ episode report: {'average_total_reward': np.float32(5.8822227), 'reward_variance': np.float32(1.4740546), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.3), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07577748745679855), 'actor_loss': np.float64(-0.938705849647522), 'hyper_actor_loss': np.float64(0.0033947919495403767), 'behavior_loss': np.float64(0.9083033740520478)}
step: 9480 @ episode report: {'average_total_reward': np.float32(5.7966666), 'reward_variance': np.float32(1.5418783), 'max_total_reward': np.float32(7.655556), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.3), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07673687264323234), 'actor_loss': np.float64(-0.9428085505962371), 'hyper_actor_loss': np.float64(0.00336694298312068), 'behavior_loss': np.float64(0.8393930554389953)}
step: 9490 @ episode report: {'average_total_reward': np.float32(5.957778), 'reward_variance': np.float32(1.7510319), 'max_total_reward': np.float32(7.6555557), 'min_total_reward': np.float32(3.4111114), 'average_n_step': np.float32(7.4), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08216456100344657), 'actor_loss': np.float64(-0.9580899894237518), 'hyper_actor_loss': np.float64(0.003362448909319937), 'behavior_loss': np.float64(0.8085699915885926)}
step: 9500 @ episode report: {'average_total_reward': np.float32(6.5066667), 'reward_variance': np.float32(1.7706219), 'max_total_reward': np.float32(8.777778), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.9), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09073201939463615), 'actor_loss': np.float64(-0.9867039918899536), 'hyper_actor_loss': np.float64(0.0031642247922718525), 'behavior_loss': np.float64(0.8634917855262756)}
step: 9510 @ episode report: {'average_total_reward': np.float32(6.506667), 'reward_variance': np.float32(1.7431908), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.9), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08376198671758175), 'actor_loss': np.float64(-0.9458787620067597), 'hyper_actor_loss': np.float64(0.0030772970290854572), 'behavior_loss': np.float64(0.8975371301174164)}
step: 9520 @ episode report: {'average_total_reward': np.float32(6.6577783), 'reward_variance': np.float32(1.7284148), 'max_total_reward': np.float32(8.533334), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(8.1), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07738026976585388), 'actor_loss': np.float64(-0.9274115264415741), 'hyper_actor_loss': np.float64(0.0030637636547908185), 'behavior_loss': np.float64(0.8602786540985108)}
step: 9530 @ episode report: {'average_total_reward': np.float32(7.3411117), 'reward_variance': np.float32(2.1161003), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08195631802082062), 'actor_loss': np.float64(-0.9468079924583435), 'hyper_actor_loss': np.float64(0.003123683063313365), 'behavior_loss': np.float64(0.8788453817367554)}
step: 9540 @ episode report: {'average_total_reward': np.float32(6.8555555), 'reward_variance': np.float32(4.0862727), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.2), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08261943385004997), 'actor_loss': np.float64(-0.9495009779930115), 'hyper_actor_loss': np.float64(0.002871378418058157), 'behavior_loss': np.float64(0.799042022228241)}
step: 9550 @ episode report: {'average_total_reward': np.float32(7.877778), 'reward_variance': np.float32(7.569976), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(9.1), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08032772913575173), 'actor_loss': np.float64(-0.9516858220100403), 'hyper_actor_loss': np.float64(0.002671262645162642), 'behavior_loss': np.float64(0.8314879834651947)}
step: 9560 @ episode report: {'average_total_reward': np.float32(7.5188894), 'reward_variance': np.float32(1.9022728), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(8.9), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06793178096413613), 'actor_loss': np.float64(-0.9319434344768525), 'hyper_actor_loss': np.float64(0.0024726920761168002), 'behavior_loss': np.float64(0.8409971058368683)}
step: 9570 @ episode report: {'average_total_reward': np.float32(8.153334), 'reward_variance': np.float32(3.8460681), 'max_total_reward': np.float32(12.266666), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(9.4), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.075727229565382), 'actor_loss': np.float64(-0.9098110914230346), 'hyper_actor_loss': np.float64(0.0023980429861694573), 'behavior_loss': np.float64(0.8414676487445831)}
step: 9580 @ episode report: {'average_total_reward': np.float32(7.88), 'reward_variance': np.float32(2.480341), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(5.288889), 'average_n_step': np.float32(9.2), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08578101620078087), 'actor_loss': np.float64(-0.947301185131073), 'hyper_actor_loss': np.float64(0.0021972009679302575), 'behavior_loss': np.float64(0.8137534260749817)}
step: 9590 @ episode report: {'average_total_reward': np.float32(7.231111), 'reward_variance': np.float32(3.159526), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08305680081248283), 'actor_loss': np.float64(-0.9758352041244507), 'hyper_actor_loss': np.float64(0.002127342147286981), 'behavior_loss': np.float64(0.8179653942584991)}
step: 9600 @ episode report: {'average_total_reward': np.float32(8.028889), 'reward_variance': np.float32(3.0853636), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(5.6555552), 'average_n_step': np.float32(9.3), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08516901470720768), 'actor_loss': np.float64(-0.9282799899578095), 'hyper_actor_loss': np.float64(0.0021099377307109536), 'behavior_loss': np.float64(0.8602733612060547)}
step: 9610 @ episode report: {'average_total_reward': np.float32(7.831112), 'reward_variance': np.float32(1.8619702), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(9.2), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07753270417451859), 'actor_loss': np.float64(-0.9694856166839599), 'hyper_actor_loss': np.float64(0.0021076043602079155), 'behavior_loss': np.float64(0.7881886839866639)}
step: 9620 @ episode report: {'average_total_reward': np.float32(7.3922224), 'reward_variance': np.float32(3.9763477), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(5.2888894), 'average_n_step': np.float32(8.7), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08088226467370987), 'actor_loss': np.float64(-0.9490065991878509), 'hyper_actor_loss': np.float64(0.0020204922067932783), 'behavior_loss': np.float64(0.8075391411781311)}
step: 9630 @ episode report: {'average_total_reward': np.float32(7.2555556), 'reward_variance': np.float32(2.6759262), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09163245186209679), 'actor_loss': np.float64(-0.9456754624843597), 'hyper_actor_loss': np.float64(0.0021722528850659727), 'behavior_loss': np.float64(0.8164114952087402)}
step: 9640 @ episode report: {'average_total_reward': np.float32(7.38), 'reward_variance': np.float32(1.2938716), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(8.7), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06880118288099765), 'actor_loss': np.float64(-0.9680775761604309), 'hyper_actor_loss': np.float64(0.0020750055206008255), 'behavior_loss': np.float64(0.7729898989200592)}
step: 9650 @ episode report: {'average_total_reward': np.float32(8.077779), 'reward_variance': np.float32(1.7486918), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(9.3), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08889169879257679), 'actor_loss': np.float64(-0.9438751757144928), 'hyper_actor_loss': np.float64(0.0019834245438687505), 'behavior_loss': np.float64(0.8237312078475952)}
step: 9660 @ episode report: {'average_total_reward': np.float32(6.745556), 'reward_variance': np.float32(0.675147), 'max_total_reward': np.float32(7.7777786), 'min_total_reward': np.float32(5.288889), 'average_n_step': np.float32(8.2), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08307836130261421), 'actor_loss': np.float64(-0.9470158815383911), 'hyper_actor_loss': np.float64(0.0019526360323652626), 'behavior_loss': np.float64(0.8671645998954773)}
step: 9670 @ episode report: {'average_total_reward': np.float32(7.467778), 'reward_variance': np.float32(0.8210977), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(8.8), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08564176186919212), 'actor_loss': np.float64(-0.9310586988925934), 'hyper_actor_loss': np.float64(0.001904452289454639), 'behavior_loss': np.float64(0.7907995045185089)}
step: 9680 @ episode report: {'average_total_reward': np.float32(7.6288896), 'reward_variance': np.float32(4.037512), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(8.9), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08481043726205825), 'actor_loss': np.float64(-0.9543504774570465), 'hyper_actor_loss': np.float64(0.0018824275699444114), 'behavior_loss': np.float64(0.8009835660457612)}
step: 9690 @ episode report: {'average_total_reward': np.float32(7.006667), 'reward_variance': np.float32(2.2577832), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08979367166757583), 'actor_loss': np.float64(-0.9607393801212311), 'hyper_actor_loss': np.float64(0.0019288924871943892), 'behavior_loss': np.float64(0.848313057422638)}
step: 9700 @ episode report: {'average_total_reward': np.float32(7.9411116), 'reward_variance': np.float32(4.258176), 'max_total_reward': np.float32(12.266668), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(9.2), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09027468152344227), 'actor_loss': np.float64(-0.9511460840702057), 'hyper_actor_loss': np.float64(0.001884644164238125), 'behavior_loss': np.float64(0.8327313423156738)}
step: 9710 @ episode report: {'average_total_reward': np.float32(6.9800005), 'reward_variance': np.float32(1.4815509), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.533333), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08370693102478981), 'actor_loss': np.float64(-0.9460142314434051), 'hyper_actor_loss': np.float64(0.0018936250824481248), 'behavior_loss': np.float64(0.8071198642253876)}
step: 9720 @ episode report: {'average_total_reward': np.float32(7.9288893), 'reward_variance': np.float32(1.1143258), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.2), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07055427208542824), 'actor_loss': np.float64(-0.9547932922840119), 'hyper_actor_loss': np.float64(0.0018254660884849728), 'behavior_loss': np.float64(0.7863156259059906)}
step: 9730 @ episode report: {'average_total_reward': np.float32(7.2922225), 'reward_variance': np.float32(2.745335), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08009090498089791), 'actor_loss': np.float64(-0.9158933997154236), 'hyper_actor_loss': np.float64(0.0017574725090526045), 'behavior_loss': np.float64(0.797468638420105)}
step: 9740 @ episode report: {'average_total_reward': np.float32(7.7288895), 'reward_variance': np.float32(1.9697087), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(9.0), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0828409094363451), 'actor_loss': np.float64(-0.9610221028327942), 'hyper_actor_loss': np.float64(0.0018343313480727375), 'behavior_loss': np.float64(0.7983987331390381)}
step: 9750 @ episode report: {'average_total_reward': np.float32(6.9066668), 'reward_variance': np.float32(2.2993138), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08909678272902966), 'actor_loss': np.float64(-0.9398725211620331), 'hyper_actor_loss': np.float64(0.0018145933281630278), 'behavior_loss': np.float64(0.8286672711372376)}
step: 9760 @ episode report: {'average_total_reward': np.float32(7.2433343), 'reward_variance': np.float32(2.4829745), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08680219277739525), 'actor_loss': np.float64(-0.9436880052089691), 'hyper_actor_loss': np.float64(0.001761259778868407), 'behavior_loss': np.float64(0.8096806943416596)}
step: 9770 @ episode report: {'average_total_reward': np.float32(7.38), 'reward_variance': np.float32(1.861995), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.7), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07287870086729527), 'actor_loss': np.float64(-0.9644107937812805), 'hyper_actor_loss': np.float64(0.0017697918578051032), 'behavior_loss': np.float64(0.7561596632003784)}
step: 9780 @ episode report: {'average_total_reward': np.float32(7.067778), 'reward_variance': np.float32(2.2754686), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08552336022257805), 'actor_loss': np.float64(-0.9334320247173309), 'hyper_actor_loss': np.float64(0.0017973349313251674), 'behavior_loss': np.float64(0.8049175620079041)}
step: 9790 @ episode report: {'average_total_reward': np.float32(6.831111), 'reward_variance': np.float32(2.6450317), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.2), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0880323089659214), 'actor_loss': np.float64(-0.9559437096118927), 'hyper_actor_loss': np.float64(0.0019148292602039873), 'behavior_loss': np.float64(0.7579608678817749)}
step: 9800 @ episode report: {'average_total_reward': np.float32(6.831111), 'reward_variance': np.float32(1.8071067), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(8.2), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08442736491560936), 'actor_loss': np.float64(-0.9726723372936249), 'hyper_actor_loss': np.float64(0.0019301768857985734), 'behavior_loss': np.float64(0.8151001095771789)}
step: 9810 @ episode report: {'average_total_reward': np.float32(6.1577783), 'reward_variance': np.float32(1.5931317), 'max_total_reward': np.float32(7.7777777), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.6), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08933517448604107), 'actor_loss': np.float64(-0.9483830213546753), 'hyper_actor_loss': np.float64(0.0018182500381954015), 'behavior_loss': np.float64(0.8247838914394379)}
step: 9820 @ episode report: {'average_total_reward': np.float32(7.5433335), 'reward_variance': np.float32(1.5846782), 'max_total_reward': np.float32(8.900002), 'min_total_reward': np.float32(5.411111), 'average_n_step': np.float32(8.9), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08093433901667595), 'actor_loss': np.float64(-0.9426924288272858), 'hyper_actor_loss': np.float64(0.0018695551785640418), 'behavior_loss': np.float64(0.7874508798122406)}
step: 9830 @ episode report: {'average_total_reward': np.float32(7.2433343), 'reward_variance': np.float32(1.8585298), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(5.288889), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08998683989048004), 'actor_loss': np.float64(-0.9782964050769806), 'hyper_actor_loss': np.float64(0.0018165913643315434), 'behavior_loss': np.float64(0.8257773637771606)}
step: 9840 @ episode report: {'average_total_reward': np.float32(7.3555555), 'reward_variance': np.float32(2.0145183), 'max_total_reward': np.float32(8.777778), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.7), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08161482661962509), 'actor_loss': np.float64(-0.9435787558555603), 'hyper_actor_loss': np.float64(0.0017785774543881416), 'behavior_loss': np.float64(0.8081393718719483)}
step: 9850 @ episode report: {'average_total_reward': np.float32(7.067778), 'reward_variance': np.float32(3.8999863), 'max_total_reward': np.float32(11.022223), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09283800311386585), 'actor_loss': np.float64(-0.9367318511009216), 'hyper_actor_loss': np.float64(0.0017903503612615168), 'behavior_loss': np.float64(0.8409648180007935)}
step: 9860 @ episode report: {'average_total_reward': np.float32(8.1044445), 'reward_variance': np.float32(1.4119805), 'max_total_reward': np.float32(9.900002), 'min_total_reward': np.float32(5.655556), 'average_n_step': np.float32(9.4), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08416191637516021), 'actor_loss': np.float64(-0.9718485832214355), 'hyper_actor_loss': np.float64(0.0018184402724727988), 'behavior_loss': np.float64(0.8090428113937378)}
step: 9870 @ episode report: {'average_total_reward': np.float32(7.343334), 'reward_variance': np.float32(1.2234681), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(8.7), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08191269487142563), 'actor_loss': np.float64(-0.942691856622696), 'hyper_actor_loss': np.float64(0.001732913334853947), 'behavior_loss': np.float64(0.7755839049816131)}
step: 9880 @ episode report: {'average_total_reward': np.float32(7.804445), 'reward_variance': np.float32(2.389092), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(9.1), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07387817278504372), 'actor_loss': np.float64(-0.9624915897846222), 'hyper_actor_loss': np.float64(0.001792730181477964), 'behavior_loss': np.float64(0.794823169708252)}
step: 9890 @ episode report: {'average_total_reward': np.float32(7.1433334), 'reward_variance': np.float32(2.452603), 'max_total_reward': np.float32(9.777778), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.5), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08663165643811226), 'actor_loss': np.float64(-0.9308958172798156), 'hyper_actor_loss': np.float64(0.0017975668190047145), 'behavior_loss': np.float64(0.7757104456424713)}
step: 9900 @ episode report: {'average_total_reward': np.float32(8.053334), 'reward_variance': np.float32(2.098391), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.3), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07816849015653134), 'actor_loss': np.float64(-0.9583573281764984), 'hyper_actor_loss': np.float64(0.0018819069606252014), 'behavior_loss': np.float64(0.805113422870636)}
step: 9910 @ episode report: {'average_total_reward': np.float32(8.341112), 'reward_variance': np.float32(2.3141), 'max_total_reward': np.float32(12.0222225), 'min_total_reward': np.float32(6.411111), 'average_n_step': np.float32(9.6), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08168623484671116), 'actor_loss': np.float64(-0.9580349743366241), 'hyper_actor_loss': np.float64(0.0018310319166630507), 'behavior_loss': np.float64(0.7622650265693665)}
step: 9920 @ episode report: {'average_total_reward': np.float32(6.9066668), 'reward_variance': np.float32(3.0838323), 'max_total_reward': np.float32(9.777778), 'min_total_reward': np.float32(5.288889), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06757508851587772), 'actor_loss': np.float64(-0.9596413969993591), 'hyper_actor_loss': np.float64(0.0017756579327397048), 'behavior_loss': np.float64(0.7159341096878051)}
step: 9930 @ episode report: {'average_total_reward': np.float32(7.416667), 'reward_variance': np.float32(2.1920807), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(8.7), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07776962891221047), 'actor_loss': np.float64(-0.9428257703781128), 'hyper_actor_loss': np.float64(0.001709385111462325), 'behavior_loss': np.float64(0.7636754393577576)}
step: 9940 @ episode report: {'average_total_reward': np.float32(8.116667), 'reward_variance': np.float32(2.1824257), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(5.411112), 'average_n_step': np.float32(9.4), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06999305225908756), 'actor_loss': np.float64(-0.9304593443870545), 'hyper_actor_loss': np.float64(0.0017415152629837393), 'behavior_loss': np.float64(0.8103566765785217)}
step: 9950 @ episode report: {'average_total_reward': np.float32(7.7288895), 'reward_variance': np.float32(2.0629685), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.0), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08186619132757186), 'actor_loss': np.float64(-0.9203066170215607), 'hyper_actor_loss': np.float64(0.001722734433133155), 'behavior_loss': np.float64(0.8141680657863617)}
step: 9960 @ episode report: {'average_total_reward': np.float32(8.216667), 'reward_variance': np.float32(2.0165987), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(9.5), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07712083421647549), 'actor_loss': np.float64(-0.9483665645122528), 'hyper_actor_loss': np.float64(0.0017074575531296431), 'behavior_loss': np.float64(0.8065261363983154)}
step: 9970 @ episode report: {'average_total_reward': np.float32(8.153334), 'reward_variance': np.float32(2.1976495), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(9.4), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07743680886924267), 'actor_loss': np.float64(-0.9416794300079345), 'hyper_actor_loss': np.float64(0.0016585833858698607), 'behavior_loss': np.float64(0.7657248198986053)}
step: 9980 @ episode report: {'average_total_reward': np.float32(7.8533335), 'reward_variance': np.float32(3.2404888), 'max_total_reward': np.float32(12.144444), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(9.1), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08439468443393708), 'actor_loss': np.float64(-0.9581242442131043), 'hyper_actor_loss': np.float64(0.0017647177446633577), 'behavior_loss': np.float64(0.7664180874824524)}
step: 9990 @ episode report: {'average_total_reward': np.float32(8.02889), 'reward_variance': np.float32(1.8564001), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(9.3), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07676531560719013), 'actor_loss': np.float64(-0.9406073868274689), 'hyper_actor_loss': np.float64(0.00175251595210284), 'behavior_loss': np.float64(0.753447151184082)}
step: 10000 @ episode report: {'average_total_reward': np.float32(8.32889), 'reward_variance': np.float32(3.75519), 'max_total_reward': np.float32(11.022223), 'min_total_reward': np.float32(5.288889), 'average_n_step': np.float32(9.6), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06925286166369915), 'actor_loss': np.float64(-0.9464506566524505), 'hyper_actor_loss': np.float64(0.001725813583470881), 'behavior_loss': np.float64(0.7534379303455353)}
step: 10010 @ episode report: {'average_total_reward': np.float32(7.7411118), 'reward_variance': np.float32(3.332866), 'max_total_reward': np.float32(10.777779), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(9.0), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07251844070851803), 'actor_loss': np.float64(-0.9337385356426239), 'hyper_actor_loss': np.float64(0.0017861121334135533), 'behavior_loss': np.float64(0.7167655169963837)}
step: 10020 @ episode report: {'average_total_reward': np.float32(8.477778), 'reward_variance': np.float32(2.4693818), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.7), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07852858230471611), 'actor_loss': np.float64(-0.9553852021694184), 'hyper_actor_loss': np.float64(0.0017142696538940071), 'behavior_loss': np.float64(0.6976946651935577)}
step: 10030 @ episode report: {'average_total_reward': np.float32(8.165556), 'reward_variance': np.float32(1.598777), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(9.4), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07918052077293396), 'actor_loss': np.float64(-0.9472706496715546), 'hyper_actor_loss': np.float64(0.001718042476568371), 'behavior_loss': np.float64(0.799701702594757)}
step: 10040 @ episode report: {'average_total_reward': np.float32(8.677778), 'reward_variance': np.float32(2.456124), 'max_total_reward': np.float32(11.022223), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.9), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08219688721001148), 'actor_loss': np.float64(-0.9388268947601318), 'hyper_actor_loss': np.float64(0.0016327193239703774), 'behavior_loss': np.float64(0.7300388634204864)}
step: 10050 @ episode report: {'average_total_reward': np.float32(7.8288894), 'reward_variance': np.float32(1.7871904), 'max_total_reward': np.float32(11.022223), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(9.1), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08445654585957527), 'actor_loss': np.float64(-0.9511141180992126), 'hyper_actor_loss': np.float64(0.0018164785578846931), 'behavior_loss': np.float64(0.7892560958862305)}
step: 10060 @ episode report: {'average_total_reward': np.float32(9.075556), 'reward_variance': np.float32(2.3293297), 'max_total_reward': np.float32(12.144446), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.2), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09047148786485196), 'actor_loss': np.float64(-0.9741147994995117), 'hyper_actor_loss': np.float64(0.0017748374608345329), 'behavior_loss': np.float64(0.7597714543342591)}
step: 10070 @ episode report: {'average_total_reward': np.float32(8.653334), 'reward_variance': np.float32(3.4337), 'max_total_reward': np.float32(12.144446), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.9), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08151891380548477), 'actor_loss': np.float64(-0.965101283788681), 'hyper_actor_loss': np.float64(0.0017890414455905557), 'behavior_loss': np.float64(0.7305876731872558)}
step: 10080 @ episode report: {'average_total_reward': np.float32(8.565557), 'reward_variance': np.float32(1.3041096), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(7.5333333), 'average_n_step': np.float32(9.8), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08065760023891926), 'actor_loss': np.float64(-0.9496476650238037), 'hyper_actor_loss': np.float64(0.0017721897340379656), 'behavior_loss': np.float64(0.7590863883495331)}
step: 10090 @ episode report: {'average_total_reward': np.float32(8.441112), 'reward_variance': np.float32(2.743311), 'max_total_reward': np.float32(12.266668), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(9.7), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0772531695663929), 'actor_loss': np.float64(-0.9468603372573853), 'hyper_actor_loss': np.float64(0.0017123206635005772), 'behavior_loss': np.float64(0.7543172061443328)}
step: 10100 @ episode report: {'average_total_reward': np.float32(9.226667), 'reward_variance': np.float32(2.5232384), 'max_total_reward': np.float32(13.1444435), 'min_total_reward': np.float32(7.5333333), 'average_n_step': np.float32(10.4), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07863791137933732), 'actor_loss': np.float64(-0.9481443166732788), 'hyper_actor_loss': np.float64(0.0017088601714931428), 'behavior_loss': np.float64(0.7377688765525818)}
step: 10110 @ episode report: {'average_total_reward': np.float32(8.365556), 'reward_variance': np.float32(2.8465796), 'max_total_reward': np.float32(10.900001), 'min_total_reward': np.float32(4.411111), 'average_n_step': np.float32(9.6), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08387048393487931), 'actor_loss': np.float64(-0.9520102918148041), 'hyper_actor_loss': np.float64(0.0015355789917521178), 'behavior_loss': np.float64(0.7571276485919952)}
step: 10120 @ episode report: {'average_total_reward': np.float32(7.9655557), 'reward_variance': np.float32(3.2466035), 'max_total_reward': np.float32(12.266666), 'min_total_reward': np.float32(4.411111), 'average_n_step': np.float32(9.2), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08199423998594284), 'actor_loss': np.float64(-0.942482203245163), 'hyper_actor_loss': np.float64(0.0016101321554742754), 'behavior_loss': np.float64(0.7548062741756439)}
step: 10130 @ episode report: {'average_total_reward': np.float32(8.153334), 'reward_variance': np.float32(2.7014031), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(9.4), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08720875829458237), 'actor_loss': np.float64(-0.9383223414421081), 'hyper_actor_loss': np.float64(0.0016528475331142544), 'behavior_loss': np.float64(0.7449649810791016)}
step: 10140 @ episode report: {'average_total_reward': np.float32(9.038889), 'reward_variance': np.float32(1.9543022), 'max_total_reward': np.float32(11.0222225), 'min_total_reward': np.float32(6.533334), 'average_n_step': np.float32(10.2), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09804181978106499), 'actor_loss': np.float64(-0.9775230109691619), 'hyper_actor_loss': np.float64(0.0016332038096152246), 'behavior_loss': np.float64(0.7476118743419647)}
step: 10150 @ episode report: {'average_total_reward': np.float32(9.226667), 'reward_variance': np.float32(4.331733), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.4), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0896987833082676), 'actor_loss': np.float64(-0.9636259913444519), 'hyper_actor_loss': np.float64(0.0016027348814532162), 'behavior_loss': np.float64(0.7677576839923859)}
step: 10160 @ episode report: {'average_total_reward': np.float32(8.402224), 'reward_variance': np.float32(6.030663), 'max_total_reward': np.float32(13.38889), 'min_total_reward': np.float32(4.411112), 'average_n_step': np.float32(9.6), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08019688837230206), 'actor_loss': np.float64(-0.9459415793418884), 'hyper_actor_loss': np.float64(0.0016805605497211217), 'behavior_loss': np.float64(0.7229000210762024)}
step: 10170 @ episode report: {'average_total_reward': np.float32(8.975557), 'reward_variance': np.float32(2.194587), 'max_total_reward': np.float32(12.266666), 'min_total_reward': np.float32(7.655556), 'average_n_step': np.float32(10.1), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09454996027052402), 'actor_loss': np.float64(-0.9625183403491974), 'hyper_actor_loss': np.float64(0.0016981782275252045), 'behavior_loss': np.float64(0.7723715245723725)}
step: 10180 @ episode report: {'average_total_reward': np.float32(8.090001), 'reward_variance': np.float32(4.269444), 'max_total_reward': np.float32(12.022223), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(9.3), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08737724274396896), 'actor_loss': np.float64(-0.9402899980545044), 'hyper_actor_loss': np.float64(0.00173765670042485), 'behavior_loss': np.float64(0.7751639008522033)}
step: 10190 @ episode report: {'average_total_reward': np.float32(8.253334), 'reward_variance': np.float32(1.2933041), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(6.533334), 'average_n_step': np.float32(9.5), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08052834384143352), 'actor_loss': np.float64(-0.9446474969387054), 'hyper_actor_loss': np.float64(0.0017562209512107074), 'behavior_loss': np.float64(0.7486187636852264)}
step: 10200 @ episode report: {'average_total_reward': np.float32(9.151113), 'reward_variance': np.float32(3.3811417), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(10.3), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07515777200460434), 'actor_loss': np.float64(-0.9418402850627899), 'hyper_actor_loss': np.float64(0.001785887754522264), 'behavior_loss': np.float64(0.7087782323360443)}
step: 10210 @ episode report: {'average_total_reward': np.float32(8.926668), 'reward_variance': np.float32(2.5137582), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.1), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09692066162824631), 'actor_loss': np.float64(-0.968733960390091), 'hyper_actor_loss': np.float64(0.0019211425445973874), 'behavior_loss': np.float64(0.7266405284404754)}
step: 10220 @ episode report: {'average_total_reward': np.float32(8.465556), 'reward_variance': np.float32(3.5177898), 'max_total_reward': np.float32(12.266668), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.7), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07937091216444969), 'actor_loss': np.float64(-0.9562450885772705), 'hyper_actor_loss': np.float64(0.0016985477064736187), 'behavior_loss': np.float64(0.7197252452373505)}
step: 10230 @ episode report: {'average_total_reward': np.float32(9.065557), 'reward_variance': np.float32(2.3025057), 'max_total_reward': np.float32(13.022223), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(10.3), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07238308936357499), 'actor_loss': np.float64(-0.9153908371925354), 'hyper_actor_loss': np.float64(0.0016872571199201048), 'behavior_loss': np.float64(0.7070473253726959)}
step: 10240 @ episode report: {'average_total_reward': np.float32(8.177778), 'reward_variance': np.float32(3.835086), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(9.4), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07373448386788369), 'actor_loss': np.float64(-0.9400370180606842), 'hyper_actor_loss': np.float64(0.0016117644147016108), 'behavior_loss': np.float64(0.7027406752109527)}
step: 10250 @ episode report: {'average_total_reward': np.float32(8.290001), 'reward_variance': np.float32(1.4710737), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.5), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08046250231564045), 'actor_loss': np.float64(-0.9500829577445984), 'hyper_actor_loss': np.float64(0.0016590647515840828), 'behavior_loss': np.float64(0.6796836137771607)}
step: 10260 @ episode report: {'average_total_reward': np.float32(9.151112), 'reward_variance': np.float32(2.8519552), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.3), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07742001637816429), 'actor_loss': np.float64(-0.9465008080005646), 'hyper_actor_loss': np.float64(0.0015747317578643561), 'behavior_loss': np.float64(0.7153835356235504)}
step: 10270 @ episode report: {'average_total_reward': np.float32(8.93889), 'reward_variance': np.float32(3.476598), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(10.1), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0740471288561821), 'actor_loss': np.float64(-0.9420532047748565), 'hyper_actor_loss': np.float64(0.0015692299813963473), 'behavior_loss': np.float64(0.7152716875076294)}
step: 10280 @ episode report: {'average_total_reward': np.float32(8.490001), 'reward_variance': np.float32(3.1553695), 'max_total_reward': np.float32(10.9), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(9.7), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08160416558384895), 'actor_loss': np.float64(-0.950365138053894), 'hyper_actor_loss': np.float64(0.0014365493669174611), 'behavior_loss': np.float64(0.6868529081344604)}
step: 10290 @ episode report: {'average_total_reward': np.float32(8.277778), 'reward_variance': np.float32(2.0161233), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(9.5), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09035045094788074), 'actor_loss': np.float64(-0.9786621451377868), 'hyper_actor_loss': np.float64(0.0014029055018909276), 'behavior_loss': np.float64(0.6686570823192597)}
step: 10300 @ episode report: {'average_total_reward': np.float32(10.185556), 'reward_variance': np.float32(1.5558783), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(8.777778), 'average_n_step': np.float32(11.2), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07099123559892177), 'actor_loss': np.float64(-0.9605136454105377), 'hyper_actor_loss': np.float64(0.001382119138725102), 'behavior_loss': np.float64(0.6810481607913971)}
step: 10310 @ episode report: {'average_total_reward': np.float32(8.787779), 'reward_variance': np.float32(5.2990003), 'max_total_reward': np.float32(12.266668), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.9), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08719444014132023), 'actor_loss': np.float64(-0.9385496199131012), 'hyper_actor_loss': np.float64(0.001427645073272288), 'behavior_loss': np.float64(0.6947952806949615)}
step: 10320 @ episode report: {'average_total_reward': np.float32(8.526667), 'reward_variance': np.float32(1.9541779), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(9.7), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08436125852167606), 'actor_loss': np.float64(-0.9635052919387818), 'hyper_actor_loss': np.float64(0.0014591071056202054), 'behavior_loss': np.float64(0.7139201521873474)}
step: 10330 @ episode report: {'average_total_reward': np.float32(8.79), 'reward_variance': np.float32(1.7394924), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.0), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09280827566981316), 'actor_loss': np.float64(-0.9406416714191437), 'hyper_actor_loss': np.float64(0.0013985809637233615), 'behavior_loss': np.float64(0.6849108576774597)}
step: 10340 @ episode report: {'average_total_reward': np.float32(8.926668), 'reward_variance': np.float32(4.8420305), 'max_total_reward': np.float32(14.38889), 'min_total_reward': np.float32(6.655556), 'average_n_step': np.float32(10.1), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07204720601439477), 'actor_loss': np.float64(-0.9583480417728424), 'hyper_actor_loss': np.float64(0.0013857840676791966), 'behavior_loss': np.float64(0.6427097201347352)}
step: 10350 @ episode report: {'average_total_reward': np.float32(9.202223), 'reward_variance': np.float32(2.4543157), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.5333343), 'average_n_step': np.float32(10.4), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06599820964038372), 'actor_loss': np.float64(-0.9304463982582092), 'hyper_actor_loss': np.float64(0.0014130108756944537), 'behavior_loss': np.float64(0.6429686665534973)}
step: 10360 @ episode report: {'average_total_reward': np.float32(8.63889), 'reward_variance': np.float32(4.721957), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(9.8), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0809317484498024), 'actor_loss': np.float64(-0.9393613874912262), 'hyper_actor_loss': np.float64(0.0013729639817029239), 'behavior_loss': np.float64(0.6516538262367249)}
step: 10370 @ episode report: {'average_total_reward': np.float32(9.002223), 'reward_variance': np.float32(4.4454775), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(10.2), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07185472585260869), 'actor_loss': np.float64(-0.9515112817287446), 'hyper_actor_loss': np.float64(0.0014780209981836378), 'behavior_loss': np.float64(0.6769406735897064)}
step: 10380 @ episode report: {'average_total_reward': np.float32(9.163334), 'reward_variance': np.float32(2.6805694), 'max_total_reward': np.float32(11.900001), 'min_total_reward': np.float32(6.533334), 'average_n_step': np.float32(10.3), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08481775261461735), 'actor_loss': np.float64(-0.9391443133354187), 'hyper_actor_loss': np.float64(0.0015015043900348246), 'behavior_loss': np.float64(0.6757022202014923)}
step: 10390 @ episode report: {'average_total_reward': np.float32(9.948889), 'reward_variance': np.float32(3.3682513), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(6.6555567), 'average_n_step': np.float32(11.0), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0684301022440195), 'actor_loss': np.float64(-0.9568402767181396), 'hyper_actor_loss': np.float64(0.001591159391682595), 'behavior_loss': np.float64(0.6359907388687134)}
step: 10400 @ episode report: {'average_total_reward': np.float32(9.124445), 'reward_variance': np.float32(4.6559715), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.2), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08019131347537041), 'actor_loss': np.float64(-0.9422903537750245), 'hyper_actor_loss': np.float64(0.0016241388162598013), 'behavior_loss': np.float64(0.6527275741100311)}
step: 10410 @ episode report: {'average_total_reward': np.float32(9.175555), 'reward_variance': np.float32(1.9353287), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.3), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08168534561991692), 'actor_loss': np.float64(-0.9461474359035492), 'hyper_actor_loss': np.float64(0.001629158528521657), 'behavior_loss': np.float64(0.6768856704235077)}
step: 10420 @ episode report: {'average_total_reward': np.float32(8.887778), 'reward_variance': np.float32(6.7775664), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(4.2888894), 'average_n_step': np.float32(10.0), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08149999007582664), 'actor_loss': np.float64(-0.9654786169528962), 'hyper_actor_loss': np.float64(0.0016575346235185862), 'behavior_loss': np.float64(0.64436474442482)}
step: 10430 @ episode report: {'average_total_reward': np.float32(8.314445), 'reward_variance': np.float32(2.63899), 'max_total_reward': np.float32(12.266668), 'min_total_reward': np.float32(6.533334), 'average_n_step': np.float32(9.5), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07978053092956543), 'actor_loss': np.float64(-0.9352397382259369), 'hyper_actor_loss': np.float64(0.0016689866431988775), 'behavior_loss': np.float64(0.6486705034971237)}
step: 10440 @ episode report: {'average_total_reward': np.float32(7.9411116), 'reward_variance': np.float32(1.5608652), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(9.2), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08609736151993275), 'actor_loss': np.float64(-0.9462586522102356), 'hyper_actor_loss': np.float64(0.0015919762896373867), 'behavior_loss': np.float64(0.6430848717689515)}
step: 10450 @ episode report: {'average_total_reward': np.float32(8.514445), 'reward_variance': np.float32(3.55689), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.7), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07709474675357342), 'actor_loss': np.float64(-0.97099928855896), 'hyper_actor_loss': np.float64(0.001591299579013139), 'behavior_loss': np.float64(0.6168503284454345)}
step: 10460 @ episode report: {'average_total_reward': np.float32(9.038889), 'reward_variance': np.float32(2.1358337), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.2), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07749831341207028), 'actor_loss': np.float64(-0.948309451341629), 'hyper_actor_loss': np.float64(0.001378366257995367), 'behavior_loss': np.float64(0.6204963505268097)}
step: 10470 @ episode report: {'average_total_reward': np.float32(8.365557), 'reward_variance': np.float32(3.7009735), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(9.6), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07517154663801193), 'actor_loss': np.float64(-0.930854594707489), 'hyper_actor_loss': np.float64(0.001337813143618405), 'behavior_loss': np.float64(0.598260223865509)}
step: 10480 @ episode report: {'average_total_reward': np.float32(8.414445), 'reward_variance': np.float32(3.2540748), 'max_total_reward': np.float32(11.0222225), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.6), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08272027373313903), 'actor_loss': np.float64(-0.9463593065738678), 'hyper_actor_loss': np.float64(0.0013378449250012637), 'behavior_loss': np.float64(0.5878950744867325)}
step: 10490 @ episode report: {'average_total_reward': np.float32(9.224446), 'reward_variance': np.float32(3.162391), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.3), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07721909359097481), 'actor_loss': np.float64(-0.975640618801117), 'hyper_actor_loss': np.float64(0.0012306636432185768), 'behavior_loss': np.float64(0.5655916213989258)}
step: 10500 @ episode report: {'average_total_reward': np.float32(9.051111), 'reward_variance': np.float32(1.6180794), 'max_total_reward': np.float32(11.022223), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.2), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0719422634691), 'actor_loss': np.float64(-0.9485894441604614), 'hyper_actor_loss': np.float64(0.0012761198333464563), 'behavior_loss': np.float64(0.6134011328220368)}
step: 10510 @ episode report: {'average_total_reward': np.float32(8.390001), 'reward_variance': np.float32(1.2067517), 'max_total_reward': np.float32(9.777778), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(9.6), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07581275179982186), 'actor_loss': np.float64(-0.9249408841133118), 'hyper_actor_loss': np.float64(0.0013116016751155257), 'behavior_loss': np.float64(0.5909185647964478)}
step: 10520 @ episode report: {'average_total_reward': np.float32(8.265556), 'reward_variance': np.float32(2.599271), 'max_total_reward': np.float32(10.900001), 'min_total_reward': np.float32(4.411111), 'average_n_step': np.float32(9.5), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07329921387135982), 'actor_loss': np.float64(-0.9655522346496582), 'hyper_actor_loss': np.float64(0.001382283086422831), 'behavior_loss': np.float64(0.5845817744731903)}
step: 10530 @ episode report: {'average_total_reward': np.float32(9.087778), 'reward_variance': np.float32(4.87258), 'max_total_reward': np.float32(12.266666), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(10.2), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07721164301037789), 'actor_loss': np.float64(-0.9304989337921142), 'hyper_actor_loss': np.float64(0.0014717604848556221), 'behavior_loss': np.float64(0.5383564561605454)}
step: 10540 @ episode report: {'average_total_reward': np.float32(8.128889), 'reward_variance': np.float32(5.3401537), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(9.4), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07963401935994625), 'actor_loss': np.float64(-0.9881974279880523), 'hyper_actor_loss': np.float64(0.0017068994231522084), 'behavior_loss': np.float64(0.5493845880031586)}
step: 10550 @ episode report: {'average_total_reward': np.float32(9.151112), 'reward_variance': np.float32(2.2913382), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.3), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0785827424377203), 'actor_loss': np.float64(-0.9454155325889587), 'hyper_actor_loss': np.float64(0.0014672794961370528), 'behavior_loss': np.float64(0.5743253082036972)}
step: 10560 @ episode report: {'average_total_reward': np.float32(8.926668), 'reward_variance': np.float32(1.4284738), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(7.5333343), 'average_n_step': np.float32(10.1), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08323720321059228), 'actor_loss': np.float64(-0.951527065038681), 'hyper_actor_loss': np.float64(0.0013456088490784168), 'behavior_loss': np.float64(0.5864901781082154)}
step: 10570 @ episode report: {'average_total_reward': np.float32(8.441112), 'reward_variance': np.float32(1.629063), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(5.655556), 'average_n_step': np.float32(9.7), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09005274623632431), 'actor_loss': np.float64(-0.967449527978897), 'hyper_actor_loss': np.float64(0.0013061240315437317), 'behavior_loss': np.float64(0.5775505572557449)}
step: 10580 @ episode report: {'average_total_reward': np.float32(9.487778), 'reward_variance': np.float32(5.510481), 'max_total_reward': np.float32(14.144445), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.6), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07817709110677243), 'actor_loss': np.float64(-0.9647682011127472), 'hyper_actor_loss': np.float64(0.0012390378280542791), 'behavior_loss': np.float64(0.5582242846488953)}
step: 10590 @ episode report: {'average_total_reward': np.float32(8.402224), 'reward_variance': np.float32(3.3148842), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(5.411111), 'average_n_step': np.float32(9.6), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07993866391479969), 'actor_loss': np.float64(-0.9472547471523285), 'hyper_actor_loss': np.float64(0.0013549308641813695), 'behavior_loss': np.float64(0.5816542983055115)}
step: 10600 @ episode report: {'average_total_reward': np.float32(9.400001), 'reward_variance': np.float32(1.4849379), 'max_total_reward': np.float32(12.144444), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(10.5), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07765870355069637), 'actor_loss': np.float64(-0.96189746260643), 'hyper_actor_loss': np.float64(0.0015858867554925382), 'behavior_loss': np.float64(0.5649154305458068)}
step: 10610 @ episode report: {'average_total_reward': np.float32(9.251112), 'reward_variance': np.float32(1.8059059), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(7.411111), 'average_n_step': np.float32(10.4), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0750049777328968), 'actor_loss': np.float64(-0.9504325211048126), 'hyper_actor_loss': np.float64(0.0018273910274729133), 'behavior_loss': np.float64(0.5581222981214523)}
step: 10620 @ episode report: {'average_total_reward': np.float32(9.5), 'reward_variance': np.float32(1.1996046), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(7.411111), 'average_n_step': np.float32(10.6), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0717182695865631), 'actor_loss': np.float64(-0.9481382846832276), 'hyper_actor_loss': np.float64(0.001813378103543073), 'behavior_loss': np.float64(0.568792325258255)}
step: 10630 @ episode report: {'average_total_reward': np.float32(9.6), 'reward_variance': np.float32(1.4998019), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(10.7), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08654247894883156), 'actor_loss': np.float64(-0.9374205112457276), 'hyper_actor_loss': np.float64(0.0015198632725514471), 'behavior_loss': np.float64(0.5880967438220978)}
step: 10640 @ episode report: {'average_total_reward': np.float32(10.048889), 'reward_variance': np.float32(6.5044007), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(11.1), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08127502836287022), 'actor_loss': np.float64(-0.9614650726318359), 'hyper_actor_loss': np.float64(0.0013325355714187026), 'behavior_loss': np.float64(0.5809651196002961)}
step: 10650 @ episode report: {'average_total_reward': np.float32(9.626668), 'reward_variance': np.float32(1.9522517), 'max_total_reward': np.float32(12.144444), 'min_total_reward': np.float32(7.411111), 'average_n_step': np.float32(10.8), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0852753259241581), 'actor_loss': np.float64(-0.9534676909446717), 'hyper_actor_loss': np.float64(0.0013056230964139104), 'behavior_loss': np.float64(0.5519885033369064)}
step: 10660 @ episode report: {'average_total_reward': np.float32(9.775557), 'reward_variance': np.float32(2.160365), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(10.9), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08710139766335487), 'actor_loss': np.float64(-0.9757567763328552), 'hyper_actor_loss': np.float64(0.00134600029559806), 'behavior_loss': np.float64(0.5270561188459396)}
step: 10670 @ episode report: {'average_total_reward': np.float32(9.075556), 'reward_variance': np.float32(3.3976753), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.2), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07639405578374862), 'actor_loss': np.float64(-0.9576279997825623), 'hyper_actor_loss': np.float64(0.0013792698038741947), 'behavior_loss': np.float64(0.5375495076179504)}
step: 10680 @ episode report: {'average_total_reward': np.float32(10.173334), 'reward_variance': np.float32(3.0939302), 'max_total_reward': np.float32(12.266666), 'min_total_reward': np.float32(7.5333343), 'average_n_step': np.float32(11.2), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08631643615663051), 'actor_loss': np.float64(-0.9616446197032928), 'hyper_actor_loss': np.float64(0.001450005965307355), 'behavior_loss': np.float64(0.5124104738235473)}
step: 10690 @ episode report: {'average_total_reward': np.float32(10.110001), 'reward_variance': np.float32(5.0520115), 'max_total_reward': np.float32(14.511111), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(11.1), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06827979534864426), 'actor_loss': np.float64(-0.9571958005428314), 'hyper_actor_loss': np.float64(0.001423793809954077), 'behavior_loss': np.float64(0.49284749627113345)}
step: 10700 @ episode report: {'average_total_reward': np.float32(9.612223), 'reward_variance': np.float32(3.5070236), 'max_total_reward': np.float32(12.022222), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.7), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08134418800473213), 'actor_loss': np.float64(-0.9409952342510224), 'hyper_actor_loss': np.float64(0.001375683827791363), 'behavior_loss': np.float64(0.5417345643043519)}
step: 10710 @ episode report: {'average_total_reward': np.float32(10.622223), 'reward_variance': np.float32(1.7816792), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(8.777779), 'average_n_step': np.float32(11.6), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07233998253941536), 'actor_loss': np.float64(-0.9600248336791992), 'hyper_actor_loss': np.float64(0.0012921968824230134), 'behavior_loss': np.float64(0.5202807307243347)}
step: 10720 @ episode report: {'average_total_reward': np.float32(9.363333), 'reward_variance': np.float32(2.6499527), 'max_total_reward': np.float32(11.022223), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(10.5), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08152509555220604), 'actor_loss': np.float64(-0.980035400390625), 'hyper_actor_loss': np.float64(0.0012889788136817514), 'behavior_loss': np.float64(0.5023983865976334)}
step: 10730 @ episode report: {'average_total_reward': np.float32(9.051111), 'reward_variance': np.float32(4.7248945), 'max_total_reward': np.float32(14.266667), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(10.2), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07970160469412804), 'actor_loss': np.float64(-0.9490661978721618), 'hyper_actor_loss': np.float64(0.0013403433375060558), 'behavior_loss': np.float64(0.5336856812238693)}
step: 10740 @ episode report: {'average_total_reward': np.float32(10.024446), 'reward_variance': np.float32(2.0456493), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.533334), 'average_n_step': np.float32(11.1), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09019864462316037), 'actor_loss': np.float64(-0.9640331089496612), 'hyper_actor_loss': np.float64(0.0013980442890897393), 'behavior_loss': np.float64(0.5045594662427902)}
step: 10750 @ episode report: {'average_total_reward': np.float32(10.14889), 'reward_variance': np.float32(2.6687703), 'max_total_reward': np.float32(12.266666), 'min_total_reward': np.float32(6.5333333), 'average_n_step': np.float32(11.2), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08392571434378623), 'actor_loss': np.float64(-0.9781225740909576), 'hyper_actor_loss': np.float64(0.00158325363881886), 'behavior_loss': np.float64(0.5041011571884155)}
step: 10760 @ episode report: {'average_total_reward': np.float32(8.987778), 'reward_variance': np.float32(3.0783813), 'max_total_reward': np.float32(11.900001), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.1), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07081647962331772), 'actor_loss': np.float64(-0.9503492474555969), 'hyper_actor_loss': np.float64(0.001634055923204869), 'behavior_loss': np.float64(0.49717758893966674)}
step: 10770 @ episode report: {'average_total_reward': np.float32(10.185556), 'reward_variance': np.float32(3.61978), 'max_total_reward': np.float32(12.266668), 'min_total_reward': np.float32(6.533334), 'average_n_step': np.float32(11.2), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07871395386755467), 'actor_loss': np.float64(-0.9518469393253326), 'hyper_actor_loss': np.float64(0.0017452182131819428), 'behavior_loss': np.float64(0.5104956597089767)}
step: 10780 @ episode report: {'average_total_reward': np.float32(9.551112), 'reward_variance': np.float32(2.9883027), 'max_total_reward': np.float32(13.022223), 'min_total_reward': np.float32(7.533333), 'average_n_step': np.float32(10.7), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07563507221639157), 'actor_loss': np.float64(-0.951620751619339), 'hyper_actor_loss': np.float64(0.0017474233522079886), 'behavior_loss': np.float64(0.5011524468660354)}
step: 10790 @ episode report: {'average_total_reward': np.float32(11.083334), 'reward_variance': np.float32(1.8491675), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(8.777779), 'average_n_step': np.float32(12.0), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07254962921142578), 'actor_loss': np.float64(-0.9457428216934204), 'hyper_actor_loss': np.float64(0.0018089518882334233), 'behavior_loss': np.float64(0.47829577028751374)}
step: 10800 @ episode report: {'average_total_reward': np.float32(9.324445), 'reward_variance': np.float32(1.3340943), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(10.4), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07373109310865403), 'actor_loss': np.float64(-0.9655006289482116), 'hyper_actor_loss': np.float64(0.0016730520292185247), 'behavior_loss': np.float64(0.49075338840484617)}
step: 10810 @ episode report: {'average_total_reward': np.float32(9.1877775), 'reward_variance': np.float32(1.7573693), 'max_total_reward': np.float32(11.0222225), 'min_total_reward': np.float32(6.5333333), 'average_n_step': np.float32(10.3), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08507140167057514), 'actor_loss': np.float64(-0.9752062439918519), 'hyper_actor_loss': np.float64(0.0013977708877064288), 'behavior_loss': np.float64(0.5234609723091126)}
step: 10820 @ episode report: {'average_total_reward': np.float32(10.185556), 'reward_variance': np.float32(2.8671386), 'max_total_reward': np.float32(13.38889), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(11.2), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07311865352094174), 'actor_loss': np.float64(-0.9555197775363922), 'hyper_actor_loss': np.float64(0.0013059875695034862), 'behavior_loss': np.float64(0.5044412970542907)}
step: 10830 @ episode report: {'average_total_reward': np.float32(10.04889), 'reward_variance': np.float32(0.372079), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(8.900001), 'average_n_step': np.float32(11.1), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07901985421776772), 'actor_loss': np.float64(-0.9398342251777649), 'hyper_actor_loss': np.float64(0.001273381896317005), 'behavior_loss': np.float64(0.5169754385948181)}
step: 10840 @ episode report: {'average_total_reward': np.float32(9.014444), 'reward_variance': np.float32(2.5525193), 'max_total_reward': np.float32(12.266666), 'min_total_reward': np.float32(6.5333333), 'average_n_step': np.float32(10.2), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08956316336989403), 'actor_loss': np.float64(-0.9537020444869995), 'hyper_actor_loss': np.float64(0.0011603421065956355), 'behavior_loss': np.float64(0.5475637763738632)}
step: 10850 @ episode report: {'average_total_reward': np.float32(10.185556), 'reward_variance': np.float32(3.8766434), 'max_total_reward': np.float32(13.144444), 'min_total_reward': np.float32(6.6555552), 'average_n_step': np.float32(11.2), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08601585254073144), 'actor_loss': np.float64(-0.9862766206264496), 'hyper_actor_loss': np.float64(0.0010653554869350045), 'behavior_loss': np.float64(0.531143119931221)}
step: 10860 @ episode report: {'average_total_reward': np.float32(9.387779), 'reward_variance': np.float32(2.5364306), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(10.5), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07545596472918988), 'actor_loss': np.float64(-0.961192524433136), 'hyper_actor_loss': np.float64(0.0011137491033878177), 'behavior_loss': np.float64(0.4997297883033752)}
step: 10870 @ episode report: {'average_total_reward': np.float32(10.122223), 'reward_variance': np.float32(2.6361969), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(11.1), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0826478149741888), 'actor_loss': np.float64(-0.9475998401641845), 'hyper_actor_loss': np.float64(0.0011533814598806203), 'behavior_loss': np.float64(0.532423684000969)}
step: 10880 @ episode report: {'average_total_reward': np.float32(8.8144455), 'reward_variance': np.float32(2.051557), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.0), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08242935538291932), 'actor_loss': np.float64(-0.9518567085266113), 'hyper_actor_loss': np.float64(0.0010848803620319813), 'behavior_loss': np.float64(0.5381462723016739)}
step: 10890 @ episode report: {'average_total_reward': np.float32(9.1), 'reward_variance': np.float32(2.3750126), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.2), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07311273217201233), 'actor_loss': np.float64(-0.9520129442214966), 'hyper_actor_loss': np.float64(0.0010959722159896046), 'behavior_loss': np.float64(0.5078056544065476)}
step: 10900 @ episode report: {'average_total_reward': np.float32(9.663335), 'reward_variance': np.float32(1.4686927), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(7.5333333), 'average_n_step': np.float32(10.8), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06652678288519383), 'actor_loss': np.float64(-0.9384717345237732), 'hyper_actor_loss': np.float64(0.001059864368289709), 'behavior_loss': np.float64(0.5117453813552857)}
step: 10910 @ episode report: {'average_total_reward': np.float32(9.500002), 'reward_variance': np.float32(2.5343213), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.655556), 'average_n_step': np.float32(10.6), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08160459194332362), 'actor_loss': np.float64(-0.9653118133544922), 'hyper_actor_loss': np.float64(0.0011215897568035871), 'behavior_loss': np.float64(0.5063540756702423)}
step: 10920 @ episode report: {'average_total_reward': np.float32(9.23889), 'reward_variance': np.float32(3.4173646), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.4), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08790340423583984), 'actor_loss': np.float64(-0.957547253370285), 'hyper_actor_loss': np.float64(0.001153573766350746), 'behavior_loss': np.float64(0.5214152753353118)}
step: 10930 @ episode report: {'average_total_reward': np.float32(9.33889), 'reward_variance': np.float32(1.956748), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(7.4111114), 'average_n_step': np.float32(10.5), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08066469430923462), 'actor_loss': np.float64(-0.9806656658649444), 'hyper_actor_loss': np.float64(0.0011131634586490692), 'behavior_loss': np.float64(0.5027093321084977)}
step: 10940 @ episode report: {'average_total_reward': np.float32(9.985556), 'reward_variance': np.float32(3.8087182), 'max_total_reward': np.float32(14.511111), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(11.0), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07695552855730056), 'actor_loss': np.float64(-0.9691882371902466), 'hyper_actor_loss': np.float64(0.0011405963101424276), 'behavior_loss': np.float64(0.48038685917854307)}
step: 10950 @ episode report: {'average_total_reward': np.float32(9.03889), 'reward_variance': np.float32(2.989241), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(6.5333343), 'average_n_step': np.float32(10.2), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08515929989516735), 'actor_loss': np.float64(-0.9592087268829346), 'hyper_actor_loss': np.float64(0.0011935633374378085), 'behavior_loss': np.float64(0.5278832405805588)}
step: 10960 @ episode report: {'average_total_reward': np.float32(9.761111), 'reward_variance': np.float32(2.400203), 'max_total_reward': np.float32(12.266666), 'min_total_reward': np.float32(6.6555567), 'average_n_step': np.float32(10.8), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0855482742190361), 'actor_loss': np.float64(-0.9708625435829162), 'hyper_actor_loss': np.float64(0.001270769815891981), 'behavior_loss': np.float64(0.5140434533357621)}
step: 10970 @ episode report: {'average_total_reward': np.float32(10.75889), 'reward_variance': np.float32(1.4975069), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(8.900001), 'average_n_step': np.float32(11.7), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08269263766705989), 'actor_loss': np.float64(-0.9736452281475068), 'hyper_actor_loss': np.float64(0.0014685493661090732), 'behavior_loss': np.float64(0.5181294441223144)}
step: 10980 @ episode report: {'average_total_reward': np.float32(9.975557), 'reward_variance': np.float32(1.1107613), 'max_total_reward': np.float32(12.266668), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(11.1), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07714259400963783), 'actor_loss': np.float64(-0.9568361222743988), 'hyper_actor_loss': np.float64(0.0015333447721786798), 'behavior_loss': np.float64(0.4915365517139435)}
step: 10990 @ episode report: {'average_total_reward': np.float32(9.424444), 'reward_variance': np.float32(3.4963665), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(7.777778), 'average_n_step': np.float32(10.5), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0749447863548994), 'actor_loss': np.float64(-0.9835136115550995), 'hyper_actor_loss': np.float64(0.0016437202459201217), 'behavior_loss': np.float64(0.5026186794042588)}
step: 11000 @ episode report: {'average_total_reward': np.float32(9.575556), 'reward_variance': np.float32(1.3837725), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(7.777778), 'average_n_step': np.float32(10.7), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06612684652209282), 'actor_loss': np.float64(-0.9542501151561738), 'hyper_actor_loss': np.float64(0.0016191735281608998), 'behavior_loss': np.float64(0.4960194110870361)}
step: 11010 @ episode report: {'average_total_reward': np.float32(8.73889), 'reward_variance': np.float32(2.0446477), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.9), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08066977225244046), 'actor_loss': np.float64(-0.9659837424755097), 'hyper_actor_loss': np.float64(0.001588941237423569), 'behavior_loss': np.float64(0.46906550228595734)}
step: 11020 @ episode report: {'average_total_reward': np.float32(8.987778), 'reward_variance': np.float32(5.1587524), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(6.5333333), 'average_n_step': np.float32(10.1), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07750936485826969), 'actor_loss': np.float64(-0.9763042092323303), 'hyper_actor_loss': np.float64(0.001559027365874499), 'behavior_loss': np.float64(0.5170481741428375)}
step: 11030 @ episode report: {'average_total_reward': np.float32(9.23889), 'reward_variance': np.float32(2.702649), 'max_total_reward': np.float32(13.38889), 'min_total_reward': np.float32(7.533334), 'average_n_step': np.float32(10.4), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07118304967880248), 'actor_loss': np.float64(-0.9502090156078339), 'hyper_actor_loss': np.float64(0.0016202821047045291), 'behavior_loss': np.float64(0.5191341906785965)}
step: 11040 @ episode report: {'average_total_reward': np.float32(8.714445), 'reward_variance': np.float32(1.202224), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(9.9), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08261060640215874), 'actor_loss': np.float64(-0.9716519176959991), 'hyper_actor_loss': np.float64(0.0015167850186116993), 'behavior_loss': np.float64(0.48102574050426483)}
step: 11050 @ episode report: {'average_total_reward': np.float32(9.463333), 'reward_variance': np.float32(2.8432856), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(6.5333333), 'average_n_step': np.float32(10.6), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08284963108599186), 'actor_loss': np.float64(-0.9976905345916748), 'hyper_actor_loss': np.float64(0.001548999035730958), 'behavior_loss': np.float64(0.5069556713104248)}
step: 11060 @ episode report: {'average_total_reward': np.float32(9.873334), 'reward_variance': np.float32(2.0684009), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.9), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06950213946402073), 'actor_loss': np.float64(-0.9636104226112365), 'hyper_actor_loss': np.float64(0.0014355993131175636), 'behavior_loss': np.float64(0.48447381258010863)}
step: 11070 @ episode report: {'average_total_reward': np.float32(9.351111), 'reward_variance': np.float32(1.9169433), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.5), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08388273678719997), 'actor_loss': np.float64(-0.9691129267215729), 'hyper_actor_loss': np.float64(0.0013487784890457988), 'behavior_loss': np.float64(0.4875702440738678)}
step: 11080 @ episode report: {'average_total_reward': np.float32(9.336667), 'reward_variance': np.float32(1.2946433), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(7.777778), 'average_n_step': np.float32(10.4), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07025600820779801), 'actor_loss': np.float64(-0.9859601795673371), 'hyper_actor_loss': np.float64(0.0014228979242034256), 'behavior_loss': np.float64(0.46567435562610626)}
step: 11090 @ episode report: {'average_total_reward': np.float32(9.561111), 'reward_variance': np.float32(4.1640315), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.6), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07955625541508198), 'actor_loss': np.float64(-0.9617586076259613), 'hyper_actor_loss': np.float64(0.0014513602945953608), 'behavior_loss': np.float64(0.4802631437778473)}
step: 11100 @ episode report: {'average_total_reward': np.float32(9.412223), 'reward_variance': np.float32(2.2237148), 'max_total_reward': np.float32(12.144444), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(10.5), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08033820539712906), 'actor_loss': np.float64(-0.9822098076343536), 'hyper_actor_loss': np.float64(0.0014702449669130146), 'behavior_loss': np.float64(0.4700466424226761)}
step: 11110 @ episode report: {'average_total_reward': np.float32(9.9366665), 'reward_variance': np.float32(1.6595322), 'max_total_reward': np.float32(12.022222), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(11.0), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06492996662855148), 'actor_loss': np.float64(-0.9579746127128601), 'hyper_actor_loss': np.float64(0.0013417723239399493), 'behavior_loss': np.float64(0.47130198776721954)}
step: 11120 @ episode report: {'average_total_reward': np.float32(9.065557), 'reward_variance': np.float32(1.9907767), 'max_total_reward': np.float32(12.0222225), 'min_total_reward': np.float32(6.4111114), 'average_n_step': np.float32(10.3), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07376704774796963), 'actor_loss': np.float64(-0.9425398230552673), 'hyper_actor_loss': np.float64(0.0011832574848085642), 'behavior_loss': np.float64(0.48244848251342776)}
step: 11130 @ episode report: {'average_total_reward': np.float32(8.726667), 'reward_variance': np.float32(3.1124008), 'max_total_reward': np.float32(11.022223), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(9.9), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06485857330262661), 'actor_loss': np.float64(-0.967763888835907), 'hyper_actor_loss': np.float64(0.0010847882251255215), 'behavior_loss': np.float64(0.4804195165634155)}
step: 11140 @ episode report: {'average_total_reward': np.float32(8.765556), 'reward_variance': np.float32(0.21628253), 'max_total_reward': np.float32(9.777778), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(10.0), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08088755272328854), 'actor_loss': np.float64(-0.9583522558212281), 'hyper_actor_loss': np.float64(0.0011291761533357204), 'behavior_loss': np.float64(0.4743708074092865)}
step: 11150 @ episode report: {'average_total_reward': np.float32(9.575556), 'reward_variance': np.float32(1.517946), 'max_total_reward': np.float32(12.144444), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(10.7), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.062009752914309504), 'actor_loss': np.float64(-0.9537941515445709), 'hyper_actor_loss': np.float64(0.0011684250552207232), 'behavior_loss': np.float64(0.4603142201900482)}
step: 11160 @ episode report: {'average_total_reward': np.float32(8.851111), 'reward_variance': np.float32(3.1682527), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(10.0), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06961667202413083), 'actor_loss': np.float64(-0.9529627621173858), 'hyper_actor_loss': np.float64(0.0013218248263001443), 'behavior_loss': np.float64(0.42244035601615904)}
step: 11170 @ episode report: {'average_total_reward': np.float32(9.587779), 'reward_variance': np.float32(2.4524312), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(6.777778), 'average_n_step': np.float32(10.7), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06868376955389977), 'actor_loss': np.float64(-0.9616289556026458), 'hyper_actor_loss': np.float64(0.0015292959404177963), 'behavior_loss': np.float64(0.4510499000549316)}
step: 11180 @ episode report: {'average_total_reward': np.float32(9.424445), 'reward_variance': np.float32(3.3267856), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(6.6555567), 'average_n_step': np.float32(10.5), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06908283457159996), 'actor_loss': np.float64(-0.966878879070282), 'hyper_actor_loss': np.float64(0.0016521503101103007), 'behavior_loss': np.float64(0.4301676094532013)}
step: 11190 @ episode report: {'average_total_reward': np.float32(9.463334), 'reward_variance': np.float32(1.6347917), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(7.6555567), 'average_n_step': np.float32(10.6), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07590613476932048), 'actor_loss': np.float64(-0.9695758044719696), 'hyper_actor_loss': np.float64(0.001510256831534207), 'behavior_loss': np.float64(0.45294601023197173)}
step: 11200 @ episode report: {'average_total_reward': np.float32(10.085556), 'reward_variance': np.float32(1.335409), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(7.777778), 'average_n_step': np.float32(11.1), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07231423817574978), 'actor_loss': np.float64(-0.9666824758052825), 'hyper_actor_loss': np.float64(0.0012690284638665617), 'behavior_loss': np.float64(0.46710140705108644)}
step: 11210 @ episode report: {'average_total_reward': np.float32(9.624445), 'reward_variance': np.float32(2.3273537), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.777778), 'average_n_step': np.float32(10.7), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0835427213460207), 'actor_loss': np.float64(-0.9761255741119385), 'hyper_actor_loss': np.float64(0.0011047907639294863), 'behavior_loss': np.float64(0.46625572741031646)}
step: 11220 @ episode report: {'average_total_reward': np.float32(9.861112), 'reward_variance': np.float32(2.4032655), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.777778), 'average_n_step': np.float32(10.9), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07026825919747352), 'actor_loss': np.float64(-0.9785707235336304), 'hyper_actor_loss': np.float64(0.0010643096291460096), 'behavior_loss': np.float64(0.47813098430633544)}
step: 11230 @ episode report: {'average_total_reward': np.float32(10.097778), 'reward_variance': np.float32(4.910367), 'max_total_reward': np.float32(15.633334), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(11.1), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08931817151606083), 'actor_loss': np.float64(-0.9572817921638489), 'hyper_actor_loss': np.float64(0.0011135807493701578), 'behavior_loss': np.float64(0.4586212158203125)}
step: 11240 @ episode report: {'average_total_reward': np.float32(9.724444), 'reward_variance': np.float32(1.2679455), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(10.8), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0652827549725771), 'actor_loss': np.float64(-0.9894543528556824), 'hyper_actor_loss': np.float64(0.0010555413551628589), 'behavior_loss': np.float64(0.4693965673446655)}
step: 11250 @ episode report: {'average_total_reward': np.float32(8.826666), 'reward_variance': np.float32(2.730326), 'max_total_reward': np.float32(11.022223), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.0), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07195530608296394), 'actor_loss': np.float64(-0.9509217977523804), 'hyper_actor_loss': np.float64(0.0011387330654542894), 'behavior_loss': np.float64(0.4824623942375183)}
step: 11260 @ episode report: {'average_total_reward': np.float32(9.075556), 'reward_variance': np.float32(0.93377274), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(10.2), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07417532727122307), 'actor_loss': np.float64(-0.9686208069324493), 'hyper_actor_loss': np.float64(0.0013683781609870494), 'behavior_loss': np.float64(0.4653333991765976)}
step: 11270 @ episode report: {'average_total_reward': np.float32(9.163333), 'reward_variance': np.float32(2.9080012), 'max_total_reward': np.float32(12.144444), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.3), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07377947196364402), 'actor_loss': np.float64(-0.9898622155189514), 'hyper_actor_loss': np.float64(0.0013412073371000589), 'behavior_loss': np.float64(0.48028501570224763)}
step: 11280 @ episode report: {'average_total_reward': np.float32(9.387779), 'reward_variance': np.float32(2.2052464), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.5), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06728647872805596), 'actor_loss': np.float64(-0.9593330144882202), 'hyper_actor_loss': np.float64(0.0012291372404433787), 'behavior_loss': np.float64(0.45674256086349485)}
step: 11290 @ episode report: {'average_total_reward': np.float32(8.9388895), 'reward_variance': np.float32(4.325488), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(10.1), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07350363209843636), 'actor_loss': np.float64(-0.9766138136386872), 'hyper_actor_loss': np.float64(0.0012865632539615034), 'behavior_loss': np.float64(0.5114258855581284)}
step: 11300 @ episode report: {'average_total_reward': np.float32(9.375556), 'reward_variance': np.float32(2.0429583), 'max_total_reward': np.float32(11.144446), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.5), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07995815500617028), 'actor_loss': np.float64(-0.9812691390514374), 'hyper_actor_loss': np.float64(0.001303382113110274), 'behavior_loss': np.float64(0.4910504400730133)}
step: 11310 @ episode report: {'average_total_reward': np.float32(9.226667), 'reward_variance': np.float32(3.6738815), 'max_total_reward': np.float32(13.38889), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.4), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07453578338027), 'actor_loss': np.float64(-0.9787454068660736), 'hyper_actor_loss': np.float64(0.001253049704246223), 'behavior_loss': np.float64(0.46213647425174714)}
step: 11320 @ episode report: {'average_total_reward': np.float32(9.3144455), 'reward_variance': np.float32(1.2484204), 'max_total_reward': np.float32(11.0222225), 'min_total_reward': np.float32(7.6555567), 'average_n_step': np.float32(10.5), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08404859006404877), 'actor_loss': np.float64(-0.9692618489265442), 'hyper_actor_loss': np.float64(0.001265862735453993), 'behavior_loss': np.float64(0.5200099021196365)}
step: 11330 @ episode report: {'average_total_reward': np.float32(9.687778), 'reward_variance': np.float32(1.1669492), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(10.8), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06626425497233868), 'actor_loss': np.float64(-0.9730551064014434), 'hyper_actor_loss': np.float64(0.0012837561196647584), 'behavior_loss': np.float64(0.47045942544937136)}
step: 11340 @ episode report: {'average_total_reward': np.float32(9.961111), 'reward_variance': np.float32(3.053685), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(6.533334), 'average_n_step': np.float32(11.0), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07362559400498866), 'actor_loss': np.float64(-0.9627324521541596), 'hyper_actor_loss': np.float64(0.0014234010595828295), 'behavior_loss': np.float64(0.47685871720314027)}
step: 11350 @ episode report: {'average_total_reward': np.float32(8.8144455), 'reward_variance': np.float32(1.7782242), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(6.5333333), 'average_n_step': np.float32(10.0), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07543327137827874), 'actor_loss': np.float64(-0.9659503102302551), 'hyper_actor_loss': np.float64(0.0018821087898686529), 'behavior_loss': np.float64(0.4835434377193451)}
step: 11360 @ episode report: {'average_total_reward': np.float32(8.377779), 'reward_variance': np.float32(1.50237), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(9.6), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08534423932433129), 'actor_loss': np.float64(-1.0001353859901427), 'hyper_actor_loss': np.float64(0.002167829382233322), 'behavior_loss': np.float64(0.46119447350502013)}
step: 11370 @ episode report: {'average_total_reward': np.float32(9.075556), 'reward_variance': np.float32(2.58718), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.2), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0798149012029171), 'actor_loss': np.float64(-0.9924392223358154), 'hyper_actor_loss': np.float64(0.0016950635006651282), 'behavior_loss': np.float64(0.4937734842300415)}
step: 11380 @ episode report: {'average_total_reward': np.float32(10.285556), 'reward_variance': np.float32(1.8376554), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(8.533334), 'average_n_step': np.float32(11.3), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06527498029172421), 'actor_loss': np.float64(-0.9489961743354798), 'hyper_actor_loss': np.float64(0.001774058339651674), 'behavior_loss': np.float64(0.4800837904214859)}
step: 11390 @ episode report: {'average_total_reward': np.float32(9.736668), 'reward_variance': np.float32(4.9225445), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(5.655556), 'average_n_step': np.float32(10.8), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06414041854441166), 'actor_loss': np.float64(-0.9540834844112396), 'hyper_actor_loss': np.float64(0.002123866288457066), 'behavior_loss': np.float64(0.49069285690784453)}
step: 11400 @ episode report: {'average_total_reward': np.float32(8.963335), 'reward_variance': np.float32(3.5993104), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(10.1), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07093925401568413), 'actor_loss': np.float64(-0.9605975687503815), 'hyper_actor_loss': np.float64(0.0023251156555488704), 'behavior_loss': np.float64(0.48051262497901914)}
step: 11410 @ episode report: {'average_total_reward': np.float32(10.51), 'reward_variance': np.float32(3.6616416), 'max_total_reward': np.float32(12.266668), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(11.5), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07536082416772842), 'actor_loss': np.float64(-0.9818510711193085), 'hyper_actor_loss': np.float64(0.0019087031716480852), 'behavior_loss': np.float64(0.42659507095813753)}
step: 11420 @ episode report: {'average_total_reward': np.float32(8.877778), 'reward_variance': np.float32(1.1673088), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(6.4111114), 'average_n_step': np.float32(10.1), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07047302685678006), 'actor_loss': np.float64(-0.9904551327228546), 'hyper_actor_loss': np.float64(0.001318433601409197), 'behavior_loss': np.float64(0.49796896874904634)}
step: 11430 @ episode report: {'average_total_reward': np.float32(8.975555), 'reward_variance': np.float32(4.885922), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(5.411111), 'average_n_step': np.float32(10.1), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07727471217513085), 'actor_loss': np.float64(-0.9644057989120484), 'hyper_actor_loss': np.float64(0.0013001498416997492), 'behavior_loss': np.float64(0.47313764691352844)}
step: 11440 @ episode report: {'average_total_reward': np.float32(9.038889), 'reward_variance': np.float32(3.6605747), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(6.411111), 'average_n_step': np.float32(10.2), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07788678966462612), 'actor_loss': np.float64(-0.9970950126647949), 'hyper_actor_loss': np.float64(0.002189683064352721), 'behavior_loss': np.float64(0.4734526664018631)}
step: 11450 @ episode report: {'average_total_reward': np.float32(8.702223), 'reward_variance': np.float32(2.8115268), 'max_total_reward': np.float32(11.022223), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.9), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06734379436820745), 'actor_loss': np.float64(-0.9911498248577117), 'hyper_actor_loss': np.float64(0.004464215785264969), 'behavior_loss': np.float64(0.45742118954658506)}
step: 11460 @ episode report: {'average_total_reward': np.float32(9.775556), 'reward_variance': np.float32(1.3832796), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(7.533334), 'average_n_step': np.float32(10.9), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07586177214980125), 'actor_loss': np.float64(-0.9909955501556397), 'hyper_actor_loss': np.float64(0.005366261070594192), 'behavior_loss': np.float64(0.516772598028183)}
step: 11470 @ episode report: {'average_total_reward': np.float32(8.316668), 'reward_variance': np.float32(0.78089464), 'max_total_reward': np.float32(10.022222), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(9.6), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07866445742547512), 'actor_loss': np.float64(-1.0196024179458618), 'hyper_actor_loss': np.float64(0.006600436475127936), 'behavior_loss': np.float64(0.5286269575357437)}
step: 11480 @ episode report: {'average_total_reward': np.float32(6.6433334), 'reward_variance': np.float32(1.9370482), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.0), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.060592289082705975), 'actor_loss': np.float64(-0.9987536311149597), 'hyper_actor_loss': np.float64(0.00800069239921868), 'behavior_loss': np.float64(0.5384318619966507)}
step: 11490 @ episode report: {'average_total_reward': np.float32(5.7455554), 'reward_variance': np.float32(1.0602086), 'max_total_reward': np.float32(7.6555557), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.2), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07836192809045314), 'actor_loss': np.float64(-0.9622822344303131), 'hyper_actor_loss': np.float64(0.008846246264874935), 'behavior_loss': np.float64(0.5083717852830887)}
step: 11500 @ episode report: {'average_total_reward': np.float32(6.8188887), 'reward_variance': np.float32(2.6616309), 'max_total_reward': np.float32(8.777778), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(8.2), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08113157078623771), 'actor_loss': np.float64(-0.9990359425544739), 'hyper_actor_loss': np.float64(0.007763266377151012), 'behavior_loss': np.float64(0.545277652144432)}
step: 11510 @ episode report: {'average_total_reward': np.float32(7.2066674), 'reward_variance': np.float32(1.1296837), 'max_total_reward': np.float32(8.777778), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07597396336495876), 'actor_loss': np.float64(-0.9712157309055328), 'hyper_actor_loss': np.float64(0.0065587559714913365), 'behavior_loss': np.float64(0.5149035751819611)}
step: 11520 @ episode report: {'average_total_reward': np.float32(5.884444), 'reward_variance': np.float32(1.6931902), 'max_total_reward': np.float32(7.7777786), 'min_total_reward': np.float32(4.2888894), 'average_n_step': np.float32(7.4), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08090049587190151), 'actor_loss': np.float64(-0.9650605857372284), 'hyper_actor_loss': np.float64(0.005754082044586539), 'behavior_loss': np.float64(0.534704452753067)}
step: 11530 @ episode report: {'average_total_reward': np.float32(6.533334), 'reward_variance': np.float32(0.71570367), 'max_total_reward': np.float32(7.6555557), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(8.0), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09200418591499329), 'actor_loss': np.float64(-0.9864012718200683), 'hyper_actor_loss': np.float64(0.005281276535242796), 'behavior_loss': np.float64(0.5174723714590073)}
step: 11540 @ episode report: {'average_total_reward': np.float32(5.4722223), 'reward_variance': np.float32(2.3838093), 'max_total_reward': np.float32(8.533334), 'min_total_reward': np.float32(3.411111), 'average_n_step': np.float32(7.0), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06834262870252132), 'actor_loss': np.float64(-0.9821574330329895), 'hyper_actor_loss': np.float64(0.0050750190392136576), 'behavior_loss': np.float64(0.5032381743192673)}
step: 11550 @ episode report: {'average_total_reward': np.float32(6.2066665), 'reward_variance': np.float32(0.7875359), 'max_total_reward': np.float32(7.777778), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(7.6), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08041203022003174), 'actor_loss': np.float64(-0.9692824721336365), 'hyper_actor_loss': np.float64(0.004717170866206289), 'behavior_loss': np.float64(0.518169391155243)}
step: 11560 @ episode report: {'average_total_reward': np.float32(6.794445), 'reward_variance': np.float32(2.0156112), 'max_total_reward': np.float32(8.533334), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.2), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06249865256249905), 'actor_loss': np.float64(-0.975078570842743), 'hyper_actor_loss': np.float64(0.004083095258101821), 'behavior_loss': np.float64(0.5372512221336365)}
step: 11570 @ episode report: {'average_total_reward': np.float32(6.6699996), 'reward_variance': np.float32(2.1466432), 'max_total_reward': np.float32(9.655556), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.1), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07569340504705906), 'actor_loss': np.float64(-0.935914409160614), 'hyper_actor_loss': np.float64(0.003471935517154634), 'behavior_loss': np.float64(0.5143903464078903)}
step: 11580 @ episode report: {'average_total_reward': np.float32(7.045556), 'reward_variance': np.float32(1.333369), 'max_total_reward': np.float32(8.777778), 'min_total_reward': np.float32(5.411111), 'average_n_step': np.float32(8.5), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06530495919287205), 'actor_loss': np.float64(-0.974066025018692), 'hyper_actor_loss': np.float64(0.0030725743621587754), 'behavior_loss': np.float64(0.5376511067152023)}
step: 11590 @ episode report: {'average_total_reward': np.float32(6.8555555), 'reward_variance': np.float32(2.2438276), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.2), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0787822462618351), 'actor_loss': np.float64(-0.9608621180057526), 'hyper_actor_loss': np.float64(0.0026176614919677377), 'behavior_loss': np.float64(0.5109913945198059)}
step: 11600 @ episode report: {'average_total_reward': np.float32(6.831111), 'reward_variance': np.float32(2.3003654), 'max_total_reward': np.float32(9.777778), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.2), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08308879286050797), 'actor_loss': np.float64(-0.991884458065033), 'hyper_actor_loss': np.float64(0.002373486710712314), 'behavior_loss': np.float64(0.49270249903202057)}
step: 11610 @ episode report: {'average_total_reward': np.float32(5.6577773), 'reward_variance': np.float32(1.3194523), 'max_total_reward': np.float32(7.7777786), 'min_total_reward': np.float32(3.4111114), 'average_n_step': np.float32(7.1), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07556042298674584), 'actor_loss': np.float64(-0.9603048920631408), 'hyper_actor_loss': np.float64(0.0020169745432212947), 'behavior_loss': np.float64(0.5227739810943604)}
step: 11620 @ episode report: {'average_total_reward': np.float32(7.367778), 'reward_variance': np.float32(1.2381341), 'max_total_reward': np.float32(8.9), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(8.7), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06631384305655956), 'actor_loss': np.float64(-0.9454762995243072), 'hyper_actor_loss': np.float64(0.0018712619435973465), 'behavior_loss': np.float64(0.5200771480798722)}
step: 11630 @ episode report: {'average_total_reward': np.float32(6.618889), 'reward_variance': np.float32(1.8106434), 'max_total_reward': np.float32(8.655556), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.0), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07710200361907482), 'actor_loss': np.float64(-0.9800157487392426), 'hyper_actor_loss': np.float64(0.0016195305273868144), 'behavior_loss': np.float64(0.49522957801818845)}
step: 11640 @ episode report: {'average_total_reward': np.float32(6.7211113), 'reward_variance': np.float32(3.6859863), 'max_total_reward': np.float32(8.9), 'min_total_reward': np.float32(3.0444446), 'average_n_step': np.float32(8.2), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07012107372283935), 'actor_loss': np.float64(-0.9749989628791809), 'hyper_actor_loss': np.float64(0.001582382805645466), 'behavior_loss': np.float64(0.47986128032207487)}
step: 11650 @ episode report: {'average_total_reward': np.float32(6.555556), 'reward_variance': np.float32(1.9738277), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(3.4111114), 'average_n_step': np.float32(7.9), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07950001135468483), 'actor_loss': np.float64(-0.9519872546195984), 'hyper_actor_loss': np.float64(0.0014556384296156466), 'behavior_loss': np.float64(0.5328047662973404)}
step: 11660 @ episode report: {'average_total_reward': np.float32(6.6066675), 'reward_variance': np.float32(1.3208201), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.0), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07935386933386326), 'actor_loss': np.float64(-0.9783237934112549), 'hyper_actor_loss': np.float64(0.0013739603920839727), 'behavior_loss': np.float64(0.48951880633831024)}
step: 11670 @ episode report: {'average_total_reward': np.float32(7.3922224), 'reward_variance': np.float32(1.3877795), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(5.533333), 'average_n_step': np.float32(8.7), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07289803326129914), 'actor_loss': np.float64(-0.9704158902168274), 'hyper_actor_loss': np.float64(0.0013830898678861558), 'behavior_loss': np.float64(0.49311549961566925)}
step: 11680 @ episode report: {'average_total_reward': np.float32(7.2555556), 'reward_variance': np.float32(4.2410617), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07434338442981243), 'actor_loss': np.float64(-0.9547873497009277), 'hyper_actor_loss': np.float64(0.0013332388713024556), 'behavior_loss': np.float64(0.5039940357208252)}
step: 11690 @ episode report: {'average_total_reward': np.float32(6.406667), 'reward_variance': np.float32(1.6797335), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(7.8), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0781956173479557), 'actor_loss': np.float64(-0.9789891004562378), 'hyper_actor_loss': np.float64(0.00131335238693282), 'behavior_loss': np.float64(0.5167486280202865)}
step: 11700 @ episode report: {'average_total_reward': np.float32(6.9188895), 'reward_variance': np.float32(1.9249395), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05949007272720337), 'actor_loss': np.float64(-0.9459448218345642), 'hyper_actor_loss': np.float64(0.00127551534678787), 'behavior_loss': np.float64(0.4756277233362198)}
step: 11710 @ episode report: {'average_total_reward': np.float32(6.694444), 'reward_variance': np.float32(2.0261788), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(4.2888894), 'average_n_step': np.float32(8.1), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0826668854802847), 'actor_loss': np.float64(-0.9445331573486329), 'hyper_actor_loss': np.float64(0.0012605705647729336), 'behavior_loss': np.float64(0.5119988322257996)}
step: 11720 @ episode report: {'average_total_reward': np.float32(8.016667), 'reward_variance': np.float32(3.025488), 'max_total_reward': np.float32(10.655556), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(9.3), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06811990514397621), 'actor_loss': np.float64(-0.9773720622062683), 'hyper_actor_loss': np.float64(0.001314411184284836), 'behavior_loss': np.float64(0.49202724993228913)}
step: 11730 @ episode report: {'average_total_reward': np.float32(7.7777786), 'reward_variance': np.float32(3.6988406), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(9.0), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06878846548497677), 'actor_loss': np.float64(-0.9366823494434356), 'hyper_actor_loss': np.float64(0.001286811346653849), 'behavior_loss': np.float64(0.4784186780452728)}
step: 11740 @ episode report: {'average_total_reward': np.float32(8.02889), 'reward_variance': np.float32(2.2394624), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(9.3), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05684589445590973), 'actor_loss': np.float64(-0.9488214254379272), 'hyper_actor_loss': np.float64(0.0013293138355948031), 'behavior_loss': np.float64(0.4884566247463226)}
step: 11750 @ episode report: {'average_total_reward': np.float32(8.514444), 'reward_variance': np.float32(1.72494), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.7), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0758206531405449), 'actor_loss': np.float64(-0.969800877571106), 'hyper_actor_loss': np.float64(0.0013415216701105237), 'behavior_loss': np.float64(0.472164386510849)}
step: 11760 @ episode report: {'average_total_reward': np.float32(8.53889), 'reward_variance': np.float32(3.5522296), 'max_total_reward': np.float32(13.38889), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(9.7), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0761489950120449), 'actor_loss': np.float64(-0.9960022926330566), 'hyper_actor_loss': np.float64(0.0013646475970745086), 'behavior_loss': np.float64(0.5053245186805725)}
step: 11770 @ episode report: {'average_total_reward': np.float32(8.851112), 'reward_variance': np.float32(0.92879474), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(6.6555567), 'average_n_step': np.float32(10.0), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06991357766091824), 'actor_loss': np.float64(-0.975921493768692), 'hyper_actor_loss': np.float64(0.0013019598671235144), 'behavior_loss': np.float64(0.4590582370758057)}
step: 11780 @ episode report: {'average_total_reward': np.float32(9.375555), 'reward_variance': np.float32(2.9711554), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(10.5), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06507933400571346), 'actor_loss': np.float64(-0.9626911401748657), 'hyper_actor_loss': np.float64(0.001295994652900845), 'behavior_loss': np.float64(0.45262558460235597)}
step: 11790 @ episode report: {'average_total_reward': np.float32(10.048889), 'reward_variance': np.float32(2.2988198), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(11.1), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06467811204493046), 'actor_loss': np.float64(-0.9424524366855621), 'hyper_actor_loss': np.float64(0.0012423180742189288), 'behavior_loss': np.float64(0.5031467765569687)}
step: 11800 @ episode report: {'average_total_reward': np.float32(8.726667), 'reward_variance': np.float32(4.134845), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(9.9), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07955138273537159), 'actor_loss': np.float64(-0.9639160096645355), 'hyper_actor_loss': np.float64(0.0011751364101655782), 'behavior_loss': np.float64(0.46690425276756287)}
step: 11810 @ episode report: {'average_total_reward': np.float32(9.836667), 'reward_variance': np.float32(2.507508), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.533334), 'average_n_step': np.float32(10.9), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08719100207090377), 'actor_loss': np.float64(-0.9861452281475067), 'hyper_actor_loss': np.float64(0.0011347416206263007), 'behavior_loss': np.float64(0.46671704649925233)}
step: 11820 @ episode report: {'average_total_reward': np.float32(9.287779), 'reward_variance': np.float32(1.7957885), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.6555567), 'average_n_step': np.float32(10.4), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07377386465668678), 'actor_loss': np.float64(-0.979608166217804), 'hyper_actor_loss': np.float64(0.0011431538383476435), 'behavior_loss': np.float64(0.4226331919431686)}
step: 11830 @ episode report: {'average_total_reward': np.float32(10.834445), 'reward_variance': np.float32(5.2177153), 'max_total_reward': np.float32(14.38889), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(11.8), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07784008122980594), 'actor_loss': np.float64(-0.9734759509563446), 'hyper_actor_loss': np.float64(0.0010369633499067276), 'behavior_loss': np.float64(0.44187813699245454)}
step: 11840 @ episode report: {'average_total_reward': np.float32(8.8144455), 'reward_variance': np.float32(3.2805202), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(10.0), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07421087138354779), 'actor_loss': np.float64(-0.9800882160663604), 'hyper_actor_loss': np.float64(0.0010219974734354763), 'behavior_loss': np.float64(0.45928039848804475)}
step: 11850 @ episode report: {'average_total_reward': np.float32(9.324446), 'reward_variance': np.float32(4.9476504), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.4), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07210338935256004), 'actor_loss': np.float64(-0.9610676229000091), 'hyper_actor_loss': np.float64(0.0009715443826280534), 'behavior_loss': np.float64(0.4858975797891617)}
step: 11860 @ episode report: {'average_total_reward': np.float32(9.2), 'reward_variance': np.float32(4.2814074), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(5.6555552), 'average_n_step': np.float32(10.3), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06737371534109116), 'actor_loss': np.float64(-0.966229248046875), 'hyper_actor_loss': np.float64(0.0009594582254067064), 'behavior_loss': np.float64(0.4410252869129181)}
step: 11870 @ episode report: {'average_total_reward': np.float32(9.575556), 'reward_variance': np.float32(1.0171803), 'max_total_reward': np.float32(12.144444), 'min_total_reward': np.float32(8.655555), 'average_n_step': np.float32(10.7), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07176608629524708), 'actor_loss': np.float64(-0.9697988033294678), 'hyper_actor_loss': np.float64(0.0009233083401340991), 'behavior_loss': np.float64(0.45830214619636533)}
step: 11880 @ episode report: {'average_total_reward': np.float32(9.3), 'reward_variance': np.float32(4.144816), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(4.533333), 'average_n_step': np.float32(10.4), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07750076986849308), 'actor_loss': np.float64(-0.9659213960170746), 'hyper_actor_loss': np.float64(0.0009208771109115333), 'behavior_loss': np.float64(0.462693789601326)}
step: 11890 @ episode report: {'average_total_reward': np.float32(9.551112), 'reward_variance': np.float32(4.2272153), 'max_total_reward': np.float32(12.266668), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(10.7), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07676739618182182), 'actor_loss': np.float64(-0.9811369061470032), 'hyper_actor_loss': np.float64(0.0009674435306806118), 'behavior_loss': np.float64(0.45740693509578706)}
step: 11900 @ episode report: {'average_total_reward': np.float32(9.0633335), 'reward_variance': np.float32(1.5224707), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(10.2), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08058300092816353), 'actor_loss': np.float64(-0.9549527704715729), 'hyper_actor_loss': np.float64(0.000934855715604499), 'behavior_loss': np.float64(0.4663466662168503)}
step: 11910 @ episode report: {'average_total_reward': np.float32(9.163335), 'reward_variance': np.float32(0.79375446), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(7.655556), 'average_n_step': np.float32(10.3), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0699316594749689), 'actor_loss': np.float64(-0.9710426688194275), 'hyper_actor_loss': np.float64(0.0009606618143152446), 'behavior_loss': np.float64(0.43719284534454345)}
step: 11920 @ episode report: {'average_total_reward': np.float32(9.887778), 'reward_variance': np.float32(2.2223315), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(7.5333343), 'average_n_step': np.float32(11.0), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07805721461772919), 'actor_loss': np.float64(-0.9611770868301391), 'hyper_actor_loss': np.float64(0.0009279194637201726), 'behavior_loss': np.float64(0.47640261650085447)}
step: 11930 @ episode report: {'average_total_reward': np.float32(9.412222), 'reward_variance': np.float32(1.6955181), 'max_total_reward': np.float32(11.022223), 'min_total_reward': np.float32(6.6555552), 'average_n_step': np.float32(10.5), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07771551981568336), 'actor_loss': np.float64(-0.9733177781105041), 'hyper_actor_loss': np.float64(0.0009357932314742357), 'behavior_loss': np.float64(0.4389978736639023)}
step: 11940 @ episode report: {'average_total_reward': np.float32(8.93889), 'reward_variance': np.float32(2.241661), 'max_total_reward': np.float32(11.022223), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.1), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07795787677168846), 'actor_loss': np.float64(-0.9916748046875), 'hyper_actor_loss': np.float64(0.0009105166886001825), 'behavior_loss': np.float64(0.44071791470050814)}
step: 11950 @ episode report: {'average_total_reward': np.float32(9.175556), 'reward_variance': np.float32(2.05602), 'max_total_reward': np.float32(12.022223), 'min_total_reward': np.float32(6.6555567), 'average_n_step': np.float32(10.3), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08040275163948536), 'actor_loss': np.float64(-0.9700559258460999), 'hyper_actor_loss': np.float64(0.0009251837676856667), 'behavior_loss': np.float64(0.44845831096172334)}
step: 11960 @ episode report: {'average_total_reward': np.float32(9.912222), 'reward_variance': np.float32(1.3060857), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(8.533334), 'average_n_step': np.float32(11.0), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07106703147292137), 'actor_loss': np.float64(-0.9590105235576629), 'hyper_actor_loss': np.float64(0.000887254811823368), 'behavior_loss': np.float64(0.4267211467027664)}
step: 11970 @ episode report: {'average_total_reward': np.float32(9.6), 'reward_variance': np.float32(1.979111), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.777778), 'average_n_step': np.float32(10.7), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07979251109063626), 'actor_loss': np.float64(-0.9895186960697174), 'hyper_actor_loss': np.float64(0.0008991717360913754), 'behavior_loss': np.float64(0.4211737155914307)}
step: 11980 @ episode report: {'average_total_reward': np.float32(9.026668), 'reward_variance': np.float32(0.73306656), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(7.655556), 'average_n_step': np.float32(10.2), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06787629425525665), 'actor_loss': np.float64(-0.9596514105796814), 'hyper_actor_loss': np.float64(0.0009238440426997841), 'behavior_loss': np.float64(0.46770249903202055)}
step: 11990 @ episode report: {'average_total_reward': np.float32(9.736667), 'reward_variance': np.float32(1.2127417), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(10.8), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08084594346582889), 'actor_loss': np.float64(-0.9532231032848358), 'hyper_actor_loss': np.float64(0.0009293221053667366), 'behavior_loss': np.float64(0.47013868391513824)}
step: 12000 @ episode report: {'average_total_reward': np.float32(9.94889), 'reward_variance': np.float32(2.4430423), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(7.777778), 'average_n_step': np.float32(11.0), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0769672341644764), 'actor_loss': np.float64(-0.9785420417785644), 'hyper_actor_loss': np.float64(0.0009670153085608035), 'behavior_loss': np.float64(0.4320910155773163)}
step: 12010 @ episode report: {'average_total_reward': np.float32(8.32889), 'reward_variance': np.float32(1.9676106), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(9.6), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07152406647801399), 'actor_loss': np.float64(-0.9590108096599579), 'hyper_actor_loss': np.float64(0.0009649809449911118), 'behavior_loss': np.float64(0.465145006775856)}
step: 12020 @ episode report: {'average_total_reward': np.float32(9.875556), 'reward_variance': np.float32(1.6597732), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(7.5333333), 'average_n_step': np.float32(11.0), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08000542744994163), 'actor_loss': np.float64(-0.9722882747650147), 'hyper_actor_loss': np.float64(0.0010366174450609834), 'behavior_loss': np.float64(0.41467538475990295)}
step: 12030 @ episode report: {'average_total_reward': np.float32(9.151113), 'reward_variance': np.float32(1.4259809), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(10.3), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07873547151684761), 'actor_loss': np.float64(-1.0047143816947937), 'hyper_actor_loss': np.float64(0.0010955419624224306), 'behavior_loss': np.float64(0.45278393626213076)}
step: 12040 @ episode report: {'average_total_reward': np.float32(10.285557), 'reward_variance': np.float32(3.3479276), 'max_total_reward': np.float32(14.38889), 'min_total_reward': np.float32(7.777778), 'average_n_step': np.float32(11.3), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0825042262673378), 'actor_loss': np.float64(-0.9753137111663819), 'hyper_actor_loss': np.float64(0.0011444360483437777), 'behavior_loss': np.float64(0.41782946288585665)}
step: 12050 @ episode report: {'average_total_reward': np.float32(9.0633335), 'reward_variance': np.float32(4.635261), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.2), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06851850189268589), 'actor_loss': np.float64(-0.9649475455284119), 'hyper_actor_loss': np.float64(0.0012242768425494432), 'behavior_loss': np.float64(0.47012740969657896)}
step: 12060 @ episode report: {'average_total_reward': np.float32(8.926668), 'reward_variance': np.float32(1.0883262), 'max_total_reward': np.float32(11.022223), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(10.1), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06610607374459505), 'actor_loss': np.float64(-0.9427393734455108), 'hyper_actor_loss': np.float64(0.001273566880263388), 'behavior_loss': np.float64(0.43946529626846315)}
step: 12070 @ episode report: {'average_total_reward': np.float32(8.851111), 'reward_variance': np.float32(1.5697091), 'max_total_reward': np.float32(11.144446), 'min_total_reward': np.float32(6.533334), 'average_n_step': np.float32(10.0), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07883746922016144), 'actor_loss': np.float64(-0.9715876579284668), 'hyper_actor_loss': np.float64(0.0012336605810560285), 'behavior_loss': np.float64(0.41833398342132566)}
step: 12080 @ episode report: {'average_total_reward': np.float32(8.663335), 'reward_variance': np.float32(2.5545204), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.8), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06905231140553951), 'actor_loss': np.float64(-0.9815034210681916), 'hyper_actor_loss': np.float64(0.001245754596311599), 'behavior_loss': np.float64(0.419167622923851)}
step: 12090 @ episode report: {'average_total_reward': np.float32(9.412224), 'reward_variance': np.float32(2.2237153), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(6.655556), 'average_n_step': np.float32(10.5), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07667637914419174), 'actor_loss': np.float64(-0.963588273525238), 'hyper_actor_loss': np.float64(0.0011380791547708213), 'behavior_loss': np.float64(0.43824350237846377)}
step: 12100 @ episode report: {'average_total_reward': np.float32(9.73889), 'reward_variance': np.float32(0.9363766), 'max_total_reward': np.float32(10.900001), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(10.9), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07814977951347828), 'actor_loss': np.float64(-0.9921493351459503), 'hyper_actor_loss': np.float64(0.0010042994399555027), 'behavior_loss': np.float64(0.4314005583524704)}
step: 12110 @ episode report: {'average_total_reward': np.float32(9.773334), 'reward_variance': np.float32(1.4248699), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(7.777778), 'average_n_step': np.float32(10.8), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07893821485340595), 'actor_loss': np.float64(-0.9723616898059845), 'hyper_actor_loss': np.float64(0.001023438252741471), 'behavior_loss': np.float64(0.4144546568393707)}
step: 12120 @ episode report: {'average_total_reward': np.float32(9.512223), 'reward_variance': np.float32(1.313493), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.6), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08155306205153465), 'actor_loss': np.float64(-0.9687422931194305), 'hyper_actor_loss': np.float64(0.0010010592464823275), 'behavior_loss': np.float64(0.43940130770206454)}
step: 12130 @ episode report: {'average_total_reward': np.float32(9.512222), 'reward_variance': np.float32(3.5883572), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(10.6), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07885076850652695), 'actor_loss': np.float64(-0.9693006634712219), 'hyper_actor_loss': np.float64(0.000929465756053105), 'behavior_loss': np.float64(0.4330348640680313)}
step: 12140 @ episode report: {'average_total_reward': np.float32(9.300001), 'reward_variance': np.float32(1.0534817), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(10.4), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07947642803192138), 'actor_loss': np.float64(-0.9664342701435089), 'hyper_actor_loss': np.float64(0.000977713620522991), 'behavior_loss': np.float64(0.41756289899349214)}
step: 12150 @ episode report: {'average_total_reward': np.float32(9.624445), 'reward_variance': np.float32(3.2665143), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.7), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0815452490001917), 'actor_loss': np.float64(-0.9841783761978149), 'hyper_actor_loss': np.float64(0.0009890660701785236), 'behavior_loss': np.float64(0.42171856462955476)}
step: 12160 @ episode report: {'average_total_reward': np.float32(9.475555), 'reward_variance': np.float32(1.2029089), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(10.6), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07506694048643112), 'actor_loss': np.float64(-0.9743637323379517), 'hyper_actor_loss': np.float64(0.0010840653092600405), 'behavior_loss': np.float64(0.4112954825162888)}
step: 12170 @ episode report: {'average_total_reward': np.float32(8.665556), 'reward_variance': np.float32(2.13732), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(6.4111114), 'average_n_step': np.float32(9.9), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07763678468763828), 'actor_loss': np.float64(-0.9732909560203552), 'hyper_actor_loss': np.float64(0.0012082629022188486), 'behavior_loss': np.float64(0.3979425966739655)}
step: 12180 @ episode report: {'average_total_reward': np.float32(9.3144455), 'reward_variance': np.float32(2.3197548), 'max_total_reward': np.float32(11.900001), 'min_total_reward': np.float32(7.533334), 'average_n_step': np.float32(10.5), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08327382579445838), 'actor_loss': np.float64(-0.9994702458381652), 'hyper_actor_loss': np.float64(0.0014221272547729313), 'behavior_loss': np.float64(0.4240929037332535)}
step: 12190 @ episode report: {'average_total_reward': np.float32(9.275557), 'reward_variance': np.float32(2.5348098), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.4), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07267130427062511), 'actor_loss': np.float64(-0.975242680311203), 'hyper_actor_loss': np.float64(0.001777531870175153), 'behavior_loss': np.float64(0.41456915736198424)}
step: 12200 @ episode report: {'average_total_reward': np.float32(8.751112), 'reward_variance': np.float32(6.3837085), 'max_total_reward': np.float32(14.511112), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(9.9), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07876215726137162), 'actor_loss': np.float64(-0.9641285836696625), 'hyper_actor_loss': np.float64(0.002038756129331887), 'behavior_loss': np.float64(0.4167431354522705)}
step: 12210 @ episode report: {'average_total_reward': np.float32(10.385556), 'reward_variance': np.float32(2.8246422), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(11.4), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07531556785106659), 'actor_loss': np.float64(-0.984039968252182), 'hyper_actor_loss': np.float64(0.00227708350867033), 'behavior_loss': np.float64(0.4371305763721466)}
step: 12220 @ episode report: {'average_total_reward': np.float32(9.587778), 'reward_variance': np.float32(2.4768746), 'max_total_reward': np.float32(12.022222), 'min_total_reward': np.float32(7.5333343), 'average_n_step': np.float32(10.7), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07810352928936481), 'actor_loss': np.float64(-0.9644069790840148), 'hyper_actor_loss': np.float64(0.002247172431088984), 'behavior_loss': np.float64(0.4165013074874878)}
step: 12230 @ episode report: {'average_total_reward': np.float32(9.961111), 'reward_variance': np.float32(1.1838088), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(7.777778), 'average_n_step': np.float32(11.0), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0698122251778841), 'actor_loss': np.float64(-0.9637050747871398), 'hyper_actor_loss': np.float64(0.0022306717932224275), 'behavior_loss': np.float64(0.42345923483371734)}
step: 12240 @ episode report: {'average_total_reward': np.float32(9.636667), 'reward_variance': np.float32(1.7463964), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.7), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06776063442230225), 'actor_loss': np.float64(-0.972639137506485), 'hyper_actor_loss': np.float64(0.0021083161467686296), 'behavior_loss': np.float64(0.4024422228336334)}
step: 12250 @ episode report: {'average_total_reward': np.float32(10.434445), 'reward_variance': np.float32(1.9672699), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(8.900001), 'average_n_step': np.float32(11.4), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07080438770353795), 'actor_loss': np.float64(-0.9885830461978913), 'hyper_actor_loss': np.float64(0.0020626543555408716), 'behavior_loss': np.float64(0.42164296805858614)}
step: 12260 @ episode report: {'average_total_reward': np.float32(10.04889), 'reward_variance': np.float32(2.8604245), 'max_total_reward': np.float32(14.388889), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(11.1), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08024144731462002), 'actor_loss': np.float64(-0.9923559308052063), 'hyper_actor_loss': np.float64(0.0021375830518081786), 'behavior_loss': np.float64(0.3969075560569763)}
step: 12270 @ episode report: {'average_total_reward': np.float32(10.348889), 'reward_variance': np.float32(2.4479067), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(11.4), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07747112661600113), 'actor_loss': np.float64(-0.9887362599372864), 'hyper_actor_loss': np.float64(0.0021693914430215957), 'behavior_loss': np.float64(0.4246574968099594)}
step: 12280 @ episode report: {'average_total_reward': np.float32(8.963333), 'reward_variance': np.float32(3.520001), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(10.1), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06724564470350743), 'actor_loss': np.float64(-0.9622041940689087), 'hyper_actor_loss': np.float64(0.002222455944865942), 'behavior_loss': np.float64(0.40867567956447604)}
step: 12290 @ episode report: {'average_total_reward': np.float32(9.287778), 'reward_variance': np.float32(2.3868256), 'max_total_reward': np.float32(12.0222225), 'min_total_reward': np.float32(6.6555567), 'average_n_step': np.float32(10.4), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07680038884282112), 'actor_loss': np.float64(-0.9916251420974731), 'hyper_actor_loss': np.float64(0.0022356062196195125), 'behavior_loss': np.float64(0.36990993320941923)}
step: 12300 @ episode report: {'average_total_reward': np.float32(11.1466675), 'reward_variance': np.float32(1.2411307), 'max_total_reward': np.float32(13.388888), 'min_total_reward': np.float32(9.655556), 'average_n_step': np.float32(12.1), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(11.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06261160597205162), 'actor_loss': np.float64(-0.9630827844142914), 'hyper_actor_loss': np.float64(0.0019719849457032978), 'behavior_loss': np.float64(0.41867789030075075)}
step: 12310 @ episode report: {'average_total_reward': np.float32(10.31), 'reward_variance': np.float32(2.0641103), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(11.3), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06197512820363045), 'actor_loss': np.float64(-0.9217579126358032), 'hyper_actor_loss': np.float64(0.0015863887965679169), 'behavior_loss': np.float64(0.39719509780406953)}
step: 12320 @ episode report: {'average_total_reward': np.float32(10.995557), 'reward_variance': np.float32(4.8694615), 'max_total_reward': np.float32(15.633333), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(11.9), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07688903212547302), 'actor_loss': np.float64(-0.9827389478683471), 'hyper_actor_loss': np.float64(0.0016214025788940489), 'behavior_loss': np.float64(0.3968586653470993)}
step: 12330 @ episode report: {'average_total_reward': np.float32(10.210001), 'reward_variance': np.float32(4.9518886), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(11.2), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07890389151871205), 'actor_loss': np.float64(-0.9600759327411652), 'hyper_actor_loss': np.float64(0.0015274027013219894), 'behavior_loss': np.float64(0.39382455348968504)}
step: 12340 @ episode report: {'average_total_reward': np.float32(8.802222), 'reward_variance': np.float32(4.4952555), 'max_total_reward': np.float32(14.266667), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.0), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07679296135902405), 'actor_loss': np.float64(-0.9800333678722382), 'hyper_actor_loss': np.float64(0.0014328919001854955), 'behavior_loss': np.float64(0.4212962418794632)}
step: 12350 @ episode report: {'average_total_reward': np.float32(10.173334), 'reward_variance': np.float32(2.4804502), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(11.2), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06905375979840755), 'actor_loss': np.float64(-0.9658807873725891), 'hyper_actor_loss': np.float64(0.001419186347629875), 'behavior_loss': np.float64(0.3956896126270294)}
step: 12360 @ episode report: {'average_total_reward': np.float32(10.758889), 'reward_variance': np.float32(4.460176), 'max_total_reward': np.float32(14.511112), 'min_total_reward': np.float32(8.655555), 'average_n_step': np.float32(11.7), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.060227082669734956), 'actor_loss': np.float64(-0.9530023276805878), 'hyper_actor_loss': np.float64(0.0015146271442063152), 'behavior_loss': np.float64(0.37320027947425843)}
step: 12370 @ episode report: {'average_total_reward': np.float32(10.01), 'reward_variance': np.float32(3.645321), 'max_total_reward': np.float32(13.38889), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(11.0), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07999634929001331), 'actor_loss': np.float64(-0.9871816098690033), 'hyper_actor_loss': np.float64(0.0016304322169162333), 'behavior_loss': np.float64(0.40321671664714814)}
step: 12380 @ episode report: {'average_total_reward': np.float32(10.285556), 'reward_variance': np.float32(2.6696064), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(7.6555552), 'average_n_step': np.float32(11.3), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06709385327994824), 'actor_loss': np.float64(-0.9710994243621827), 'hyper_actor_loss': np.float64(0.0016848016413860023), 'behavior_loss': np.float64(0.39158024191856383)}
step: 12390 @ episode report: {'average_total_reward': np.float32(10.634445), 'reward_variance': np.float32(3.72253), 'max_total_reward': np.float32(13.266668), 'min_total_reward': np.float32(7.6555567), 'average_n_step': np.float32(11.6), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.09249870479106903), 'actor_loss': np.float64(-0.9798413932323455), 'hyper_actor_loss': np.float64(0.0019409155240282417), 'behavior_loss': np.float64(0.39328652918338775)}
step: 12400 @ episode report: {'average_total_reward': np.float32(10.261111), 'reward_variance': np.float32(1.7736107), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(8.533334), 'average_n_step': np.float32(11.3), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.061618483066558837), 'actor_loss': np.float64(-0.994584983587265), 'hyper_actor_loss': np.float64(0.0020407634321600197), 'behavior_loss': np.float64(0.3352804481983185)}
step: 12410 @ episode report: {'average_total_reward': np.float32(10.771112), 'reward_variance': np.float32(3.8544736), 'max_total_reward': np.float32(14.511111), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(11.7), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07761050630360841), 'actor_loss': np.float64(-0.9556316673755646), 'hyper_actor_loss': np.float64(0.0019628486479632556), 'behavior_loss': np.float64(0.39733709394931793)}
step: 12420 @ episode report: {'average_total_reward': np.float32(10.871112), 'reward_variance': np.float32(1.7492641), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.6555567), 'average_n_step': np.float32(11.8), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08054916895925998), 'actor_loss': np.float64(-0.9836196959018707), 'hyper_actor_loss': np.float64(0.001839210547041148), 'behavior_loss': np.float64(0.36263965666294096)}
step: 12430 @ episode report: {'average_total_reward': np.float32(11.432223), 'reward_variance': np.float32(5.448233), 'max_total_reward': np.float32(15.633334), 'min_total_reward': np.float32(7.6555567), 'average_n_step': np.float32(12.3), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07229368686676026), 'actor_loss': np.float64(-0.9928295910358429), 'hyper_actor_loss': np.float64(0.0017030902090482414), 'behavior_loss': np.float64(0.37862181663513184)}
step: 12440 @ episode report: {'average_total_reward': np.float32(11.66889), 'reward_variance': np.float32(3.9726872), 'max_total_reward': np.float32(15.511112), 'min_total_reward': np.float32(8.900001), 'average_n_step': np.float32(12.5), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07589561305940151), 'actor_loss': np.float64(-0.9651904225349426), 'hyper_actor_loss': np.float64(0.0016116579528898001), 'behavior_loss': np.float64(0.40177385210990907)}
step: 12450 @ episode report: {'average_total_reward': np.float32(10.85889), 'reward_variance': np.float32(3.9295082), 'max_total_reward': np.float32(14.511112), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(11.8), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0736784391105175), 'actor_loss': np.float64(-1.0021569371223449), 'hyper_actor_loss': np.float64(0.0016183321247808635), 'behavior_loss': np.float64(0.35372146368026736)}
step: 12460 @ episode report: {'average_total_reward': np.float32(11.432223), 'reward_variance': np.float32(5.845246), 'max_total_reward': np.float32(15.633334), 'min_total_reward': np.float32(6.655556), 'average_n_step': np.float32(12.3), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07911421619355678), 'actor_loss': np.float64(-0.984975266456604), 'hyper_actor_loss': np.float64(0.0014609970967285335), 'behavior_loss': np.float64(0.3661098301410675)}
step: 12470 @ episode report: {'average_total_reward': np.float32(9.861112), 'reward_variance': np.float32(1.9788212), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.655556), 'average_n_step': np.float32(10.9), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07670213766396046), 'actor_loss': np.float64(-0.9820279121398926), 'hyper_actor_loss': np.float64(0.001388111722189933), 'behavior_loss': np.float64(0.35728880763053894)}
step: 12480 @ episode report: {'average_total_reward': np.float32(10.285556), 'reward_variance': np.float32(2.056125), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(11.3), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0706606436520815), 'actor_loss': np.float64(-0.9893537580966949), 'hyper_actor_loss': np.float64(0.0012405134621076286), 'behavior_loss': np.float64(0.36424470543861387)}
step: 12490 @ episode report: {'average_total_reward': np.float32(11.532224), 'reward_variance': np.float32(2.6032956), 'max_total_reward': np.float32(14.511112), 'min_total_reward': np.float32(8.900001), 'average_n_step': np.float32(12.4), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07451283596456051), 'actor_loss': np.float64(-0.9671799719333649), 'hyper_actor_loss': np.float64(0.0012986418907530606), 'behavior_loss': np.float64(0.366587883234024)}
step: 12500 @ episode report: {'average_total_reward': np.float32(10.610001), 'reward_variance': np.float32(3.4755433), 'max_total_reward': np.float32(14.38889), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(11.6), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07375752031803132), 'actor_loss': np.float64(-0.9937994539737701), 'hyper_actor_loss': np.float64(0.0014417144819162786), 'behavior_loss': np.float64(0.36439178287982943)}
step: 12510 @ episode report: {'average_total_reward': np.float32(11.120001), 'reward_variance': np.float32(1.4862179), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(8.900001), 'average_n_step': np.float32(12.0), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07639221511781216), 'actor_loss': np.float64(-1.005272912979126), 'hyper_actor_loss': np.float64(0.0014265638776123524), 'behavior_loss': np.float64(0.3573922663927078)}
step: 12520 @ episode report: {'average_total_reward': np.float32(10.334445), 'reward_variance': np.float32(4.742778), 'max_total_reward': np.float32(13.266668), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(11.3), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06481790393590928), 'actor_loss': np.float64(-0.9648144781589508), 'hyper_actor_loss': np.float64(0.001443387067411095), 'behavior_loss': np.float64(0.35251704454421995)}
step: 12530 @ episode report: {'average_total_reward': np.float32(11.644445), 'reward_variance': np.float32(7.329975), 'max_total_reward': np.float32(15.511112), 'min_total_reward': np.float32(6.533334), 'average_n_step': np.float32(12.5), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.083558614179492), 'actor_loss': np.float64(-0.9951387643814087), 'hyper_actor_loss': np.float64(0.0015607329667545855), 'behavior_loss': np.float64(0.38496565222740176)}
step: 12540 @ episode report: {'average_total_reward': np.float32(10.124445), 'reward_variance': np.float32(5.861478), 'max_total_reward': np.float32(15.511112), 'min_total_reward': np.float32(6.411112), 'average_n_step': np.float32(11.2), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08372295275330544), 'actor_loss': np.float64(-0.9852904379367828), 'hyper_actor_loss': np.float64(0.0015148734441027046), 'behavior_loss': np.float64(0.37546891570091245)}
step: 12550 @ episode report: {'average_total_reward': np.float32(10.971112), 'reward_variance': np.float32(1.9243513), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(8.777778), 'average_n_step': np.float32(11.9), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07932790741324425), 'actor_loss': np.float64(-0.988852572441101), 'hyper_actor_loss': np.float64(0.0014084493974223732), 'behavior_loss': np.float64(0.3647761672735214)}
step: 12560 @ episode report: {'average_total_reward': np.float32(11.007779), 'reward_variance': np.float32(6.54931), 'max_total_reward': np.float32(14.388889), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(11.9), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07786641158163547), 'actor_loss': np.float64(-0.993162888288498), 'hyper_actor_loss': np.float64(0.0013175522908568382), 'behavior_loss': np.float64(0.3868531554937363)}
step: 12570 @ episode report: {'average_total_reward': np.float32(11.2711115), 'reward_variance': np.float32(3.5909927), 'max_total_reward': np.float32(14.511111), 'min_total_reward': np.float32(7.777778), 'average_n_step': np.float32(12.2), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07280798628926277), 'actor_loss': np.float64(-0.9456065595149994), 'hyper_actor_loss': np.float64(0.0010998957324773074), 'behavior_loss': np.float64(0.4031727880239487)}
step: 12580 @ episode report: {'average_total_reward': np.float32(10.995557), 'reward_variance': np.float32(0.8913143), 'max_total_reward': np.float32(13.38889), 'min_total_reward': np.float32(9.9), 'average_n_step': np.float32(11.9), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(11.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07845389991998672), 'actor_loss': np.float64(-0.984127938747406), 'hyper_actor_loss': np.float64(0.0010307946242392064), 'behavior_loss': np.float64(0.365837037563324)}
step: 12590 @ episode report: {'average_total_reward': np.float32(10.997779), 'reward_variance': np.float32(3.734637), 'max_total_reward': np.float32(14.388889), 'min_total_reward': np.float32(8.655556), 'average_n_step': np.float32(12.0), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07281942442059516), 'actor_loss': np.float64(-0.9984494686126709), 'hyper_actor_loss': np.float64(0.0010063889785669744), 'behavior_loss': np.float64(0.35076929032802584)}
step: 12600 @ episode report: {'average_total_reward': np.float32(10.197779), 'reward_variance': np.float32(4.325872), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(11.2), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07515089437365532), 'actor_loss': np.float64(-0.9654918432235717), 'hyper_actor_loss': np.float64(0.0009786059032194316), 'behavior_loss': np.float64(0.3888481199741364)}
step: 12610 @ episode report: {'average_total_reward': np.float32(10.995557), 'reward_variance': np.float32(3.3856342), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(11.9), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07387151457369327), 'actor_loss': np.float64(-0.9711686968803406), 'hyper_actor_loss': np.float64(0.0011851254967041314), 'behavior_loss': np.float64(0.3673625886440277)}
step: 12620 @ episode report: {'average_total_reward': np.float32(10.45889), 'reward_variance': np.float32(2.0777042), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(8.900001), 'average_n_step': np.float32(11.4), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06794992536306381), 'actor_loss': np.float64(-0.9922299683094025), 'hyper_actor_loss': np.float64(0.0014602491399273276), 'behavior_loss': np.float64(0.37517629861831664)}
step: 12630 @ episode report: {'average_total_reward': np.float32(11.407778), 'reward_variance': np.float32(4.3230143), 'max_total_reward': np.float32(14.511112), 'min_total_reward': np.float32(8.655556), 'average_n_step': np.float32(12.3), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06641994789242744), 'actor_loss': np.float64(-0.9663949966430664), 'hyper_actor_loss': np.float64(0.0014573344960808754), 'behavior_loss': np.float64(0.36860481798648836)}
step: 12640 @ episode report: {'average_total_reward': np.float32(9.773334), 'reward_variance': np.float32(5.348153), 'max_total_reward': np.float32(12.266666), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.8), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07245322987437249), 'actor_loss': np.float64(-0.9856453120708466), 'hyper_actor_loss': np.float64(0.001506377023179084), 'behavior_loss': np.float64(0.37353948652744295)}
step: 12650 @ episode report: {'average_total_reward': np.float32(10.273334), 'reward_variance': np.float32(1.9297333), 'max_total_reward': np.float32(12.266666), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(11.3), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06220309510827064), 'actor_loss': np.float64(-0.9887715816497803), 'hyper_actor_loss': np.float64(0.0014631657511927187), 'behavior_loss': np.float64(0.37676323354244234)}
step: 12660 @ episode report: {'average_total_reward': np.float32(10.061111), 'reward_variance': np.float32(1.3408947), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(11.1), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07549624033272266), 'actor_loss': np.float64(-0.9736566841602325), 'hyper_actor_loss': np.float64(0.0015860217506997287), 'behavior_loss': np.float64(0.3715848386287689)}
step: 12670 @ episode report: {'average_total_reward': np.float32(9.624445), 'reward_variance': np.float32(1.8784645), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.533334), 'average_n_step': np.float32(10.7), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06904065646231175), 'actor_loss': np.float64(-1.0039330184459687), 'hyper_actor_loss': np.float64(0.0015119041316211223), 'behavior_loss': np.float64(0.38182693123817446)}
step: 12680 @ episode report: {'average_total_reward': np.float32(9.43889), 'reward_variance': np.float32(1.2936113), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(10.6), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07723678350448608), 'actor_loss': np.float64(-0.9801883161067962), 'hyper_actor_loss': np.float64(0.0015135946800000966), 'behavior_loss': np.float64(0.3892816573381424)}
step: 12690 @ episode report: {'average_total_reward': np.float32(8.963334), 'reward_variance': np.float32(1.9214576), 'max_total_reward': np.float32(12.266666), 'min_total_reward': np.float32(7.533334), 'average_n_step': np.float32(10.1), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08494985476136208), 'actor_loss': np.float64(-0.9884576678276062), 'hyper_actor_loss': np.float64(0.0015048947650939226), 'behavior_loss': np.float64(0.39642880856990814)}
step: 12700 @ episode report: {'average_total_reward': np.float32(10.024446), 'reward_variance': np.float32(1.1373781), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(8.533334), 'average_n_step': np.float32(11.1), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07772081047296524), 'actor_loss': np.float64(-1.006828600168228), 'hyper_actor_loss': np.float64(0.001500546233728528), 'behavior_loss': np.float64(0.40094674825668336)}
step: 12710 @ episode report: {'average_total_reward': np.float32(8.951112), 'reward_variance': np.float32(2.0176091), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(5.655556), 'average_n_step': np.float32(10.1), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07750485576689244), 'actor_loss': np.float64(-0.9759905397891998), 'hyper_actor_loss': np.float64(0.001552452880423516), 'behavior_loss': np.float64(0.38871017694473264)}
step: 12720 @ episode report: {'average_total_reward': np.float32(8.938889), 'reward_variance': np.float32(3.3254876), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.1), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07371986545622349), 'actor_loss': np.float64(-1.006557047367096), 'hyper_actor_loss': np.float64(0.0016905351192690432), 'behavior_loss': np.float64(0.36765762269496916)}
step: 12730 @ episode report: {'average_total_reward': np.float32(7.492223), 'reward_variance': np.float32(1.3698283), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(8.8), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06433177031576634), 'actor_loss': np.float64(-0.9765113294124603), 'hyper_actor_loss': np.float64(0.0014138494967482983), 'behavior_loss': np.float64(0.3717176020145416)}
step: 12740 @ episode report: {'average_total_reward': np.float32(7.331111), 'reward_variance': np.float32(0.7837727), 'max_total_reward': np.float32(8.9), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(8.7), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0790579542517662), 'actor_loss': np.float64(-0.9761733770370483), 'hyper_actor_loss': np.float64(0.0013153569772839547), 'behavior_loss': np.float64(0.4007457882165909)}
step: 12750 @ episode report: {'average_total_reward': np.float32(7.504445), 'reward_variance': np.float32(1.3387707), 'max_total_reward': np.float32(8.900002), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(8.8), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06710282266139984), 'actor_loss': np.float64(-0.9802886128425599), 'hyper_actor_loss': np.float64(0.0011586632463149726), 'behavior_loss': np.float64(0.40614074766635894)}
step: 12760 @ episode report: {'average_total_reward': np.float32(7.455556), 'reward_variance': np.float32(1.5764692), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(8.8), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07721818499267101), 'actor_loss': np.float64(-0.9619163393974304), 'hyper_actor_loss': np.float64(0.0010478323034476488), 'behavior_loss': np.float64(0.3768793195486069)}
step: 12770 @ episode report: {'average_total_reward': np.float32(7.716667), 'reward_variance': np.float32(1.3104757), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.0), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06518284715712071), 'actor_loss': np.float64(-0.9966401875019073), 'hyper_actor_loss': np.float64(0.0009886361251119525), 'behavior_loss': np.float64(0.38591532707214354)}
step: 12780 @ episode report: {'average_total_reward': np.float32(7.492223), 'reward_variance': np.float32(1.7882979), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(5.6555552), 'average_n_step': np.float32(8.8), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06275578364729881), 'actor_loss': np.float64(-0.9702133297920227), 'hyper_actor_loss': np.float64(0.00096533143077977), 'behavior_loss': np.float64(0.3881897807121277)}
step: 12790 @ episode report: {'average_total_reward': np.float32(7.0800004), 'reward_variance': np.float32(1.7036743), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07864417433738709), 'actor_loss': np.float64(-0.9512239694595337), 'hyper_actor_loss': np.float64(0.0010538673086557537), 'behavior_loss': np.float64(0.40171518325805666)}
step: 12800 @ episode report: {'average_total_reward': np.float32(8.714445), 'reward_variance': np.float32(2.005755), 'max_total_reward': np.float32(11.0222225), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(9.9), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07726628556847573), 'actor_loss': np.float64(-1.0071875214576722), 'hyper_actor_loss': np.float64(0.001401460380293429), 'behavior_loss': np.float64(0.38117348253726957)}
step: 12810 @ episode report: {'average_total_reward': np.float32(9.412222), 'reward_variance': np.float32(1.3533694), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(10.5), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.079436020180583), 'actor_loss': np.float64(-0.9769271850585938), 'hyper_actor_loss': np.float64(0.001214641029946506), 'behavior_loss': np.float64(0.3729088634252548)}
step: 12820 @ episode report: {'average_total_reward': np.float32(10.697779), 'reward_variance': np.float32(3.9219952), 'max_total_reward': np.float32(14.388889), 'min_total_reward': np.float32(7.4111114), 'average_n_step': np.float32(11.7), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06808396615087986), 'actor_loss': np.float64(-0.9688004672527313), 'hyper_actor_loss': np.float64(0.0009704350493848323), 'behavior_loss': np.float64(0.40109494626522063)}
step: 12830 @ episode report: {'average_total_reward': np.float32(10.14889), 'reward_variance': np.float32(3.8348947), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(11.2), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0664810635149479), 'actor_loss': np.float64(-0.9447567880153656), 'hyper_actor_loss': np.float64(0.0008858421177137643), 'behavior_loss': np.float64(0.40286171734333037)}
step: 12840 @ episode report: {'average_total_reward': np.float32(9.387779), 'reward_variance': np.float32(2.4217153), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.5), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08209848403930664), 'actor_loss': np.float64(-0.9820270001888275), 'hyper_actor_loss': np.float64(0.0008378717524465173), 'behavior_loss': np.float64(0.4077057898044586)}
step: 12850 @ episode report: {'average_total_reward': np.float32(9.936668), 'reward_variance': np.float32(6.669632), 'max_total_reward': np.float32(13.266668), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(11.0), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06496947798877954), 'actor_loss': np.float64(-0.9863481104373932), 'hyper_actor_loss': np.float64(0.0008493763220030814), 'behavior_loss': np.float64(0.3675653636455536)}
step: 12860 @ episode report: {'average_total_reward': np.float32(9.873334), 'reward_variance': np.float32(4.225561), 'max_total_reward': np.float32(14.38889), 'min_total_reward': np.float32(7.777778), 'average_n_step': np.float32(10.9), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06446085628122092), 'actor_loss': np.float64(-0.9479974806308746), 'hyper_actor_loss': np.float64(0.000891471205977723), 'behavior_loss': np.float64(0.39400040209293363)}
step: 12870 @ episode report: {'average_total_reward': np.float32(9.948889), 'reward_variance': np.float32(3.6974368), 'max_total_reward': np.float32(12.266666), 'min_total_reward': np.float32(7.533334), 'average_n_step': np.float32(11.0), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08066929541528226), 'actor_loss': np.float64(-0.9721209049224854), 'hyper_actor_loss': np.float64(0.0009615013841539621), 'behavior_loss': np.float64(0.35675286054611205)}
step: 12880 @ episode report: {'average_total_reward': np.float32(10.173334), 'reward_variance': np.float32(1.7796848), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(8.655555), 'average_n_step': np.float32(11.2), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06867711953818798), 'actor_loss': np.float64(-0.9825145900249481), 'hyper_actor_loss': np.float64(0.0009853399475105106), 'behavior_loss': np.float64(0.3793663293123245)}
step: 12890 @ episode report: {'average_total_reward': np.float32(9.836667), 'reward_variance': np.float32(0.7583218), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(8.777779), 'average_n_step': np.float32(10.9), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07218780033290387), 'actor_loss': np.float64(-0.9731564283370971), 'hyper_actor_loss': np.float64(0.0008627836068626493), 'behavior_loss': np.float64(0.3512998431921005)}
step: 12900 @ episode report: {'average_total_reward': np.float32(9.6), 'reward_variance': np.float32(1.8968147), 'max_total_reward': np.float32(13.144444), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(10.7), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06370402500033379), 'actor_loss': np.float64(-0.976197499036789), 'hyper_actor_loss': np.float64(0.0007985703705344349), 'behavior_loss': np.float64(0.3674515515565872)}
step: 12910 @ episode report: {'average_total_reward': np.float32(10.546667), 'reward_variance': np.float32(1.1421926), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(7.6555567), 'average_n_step': np.float32(11.5), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.069279008731246), 'actor_loss': np.float64(-0.9561162471771241), 'hyper_actor_loss': np.float64(0.0007357905618846416), 'behavior_loss': np.float64(0.3748217523097992)}
step: 12920 @ episode report: {'average_total_reward': np.float32(10.185556), 'reward_variance': np.float32(2.644693), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(6.6555552), 'average_n_step': np.float32(11.2), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07869313172996044), 'actor_loss': np.float64(-0.9817487359046936), 'hyper_actor_loss': np.float64(0.000788908766116947), 'behavior_loss': np.float64(0.37197692394256593)}
step: 12930 @ episode report: {'average_total_reward': np.float32(10.024446), 'reward_variance': np.float32(3.9374528), 'max_total_reward': np.float32(13.266668), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(11.1), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08119766637682915), 'actor_loss': np.float64(-0.9930157780647277), 'hyper_actor_loss': np.float64(0.0007842163147870451), 'behavior_loss': np.float64(0.38609660863876344)}
step: 12940 @ episode report: {'average_total_reward': np.float32(9.985556), 'reward_variance': np.float32(5.2760763), 'max_total_reward': np.float32(13.38889), 'min_total_reward': np.float32(5.6555552), 'average_n_step': np.float32(11.0), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07567143514752388), 'actor_loss': np.float64(-0.9789493381977081), 'hyper_actor_loss': np.float64(0.0007423747447319329), 'behavior_loss': np.float64(0.36647210717201234)}
step: 12950 @ episode report: {'average_total_reward': np.float32(10.024446), 'reward_variance': np.float32(2.4152305), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.5333333), 'average_n_step': np.float32(11.1), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08680249974131585), 'actor_loss': np.float64(-0.9995496511459351), 'hyper_actor_loss': np.float64(0.000827914453111589), 'behavior_loss': np.float64(0.378781858086586)}
step: 12960 @ episode report: {'average_total_reward': np.float32(9.151111), 'reward_variance': np.float32(2.6549423), 'max_total_reward': np.float32(12.144444), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(10.3), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08231737986207008), 'actor_loss': np.float64(-0.9754657804965973), 'hyper_actor_loss': np.float64(0.0009179967979434878), 'behavior_loss': np.float64(0.3884335786104202)}
step: 12970 @ episode report: {'average_total_reward': np.float32(9.812223), 'reward_variance': np.float32(6.058506), 'max_total_reward': np.float32(13.38889), 'min_total_reward': np.float32(6.533334), 'average_n_step': np.float32(10.9), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07588421404361725), 'actor_loss': np.float64(-0.9870489716529847), 'hyper_actor_loss': np.float64(0.000967875577043742), 'behavior_loss': np.float64(0.37125149369239807)}
step: 12980 @ episode report: {'average_total_reward': np.float32(9.487779), 'reward_variance': np.float32(2.9473453), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.6), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06979390382766723), 'actor_loss': np.float64(-0.9915946662425995), 'hyper_actor_loss': np.float64(0.0009456299419980496), 'behavior_loss': np.float64(0.36126460433006286)}
step: 12990 @ episode report: {'average_total_reward': np.float32(9.948889), 'reward_variance': np.float32(1.4355356), 'max_total_reward': np.float32(12.0222225), 'min_total_reward': np.float32(7.777778), 'average_n_step': np.float32(11.0), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08524073585867882), 'actor_loss': np.float64(-0.9698127329349517), 'hyper_actor_loss': np.float64(0.0009149583347607404), 'behavior_loss': np.float64(0.36904022097587585)}
step: 13000 @ episode report: {'average_total_reward': np.float32(9.014445), 'reward_variance': np.float32(2.700643), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(10.2), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06702492609620095), 'actor_loss': np.float64(-0.9910973072052002), 'hyper_actor_loss': np.float64(0.0008550558472052216), 'behavior_loss': np.float64(0.3730981111526489)}
step: 13010 @ episode report: {'average_total_reward': np.float32(9.075556), 'reward_variance': np.float32(3.0280943), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.2), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05847739540040493), 'actor_loss': np.float64(-0.9608496963977814), 'hyper_actor_loss': np.float64(0.0008992661081720143), 'behavior_loss': np.float64(0.34673941135406494)}
step: 13020 @ episode report: {'average_total_reward': np.float32(8.665556), 'reward_variance': np.float32(2.0884304), 'max_total_reward': np.float32(12.0222225), 'min_total_reward': np.float32(6.533334), 'average_n_step': np.float32(9.9), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06548305731266738), 'actor_loss': np.float64(-0.9676165401935577), 'hyper_actor_loss': np.float64(0.0010734103969298303), 'behavior_loss': np.float64(0.3504522293806076)}
step: 13030 @ episode report: {'average_total_reward': np.float32(9.848889), 'reward_variance': np.float32(1.4205977), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(8.777778), 'average_n_step': np.float32(10.9), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07270377613604069), 'actor_loss': np.float64(-1.0038015723228455), 'hyper_actor_loss': np.float64(0.0012656969367526472), 'behavior_loss': np.float64(0.38589766919612883)}
step: 13040 @ episode report: {'average_total_reward': np.float32(8.863333), 'reward_variance': np.float32(2.3358529), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.0), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0841690331697464), 'actor_loss': np.float64(-0.973514610528946), 'hyper_actor_loss': np.float64(0.0013180055539123714), 'behavior_loss': np.float64(0.35176063776016236)}
step: 13050 @ episode report: {'average_total_reward': np.float32(9.263334), 'reward_variance': np.float32(2.3288655), 'max_total_reward': np.float32(11.900002), 'min_total_reward': np.float32(6.6555567), 'average_n_step': np.float32(10.4), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08378967717289924), 'actor_loss': np.float64(-1.017678141593933), 'hyper_actor_loss': np.float64(0.0011844528955407441), 'behavior_loss': np.float64(0.3533462226390839)}
step: 13060 @ episode report: {'average_total_reward': np.float32(9.326667), 'reward_variance': np.float32(1.770819), 'max_total_reward': np.float32(12.022222), 'min_total_reward': np.float32(7.5333343), 'average_n_step': np.float32(10.5), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06920934990048408), 'actor_loss': np.float64(-0.970265907049179), 'hyper_actor_loss': np.float64(0.0009850549278780818), 'behavior_loss': np.float64(0.3581786721944809)}
step: 13070 @ episode report: {'average_total_reward': np.float32(9.961111), 'reward_variance': np.float32(1.4905488), 'max_total_reward': np.float32(12.266666), 'min_total_reward': np.float32(7.777778), 'average_n_step': np.float32(11.0), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06768247634172439), 'actor_loss': np.float64(-0.9631787717342377), 'hyper_actor_loss': np.float64(0.0008673788688611239), 'behavior_loss': np.float64(0.3492346227169037)}
step: 13080 @ episode report: {'average_total_reward': np.float32(8.165556), 'reward_variance': np.float32(1.9623817), 'max_total_reward': np.float32(11.0222225), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(9.4), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05687289126217365), 'actor_loss': np.float64(-0.9753035187721253), 'hyper_actor_loss': np.float64(0.0008271948026958853), 'behavior_loss': np.float64(0.3825560539960861)}
step: 13090 @ episode report: {'average_total_reward': np.float32(8.726667), 'reward_variance': np.float32(5.4126964), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.9), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07259900011122226), 'actor_loss': np.float64(-0.9642188727855683), 'hyper_actor_loss': np.float64(0.0007860065146815032), 'behavior_loss': np.float64(0.35140059888362885)}
step: 13100 @ episode report: {'average_total_reward': np.float32(9.3144455), 'reward_variance': np.float32(3.0938535), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(6.5333333), 'average_n_step': np.float32(10.5), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06435801461338997), 'actor_loss': np.float64(-0.9886131525039673), 'hyper_actor_loss': np.float64(0.0006929072784259916), 'behavior_loss': np.float64(0.33651762306690214)}
step: 13110 @ episode report: {'average_total_reward': np.float32(8.851111), 'reward_variance': np.float32(3.343808), 'max_total_reward': np.float32(12.0222225), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.0), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0743553563952446), 'actor_loss': np.float64(-0.9690139949321747), 'hyper_actor_loss': np.float64(0.0007019356940872967), 'behavior_loss': np.float64(0.34959199130535124)}
step: 13120 @ episode report: {'average_total_reward': np.float32(9.412222), 'reward_variance': np.float32(1.1927525), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(7.411111), 'average_n_step': np.float32(10.5), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06659287549555301), 'actor_loss': np.float64(-0.9812242090702057), 'hyper_actor_loss': np.float64(0.0006319747131783515), 'behavior_loss': np.float64(0.34715864062309265)}
step: 13130 @ episode report: {'average_total_reward': np.float32(10.373334), 'reward_variance': np.float32(6.2464247), 'max_total_reward': np.float32(15.633334), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(11.4), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06614118665456772), 'actor_loss': np.float64(-0.9713257491588593), 'hyper_actor_loss': np.float64(0.0006804822362028063), 'behavior_loss': np.float64(0.32699393630027773)}
step: 13140 @ episode report: {'average_total_reward': np.float32(10.410001), 'reward_variance': np.float32(3.2491956), 'max_total_reward': np.float32(14.511111), 'min_total_reward': np.float32(8.777779), 'average_n_step': np.float32(11.4), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07133923508226872), 'actor_loss': np.float64(-0.9833714544773102), 'hyper_actor_loss': np.float64(0.0006954578158911318), 'behavior_loss': np.float64(0.34288405179977416)}
step: 13150 @ episode report: {'average_total_reward': np.float32(9.275556), 'reward_variance': np.float32(2.8111315), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(10.4), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06578949987888336), 'actor_loss': np.float64(-0.972951489686966), 'hyper_actor_loss': np.float64(0.0007023577054496855), 'behavior_loss': np.float64(0.34758117496967317)}
step: 13160 @ episode report: {'average_total_reward': np.float32(9.848889), 'reward_variance': np.float32(1.3383013), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(7.777778), 'average_n_step': np.float32(10.9), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07450488433241845), 'actor_loss': np.float64(-0.9687747716903686), 'hyper_actor_loss': np.float64(0.0006902645400259644), 'behavior_loss': np.float64(0.3664271056652069)}
step: 13170 @ episode report: {'average_total_reward': np.float32(9.724445), 'reward_variance': np.float32(2.4664898), 'max_total_reward': np.float32(13.38889), 'min_total_reward': np.float32(7.777778), 'average_n_step': np.float32(10.8), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0627733089029789), 'actor_loss': np.float64(-0.9780903697013855), 'hyper_actor_loss': np.float64(0.0007357121095992625), 'behavior_loss': np.float64(0.35897561013698576)}
step: 13180 @ episode report: {'average_total_reward': np.float32(10.024445), 'reward_variance': np.float32(1.6351557), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(8.777779), 'average_n_step': np.float32(11.1), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06567320451140404), 'actor_loss': np.float64(-0.9619933605194092), 'hyper_actor_loss': np.float64(0.0007956569083034992), 'behavior_loss': np.float64(0.3386620134115219)}
step: 13190 @ episode report: {'average_total_reward': np.float32(9.912224), 'reward_variance': np.float32(2.1919112), 'max_total_reward': np.float32(12.144444), 'min_total_reward': np.float32(7.6555567), 'average_n_step': np.float32(11.0), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06665562726557255), 'actor_loss': np.float64(-0.9740398049354553), 'hyper_actor_loss': np.float64(0.000712851679418236), 'behavior_loss': np.float64(0.34714228808879855)}
step: 13200 @ episode report: {'average_total_reward': np.float32(10.834444), 'reward_variance': np.float32(3.8356411), 'max_total_reward': np.float32(14.511112), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(11.8), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07609023563563824), 'actor_loss': np.float64(-0.9867857217788696), 'hyper_actor_loss': np.float64(0.0007331314089242369), 'behavior_loss': np.float64(0.3508853405714035)}
step: 13210 @ episode report: {'average_total_reward': np.float32(10.036667), 'reward_variance': np.float32(2.233458), 'max_total_reward': np.float32(11.777778), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(11.1), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06676041856408119), 'actor_loss': np.float64(-0.9667564809322358), 'hyper_actor_loss': np.float64(0.0007195384940132498), 'behavior_loss': np.float64(0.3250733345746994)}
step: 13220 @ episode report: {'average_total_reward': np.float32(9.94889), 'reward_variance': np.float32(2.525338), 'max_total_reward': np.float32(12.266666), 'min_total_reward': np.float32(6.5333343), 'average_n_step': np.float32(11.0), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08135485574603081), 'actor_loss': np.float64(-0.9919557452201844), 'hyper_actor_loss': np.float64(0.0007434131228365004), 'behavior_loss': np.float64(0.33960957229137423)}
step: 13230 @ episode report: {'average_total_reward': np.float32(10.285557), 'reward_variance': np.float32(3.657655), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(7.777778), 'average_n_step': np.float32(11.3), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06701896041631698), 'actor_loss': np.float64(-0.9852202355861663), 'hyper_actor_loss': np.float64(0.000720509368693456), 'behavior_loss': np.float64(0.35272284150123595)}
step: 13240 @ episode report: {'average_total_reward': np.float32(10.834445), 'reward_variance': np.float32(5.9154696), 'max_total_reward': np.float32(13.38889), 'min_total_reward': np.float32(7.288889), 'average_n_step': np.float32(11.8), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06814890392124653), 'actor_loss': np.float64(-0.964725661277771), 'hyper_actor_loss': np.float64(0.0006918616476468742), 'behavior_loss': np.float64(0.35051119029521943)}
step: 13250 @ episode report: {'average_total_reward': np.float32(9.612223), 'reward_variance': np.float32(3.9813442), 'max_total_reward': np.float32(12.144444), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.7), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07884724922478199), 'actor_loss': np.float64(-0.9980663657188416), 'hyper_actor_loss': np.float64(0.0006852673599496484), 'behavior_loss': np.float64(0.3484231114387512)}
step: 13260 @ episode report: {'average_total_reward': np.float32(10.210001), 'reward_variance': np.float32(3.7857647), 'max_total_reward': np.float32(12.266668), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(11.2), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07938140965998172), 'actor_loss': np.float64(-0.9929794490337371), 'hyper_actor_loss': np.float64(0.0007660556701011955), 'behavior_loss': np.float64(0.3460975676774979)}
step: 13270 @ episode report: {'average_total_reward': np.float32(9.673334), 'reward_variance': np.float32(3.4830925), 'max_total_reward': np.float32(12.266668), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.7), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06706856526434421), 'actor_loss': np.float64(-0.9767485678195953), 'hyper_actor_loss': np.float64(0.0007187615090515464), 'behavior_loss': np.float64(0.3404954940080643)}
step: 13280 @ episode report: {'average_total_reward': np.float32(8.975555), 'reward_variance': np.float32(1.0499212), 'max_total_reward': np.float32(11.0222225), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(10.1), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06869564093649387), 'actor_loss': np.float64(-0.9658243954181671), 'hyper_actor_loss': np.float64(0.0006666148838121444), 'behavior_loss': np.float64(0.3524121105670929)}
step: 13290 @ episode report: {'average_total_reward': np.float32(8.9388895), 'reward_variance': np.float32(4.891612), 'max_total_reward': np.float32(12.144444), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(10.1), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08246340602636337), 'actor_loss': np.float64(-0.9800214052200318), 'hyper_actor_loss': np.float64(0.0007046564889606089), 'behavior_loss': np.float64(0.361609610915184)}
step: 13300 @ episode report: {'average_total_reward': np.float32(8.714444), 'reward_variance': np.float32(4.9823713), 'max_total_reward': np.float32(12.144444), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(9.9), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07314825542271138), 'actor_loss': np.float64(-1.006936252117157), 'hyper_actor_loss': np.float64(0.0007598954660352319), 'behavior_loss': np.float64(0.335554638504982)}
step: 13310 @ episode report: {'average_total_reward': np.float32(8.963333), 'reward_variance': np.float32(3.495557), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(5.655556), 'average_n_step': np.float32(10.1), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06846378855407238), 'actor_loss': np.float64(-0.962586510181427), 'hyper_actor_loss': np.float64(0.0007285815838258714), 'behavior_loss': np.float64(0.3478934973478317)}
step: 13320 @ episode report: {'average_total_reward': np.float32(8.93889), 'reward_variance': np.float32(2.8062532), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(5.655556), 'average_n_step': np.float32(10.1), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.058475982025265695), 'actor_loss': np.float64(-0.9540883719921112), 'hyper_actor_loss': np.float64(0.0007792570861056447), 'behavior_loss': np.float64(0.3487548530101776)}
step: 13330 @ episode report: {'average_total_reward': np.float32(8.902224), 'reward_variance': np.float32(3.1728597), 'max_total_reward': np.float32(11.0222225), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(10.1), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07463685050606728), 'actor_loss': np.float64(-0.9860595047473908), 'hyper_actor_loss': np.float64(0.0012151798757258803), 'behavior_loss': np.float64(0.32741071879863737)}
step: 13340 @ episode report: {'average_total_reward': np.float32(9.600001), 'reward_variance': np.float32(5.314346), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.7), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07231196276843548), 'actor_loss': np.float64(-0.9932729482650757), 'hyper_actor_loss': np.float64(0.001233317016158253), 'behavior_loss': np.float64(0.32455745339393616)}
step: 13350 @ episode report: {'average_total_reward': np.float32(9.475556), 'reward_variance': np.float32(2.4712546), 'max_total_reward': np.float32(11.0222225), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.6), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07621313631534576), 'actor_loss': np.float64(-0.9698495507240296), 'hyper_actor_loss': np.float64(0.0009435871033929288), 'behavior_loss': np.float64(0.3388864517211914)}
step: 13360 @ episode report: {'average_total_reward': np.float32(8.738889), 'reward_variance': np.float32(2.517981), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(9.9), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.068705515563488), 'actor_loss': np.float64(-0.9782021760940551), 'hyper_actor_loss': np.float64(0.00075991241610609), 'behavior_loss': np.float64(0.3495378315448761)}
step: 13370 @ episode report: {'average_total_reward': np.float32(8.092222), 'reward_variance': np.float32(2.2133348), 'max_total_reward': np.float32(10.900001), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.4), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05642849188297987), 'actor_loss': np.float64(-0.9776360511779785), 'hyper_actor_loss': np.float64(0.0006748245737981051), 'behavior_loss': np.float64(0.311240117251873)}
step: 13380 @ episode report: {'average_total_reward': np.float32(8.951113), 'reward_variance': np.float32(3.6954627), 'max_total_reward': np.float32(12.144446), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.1), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06850871052592993), 'actor_loss': np.float64(-0.9600234866142273), 'hyper_actor_loss': np.float64(0.0007009910419583321), 'behavior_loss': np.float64(0.3482606589794159)}
step: 13390 @ episode report: {'average_total_reward': np.float32(9.1), 'reward_variance': np.float32(3.5166917), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.2), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07215126939117908), 'actor_loss': np.float64(-0.9857151091098786), 'hyper_actor_loss': np.float64(0.0007355000940151513), 'behavior_loss': np.float64(0.3498091220855713)}
step: 13400 @ episode report: {'average_total_reward': np.float32(9.924444), 'reward_variance': np.float32(5.2429094), 'max_total_reward': np.float32(15.511112), 'min_total_reward': np.float32(7.6555552), 'average_n_step': np.float32(11.0), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.055975521355867384), 'actor_loss': np.float64(-0.9739307880401611), 'hyper_actor_loss': np.float64(0.0007151887170039117), 'behavior_loss': np.float64(0.31696759164333344)}
step: 13410 @ episode report: {'average_total_reward': np.float32(9.363333), 'reward_variance': np.float32(3.3546925), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.5), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07485373429954052), 'actor_loss': np.float64(-0.9760660588741302), 'hyper_actor_loss': np.float64(0.0006763596436940133), 'behavior_loss': np.float64(0.3363359719514847)}
step: 13420 @ episode report: {'average_total_reward': np.float32(9.300001), 'reward_variance': np.float32(1.7816794), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.4), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07662078067660331), 'actor_loss': np.float64(-0.9894416689872741), 'hyper_actor_loss': np.float64(0.0006891092634759843), 'behavior_loss': np.float64(0.32816055715084075)}
step: 13430 @ episode report: {'average_total_reward': np.float32(9.512223), 'reward_variance': np.float32(1.5928015), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(10.6), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08254044763743877), 'actor_loss': np.float64(-0.9954403400421142), 'hyper_actor_loss': np.float64(0.0006762586184777319), 'behavior_loss': np.float64(0.32395547330379487)}
step: 13440 @ episode report: {'average_total_reward': np.float32(10.061111), 'reward_variance': np.float32(4.8995867), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(6.655556), 'average_n_step': np.float32(11.1), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06896042469888926), 'actor_loss': np.float64(-0.9782057285308838), 'hyper_actor_loss': np.float64(0.0006253005121834576), 'behavior_loss': np.float64(0.3258770346641541)}
step: 13450 @ episode report: {'average_total_reward': np.float32(9.287778), 'reward_variance': np.float32(2.1239867), 'max_total_reward': np.float32(12.266668), 'min_total_reward': np.float32(7.655556), 'average_n_step': np.float32(10.4), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07348760478198528), 'actor_loss': np.float64(-0.9823892533779144), 'hyper_actor_loss': np.float64(0.0005982992704957723), 'behavior_loss': np.float64(0.3232809782028198)}
step: 13460 @ episode report: {'average_total_reward': np.float32(10.273334), 'reward_variance': np.float32(2.6304994), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(11.3), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08260192163288593), 'actor_loss': np.float64(-0.9962852537631989), 'hyper_actor_loss': np.float64(0.0006179812597110867), 'behavior_loss': np.float64(0.31446145474910736)}
step: 13470 @ episode report: {'average_total_reward': np.float32(10.2733345), 'reward_variance': np.float32(1.3232152), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(8.533334), 'average_n_step': np.float32(11.3), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06441823672503233), 'actor_loss': np.float64(-0.9782868146896362), 'hyper_actor_loss': np.float64(0.0006530725513584912), 'behavior_loss': np.float64(0.3300301909446716)}
step: 13480 @ episode report: {'average_total_reward': np.float32(10.161112), 'reward_variance': np.float32(3.775289), 'max_total_reward': np.float32(13.266666), 'min_total_reward': np.float32(6.6555567), 'average_n_step': np.float32(11.2), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06956178918480874), 'actor_loss': np.float64(-0.9620082199573516), 'hyper_actor_loss': np.float64(0.0006278421031311154), 'behavior_loss': np.float64(0.3175007626414299)}
step: 13490 @ episode report: {'average_total_reward': np.float32(9.48778), 'reward_variance': np.float32(1.685962), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.5333333), 'average_n_step': np.float32(10.6), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07909298874437809), 'actor_loss': np.float64(-1.0001495242118836), 'hyper_actor_loss': np.float64(0.0006824710813816637), 'behavior_loss': np.float64(0.32567756474018095)}
step: 13500 @ episode report: {'average_total_reward': np.float32(10.173334), 'reward_variance': np.float32(2.2011416), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(11.2), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07348453514277935), 'actor_loss': np.float64(-0.9916882514953613), 'hyper_actor_loss': np.float64(0.0007000761630479247), 'behavior_loss': np.float64(0.3235861659049988)}
step: 13510 @ episode report: {'average_total_reward': np.float32(9.363333), 'reward_variance': np.float32(3.8769145), 'max_total_reward': np.float32(14.388889), 'min_total_reward': np.float32(7.5333343), 'average_n_step': np.float32(10.5), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07878010161221027), 'actor_loss': np.float64(-0.9806697607040405), 'hyper_actor_loss': np.float64(0.0006517012137919664), 'behavior_loss': np.float64(0.3467555433511734)}
step: 13520 @ episode report: {'average_total_reward': np.float32(10.622223), 'reward_variance': np.float32(2.7871861), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(11.6), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06899641491472722), 'actor_loss': np.float64(-0.980901426076889), 'hyper_actor_loss': np.float64(0.0006534093932714313), 'behavior_loss': np.float64(0.3274476706981659)}
step: 13530 @ episode report: {'average_total_reward': np.float32(10.297778), 'reward_variance': np.float32(1.9901931), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(8.777779), 'average_n_step': np.float32(11.3), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07635357938706874), 'actor_loss': np.float64(-0.96324924826622), 'hyper_actor_loss': np.float64(0.0006617623963393271), 'behavior_loss': np.float64(0.3361454874277115)}
step: 13540 @ episode report: {'average_total_reward': np.float32(10.061111), 'reward_variance': np.float32(0.61568534), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(8.9), 'average_n_step': np.float32(11.1), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05933247022330761), 'actor_loss': np.float64(-0.9716064810752869), 'hyper_actor_loss': np.float64(0.0006714484130498022), 'behavior_loss': np.float64(0.33620116412639617)}
step: 13550 @ episode report: {'average_total_reward': np.float32(9.948889), 'reward_variance': np.float32(4.8904743), 'max_total_reward': np.float32(14.144444), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(11.0), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07477345503866673), 'actor_loss': np.float64(-0.9664993584156036), 'hyper_actor_loss': np.float64(0.0006232158979400992), 'behavior_loss': np.float64(0.324780760705471)}
step: 13560 @ episode report: {'average_total_reward': np.float32(10.497778), 'reward_variance': np.float32(5.4056253), 'max_total_reward': np.float32(15.633334), 'min_total_reward': np.float32(7.777778), 'average_n_step': np.float32(11.5), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06648461893200874), 'actor_loss': np.float64(-0.9942016839981079), 'hyper_actor_loss': np.float64(0.0005917396745644509), 'behavior_loss': np.float64(0.3001600742340088)}
step: 13570 @ episode report: {'average_total_reward': np.float32(9.9366665), 'reward_variance': np.float32(2.0485692), 'max_total_reward': np.float32(12.266666), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(11.0), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06112834364175797), 'actor_loss': np.float64(-0.9864019274711608), 'hyper_actor_loss': np.float64(0.0006044766283594072), 'behavior_loss': np.float64(0.3231698155403137)}
step: 13580 @ episode report: {'average_total_reward': np.float32(10.834445), 'reward_variance': np.float32(2.6341088), 'max_total_reward': np.float32(14.511111), 'min_total_reward': np.float32(8.533335), 'average_n_step': np.float32(11.8), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0658093474805355), 'actor_loss': np.float64(-0.9697026431560516), 'hyper_actor_loss': np.float64(0.0006823607953265309), 'behavior_loss': np.float64(0.3050790190696716)}
step: 13590 @ episode report: {'average_total_reward': np.float32(10.410001), 'reward_variance': np.float32(1.0371716), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(8.900001), 'average_n_step': np.float32(11.4), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07814642041921616), 'actor_loss': np.float64(-0.9943250477313995), 'hyper_actor_loss': np.float64(0.000702659465605393), 'behavior_loss': np.float64(0.32960230112075806)}
step: 13600 @ episode report: {'average_total_reward': np.float32(9.512223), 'reward_variance': np.float32(3.8157897), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.6), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06388377919793128), 'actor_loss': np.float64(-0.9745696008205413), 'hyper_actor_loss': np.float64(0.0006993246381171048), 'behavior_loss': np.float64(0.31150666773319247)}
step: 13610 @ episode report: {'average_total_reward': np.float32(10.361112), 'reward_variance': np.float32(0.93299425), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(8.777778), 'average_n_step': np.float32(11.4), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06752554550766945), 'actor_loss': np.float64(-0.9691296875476837), 'hyper_actor_loss': np.float64(0.0006823610630817712), 'behavior_loss': np.float64(0.32368197441101076)}
step: 13620 @ episode report: {'average_total_reward': np.float32(10.3977785), 'reward_variance': np.float32(6.003232), 'max_total_reward': np.float32(14.511112), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(11.4), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0640631016343832), 'actor_loss': np.float64(-0.9765401661396027), 'hyper_actor_loss': np.float64(0.0006674229924101382), 'behavior_loss': np.float64(0.3291437476873398)}
step: 13630 @ episode report: {'average_total_reward': np.float32(10.136667), 'reward_variance': np.float32(4.5066924), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(11.2), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07848877497017384), 'actor_loss': np.float64(-0.9834972858428955), 'hyper_actor_loss': np.float64(0.0007198146544396877), 'behavior_loss': np.float64(0.3005248546600342)}
step: 13640 @ episode report: {'average_total_reward': np.float32(10.497778), 'reward_variance': np.float32(1.1835746), 'max_total_reward': np.float32(13.144444), 'min_total_reward': np.float32(8.900002), 'average_n_step': np.float32(11.5), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06624245643615723), 'actor_loss': np.float64(-0.9955227315425873), 'hyper_actor_loss': np.float64(0.0007387314166408032), 'behavior_loss': np.float64(0.305814191699028)}
step: 13650 @ episode report: {'average_total_reward': np.float32(9.175555), 'reward_variance': np.float32(2.9458222), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(10.3), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06760176979005336), 'actor_loss': np.float64(-0.9665041208267212), 'hyper_actor_loss': np.float64(0.0007075568893924356), 'behavior_loss': np.float64(0.3113647371530533)}
step: 13660 @ episode report: {'average_total_reward': np.float32(10.012224), 'reward_variance': np.float32(2.7677407), 'max_total_reward': np.float32(13.144445), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(11.1), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07581199146807194), 'actor_loss': np.float64(-0.9854808747768402), 'hyper_actor_loss': np.float64(0.0006542740215081721), 'behavior_loss': np.float64(0.30096849501132966)}
step: 13670 @ episode report: {'average_total_reward': np.float32(10.971112), 'reward_variance': np.float32(3.8720047), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(11.9), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0749576173722744), 'actor_loss': np.float64(-1.0151846766471864), 'hyper_actor_loss': np.float64(0.0005620833369903266), 'behavior_loss': np.float64(0.3176357179880142)}
step: 13680 @ episode report: {'average_total_reward': np.float32(9.797778), 'reward_variance': np.float32(3.9003406), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.8), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0685824777930975), 'actor_loss': np.float64(-0.9707834780216217), 'hyper_actor_loss': np.float64(0.0005632270593196153), 'behavior_loss': np.float64(0.3158020257949829)}
step: 13690 @ episode report: {'average_total_reward': np.float32(9.861112), 'reward_variance': np.float32(4.5439563), 'max_total_reward': np.float32(15.266667), 'min_total_reward': np.float32(7.6555567), 'average_n_step': np.float32(10.9), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.061070815287530424), 'actor_loss': np.float64(-0.9776320457458496), 'hyper_actor_loss': np.float64(0.0005549016961595044), 'behavior_loss': np.float64(0.298606276512146)}
step: 13700 @ episode report: {'average_total_reward': np.float32(10.722223), 'reward_variance': np.float32(2.0309877), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(8.777779), 'average_n_step': np.float32(11.7), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0659908939152956), 'actor_loss': np.float64(-0.9676253855228424), 'hyper_actor_loss': np.float64(0.0005713826045393944), 'behavior_loss': np.float64(0.29431438744068145)}
step: 13710 @ episode report: {'average_total_reward': np.float32(9.785556), 'reward_variance': np.float32(7.2773347), 'max_total_reward': np.float32(14.511111), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.8), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05757912844419479), 'actor_loss': np.float64(-0.9755531132221222), 'hyper_actor_loss': np.float64(0.0005725595459807664), 'behavior_loss': np.float64(0.2961576461791992)}
step: 13720 @ episode report: {'average_total_reward': np.float32(11.295557), 'reward_variance': np.float32(2.3158574), 'max_total_reward': np.float32(14.38889), 'min_total_reward': np.float32(8.900001), 'average_n_step': np.float32(12.2), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.061304505728185174), 'actor_loss': np.float64(-0.9835174798965454), 'hyper_actor_loss': np.float64(0.0006007757328916341), 'behavior_loss': np.float64(0.30117298364639283)}
step: 13730 @ episode report: {'average_total_reward': np.float32(10.85889), 'reward_variance': np.float32(2.8367176), 'max_total_reward': np.float32(14.511111), 'min_total_reward': np.float32(8.777779), 'average_n_step': np.float32(11.8), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08869352489709854), 'actor_loss': np.float64(-0.9820149898529053), 'hyper_actor_loss': np.float64(0.0007457156840246171), 'behavior_loss': np.float64(0.32077161967754364)}
step: 13740 @ episode report: {'average_total_reward': np.float32(11.107779), 'reward_variance': np.float32(7.337976), 'max_total_reward': np.float32(14.511112), 'min_total_reward': np.float32(6.655556), 'average_n_step': np.float32(12.0), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07751233763992786), 'actor_loss': np.float64(-1.003189104795456), 'hyper_actor_loss': np.float64(0.0008275347121525556), 'behavior_loss': np.float64(0.3113835632801056)}
step: 13750 @ episode report: {'average_total_reward': np.float32(10.65889), 'reward_variance': np.float32(3.9408908), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(11.6), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06598040703684091), 'actor_loss': np.float64(-0.9619419932365417), 'hyper_actor_loss': np.float64(0.0007390130253043026), 'behavior_loss': np.float64(0.30545124411582947)}
step: 13760 @ episode report: {'average_total_reward': np.float32(11.220001), 'reward_variance': np.float32(0.82547665), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(10.0222225), 'average_n_step': np.float32(12.1), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(11.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.061890187114477156), 'actor_loss': np.float64(-0.964608633518219), 'hyper_actor_loss': np.float64(0.0006532484607305378), 'behavior_loss': np.float64(0.310828885436058)}
step: 13770 @ episode report: {'average_total_reward': np.float32(10.410001), 'reward_variance': np.float32(2.4935665), 'max_total_reward': np.float32(13.144444), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(11.4), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.079840037971735), 'actor_loss': np.float64(-0.9788030564785004), 'hyper_actor_loss': np.float64(0.0006411944981664419), 'behavior_loss': np.float64(0.3128290921449661)}
step: 13780 @ episode report: {'average_total_reward': np.float32(10.65889), 'reward_variance': np.float32(6.569384), 'max_total_reward': np.float32(15.633333), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(11.6), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06817448288202285), 'actor_loss': np.float64(-0.9923350870609283), 'hyper_actor_loss': np.float64(0.0005952117440756411), 'behavior_loss': np.float64(0.28967461585998533)}
step: 13790 @ episode report: {'average_total_reward': np.float32(10.834444), 'reward_variance': np.float32(3.1184068), 'max_total_reward': np.float32(14.511112), 'min_total_reward': np.float32(7.777778), 'average_n_step': np.float32(11.8), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06369763724505902), 'actor_loss': np.float64(-0.9780708491802216), 'hyper_actor_loss': np.float64(0.0005453932622913271), 'behavior_loss': np.float64(0.2957113027572632)}
step: 13800 @ episode report: {'average_total_reward': np.float32(10.971112), 'reward_variance': np.float32(5.1743007), 'max_total_reward': np.float32(16.633333), 'min_total_reward': np.float32(8.655556), 'average_n_step': np.float32(11.9), 'max_n_step': np.float32(17.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06796344146132469), 'actor_loss': np.float64(-0.9735230147838593), 'hyper_actor_loss': np.float64(0.0005285487626679241), 'behavior_loss': np.float64(0.3142347753047943)}
step: 13810 @ episode report: {'average_total_reward': np.float32(9.026667), 'reward_variance': np.float32(2.5999553), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(7.5333343), 'average_n_step': np.float32(10.2), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07059556376188994), 'actor_loss': np.float64(-0.9780829966068267), 'hyper_actor_loss': np.float64(0.0005139706074260176), 'behavior_loss': np.float64(0.3024420291185379)}
step: 13820 @ episode report: {'average_total_reward': np.float32(10.622223), 'reward_variance': np.float32(1.6425188), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(8.777779), 'average_n_step': np.float32(11.6), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06830177903175354), 'actor_loss': np.float64(-0.9739840149879455), 'hyper_actor_loss': np.float64(0.0005176659731660038), 'behavior_loss': np.float64(0.3043080478906631)}
step: 13830 @ episode report: {'average_total_reward': np.float32(10.222223), 'reward_variance': np.float32(3.4618275), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(7.777778), 'average_n_step': np.float32(11.2), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0674564853310585), 'actor_loss': np.float64(-0.9747951447963714), 'hyper_actor_loss': np.float64(0.0004953829484293237), 'behavior_loss': np.float64(0.3008913040161133)}
step: 13840 @ episode report: {'average_total_reward': np.float32(10.6466675), 'reward_variance': np.float32(5.0750318), 'max_total_reward': np.float32(15.511111), 'min_total_reward': np.float32(7.655556), 'average_n_step': np.float32(11.6), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06289765797555447), 'actor_loss': np.float64(-0.9838140606880188), 'hyper_actor_loss': np.float64(0.00047473441227339206), 'behavior_loss': np.float64(0.29592452347278597)}
step: 13850 @ episode report: {'average_total_reward': np.float32(10.261111), 'reward_variance': np.float32(2.2195115), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(11.3), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.061392467841506), 'actor_loss': np.float64(-0.9650289058685303), 'hyper_actor_loss': np.float64(0.0004957308963639661), 'behavior_loss': np.float64(0.30062250792980194)}
step: 13860 @ episode report: {'average_total_reward': np.float32(9.6), 'reward_variance': np.float32(2.5945923), 'max_total_reward': np.float32(13.144444), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(10.7), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07007655948400497), 'actor_loss': np.float64(-0.9726405501365661), 'hyper_actor_loss': np.float64(0.0005607705214060843), 'behavior_loss': np.float64(0.3098327308893204)}
step: 13870 @ episode report: {'average_total_reward': np.float32(10.546667), 'reward_variance': np.float32(1.366637), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(8.900001), 'average_n_step': np.float32(11.5), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07439662255346775), 'actor_loss': np.float64(-1.0032314956188202), 'hyper_actor_loss': np.float64(0.0005573518166784198), 'behavior_loss': np.float64(0.2921907424926758)}
step: 13880 @ episode report: {'average_total_reward': np.float32(11.071112), 'reward_variance': np.float32(1.5452653), 'max_total_reward': np.float32(13.266668), 'min_total_reward': np.float32(8.777778), 'average_n_step': np.float32(12.0), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06802899017930031), 'actor_loss': np.float64(-0.9995504915714264), 'hyper_actor_loss': np.float64(0.0005262238468276337), 'behavior_loss': np.float64(0.2983821749687195)}
step: 13890 @ episode report: {'average_total_reward': np.float32(10.161112), 'reward_variance': np.float32(1.3143758), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(8.777779), 'average_n_step': np.float32(11.2), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06998469680547714), 'actor_loss': np.float64(-0.9810131192207336), 'hyper_actor_loss': np.float64(0.0005503429245436564), 'behavior_loss': np.float64(0.30324859619140626)}
step: 13900 @ episode report: {'average_total_reward': np.float32(11.881113), 'reward_variance': np.float32(2.8391883), 'max_total_reward': np.float32(14.511112), 'min_total_reward': np.float32(8.9), 'average_n_step': np.float32(12.7), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.070724480971694), 'actor_loss': np.float64(-0.9876441895961762), 'hyper_actor_loss': np.float64(0.0006126905442215502), 'behavior_loss': np.float64(0.3007812350988388)}
step: 13910 @ episode report: {'average_total_reward': np.float32(10.3977785), 'reward_variance': np.float32(6.0171804), 'max_total_reward': np.float32(14.266667), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(11.4), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0696150291711092), 'actor_loss': np.float64(-0.9950378179550171), 'hyper_actor_loss': np.float64(0.0005789423477835954), 'behavior_loss': np.float64(0.3067904308438301)}
step: 13920 @ episode report: {'average_total_reward': np.float32(10.971112), 'reward_variance': np.float32(1.6784499), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(8.9), 'average_n_step': np.float32(11.9), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07460985146462917), 'actor_loss': np.float64(-0.9789192914962769), 'hyper_actor_loss': np.float64(0.0004971016111085192), 'behavior_loss': np.float64(0.30641179382801054)}
step: 13930 @ episode report: {'average_total_reward': np.float32(12.181112), 'reward_variance': np.float32(2.3278773), 'max_total_reward': np.float32(15.511111), 'min_total_reward': np.float32(9.777779), 'average_n_step': np.float32(13.0), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(11.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07693468034267426), 'actor_loss': np.float64(-0.9816357553005218), 'hyper_actor_loss': np.float64(0.0005226797424256801), 'behavior_loss': np.float64(0.29178132563829423)}
step: 13940 @ episode report: {'average_total_reward': np.float32(11.66889), 'reward_variance': np.float32(1.7606621), 'max_total_reward': np.float32(14.388889), 'min_total_reward': np.float32(10.022222), 'average_n_step': np.float32(12.5), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(11.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06293640770018101), 'actor_loss': np.float64(-0.997723788022995), 'hyper_actor_loss': np.float64(0.0005471829615999013), 'behavior_loss': np.float64(0.304082402586937)}
step: 13950 @ episode report: {'average_total_reward': np.float32(10.546667), 'reward_variance': np.float32(4.109848), 'max_total_reward': np.float32(14.511112), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(11.5), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06274074241518975), 'actor_loss': np.float64(-0.9548949241638184), 'hyper_actor_loss': np.float64(0.0006822888215538114), 'behavior_loss': np.float64(0.3044542342424393)}
step: 13960 @ episode report: {'average_total_reward': np.float32(11.444445), 'reward_variance': np.float32(4.908372), 'max_total_reward': np.float32(15.633334), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(12.3), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07340641617774964), 'actor_loss': np.float64(-0.9840692102909088), 'hyper_actor_loss': np.float64(0.0007975439424626529), 'behavior_loss': np.float64(0.301336532831192)}
step: 13970 @ episode report: {'average_total_reward': np.float32(10.31), 'reward_variance': np.float32(5.031765), 'max_total_reward': np.float32(15.633334), 'min_total_reward': np.float32(7.777778), 'average_n_step': np.float32(11.3), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0738846804946661), 'actor_loss': np.float64(-1.0024050176143646), 'hyper_actor_loss': np.float64(0.0008700576378032565), 'behavior_loss': np.float64(0.3049591988325119)}
step: 13980 @ episode report: {'average_total_reward': np.float32(10.610001), 'reward_variance': np.float32(3.3393703), 'max_total_reward': np.float32(13.38889), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(11.6), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07682131305336952), 'actor_loss': np.float64(-0.969244921207428), 'hyper_actor_loss': np.float64(0.0008412016031797975), 'behavior_loss': np.float64(0.3267680734395981)}
step: 13990 @ episode report: {'average_total_reward': np.float32(10.297778), 'reward_variance': np.float32(2.4146378), 'max_total_reward': np.float32(13.144445), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(11.3), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06719399616122246), 'actor_loss': np.float64(-0.9799042701721191), 'hyper_actor_loss': np.float64(0.0007782646920531988), 'behavior_loss': np.float64(0.30462982654571535)}
step: 14000 @ episode report: {'average_total_reward': np.float32(11.744446), 'reward_variance': np.float32(4.521902), 'max_total_reward': np.float32(14.38889), 'min_total_reward': np.float32(7.655556), 'average_n_step': np.float32(12.6), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06670819632709027), 'actor_loss': np.float64(-0.9960128486156463), 'hyper_actor_loss': np.float64(0.0008978611615020782), 'behavior_loss': np.float64(0.3044990122318268)}
step: 14010 @ episode report: {'average_total_reward': np.float32(10.710001), 'reward_variance': np.float32(2.116259), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(8.655556), 'average_n_step': np.float32(11.7), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07663300149142742), 'actor_loss': np.float64(-0.9736442565917969), 'hyper_actor_loss': np.float64(0.0013546649366617202), 'behavior_loss': np.float64(0.3034119695425034)}
step: 14020 @ episode report: {'average_total_reward': np.float32(10.273334), 'reward_variance': np.float32(1.3905722), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(7.5333343), 'average_n_step': np.float32(11.3), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05682426802814007), 'actor_loss': np.float64(-0.9903038680553437), 'hyper_actor_loss': np.float64(0.0010347973904572428), 'behavior_loss': np.float64(0.3060570597648621)}
step: 14030 @ episode report: {'average_total_reward': np.float32(10.883334), 'reward_variance': np.float32(4.3084764), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(11.8), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06091306358575821), 'actor_loss': np.float64(-0.9613539516925812), 'hyper_actor_loss': np.float64(0.0008404572785366326), 'behavior_loss': np.float64(0.30069863200187685)}
step: 14040 @ episode report: {'average_total_reward': np.float32(8.826667), 'reward_variance': np.float32(2.794153), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.0), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07514765150845051), 'actor_loss': np.float64(-0.9977849364280701), 'hyper_actor_loss': np.float64(0.000750893191434443), 'behavior_loss': np.float64(0.3141317397356033)}
step: 14050 @ episode report: {'average_total_reward': np.float32(11.220001), 'reward_variance': np.float32(3.9302917), 'max_total_reward': np.float32(15.633334), 'min_total_reward': np.float32(8.777779), 'average_n_step': np.float32(12.1), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06952691227197647), 'actor_loss': np.float64(-0.9948887944221496), 'hyper_actor_loss': np.float64(0.0007103583833668381), 'behavior_loss': np.float64(0.29200449883937835)}
step: 14060 @ episode report: {'average_total_reward': np.float32(10.534445), 'reward_variance': np.float32(1.271073), 'max_total_reward': np.float32(12.266666), 'min_total_reward': np.float32(8.9), 'average_n_step': np.float32(11.5), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07225914485752583), 'actor_loss': np.float64(-0.976670891046524), 'hyper_actor_loss': np.float64(0.0006488786661066115), 'behavior_loss': np.float64(0.30403667986392974)}
step: 14070 @ episode report: {'average_total_reward': np.float32(9.824445), 'reward_variance': np.float32(4.1088343), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.9), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06168416254222393), 'actor_loss': np.float64(-0.9858542203903198), 'hyper_actor_loss': np.float64(0.0005825124244438484), 'behavior_loss': np.float64(0.30407161116600034)}
step: 14080 @ episode report: {'average_total_reward': np.float32(10.31), 'reward_variance': np.float32(5.2317643), 'max_total_reward': np.float32(14.511112), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(11.3), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07273812517523766), 'actor_loss': np.float64(-0.9918667018413544), 'hyper_actor_loss': np.float64(0.0005611762579064816), 'behavior_loss': np.float64(0.30136153399944304)}
step: 14090 @ episode report: {'average_total_reward': np.float32(10.634445), 'reward_variance': np.float32(3.0521836), 'max_total_reward': np.float32(14.511111), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(11.6), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07683302946388722), 'actor_loss': np.float64(-0.9987353324890137), 'hyper_actor_loss': np.float64(0.0005555826181080192), 'behavior_loss': np.float64(0.31033057570457456)}
step: 14100 @ episode report: {'average_total_reward': np.float32(10.722223), 'reward_variance': np.float32(2.3182719), 'max_total_reward': np.float32(13.144444), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(11.7), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06036743950098753), 'actor_loss': np.float64(-0.9824478447437286), 'hyper_actor_loss': np.float64(0.0007166712370235473), 'behavior_loss': np.float64(0.3206965208053589)}
step: 14110 @ episode report: {'average_total_reward': np.float32(9.612223), 'reward_variance': np.float32(1.7054926), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.7), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06671540392562747), 'actor_loss': np.float64(-0.978726613521576), 'hyper_actor_loss': np.float64(0.0010435423988383262), 'behavior_loss': np.float64(0.3480511218309402)}
step: 14120 @ episode report: {'average_total_reward': np.float32(10.51), 'reward_variance': np.float32(1.6601092), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(8.777779), 'average_n_step': np.float32(11.5), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07832474168390036), 'actor_loss': np.float64(-0.994168347120285), 'hyper_actor_loss': np.float64(0.0011334308539517224), 'behavior_loss': np.float64(0.3484240710735321)}
step: 14130 @ episode report: {'average_total_reward': np.float32(9.736667), 'reward_variance': np.float32(3.7619278), 'max_total_reward': np.float32(13.38889), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.8), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07465803548693657), 'actor_loss': np.float64(-1.0052871406078339), 'hyper_actor_loss': np.float64(0.0010256641719024629), 'behavior_loss': np.float64(0.35535968542099)}
step: 14140 @ episode report: {'average_total_reward': np.float32(8.963335), 'reward_variance': np.float32(3.808274), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.1), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06481612175703048), 'actor_loss': np.float64(-0.9850627839565277), 'hyper_actor_loss': np.float64(0.0008998303092084825), 'behavior_loss': np.float64(0.3462680846452713)}
step: 14150 @ episode report: {'average_total_reward': np.float32(8.975556), 'reward_variance': np.float32(2.4848597), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.1), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07556909173727036), 'actor_loss': np.float64(-0.9836587011814117), 'hyper_actor_loss': np.float64(0.0007795445737428964), 'behavior_loss': np.float64(0.3523661881685257)}
step: 14160 @ episode report: {'average_total_reward': np.float32(10.234446), 'reward_variance': np.float32(4.1041846), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(11.2), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07464600577950478), 'actor_loss': np.float64(-1.0060240149497985), 'hyper_actor_loss': np.float64(0.0006233403051737696), 'behavior_loss': np.float64(0.3523112773895264)}
step: 14170 @ episode report: {'average_total_reward': np.float32(11.1466675), 'reward_variance': np.float32(3.7648842), 'max_total_reward': np.float32(14.266666), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(12.1), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07954182177782058), 'actor_loss': np.float64(-0.9786740720272065), 'hyper_actor_loss': np.float64(0.000494436247390695), 'behavior_loss': np.float64(0.337771400809288)}
step: 14180 @ episode report: {'average_total_reward': np.float32(9.5), 'reward_variance': np.float32(4.076001), 'max_total_reward': np.float32(12.266668), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.6), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08220092169940471), 'actor_loss': np.float64(-1.0049073219299316), 'hyper_actor_loss': np.float64(0.0004850552417337894), 'behavior_loss': np.float64(0.3304369330406189)}
step: 14190 @ episode report: {'average_total_reward': np.float32(10.322223), 'reward_variance': np.float32(1.9731362), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(8.777778), 'average_n_step': np.float32(11.3), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06888751089572906), 'actor_loss': np.float64(-1.0036987245082856), 'hyper_actor_loss': np.float64(0.0004227828641887754), 'behavior_loss': np.float64(0.3217518121004105)}
step: 14200 @ episode report: {'average_total_reward': np.float32(10.883333), 'reward_variance': np.float32(2.9313884), 'max_total_reward': np.float32(14.388889), 'min_total_reward': np.float32(8.777778), 'average_n_step': np.float32(11.8), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.065628950484097), 'actor_loss': np.float64(-0.9650125801563263), 'hyper_actor_loss': np.float64(0.0004491476312978193), 'behavior_loss': np.float64(0.32144154608249664)}
step: 14210 @ episode report: {'average_total_reward': np.float32(10.31), 'reward_variance': np.float32(2.2915416), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(11.3), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06490426324307919), 'actor_loss': np.float64(-0.9793141841888428), 'hyper_actor_loss': np.float64(0.00043255113414488735), 'behavior_loss': np.float64(0.33868924975395204)}
step: 14220 @ episode report: {'average_total_reward': np.float32(9.338889), 'reward_variance': np.float32(3.5188956), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(10.5), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.058828949183225634), 'actor_loss': np.float64(-0.9719584822654724), 'hyper_actor_loss': np.float64(0.000444288898142986), 'behavior_loss': np.float64(0.3370457708835602)}
step: 14230 @ episode report: {'average_total_reward': np.float32(9.636667), 'reward_variance': np.float32(2.5873103), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.7), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.057680236920714376), 'actor_loss': np.float64(-0.9679133653640747), 'hyper_actor_loss': np.float64(0.000474230176769197), 'behavior_loss': np.float64(0.3277603298425674)}
step: 14240 @ episode report: {'average_total_reward': np.float32(9.412222), 'reward_variance': np.float32(2.6127515), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.5), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0818157959729433), 'actor_loss': np.float64(-0.9765584707260132), 'hyper_actor_loss': np.float64(0.0005843081045895815), 'behavior_loss': np.float64(0.3301855862140656)}
step: 14250 @ episode report: {'average_total_reward': np.float32(9.512222), 'reward_variance': np.float32(2.247666), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(10.6), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06140977647155523), 'actor_loss': np.float64(-1.0073204636573792), 'hyper_actor_loss': np.float64(0.0005947428464423866), 'behavior_loss': np.float64(0.32304042875766753)}
step: 14260 @ episode report: {'average_total_reward': np.float32(9.026668), 'reward_variance': np.float32(2.1709921), 'max_total_reward': np.float32(12.266666), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.2), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07192854043096304), 'actor_loss': np.float64(-0.95934499502182), 'hyper_actor_loss': np.float64(0.0005253241921309382), 'behavior_loss': np.float64(0.3334604799747467)}
step: 14270 @ episode report: {'average_total_reward': np.float32(10.185556), 'reward_variance': np.float32(2.751434), 'max_total_reward': np.float32(13.266668), 'min_total_reward': np.float32(6.533334), 'average_n_step': np.float32(11.2), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07244539968669414), 'actor_loss': np.float64(-0.991995632648468), 'hyper_actor_loss': np.float64(0.0005269193643471226), 'behavior_loss': np.float64(0.3208869218826294)}
step: 14280 @ episode report: {'average_total_reward': np.float32(10.261111), 'reward_variance': np.float32(1.8254877), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(8.777778), 'average_n_step': np.float32(11.3), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.060446536540985106), 'actor_loss': np.float64(-0.9914339363574982), 'hyper_actor_loss': np.float64(0.0005219020356889814), 'behavior_loss': np.float64(0.31510519087314603)}
step: 14290 @ episode report: {'average_total_reward': np.float32(8.990001), 'reward_variance': np.float32(2.7205796), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(5.411111), 'average_n_step': np.float32(10.2), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.056146424077451226), 'actor_loss': np.float64(-0.9576788961887359), 'hyper_actor_loss': np.float64(0.0004847131174756214), 'behavior_loss': np.float64(0.31522840559482573)}
step: 14300 @ episode report: {'average_total_reward': np.float32(9.9366665), 'reward_variance': np.float32(1.4076555), 'max_total_reward': np.float32(12.022222), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(11.0), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07785136885941028), 'actor_loss': np.float64(-1.0013203263282775), 'hyper_actor_loss': np.float64(0.0004683440376538783), 'behavior_loss': np.float64(0.3246533006429672)}
step: 14310 @ episode report: {'average_total_reward': np.float32(9.985556), 'reward_variance': np.float32(1.9907176), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(11.0), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06352843828499317), 'actor_loss': np.float64(-1.0009931862354278), 'hyper_actor_loss': np.float64(0.0005712947808206081), 'behavior_loss': np.float64(0.3179074198007584)}
step: 14320 @ episode report: {'average_total_reward': np.float32(10.422223), 'reward_variance': np.float32(2.3647408), 'max_total_reward': np.float32(12.266668), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(11.4), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05740746967494488), 'actor_loss': np.float64(-0.9554193079471588), 'hyper_actor_loss': np.float64(0.0010445543623063714), 'behavior_loss': np.float64(0.310568705201149)}
step: 14330 @ episode report: {'average_total_reward': np.float32(10.048889), 'reward_variance': np.float32(1.7431895), 'max_total_reward': np.float32(12.022222), 'min_total_reward': np.float32(7.655556), 'average_n_step': np.float32(11.1), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06921941377222537), 'actor_loss': np.float64(-0.9735259532928466), 'hyper_actor_loss': np.float64(0.0010411657742224634), 'behavior_loss': np.float64(0.31584362089633944)}
step: 14340 @ episode report: {'average_total_reward': np.float32(9.23889), 'reward_variance': np.float32(2.2432656), 'max_total_reward': np.float32(12.0222225), 'min_total_reward': np.float32(7.411111), 'average_n_step': np.float32(10.4), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06239234991371632), 'actor_loss': np.float64(-0.9794536471366883), 'hyper_actor_loss': np.float64(0.000707123294705525), 'behavior_loss': np.float64(0.3133204966783524)}
step: 14350 @ episode report: {'average_total_reward': np.float32(10.185556), 'reward_variance': np.float32(3.0033104), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(11.2), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06955510787665845), 'actor_loss': np.float64(-0.989385849237442), 'hyper_actor_loss': np.float64(0.0006758274510502815), 'behavior_loss': np.float64(0.31642048954963686)}
step: 14360 @ episode report: {'average_total_reward': np.float32(8.838889), 'reward_variance': np.float32(3.4477088), 'max_total_reward': np.float32(11.022222), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(10.0), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07608862631022931), 'actor_loss': np.float64(-0.99207763671875), 'hyper_actor_loss': np.float64(0.0006291320314630866), 'behavior_loss': np.float64(0.3089595794677734)}
step: 14370 @ episode report: {'average_total_reward': np.float32(9.700001), 'reward_variance': np.float32(1.0313332), 'max_total_reward': np.float32(12.266666), 'min_total_reward': np.float32(8.655555), 'average_n_step': np.float32(10.8), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0669502068310976), 'actor_loss': np.float64(-0.9954269051551818), 'hyper_actor_loss': np.float64(0.0005891087523195893), 'behavior_loss': np.float64(0.32332214117050173)}
step: 14380 @ episode report: {'average_total_reward': np.float32(9.051112), 'reward_variance': np.float32(1.138771), 'max_total_reward': np.float32(11.022223), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(10.2), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07867778241634368), 'actor_loss': np.float64(-0.9847459495067596), 'hyper_actor_loss': np.float64(0.0006133805174613372), 'behavior_loss': np.float64(0.3192250907421112)}
step: 14390 @ episode report: {'average_total_reward': np.float32(8.83889), 'reward_variance': np.float32(2.4690933), 'max_total_reward': np.float32(10.777779), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.0), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06646346151828766), 'actor_loss': np.float64(-1.0074758231639862), 'hyper_actor_loss': np.float64(0.0008153280417900532), 'behavior_loss': np.float64(0.31913919746875763)}
step: 14400 @ episode report: {'average_total_reward': np.float32(9.300001), 'reward_variance': np.float32(1.8365437), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(7.655556), 'average_n_step': np.float32(10.4), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07900557704269887), 'actor_loss': np.float64(-0.9838520288467407), 'hyper_actor_loss': np.float64(0.0006406088068615645), 'behavior_loss': np.float64(0.3237853854894638)}
step: 14410 @ episode report: {'average_total_reward': np.float32(9.09), 'reward_variance': np.float32(1.2419364), 'max_total_reward': np.float32(10.9), 'min_total_reward': np.float32(7.5333343), 'average_n_step': np.float32(10.3), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0704707283526659), 'actor_loss': np.float64(-1.0030638873577118), 'hyper_actor_loss': np.float64(0.0005722885252907872), 'behavior_loss': np.float64(0.33111594021320345)}
step: 14420 @ episode report: {'average_total_reward': np.float32(9.014445), 'reward_variance': np.float32(2.4398043), 'max_total_reward': np.float32(11.022223), 'min_total_reward': np.float32(6.533334), 'average_n_step': np.float32(10.2), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06790610402822495), 'actor_loss': np.float64(-0.9767800807952881), 'hyper_actor_loss': np.float64(0.0005787578469607979), 'behavior_loss': np.float64(0.32177948355674746)}
step: 14430 @ episode report: {'average_total_reward': np.float32(7.8655562), 'reward_variance': np.float32(3.3556905), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.1), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0623335987329483), 'actor_loss': np.float64(-0.9688905477523804), 'hyper_actor_loss': np.float64(0.0005725555471144617), 'behavior_loss': np.float64(0.3290617763996124)}
step: 14440 @ episode report: {'average_total_reward': np.float32(7.5555563), 'reward_variance': np.float32(2.7827907), 'max_total_reward': np.float32(10.655556), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(8.9), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07462692260742188), 'actor_loss': np.float64(-0.9932217836380005), 'hyper_actor_loss': np.float64(0.0006159965298138559), 'behavior_loss': np.float64(0.3242719531059265)}
step: 14450 @ episode report: {'average_total_reward': np.float32(8.08), 'reward_variance': np.float32(1.2058964), 'max_total_reward': np.float32(9.777779), 'min_total_reward': np.float32(6.533334), 'average_n_step': np.float32(9.4), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0862324010580778), 'actor_loss': np.float64(-1.018406879901886), 'hyper_actor_loss': np.float64(0.0006190428743138909), 'behavior_loss': np.float64(0.3218841016292572)}
step: 14460 @ episode report: {'average_total_reward': np.float32(7.304445), 'reward_variance': np.float32(2.1420786), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06816881485283374), 'actor_loss': np.float64(-1.0115946650505065), 'hyper_actor_loss': np.float64(0.0005612878885585815), 'behavior_loss': np.float64(0.3338100552558899)}
step: 14470 @ episode report: {'average_total_reward': np.float32(7.804445), 'reward_variance': np.float32(1.5127702), 'max_total_reward': np.float32(9.9), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(9.1), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06988363899290562), 'actor_loss': np.float64(-0.9778894782066345), 'hyper_actor_loss': np.float64(0.0005481301166582852), 'behavior_loss': np.float64(0.3286019593477249)}
step: 14480 @ episode report: {'average_total_reward': np.float32(6.757778), 'reward_variance': np.float32(1.5112299), 'max_total_reward': np.float32(7.7777786), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.2), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06140141375362873), 'actor_loss': np.float64(-0.9917541146278381), 'hyper_actor_loss': np.float64(0.0005253613198874518), 'behavior_loss': np.float64(0.3348812311887741)}
step: 14490 @ episode report: {'average_total_reward': np.float32(7.1555567), 'reward_variance': np.float32(2.2819514), 'max_total_reward': np.float32(9.900002), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(8.5), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0708239434286952), 'actor_loss': np.float64(-0.9758946061134338), 'hyper_actor_loss': np.float64(0.0005126330739585683), 'behavior_loss': np.float64(0.3278210937976837)}
step: 14500 @ episode report: {'average_total_reward': np.float32(7.0922227), 'reward_variance': np.float32(1.3879026), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07797965332865715), 'actor_loss': np.float64(-1.0151274383068085), 'hyper_actor_loss': np.float64(0.00047673264634795487), 'behavior_loss': np.float64(0.32979067265987394)}
step: 14510 @ episode report: {'average_total_reward': np.float32(8.053333), 'reward_variance': np.float32(1.5717237), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(9.3), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0721719939261675), 'actor_loss': np.float64(-0.9928159594535828), 'hyper_actor_loss': np.float64(0.00046569808619096876), 'behavior_loss': np.float64(0.32933673858642576)}
step: 14520 @ episode report: {'average_total_reward': np.float32(10.173334), 'reward_variance': np.float32(1.615091), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(8.777779), 'average_n_step': np.float32(11.2), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06143442690372467), 'actor_loss': np.float64(-0.9655876100063324), 'hyper_actor_loss': np.float64(0.00043351894710212945), 'behavior_loss': np.float64(0.3311213344335556)}
step: 14530 @ episode report: {'average_total_reward': np.float32(9.387777), 'reward_variance': np.float32(2.336431), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(10.5), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07789018712937831), 'actor_loss': np.float64(-0.9879594385623932), 'hyper_actor_loss': np.float64(0.00041308883810415865), 'behavior_loss': np.float64(0.33112606704235076)}
step: 14540 @ episode report: {'average_total_reward': np.float32(9.712223), 'reward_variance': np.float32(3.3563323), 'max_total_reward': np.float32(12.266666), 'min_total_reward': np.float32(6.533334), 'average_n_step': np.float32(10.8), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0686526469886303), 'actor_loss': np.float64(-0.9934085249900818), 'hyper_actor_loss': np.float64(0.00038559617241844534), 'behavior_loss': np.float64(0.3368764787912369)}
step: 14550 @ episode report: {'average_total_reward': np.float32(9.102222), 'reward_variance': np.float32(1.0356491), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(10.3), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0750187162309885), 'actor_loss': np.float64(-0.9952487885951996), 'hyper_actor_loss': np.float64(0.0006192366505274549), 'behavior_loss': np.float64(0.34473524391651156)}
step: 14560 @ episode report: {'average_total_reward': np.float32(5.596667), 'reward_variance': np.float32(1.5413841), 'max_total_reward': np.float32(7.6555557), 'min_total_reward': np.float32(4.166667), 'average_n_step': np.float32(7.1), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08107290305197239), 'actor_loss': np.float64(-0.9930966913700103), 'hyper_actor_loss': np.float64(0.0012572602892760188), 'behavior_loss': np.float64(0.3372210592031479)}
step: 14570 @ episode report: {'average_total_reward': np.float32(6.867778), 'reward_variance': np.float32(1.6707026), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(8.2), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06259798146784305), 'actor_loss': np.float64(-0.9773988008499146), 'hyper_actor_loss': np.float64(0.0017376225674524902), 'behavior_loss': np.float64(0.3213658958673477)}
step: 14580 @ episode report: {'average_total_reward': np.float32(10.310001), 'reward_variance': np.float32(2.6531475), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.5333333), 'average_n_step': np.float32(11.3), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07737045772373677), 'actor_loss': np.float64(-1.0045643985271453), 'hyper_actor_loss': np.float64(0.0012127775116823614), 'behavior_loss': np.float64(0.3133863598108292)}
step: 14590 @ episode report: {'average_total_reward': np.float32(10.334445), 'reward_variance': np.float32(3.6125798), 'max_total_reward': np.float32(14.511112), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(11.3), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07118870913982392), 'actor_loss': np.float64(-0.9918380081653595), 'hyper_actor_loss': np.float64(0.0008612921636085957), 'behavior_loss': np.float64(0.3105598598718643)}
step: 14600 @ episode report: {'average_total_reward': np.float32(10.31), 'reward_variance': np.float32(10.455813), 'max_total_reward': np.float32(14.266667), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(11.3), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0664601694792509), 'actor_loss': np.float64(-0.9910198450088501), 'hyper_actor_loss': np.float64(0.0007429417863022536), 'behavior_loss': np.float64(0.3089151605963707)}
step: 14610 @ episode report: {'average_total_reward': np.float32(10.6466675), 'reward_variance': np.float32(2.504391), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(8.9), 'average_n_step': np.float32(11.6), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06901805214583874), 'actor_loss': np.float64(-0.976000314950943), 'hyper_actor_loss': np.float64(0.0006682824634481222), 'behavior_loss': np.float64(0.3055187851190567)}
step: 14620 @ episode report: {'average_total_reward': np.float32(10.285555), 'reward_variance': np.float32(2.0102227), 'max_total_reward': np.float32(13.266666), 'min_total_reward': np.float32(8.900001), 'average_n_step': np.float32(11.3), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07285949401557446), 'actor_loss': np.float64(-0.9837070345878601), 'hyper_actor_loss': np.float64(0.0006706610613036901), 'behavior_loss': np.float64(0.3113936573266983)}
step: 14630 @ episode report: {'average_total_reward': np.float32(10.971112), 'reward_variance': np.float32(3.419141), 'max_total_reward': np.float32(14.144445), 'min_total_reward': np.float32(7.777778), 'average_n_step': np.float32(11.9), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07198521494865417), 'actor_loss': np.float64(-0.9959332466125488), 'hyper_actor_loss': np.float64(0.0006766462291125208), 'behavior_loss': np.float64(0.30867010951042173)}
step: 14640 @ episode report: {'average_total_reward': np.float32(9.873334), 'reward_variance': np.float32(2.4329927), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.9), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06923640016466379), 'actor_loss': np.float64(-0.9806955099105835), 'hyper_actor_loss': np.float64(0.0006993738294113428), 'behavior_loss': np.float64(0.3026592075824738)}
step: 14650 @ episode report: {'average_total_reward': np.float32(10.110001), 'reward_variance': np.float32(2.5881104), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(11.1), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0678941709920764), 'actor_loss': np.float64(-0.9779768645763397), 'hyper_actor_loss': np.float64(0.0008027241041418165), 'behavior_loss': np.float64(0.3098107397556305)}
step: 14660 @ episode report: {'average_total_reward': np.float32(11.095556), 'reward_variance': np.float32(1.6001284), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(8.655557), 'average_n_step': np.float32(12.0), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07142972461879253), 'actor_loss': np.float64(-0.9911141812801361), 'hyper_actor_loss': np.float64(0.0011320260004140438), 'behavior_loss': np.float64(0.31382368206977845)}
step: 14670 @ episode report: {'average_total_reward': np.float32(11.107779), 'reward_variance': np.float32(7.64173), 'max_total_reward': np.float32(15.633334), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(12.0), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07197786569595337), 'actor_loss': np.float64(-0.99504234790802), 'hyper_actor_loss': np.float64(0.0013999661430716514), 'behavior_loss': np.float64(0.30530022978782656)}
step: 14680 @ episode report: {'average_total_reward': np.float32(10.85889), 'reward_variance': np.float32(7.3430634), 'max_total_reward': np.float32(15.633334), 'min_total_reward': np.float32(7.533334), 'average_n_step': np.float32(11.8), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0750484000891447), 'actor_loss': np.float64(-0.9932743728160858), 'hyper_actor_loss': np.float64(0.0016764998086728155), 'behavior_loss': np.float64(0.31568631529808044)}
step: 14690 @ episode report: {'average_total_reward': np.float32(11.981112), 'reward_variance': np.float32(2.2536561), 'max_total_reward': np.float32(14.511112), 'min_total_reward': np.float32(10.0222225), 'average_n_step': np.float32(12.8), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(11.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06654997356235981), 'actor_loss': np.float64(-0.9926766514778137), 'hyper_actor_loss': np.float64(0.0015916768810711802), 'behavior_loss': np.float64(0.3032362848520279)}
step: 14700 @ episode report: {'average_total_reward': np.float32(11.632223), 'reward_variance': np.float32(1.9453943), 'max_total_reward': np.float32(14.511111), 'min_total_reward': np.float32(9.900001), 'average_n_step': np.float32(12.5), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(11.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07886395044624805), 'actor_loss': np.float64(-0.9927846848964691), 'hyper_actor_loss': np.float64(0.001064096431946382), 'behavior_loss': np.float64(0.3128503441810608)}
step: 14710 @ episode report: {'average_total_reward': np.float32(11.107779), 'reward_variance': np.float32(2.521903), 'max_total_reward': np.float32(14.511112), 'min_total_reward': np.float32(8.9), 'average_n_step': np.float32(12.0), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06401253547519445), 'actor_loss': np.float64(-0.9648660123348236), 'hyper_actor_loss': np.float64(0.0007457537634763866), 'behavior_loss': np.float64(0.3033447712659836)}
step: 14720 @ episode report: {'average_total_reward': np.float32(11.383333), 'reward_variance': np.float32(1.4638827), 'max_total_reward': np.float32(13.266666), 'min_total_reward': np.float32(9.777779), 'average_n_step': np.float32(12.3), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(11.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08011751547455788), 'actor_loss': np.float64(-0.9965624570846557), 'hyper_actor_loss': np.float64(0.0007063800934702158), 'behavior_loss': np.float64(0.29436555206775666)}
step: 14730 @ episode report: {'average_total_reward': np.float32(10.248889), 'reward_variance': np.float32(1.0710667), 'max_total_reward': np.float32(12.266666), 'min_total_reward': np.float32(8.777777), 'average_n_step': np.float32(11.3), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08478052541613579), 'actor_loss': np.float64(-1.0248118400573731), 'hyper_actor_loss': np.float64(0.0007316017290577292), 'behavior_loss': np.float64(0.2888108789920807)}
step: 14740 @ episode report: {'average_total_reward': np.float32(11.183334), 'reward_variance': np.float32(3.6596603), 'max_total_reward': np.float32(14.511111), 'min_total_reward': np.float32(8.777778), 'average_n_step': np.float32(12.1), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07367577813565732), 'actor_loss': np.float64(-0.996296501159668), 'hyper_actor_loss': np.float64(0.000901704712305218), 'behavior_loss': np.float64(0.2879014641046524)}
step: 14750 @ episode report: {'average_total_reward': np.float32(11.993334), 'reward_variance': np.float32(2.056005), 'max_total_reward': np.float32(14.511111), 'min_total_reward': np.float32(10.022223), 'average_n_step': np.float32(12.8), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(11.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06595805585384369), 'actor_loss': np.float64(-0.9871944844722748), 'hyper_actor_loss': np.float64(0.0010611625155434012), 'behavior_loss': np.float64(0.2890136867761612)}
step: 14760 @ episode report: {'average_total_reward': np.float32(11.993334), 'reward_variance': np.float32(2.981216), 'max_total_reward': np.float32(15.633334), 'min_total_reward': np.float32(9.9), 'average_n_step': np.float32(12.8), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(11.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06675781235098839), 'actor_loss': np.float64(-0.978138542175293), 'hyper_actor_loss': np.float64(0.0011534395278431475), 'behavior_loss': np.float64(0.28897368013858793)}
step: 14770 @ episode report: {'average_total_reward': np.float32(10.922222), 'reward_variance': np.float32(5.922544), 'max_total_reward': np.float32(15.633334), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(11.9), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.061202398501336575), 'actor_loss': np.float64(-0.9910377860069275), 'hyper_actor_loss': np.float64(0.0013458029134199023), 'behavior_loss': np.float64(0.29011426866054535)}
step: 14780 @ episode report: {'average_total_reward': np.float32(10.546667), 'reward_variance': np.float32(1.9556751), 'max_total_reward': np.float32(13.38889), 'min_total_reward': np.float32(8.655556), 'average_n_step': np.float32(11.5), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07055237106978893), 'actor_loss': np.float64(-0.9970990300178528), 'hyper_actor_loss': np.float64(0.0012498109834268689), 'behavior_loss': np.float64(0.2896580308675766)}
step: 14790 @ episode report: {'average_total_reward': np.float32(10.746668), 'reward_variance': np.float32(2.855551), 'max_total_reward': np.float32(14.511112), 'min_total_reward': np.float32(7.655556), 'average_n_step': np.float32(11.7), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07407118491828442), 'actor_loss': np.float64(-0.997175931930542), 'hyper_actor_loss': np.float64(0.0010556545399595051), 'behavior_loss': np.float64(0.2779108673334122)}
step: 14800 @ episode report: {'average_total_reward': np.float32(11.295556), 'reward_variance': np.float32(4.714919), 'max_total_reward': np.float32(14.511112), 'min_total_reward': np.float32(6.411111), 'average_n_step': np.float32(12.2), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06074910461902618), 'actor_loss': np.float64(-0.9951698958873749), 'hyper_actor_loss': np.float64(0.0008384393353480845), 'behavior_loss': np.float64(0.2869009330868721)}
step: 14810 @ episode report: {'average_total_reward': np.float32(11.15889), 'reward_variance': np.float32(5.8221006), 'max_total_reward': np.float32(15.633334), 'min_total_reward': np.float32(6.411111), 'average_n_step': np.float32(12.1), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06779108755290508), 'actor_loss': np.float64(-0.9619245052337646), 'hyper_actor_loss': np.float64(0.0007681134622544051), 'behavior_loss': np.float64(0.27883853316307067)}
step: 14820 @ episode report: {'average_total_reward': np.float32(13.103334), 'reward_variance': np.float32(2.0187185), 'max_total_reward': np.float32(15.144445), 'min_total_reward': np.float32(10.022222), 'average_n_step': np.float32(13.8), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(11.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0611000832170248), 'actor_loss': np.float64(-0.9831378221511841), 'hyper_actor_loss': np.float64(0.00074851083336398), 'behavior_loss': np.float64(0.28091617822647097)}
step: 14830 @ episode report: {'average_total_reward': np.float32(11.520001), 'reward_variance': np.float32(3.2051558), 'max_total_reward': np.float32(14.388889), 'min_total_reward': np.float32(7.777778), 'average_n_step': np.float32(12.4), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06857089437544346), 'actor_loss': np.float64(-1.0008289456367492), 'hyper_actor_loss': np.float64(0.0006761157012078911), 'behavior_loss': np.float64(0.26625014543533326)}
step: 14840 @ episode report: {'average_total_reward': np.float32(11.2322235), 'reward_variance': np.float32(5.186185), 'max_total_reward': np.float32(14.511112), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(12.1), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06003852151334286), 'actor_loss': np.float64(-0.9748783648014069), 'hyper_actor_loss': np.float64(0.0007609824766404927), 'behavior_loss': np.float64(0.2838087037205696)}
step: 14850 @ episode report: {'average_total_reward': np.float32(10.734446), 'reward_variance': np.float32(1.1468754), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(8.900001), 'average_n_step': np.float32(11.7), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.062356643937528135), 'actor_loss': np.float64(-0.9600948512554168), 'hyper_actor_loss': np.float64(0.0008268337172921747), 'behavior_loss': np.float64(0.2847586512565613)}
step: 14860 @ episode report: {'average_total_reward': np.float32(12.317778), 'reward_variance': np.float32(1.0589929), 'max_total_reward': np.float32(14.388889), 'min_total_reward': np.float32(11.144444), 'average_n_step': np.float32(13.1), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(12.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06318872608244419), 'actor_loss': np.float64(-0.9874765455722809), 'hyper_actor_loss': np.float64(0.0008526997349690646), 'behavior_loss': np.float64(0.28271550238132476)}
step: 14870 @ episode report: {'average_total_reward': np.float32(11.756667), 'reward_variance': np.float32(3.8352458), 'max_total_reward': np.float32(16.755556), 'min_total_reward': np.float32(10.0222225), 'average_n_step': np.float32(12.6), 'max_n_step': np.float32(17.0), 'min_n_step': np.float32(11.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06953472234308719), 'actor_loss': np.float64(-0.9971418440341949), 'hyper_actor_loss': np.float64(0.0008479806187096983), 'behavior_loss': np.float64(0.2936321198940277)}
step: 14880 @ episode report: {'average_total_reward': np.float32(10.622223), 'reward_variance': np.float32(2.091407), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(11.6), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06325655104592443), 'actor_loss': np.float64(-0.9661380469799041), 'hyper_actor_loss': np.float64(0.0007338964380323887), 'behavior_loss': np.float64(0.2804870083928108)}
step: 14890 @ episode report: {'average_total_reward': np.float32(11.332224), 'reward_variance': np.float32(1.9568018), 'max_total_reward': np.float32(14.511112), 'min_total_reward': np.float32(8.900001), 'average_n_step': np.float32(12.2), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0627055037766695), 'actor_loss': np.float64(-0.9817293226718903), 'hyper_actor_loss': np.float64(0.0006838383036665618), 'behavior_loss': np.float64(0.2862570911645889)}
step: 14900 @ episode report: {'average_total_reward': np.float32(11.095556), 'reward_variance': np.float32(2.1881785), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(8.9), 'average_n_step': np.float32(12.0), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07248565219342709), 'actor_loss': np.float64(-0.9905394732952117), 'hyper_actor_loss': np.float64(0.0006208252627402544), 'behavior_loss': np.float64(0.27843265384435656)}
step: 14910 @ episode report: {'average_total_reward': np.float32(11.532223), 'reward_variance': np.float32(2.3209996), 'max_total_reward': np.float32(14.511112), 'min_total_reward': np.float32(8.777778), 'average_n_step': np.float32(12.4), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07070802114903926), 'actor_loss': np.float64(-1.0003615498542786), 'hyper_actor_loss': np.float64(0.0005759752064477652), 'behavior_loss': np.float64(0.27682057619094846)}
step: 14920 @ episode report: {'average_total_reward': np.float32(11.917778), 'reward_variance': np.float32(2.7763507), 'max_total_reward': np.float32(14.511112), 'min_total_reward': np.float32(8.900001), 'average_n_step': np.float32(12.7), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06172298826277256), 'actor_loss': np.float64(-0.9712623536586762), 'hyper_actor_loss': np.float64(0.0005887933657504618), 'behavior_loss': np.float64(0.287287113070488)}
step: 14930 @ episode report: {'average_total_reward': np.float32(11.120001), 'reward_variance': np.float32(3.2797718), 'max_total_reward': np.float32(14.511111), 'min_total_reward': np.float32(8.900001), 'average_n_step': np.float32(12.0), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06663597859442234), 'actor_loss': np.float64(-0.9833053529262543), 'hyper_actor_loss': np.float64(0.0005626536498311907), 'behavior_loss': np.float64(0.2749759525060654)}
step: 14940 @ episode report: {'average_total_reward': np.float32(11.295557), 'reward_variance': np.float32(3.2390664), 'max_total_reward': np.float32(13.38889), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(12.2), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07308149263262749), 'actor_loss': np.float64(-1.0077812433242799), 'hyper_actor_loss': np.float64(0.0005742742621805518), 'behavior_loss': np.float64(0.2866459786891937)}
step: 14950 @ episode report: {'average_total_reward': np.float32(10.795557), 'reward_variance': np.float32(1.5718322), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(8.777778), 'average_n_step': np.float32(11.7), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07672876939177513), 'actor_loss': np.float64(-0.9895920634269715), 'hyper_actor_loss': np.float64(0.0005562025413382799), 'behavior_loss': np.float64(0.2838592931628227)}
step: 14960 @ episode report: {'average_total_reward': np.float32(11.120001), 'reward_variance': np.float32(1.7685139), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(8.900001), 'average_n_step': np.float32(12.0), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07755823843181134), 'actor_loss': np.float64(-0.9966043412685395), 'hyper_actor_loss': np.float64(0.0006465432234108448), 'behavior_loss': np.float64(0.2830022215843201)}
step: 14970 @ episode report: {'average_total_reward': np.float32(11.107779), 'reward_variance': np.float32(1.5143969), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(8.777778), 'average_n_step': np.float32(12.0), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0657985532656312), 'actor_loss': np.float64(-0.9983988046646118), 'hyper_actor_loss': np.float64(0.0006271513469982892), 'behavior_loss': np.float64(0.2719714492559433)}
step: 14980 @ episode report: {'average_total_reward': np.float32(11.556667), 'reward_variance': np.float32(3.054084), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(12.4), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07515673935413361), 'actor_loss': np.float64(-0.9826995670795441), 'hyper_actor_loss': np.float64(0.0006322802393697203), 'behavior_loss': np.float64(0.2884161382913589)}
step: 14990 @ episode report: {'average_total_reward': np.float32(12.081112), 'reward_variance': np.float32(3.881607), 'max_total_reward': np.float32(14.511111), 'min_total_reward': np.float32(8.777778), 'average_n_step': np.float32(12.9), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.050796670466661455), 'actor_loss': np.float64(-0.9671708941459656), 'hyper_actor_loss': np.float64(0.0006236361863557249), 'behavior_loss': np.float64(0.28453495651483535)}
step: 15000 @ episode report: {'average_total_reward': np.float32(11.095556), 'reward_variance': np.float32(0.7592149), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(9.900001), 'average_n_step': np.float32(12.0), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(11.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.060304447263479236), 'actor_loss': np.float64(-0.9725855171680451), 'hyper_actor_loss': np.float64(0.0006744583253748715), 'behavior_loss': np.float64(0.288239386677742)}
step: 15010 @ episode report: {'average_total_reward': np.float32(11.944445), 'reward_variance': np.float32(2.5231357), 'max_total_reward': np.float32(14.266666), 'min_total_reward': np.float32(8.900001), 'average_n_step': np.float32(12.8), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06263596061617135), 'actor_loss': np.float64(-0.9933299481868744), 'hyper_actor_loss': np.float64(0.0007438274216838181), 'behavior_loss': np.float64(0.27656024396419526)}
step: 15020 @ episode report: {'average_total_reward': np.float32(11.556667), 'reward_variance': np.float32(2.9473448), 'max_total_reward': np.float32(13.38889), 'min_total_reward': np.float32(7.777778), 'average_n_step': np.float32(12.4), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06683161109685898), 'actor_loss': np.float64(-0.9946601688861847), 'hyper_actor_loss': np.float64(0.0008883902570232749), 'behavior_loss': np.float64(0.26419693529605864)}
step: 15030 @ episode report: {'average_total_reward': np.float32(10.610001), 'reward_variance': np.float32(3.5608258), 'max_total_reward': np.float32(14.388889), 'min_total_reward': np.float32(7.655556), 'average_n_step': np.float32(11.6), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06508171036839486), 'actor_loss': np.float64(-0.993829733133316), 'hyper_actor_loss': np.float64(0.0009615990042220801), 'behavior_loss': np.float64(0.27075860649347305)}
step: 15040 @ episode report: {'average_total_reward': np.float32(11.583334), 'reward_variance': np.float32(4.187241), 'max_total_reward': np.float32(15.633334), 'min_total_reward': np.float32(8.655556), 'average_n_step': np.float32(12.5), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07511144876480103), 'actor_loss': np.float64(-0.9947262108325958), 'hyper_actor_loss': np.float64(0.0009020416124258191), 'behavior_loss': np.float64(0.272204726934433)}
step: 15050 @ episode report: {'average_total_reward': np.float32(10.6466675), 'reward_variance': np.float32(1.776193), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.777778), 'average_n_step': np.float32(11.6), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.059642478451132776), 'actor_loss': np.float64(-0.9919878780841828), 'hyper_actor_loss': np.float64(0.0007537469442468137), 'behavior_loss': np.float64(0.28669515550136565)}
step: 15060 @ episode report: {'average_total_reward': np.float32(11.095556), 'reward_variance': np.float32(2.218598), 'max_total_reward': np.float32(14.511112), 'min_total_reward': np.float32(9.900001), 'average_n_step': np.float32(12.0), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(11.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06260676849633455), 'actor_loss': np.float64(-0.9612004518508911), 'hyper_actor_loss': np.float64(0.0006606882379855961), 'behavior_loss': np.float64(0.2838164657354355)}
step: 15070 @ episode report: {'average_total_reward': np.float32(12.642222), 'reward_variance': np.float32(3.369749), 'max_total_reward': np.float32(15.511112), 'min_total_reward': np.float32(9.900001), 'average_n_step': np.float32(13.4), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(11.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05605654828250408), 'actor_loss': np.float64(-0.9814590096473694), 'hyper_actor_loss': np.float64(0.0007042764336802065), 'behavior_loss': np.float64(0.2768241032958031)}
step: 15080 @ episode report: {'average_total_reward': np.float32(11.844446), 'reward_variance': np.float32(4.49289), 'max_total_reward': np.float32(15.511112), 'min_total_reward': np.float32(8.655556), 'average_n_step': np.float32(12.7), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06718321712687611), 'actor_loss': np.float64(-0.9920373797416687), 'hyper_actor_loss': np.float64(0.0007863350212574006), 'behavior_loss': np.float64(0.2775808572769165)}
step: 15090 @ episode report: {'average_total_reward': np.float32(11.556668), 'reward_variance': np.float32(2.7199116), 'max_total_reward': np.float32(13.388888), 'min_total_reward': np.float32(8.900001), 'average_n_step': np.float32(12.4), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06321541219949722), 'actor_loss': np.float64(-0.9767119467258454), 'hyper_actor_loss': np.float64(0.000811453367350623), 'behavior_loss': np.float64(0.2691031157970428)}
step: 15100 @ episode report: {'average_total_reward': np.float32(12.678889), 'reward_variance': np.float32(3.223666), 'max_total_reward': np.float32(14.511111), 'min_total_reward': np.float32(8.9), 'average_n_step': np.float32(13.4), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06253464594483375), 'actor_loss': np.float64(-0.984712815284729), 'hyper_actor_loss': np.float64(0.0008313190715853125), 'behavior_loss': np.float64(0.27125130891799926)}
step: 15110 @ episode report: {'average_total_reward': np.float32(12.093335), 'reward_variance': np.float32(4.412696), 'max_total_reward': np.float32(15.511112), 'min_total_reward': np.float32(7.6555567), 'average_n_step': np.float32(12.9), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06858205422759056), 'actor_loss': np.float64(-0.9994908332824707), 'hyper_actor_loss': np.float64(0.0007650144398212433), 'behavior_loss': np.float64(0.27767023891210557)}
step: 15120 @ episode report: {'average_total_reward': np.float32(11.107779), 'reward_variance': np.float32(1.7662728), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(9.900001), 'average_n_step': np.float32(12.0), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(11.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06993235051631927), 'actor_loss': np.float64(-0.9924149692058564), 'hyper_actor_loss': np.float64(0.0007288757187779993), 'behavior_loss': np.float64(0.2766569942235947)}
step: 15130 @ episode report: {'average_total_reward': np.float32(12.205557), 'reward_variance': np.float32(4.7619576), 'max_total_reward': np.float32(14.511111), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(13.0), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06669502258300782), 'actor_loss': np.float64(-0.9998203575611114), 'hyper_actor_loss': np.float64(0.0007182103814557195), 'behavior_loss': np.float64(0.2886816024780273)}
step: 15140 @ episode report: {'average_total_reward': np.float32(11.095556), 'reward_variance': np.float32(6.3613396), 'max_total_reward': np.float32(15.633334), 'min_total_reward': np.float32(7.777778), 'average_n_step': np.float32(12.0), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0607906423509121), 'actor_loss': np.float64(-0.981923520565033), 'hyper_actor_loss': np.float64(0.0007266220112796873), 'behavior_loss': np.float64(0.275892673432827)}
step: 15150 @ episode report: {'average_total_reward': np.float32(11.244446), 'reward_variance': np.float32(3.3643951), 'max_total_reward': np.float32(14.511112), 'min_total_reward': np.float32(7.777778), 'average_n_step': np.float32(12.1), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05260218661278486), 'actor_loss': np.float64(-0.9794256091117859), 'hyper_actor_loss': np.float64(0.0008223894925322384), 'behavior_loss': np.float64(0.27019843757152556)}
step: 15160 @ episode report: {'average_total_reward': np.float32(11.432222), 'reward_variance': np.float32(4.530999), 'max_total_reward': np.float32(15.633334), 'min_total_reward': np.float32(8.900001), 'average_n_step': np.float32(12.3), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06317775025963783), 'actor_loss': np.float64(-0.9750918209552765), 'hyper_actor_loss': np.float64(0.0009163982118479908), 'behavior_loss': np.float64(0.279742431640625)}
step: 15170 @ episode report: {'average_total_reward': np.float32(11.307779), 'reward_variance': np.float32(3.9863725), 'max_total_reward': np.float32(14.38889), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(12.2), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06943114921450615), 'actor_loss': np.float64(-0.9938384652137756), 'hyper_actor_loss': np.float64(0.0010325582115910947), 'behavior_loss': np.float64(0.29364390969276427)}
step: 15180 @ episode report: {'average_total_reward': np.float32(12.31778), 'reward_variance': np.float32(1.9517839), 'max_total_reward': np.float32(14.511112), 'min_total_reward': np.float32(9.777778), 'average_n_step': np.float32(13.1), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(11.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07380523569881917), 'actor_loss': np.float64(-0.9936980843544007), 'hyper_actor_loss': np.float64(0.0011328579159453512), 'behavior_loss': np.float64(0.2861766189336777)}
step: 15190 @ episode report: {'average_total_reward': np.float32(10.983335), 'reward_variance': np.float32(2.0690923), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(8.900001), 'average_n_step': np.float32(11.9), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0670294489711523), 'actor_loss': np.float64(-0.988231098651886), 'hyper_actor_loss': np.float64(0.00113794436911121), 'behavior_loss': np.float64(0.302498397231102)}
step: 15200 @ episode report: {'average_total_reward': np.float32(10.85889), 'reward_variance': np.float32(2.3653846), 'max_total_reward': np.float32(13.38889), 'min_total_reward': np.float32(8.900001), 'average_n_step': np.float32(11.8), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07144413217902183), 'actor_loss': np.float64(-0.9868209779262542), 'hyper_actor_loss': np.float64(0.001041572546819225), 'behavior_loss': np.float64(0.27567584067583084)}
step: 15210 @ episode report: {'average_total_reward': np.float32(11.432223), 'reward_variance': np.float32(6.975445), 'max_total_reward': np.float32(14.38889), 'min_total_reward': np.float32(5.655556), 'average_n_step': np.float32(12.3), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.061574846133589746), 'actor_loss': np.float64(-1.002144557237625), 'hyper_actor_loss': np.float64(0.0009132769075222314), 'behavior_loss': np.float64(0.29235700964927674)}
step: 15220 @ episode report: {'average_total_reward': np.float32(12.330001), 'reward_variance': np.float32(2.761384), 'max_total_reward': np.float32(14.511111), 'min_total_reward': np.float32(10.0222225), 'average_n_step': np.float32(13.1), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(11.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07117370404303074), 'actor_loss': np.float64(-0.9702605426311492), 'hyper_actor_loss': np.float64(0.0009049033455085009), 'behavior_loss': np.float64(0.297303731739521)}
step: 15230 @ episode report: {'average_total_reward': np.float32(11.968889), 'reward_variance': np.float32(4.1503167), 'max_total_reward': np.float32(15.511112), 'min_total_reward': np.float32(8.777778), 'average_n_step': np.float32(12.8), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0551990469917655), 'actor_loss': np.float64(-0.9980047941207886), 'hyper_actor_loss': np.float64(0.0008489639323670418), 'behavior_loss': np.float64(0.27819679826498034)}
step: 15240 @ episode report: {'average_total_reward': np.float32(11.76889), 'reward_variance': np.float32(3.5393283), 'max_total_reward': np.float32(15.633334), 'min_total_reward': np.float32(8.900001), 'average_n_step': np.float32(12.6), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07493838928639888), 'actor_loss': np.float64(-0.9794860124588013), 'hyper_actor_loss': np.float64(0.000863835820928216), 'behavior_loss': np.float64(0.3045796602964401)}
step: 15250 @ episode report: {'average_total_reward': np.float32(11.195557), 'reward_variance': np.float32(3.0221276), 'max_total_reward': np.float32(14.388889), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(12.1), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07029360122978687), 'actor_loss': np.float64(-0.9995007038116455), 'hyper_actor_loss': np.float64(0.0009056701324880123), 'behavior_loss': np.float64(0.2948965221643448)}
step: 15260 @ episode report: {'average_total_reward': np.float32(12.33), 'reward_variance': np.float32(2.200767), 'max_total_reward': np.float32(14.511112), 'min_total_reward': np.float32(10.0222225), 'average_n_step': np.float32(13.1), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(11.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0564126942306757), 'actor_loss': np.float64(-0.9751639842987061), 'hyper_actor_loss': np.float64(0.0009279566758777947), 'behavior_loss': np.float64(0.27471187710762024)}
step: 15270 @ episode report: {'average_total_reward': np.float32(10.822223), 'reward_variance': np.float32(2.0233579), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(8.533334), 'average_n_step': np.float32(11.8), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05959860756993294), 'actor_loss': np.float64(-0.9725358664989472), 'hyper_actor_loss': np.float64(0.0009428268007468432), 'behavior_loss': np.float64(0.2831667482852936)}
step: 15280 @ episode report: {'average_total_reward': np.float32(10.685556), 'reward_variance': np.float32(2.952273), 'max_total_reward': np.float32(13.38889), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(11.7), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06256236173212529), 'actor_loss': np.float64(-0.9898372888565063), 'hyper_actor_loss': np.float64(0.000977886375039816), 'behavior_loss': np.float64(0.2741837829351425)}
step: 15290 @ episode report: {'average_total_reward': np.float32(10.710001), 'reward_variance': np.float32(4.3193207), 'max_total_reward': np.float32(15.511112), 'min_total_reward': np.float32(8.655556), 'average_n_step': np.float32(11.7), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05604254715144634), 'actor_loss': np.float64(-0.9863136649131775), 'hyper_actor_loss': np.float64(0.0010091680102050304), 'behavior_loss': np.float64(0.2733371779322624)}
step: 15300 @ episode report: {'average_total_reward': np.float32(11.495557), 'reward_variance': np.float32(7.002055), 'max_total_reward': np.float32(15.633333), 'min_total_reward': np.float32(7.777778), 'average_n_step': np.float32(12.4), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06528884135186672), 'actor_loss': np.float64(-0.9890008509159088), 'hyper_actor_loss': np.float64(0.0010502049291972071), 'behavior_loss': np.float64(0.27235368341207505)}
step: 15310 @ episode report: {'average_total_reward': np.float32(11.981112), 'reward_variance': np.float32(4.372422), 'max_total_reward': np.float32(15.633334), 'min_total_reward': np.float32(8.777778), 'average_n_step': np.float32(12.8), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06518000010401011), 'actor_loss': np.float64(-0.98144890666008), 'hyper_actor_loss': np.float64(0.0011310973204672337), 'behavior_loss': np.float64(0.2818943843245506)}
step: 15320 @ episode report: {'average_total_reward': np.float32(10.322223), 'reward_variance': np.float32(4.07842), 'max_total_reward': np.float32(12.266666), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(11.3), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0702091570943594), 'actor_loss': np.float64(-0.9956314742565155), 'hyper_actor_loss': np.float64(0.0011638086871244013), 'behavior_loss': np.float64(0.2813865438103676)}
step: 15330 @ episode report: {'average_total_reward': np.float32(10.51), 'reward_variance': np.float32(2.733443), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(11.5), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06529647149145604), 'actor_loss': np.float64(-1.004762876033783), 'hyper_actor_loss': np.float64(0.0012179906712844967), 'behavior_loss': np.float64(0.2867374524474144)}
step: 15340 @ episode report: {'average_total_reward': np.float32(11.207779), 'reward_variance': np.float32(3.4601502), 'max_total_reward': np.float32(14.511112), 'min_total_reward': np.float32(8.655556), 'average_n_step': np.float32(12.1), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07526292242109775), 'actor_loss': np.float64(-0.9795091450214386), 'hyper_actor_loss': np.float64(0.0012149592977948487), 'behavior_loss': np.float64(0.29607344418764114)}
step: 15350 @ episode report: {'average_total_reward': np.float32(10.073334), 'reward_variance': np.float32(2.9044254), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(11.1), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07065146788954735), 'actor_loss': np.float64(-1.0003496885299683), 'hyper_actor_loss': np.float64(0.0010986507055349647), 'behavior_loss': np.float64(0.27722572535276413)}
step: 15360 @ episode report: {'average_total_reward': np.float32(9.948889), 'reward_variance': np.float32(3.2535348), 'max_total_reward': np.float32(14.511111), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(11.0), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.059060953184962274), 'actor_loss': np.float64(-1.0054775655269623), 'hyper_actor_loss': np.float64(0.0012373923789709806), 'behavior_loss': np.float64(0.2712766945362091)}
step: 15370 @ episode report: {'average_total_reward': np.float32(10.297778), 'reward_variance': np.float32(3.4221425), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(7.777778), 'average_n_step': np.float32(11.3), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05988570377230644), 'actor_loss': np.float64(-0.9659975230693817), 'hyper_actor_loss': np.float64(0.0016845338279381395), 'behavior_loss': np.float64(0.2803203076124191)}
step: 15380 @ episode report: {'average_total_reward': np.float32(8.302222), 'reward_variance': np.float32(2.303798), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.5), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07002627551555633), 'actor_loss': np.float64(-0.9942757368087769), 'hyper_actor_loss': np.float64(0.0019016827689483761), 'behavior_loss': np.float64(0.2903663799166679)}
step: 15390 @ episode report: {'average_total_reward': np.float32(9.900001), 'reward_variance': np.float32(4.750173), 'max_total_reward': np.float32(13.144444), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(11.0), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07380703650414944), 'actor_loss': np.float64(-1.0253352522850037), 'hyper_actor_loss': np.float64(0.001793121627997607), 'behavior_loss': np.float64(0.2941111817955971)}
step: 15400 @ episode report: {'average_total_reward': np.float32(7.4288893), 'reward_variance': np.float32(4.5838566), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(8.7), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06736431196331978), 'actor_loss': np.float64(-1.0025550544261932), 'hyper_actor_loss': np.float64(0.0018997402512468398), 'behavior_loss': np.float64(0.2830623805522919)}
step: 15410 @ episode report: {'average_total_reward': np.float32(7.231112), 'reward_variance': np.float32(7.4070334), 'max_total_reward': np.float32(11.900001), 'min_total_reward': np.float32(3.1666667), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07108146212995052), 'actor_loss': np.float64(-0.9933974385261536), 'hyper_actor_loss': np.float64(0.0017452292726375163), 'behavior_loss': np.float64(0.27225730419158933)}
step: 15420 @ episode report: {'average_total_reward': np.float32(8.316668), 'reward_variance': np.float32(1.9973638), 'max_total_reward': np.float32(10.900001), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.6), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06614529527723789), 'actor_loss': np.float64(-1.031057596206665), 'hyper_actor_loss': np.float64(0.0019196929410099984), 'behavior_loss': np.float64(0.27697878181934354)}
step: 15430 @ episode report: {'average_total_reward': np.float32(7.504445), 'reward_variance': np.float32(3.712401), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(8.8), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05925377644598484), 'actor_loss': np.float64(-1.013557243347168), 'hyper_actor_loss': np.float64(0.0022527049062773586), 'behavior_loss': np.float64(0.2740601822733879)}
step: 15440 @ episode report: {'average_total_reward': np.float32(7.2922225), 'reward_variance': np.float32(4.883039), 'max_total_reward': np.float32(10.900001), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05491927079856396), 'actor_loss': np.float64(-0.9891043245792389), 'hyper_actor_loss': np.float64(0.0024436152772977946), 'behavior_loss': np.float64(0.2874105989933014)}
step: 15450 @ episode report: {'average_total_reward': np.float32(7.5433335), 'reward_variance': np.float32(1.1173202), 'max_total_reward': np.float32(8.900002), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(8.9), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06017786003649235), 'actor_loss': np.float64(-0.9993343949317932), 'hyper_actor_loss': np.float64(0.002126239216886461), 'behavior_loss': np.float64(0.28268924355506897)}
step: 15460 @ episode report: {'average_total_reward': np.float32(7.018889), 'reward_variance': np.float32(2.5592859), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(4.411111), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0673899620771408), 'actor_loss': np.float64(-1.011963999271393), 'hyper_actor_loss': np.float64(0.0020651552942581473), 'behavior_loss': np.float64(0.3025604099035263)}
step: 15470 @ episode report: {'average_total_reward': np.float32(6.867778), 'reward_variance': np.float32(1.3365301), 'max_total_reward': np.float32(8.900002), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(8.2), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07250988371670246), 'actor_loss': np.float64(-1.0037200272083282), 'hyper_actor_loss': np.float64(0.0019287158735096454), 'behavior_loss': np.float64(0.30776546597480775)}
step: 15480 @ episode report: {'average_total_reward': np.float32(7.5288887), 'reward_variance': np.float32(3.032375), 'max_total_reward': np.float32(10.022222), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(8.8), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06273480784147978), 'actor_loss': np.float64(-0.9843732118606567), 'hyper_actor_loss': np.float64(0.0018682566937059165), 'behavior_loss': np.float64(0.30126955807209016)}
step: 15490 @ episode report: {'average_total_reward': np.float32(7.7288895), 'reward_variance': np.float32(1.3622029), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.0), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07295038625597954), 'actor_loss': np.float64(-1.0030617356300353), 'hyper_actor_loss': np.float64(0.0018085832474753261), 'behavior_loss': np.float64(0.32517187893390653)}
step: 15500 @ episode report: {'average_total_reward': np.float32(7.853334), 'reward_variance': np.float32(2.8878484), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(9.1), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06529796831309795), 'actor_loss': np.float64(-0.9826790690422058), 'hyper_actor_loss': np.float64(0.0017252723220735789), 'behavior_loss': np.float64(0.30760557055473325)}
step: 15510 @ episode report: {'average_total_reward': np.float32(9.587779), 'reward_variance': np.float32(2.3925796), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.411111), 'average_n_step': np.float32(10.7), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.060965605080127716), 'actor_loss': np.float64(-0.9794823706150055), 'hyper_actor_loss': np.float64(0.001854794647078961), 'behavior_loss': np.float64(0.3091802716255188)}
step: 15520 @ episode report: {'average_total_reward': np.float32(10.410001), 'reward_variance': np.float32(2.1269736), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(8.777779), 'average_n_step': np.float32(11.4), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08161506168544293), 'actor_loss': np.float64(-1.0001977145671845), 'hyper_actor_loss': np.float64(0.0018224686151370405), 'behavior_loss': np.float64(0.3050220012664795)}
step: 15530 @ episode report: {'average_total_reward': np.float32(10.95889), 'reward_variance': np.float32(1.8391619), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(11.9), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05702981762588024), 'actor_loss': np.float64(-0.9796465992927551), 'hyper_actor_loss': np.float64(0.0016468134592287243), 'behavior_loss': np.float64(0.2974701106548309)}
step: 15540 @ episode report: {'average_total_reward': np.float32(10.297778), 'reward_variance': np.float32(1.9108852), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(11.3), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07294304370880127), 'actor_loss': np.float64(-0.995996105670929), 'hyper_actor_loss': np.float64(0.0015861207153648137), 'behavior_loss': np.float64(0.29098246693611146)}
step: 15550 @ episode report: {'average_total_reward': np.float32(10.771112), 'reward_variance': np.float32(2.3676596), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(11.7), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05528264343738556), 'actor_loss': np.float64(-0.9916751921176911), 'hyper_actor_loss': np.float64(0.0015679297270253302), 'behavior_loss': np.float64(0.29396034628152845)}
step: 15560 @ episode report: {'average_total_reward': np.float32(10.5222225), 'reward_variance': np.float32(3.3578026), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(11.5), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06269816979765892), 'actor_loss': np.float64(-0.9517487764358521), 'hyper_actor_loss': np.float64(0.0016101083485409618), 'behavior_loss': np.float64(0.30805512964725495)}
step: 15570 @ episode report: {'average_total_reward': np.float32(10.434444), 'reward_variance': np.float32(3.3363814), 'max_total_reward': np.float32(13.388888), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(11.4), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06549643017351628), 'actor_loss': np.float64(-0.9858219623565674), 'hyper_actor_loss': np.float64(0.0017462832969613374), 'behavior_loss': np.float64(0.2987171232700348)}
step: 15580 @ episode report: {'average_total_reward': np.float32(11.607779), 'reward_variance': np.float32(2.0344703), 'max_total_reward': np.float32(13.388888), 'min_total_reward': np.float32(8.777778), 'average_n_step': np.float32(12.5), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06361961588263512), 'actor_loss': np.float64(-1.0019829094409942), 'hyper_actor_loss': np.float64(0.0016081571578979493), 'behavior_loss': np.float64(0.28927266150712966)}
step: 15590 @ episode report: {'average_total_reward': np.float32(11.25889), 'reward_variance': np.float32(2.1694586), 'max_total_reward': np.float32(13.38889), 'min_total_reward': np.float32(8.655556), 'average_n_step': np.float32(12.2), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.062373198196291925), 'actor_loss': np.float64(-0.9840485751628876), 'hyper_actor_loss': np.float64(0.0015422716038301586), 'behavior_loss': np.float64(0.2772997424006462)}
step: 15600 @ episode report: {'average_total_reward': np.float32(11.220001), 'reward_variance': np.float32(1.7486868), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(8.655556), 'average_n_step': np.float32(12.1), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0717228926718235), 'actor_loss': np.float64(-0.9981637537479401), 'hyper_actor_loss': np.float64(0.0014580142451450229), 'behavior_loss': np.float64(0.29255310595035555)}
step: 15610 @ episode report: {'average_total_reward': np.float32(10.910001), 'reward_variance': np.float32(1.7158629), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(8.900001), 'average_n_step': np.float32(11.9), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07042567580938339), 'actor_loss': np.float64(-1.001126879453659), 'hyper_actor_loss': np.float64(0.0013547934242524207), 'behavior_loss': np.float64(0.3092411383986473)}
step: 15620 @ episode report: {'average_total_reward': np.float32(10.846667), 'reward_variance': np.float32(1.5138468), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(8.777779), 'average_n_step': np.float32(11.8), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06826020143926144), 'actor_loss': np.float64(-0.9817891001701355), 'hyper_actor_loss': np.float64(0.0012369367759674788), 'behavior_loss': np.float64(0.296124792098999)}
step: 15630 @ episode report: {'average_total_reward': np.float32(11.495557), 'reward_variance': np.float32(5.295783), 'max_total_reward': np.float32(14.511112), 'min_total_reward': np.float32(7.655556), 'average_n_step': np.float32(12.4), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06515937522053719), 'actor_loss': np.float64(-0.9988470196723938), 'hyper_actor_loss': np.float64(0.0011580077232792973), 'behavior_loss': np.float64(0.2844834208488464)}
step: 15640 @ episode report: {'average_total_reward': np.float32(10.361112), 'reward_variance': np.float32(2.5165985), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.777778), 'average_n_step': np.float32(11.4), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07014190107584), 'actor_loss': np.float64(-0.996903932094574), 'hyper_actor_loss': np.float64(0.0010119765473064035), 'behavior_loss': np.float64(0.2971750766038895)}
step: 15650 @ episode report: {'average_total_reward': np.float32(10.048889), 'reward_variance': np.float32(3.4055603), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(7.6555567), 'average_n_step': np.float32(11.1), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.074354712292552), 'actor_loss': np.float64(-0.9892128229141235), 'hyper_actor_loss': np.float64(0.0009215207130182535), 'behavior_loss': np.float64(0.28290700614452363)}
step: 15660 @ episode report: {'average_total_reward': np.float32(10.85889), 'reward_variance': np.float32(0.90898925), 'max_total_reward': np.float32(12.266668), 'min_total_reward': np.float32(9.900001), 'average_n_step': np.float32(11.8), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(11.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06323351040482521), 'actor_loss': np.float64(-0.9942398011684418), 'hyper_actor_loss': np.float64(0.0008537154644727707), 'behavior_loss': np.float64(0.2911934837698936)}
step: 15670 @ episode report: {'average_total_reward': np.float32(10.683334), 'reward_variance': np.float32(1.5520067), 'max_total_reward': np.float32(12.266668), 'min_total_reward': np.float32(7.777778), 'average_n_step': np.float32(11.6), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.058857477456331256), 'actor_loss': np.float64(-0.9703676521778106), 'hyper_actor_loss': np.float64(0.0008154717332217842), 'behavior_loss': np.float64(0.2742352902889252)}
step: 15680 @ episode report: {'average_total_reward': np.float32(9.7), 'reward_variance': np.float32(2.0812106), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(7.288889), 'average_n_step': np.float32(10.8), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06803971230983734), 'actor_loss': np.float64(-0.986033707857132), 'hyper_actor_loss': np.float64(0.0008100235543679446), 'behavior_loss': np.float64(0.28901381492614747)}
step: 15690 @ episode report: {'average_total_reward': np.float32(11.120001), 'reward_variance': np.float32(5.154638), 'max_total_reward': np.float32(15.511112), 'min_total_reward': np.float32(8.9), 'average_n_step': np.float32(12.0), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07647592537105083), 'actor_loss': np.float64(-1.007578146457672), 'hyper_actor_loss': np.float64(0.0007816789497155696), 'behavior_loss': np.float64(0.29753231406211855)}
step: 15700 @ episode report: {'average_total_reward': np.float32(11.183334), 'reward_variance': np.float32(1.872081), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(8.900001), 'average_n_step': np.float32(12.1), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06897099483758211), 'actor_loss': np.float64(-0.9965362846851349), 'hyper_actor_loss': np.float64(0.0007444903196301312), 'behavior_loss': np.float64(0.28963613957166673)}
step: 15710 @ episode report: {'average_total_reward': np.float32(11.083334), 'reward_variance': np.float32(1.3454139), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(9.899999), 'average_n_step': np.float32(12.0), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(11.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.058676678128540515), 'actor_loss': np.float64(-0.9817960798740387), 'hyper_actor_loss': np.float64(0.000737852236488834), 'behavior_loss': np.float64(0.26941708475351334)}
step: 15720 @ episode report: {'average_total_reward': np.float32(11.993334), 'reward_variance': np.float32(2.1462767), 'max_total_reward': np.float32(14.388889), 'min_total_reward': np.float32(8.900001), 'average_n_step': np.float32(12.8), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06725334450602531), 'actor_loss': np.float64(-0.9857320308685302), 'hyper_actor_loss': np.float64(0.0006802774441894144), 'behavior_loss': np.float64(0.3000920295715332)}
step: 15730 @ episode report: {'average_total_reward': np.float32(11.307779), 'reward_variance': np.float32(3.6796308), 'max_total_reward': np.float32(14.388889), 'min_total_reward': np.float32(8.777778), 'average_n_step': np.float32(12.2), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06137018501758575), 'actor_loss': np.float64(-0.9771318733692169), 'hyper_actor_loss': np.float64(0.0006841647904366255), 'behavior_loss': np.float64(0.3118650481104851)}
step: 15740 @ episode report: {'average_total_reward': np.float32(10.373334), 'reward_variance': np.float32(1.7126474), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(7.5333333), 'average_n_step': np.float32(11.4), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06908567175269127), 'actor_loss': np.float64(-0.9705225646495819), 'hyper_actor_loss': np.float64(0.0006622916960623115), 'behavior_loss': np.float64(0.3086395710706711)}
step: 15750 @ episode report: {'average_total_reward': np.float32(11.307779), 'reward_variance': np.float32(3.7619274), 'max_total_reward': np.float32(14.511111), 'min_total_reward': np.float32(8.777778), 'average_n_step': np.float32(12.2), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06856329403817654), 'actor_loss': np.float64(-0.9977139353752136), 'hyper_actor_loss': np.float64(0.000692658091429621), 'behavior_loss': np.float64(0.2906217098236084)}
step: 15760 @ episode report: {'average_total_reward': np.float32(10.746668), 'reward_variance': np.float32(3.6191554), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(7.777778), 'average_n_step': np.float32(11.7), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06709755733609199), 'actor_loss': np.float64(-0.9953120410442352), 'hyper_actor_loss': np.float64(0.0006971500639338047), 'behavior_loss': np.float64(0.28286526501178744)}
step: 15770 @ episode report: {'average_total_reward': np.float32(10.161112), 'reward_variance': np.float32(2.847093), 'max_total_reward': np.float32(14.511111), 'min_total_reward': np.float32(8.655556), 'average_n_step': np.float32(11.2), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0714301835745573), 'actor_loss': np.float64(-0.9951360762119293), 'hyper_actor_loss': np.float64(0.0007018906646408141), 'behavior_loss': np.float64(0.28223406821489333)}
step: 15780 @ episode report: {'average_total_reward': np.float32(10.210001), 'reward_variance': np.float32(5.1324306), 'max_total_reward': np.float32(14.266667), 'min_total_reward': np.float32(5.655556), 'average_n_step': np.float32(11.2), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06620477177202702), 'actor_loss': np.float64(-1.0000448286533357), 'hyper_actor_loss': np.float64(0.0006993191374931485), 'behavior_loss': np.float64(0.3038403481245041)}
step: 15790 @ episode report: {'average_total_reward': np.float32(10.710001), 'reward_variance': np.float32(2.1072955), 'max_total_reward': np.float32(14.511112), 'min_total_reward': np.float32(9.777778), 'average_n_step': np.float32(11.7), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(11.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06718582585453987), 'actor_loss': np.float64(-0.9873433947563172), 'hyper_actor_loss': np.float64(0.0006814164924435317), 'behavior_loss': np.float64(0.28529195189476014)}
step: 15800 @ episode report: {'average_total_reward': np.float32(10.485556), 'reward_variance': np.float32(1.3581499), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(8.777778), 'average_n_step': np.float32(11.5), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06899514570832252), 'actor_loss': np.float64(-0.9862406432628632), 'hyper_actor_loss': np.float64(0.0007392892090138048), 'behavior_loss': np.float64(0.3029545992612839)}
step: 15810 @ episode report: {'average_total_reward': np.float32(10.385556), 'reward_variance': np.float32(1.9238781), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(8.655556), 'average_n_step': np.float32(11.4), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06285016611218452), 'actor_loss': np.float64(-1.001233834028244), 'hyper_actor_loss': np.float64(0.0007496886944863945), 'behavior_loss': np.float64(0.29101183116436)}
step: 15820 @ episode report: {'average_total_reward': np.float32(10.222223), 'reward_variance': np.float32(1.9779999), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(8.777779), 'average_n_step': np.float32(11.2), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06932081282138824), 'actor_loss': np.float64(-0.9952614188194275), 'hyper_actor_loss': np.float64(0.0008107334957458079), 'behavior_loss': np.float64(0.2812396794557571)}
step: 15830 @ episode report: {'average_total_reward': np.float32(9.736667), 'reward_variance': np.float32(2.3653836), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(10.8), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.058281140960752965), 'actor_loss': np.float64(-0.9936237633228302), 'hyper_actor_loss': np.float64(0.0009099611139390618), 'behavior_loss': np.float64(0.2796495959162712)}
step: 15840 @ episode report: {'average_total_reward': np.float32(10.285556), 'reward_variance': np.float32(2.6471627), 'max_total_reward': np.float32(13.144445), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(11.3), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07433336526155472), 'actor_loss': np.float64(-0.9888828039169312), 'hyper_actor_loss': np.float64(0.0010191780922468752), 'behavior_loss': np.float64(0.3170574188232422)}
step: 15850 @ episode report: {'average_total_reward': np.float32(9.051111), 'reward_variance': np.float32(2.7597587), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(10.2), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.060204706341028216), 'actor_loss': np.float64(-1.0048687875270843), 'hyper_actor_loss': np.float64(0.0010385322326328605), 'behavior_loss': np.float64(0.3015452787280083)}
step: 15860 @ episode report: {'average_total_reward': np.float32(10.95889), 'reward_variance': np.float32(3.3534093), 'max_total_reward': np.float32(14.388889), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(11.9), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0730638138949871), 'actor_loss': np.float64(-0.9991261959075928), 'hyper_actor_loss': np.float64(0.0010323909926228225), 'behavior_loss': np.float64(0.30034138560295104)}
step: 15870 @ episode report: {'average_total_reward': np.float32(10.461111), 'reward_variance': np.float32(2.6789703), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(11.5), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06927424333989621), 'actor_loss': np.float64(-0.9914552986621856), 'hyper_actor_loss': np.float64(0.0010841163515578956), 'behavior_loss': np.float64(0.3042937681078911)}
step: 15880 @ episode report: {'average_total_reward': np.float32(9.400001), 'reward_variance': np.float32(1.1457775), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(7.655556), 'average_n_step': np.float32(10.5), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06661032978445292), 'actor_loss': np.float64(-1.0094488382339477), 'hyper_actor_loss': np.float64(0.0011032869922928512), 'behavior_loss': np.float64(0.29863532781600954)}
step: 15890 @ episode report: {'average_total_reward': np.float32(10.297778), 'reward_variance': np.float32(2.5517979), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(6.655556), 'average_n_step': np.float32(11.3), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07562128975987434), 'actor_loss': np.float64(-1.0057860136032104), 'hyper_actor_loss': np.float64(0.001207711372990161), 'behavior_loss': np.float64(0.3010447919368744)}
step: 15900 @ episode report: {'average_total_reward': np.float32(9.824445), 'reward_variance': np.float32(2.85244), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(6.655556), 'average_n_step': np.float32(10.9), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.071888442710042), 'actor_loss': np.float64(-1.0121578693389892), 'hyper_actor_loss': np.float64(0.001391048275399953), 'behavior_loss': np.float64(0.29550653845071795)}
step: 15910 @ episode report: {'average_total_reward': np.float32(9.948889), 'reward_variance': np.float32(2.7772155), 'max_total_reward': np.float32(13.38889), 'min_total_reward': np.float32(7.777778), 'average_n_step': np.float32(11.0), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07219205796718597), 'actor_loss': np.float64(-1.0061203002929688), 'hyper_actor_loss': np.float64(0.001427569251973182), 'behavior_loss': np.float64(0.2883146062493324)}
step: 15920 @ episode report: {'average_total_reward': np.float32(8.702223), 'reward_variance': np.float32(0.6314521), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(7.533334), 'average_n_step': np.float32(9.9), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05949143134057522), 'actor_loss': np.float64(-1.0210946559906007), 'hyper_actor_loss': np.float64(0.0013872369192540646), 'behavior_loss': np.float64(0.2916090950369835)}
step: 15930 @ episode report: {'average_total_reward': np.float32(7.6166673), 'reward_variance': np.float32(4.415289), 'max_total_reward': np.float32(12.266666), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(8.9), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06167342942208052), 'actor_loss': np.float64(-0.9705447375774383), 'hyper_actor_loss': np.float64(0.0012962386012077332), 'behavior_loss': np.float64(0.3046129524707794)}
step: 15940 @ episode report: {'average_total_reward': np.float32(8.465556), 'reward_variance': np.float32(1.9152702), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(6.533334), 'average_n_step': np.float32(9.7), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0702974334359169), 'actor_loss': np.float64(-1.0022509276866913), 'hyper_actor_loss': np.float64(0.001145233027637005), 'behavior_loss': np.float64(0.26174641996622083)}
step: 15950 @ episode report: {'average_total_reward': np.float32(8.826667), 'reward_variance': np.float32(3.0261033), 'max_total_reward': np.float32(12.144444), 'min_total_reward': np.float32(6.533334), 'average_n_step': np.float32(10.0), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0625192265957594), 'actor_loss': np.float64(-1.0192854881286622), 'hyper_actor_loss': np.float64(0.0010810497449710965), 'behavior_loss': np.float64(0.2703075408935547)}
step: 15960 @ episode report: {'average_total_reward': np.float32(9.400001), 'reward_variance': np.float32(4.817186), 'max_total_reward': np.float32(13.38889), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.5), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06901179235428571), 'actor_loss': np.float64(-0.9670788705348968), 'hyper_actor_loss': np.float64(0.0009994489315431564), 'behavior_loss': np.float64(0.3096273273229599)}
step: 15970 @ episode report: {'average_total_reward': np.float32(8.951113), 'reward_variance': np.float32(1.4205976), 'max_total_reward': np.float32(11.0222225), 'min_total_reward': np.float32(7.533334), 'average_n_step': np.float32(10.1), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08057377114892006), 'actor_loss': np.float64(-0.9924830675125123), 'hyper_actor_loss': np.float64(0.00090899677015841), 'behavior_loss': np.float64(0.3122636616230011)}
step: 15980 @ episode report: {'average_total_reward': np.float32(10.497778), 'reward_variance': np.float32(6.549304), 'max_total_reward': np.float32(15.511112), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(11.5), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08193121328949929), 'actor_loss': np.float64(-1.0190371513366698), 'hyper_actor_loss': np.float64(0.0008106884895823895), 'behavior_loss': np.float64(0.29357788115739825)}
step: 15990 @ episode report: {'average_total_reward': np.float32(10.173334), 'reward_variance': np.float32(2.1707215), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(11.2), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0728746559470892), 'actor_loss': np.float64(-1.008780586719513), 'hyper_actor_loss': np.float64(0.0007766935683321208), 'behavior_loss': np.float64(0.2768251791596413)}
step: 16000 @ episode report: {'average_total_reward': np.float32(9.624446), 'reward_variance': np.float32(1.4864392), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(10.7), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06222158186137676), 'actor_loss': np.float64(-1.0042311012744904), 'hyper_actor_loss': np.float64(0.0007371716317720711), 'behavior_loss': np.float64(0.28625175952911375)}
step: 16010 @ episode report: {'average_total_reward': np.float32(10.497778), 'reward_variance': np.float32(1.7451805), 'max_total_reward': np.float32(13.266668), 'min_total_reward': np.float32(8.900001), 'average_n_step': np.float32(11.5), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05823371056467295), 'actor_loss': np.float64(-0.9589991986751556), 'hyper_actor_loss': np.float64(0.0007736148661933839), 'behavior_loss': np.float64(0.29333108216524123)}
step: 16020 @ episode report: {'average_total_reward': np.float32(9.712223), 'reward_variance': np.float32(3.7338881), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.8), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06496923565864562), 'actor_loss': np.float64(-0.9913106262683868), 'hyper_actor_loss': np.float64(0.0007157291809562593), 'behavior_loss': np.float64(0.298266327381134)}
step: 16030 @ episode report: {'average_total_reward': np.float32(9.961111), 'reward_variance': np.float32(3.0292418), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(11.0), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07461948320269585), 'actor_loss': np.float64(-0.9963467180728912), 'hyper_actor_loss': np.float64(0.000684681348502636), 'behavior_loss': np.float64(0.2872808426618576)}
step: 16040 @ episode report: {'average_total_reward': np.float32(11.095556), 'reward_variance': np.float32(3.3602772), 'max_total_reward': np.float32(14.511112), 'min_total_reward': np.float32(7.655556), 'average_n_step': np.float32(12.0), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05480255484580994), 'actor_loss': np.float64(-0.987472540140152), 'hyper_actor_loss': np.float64(0.0006797518697567284), 'behavior_loss': np.float64(0.28519182205200194)}
step: 16050 @ episode report: {'average_total_reward': np.float32(9.985556), 'reward_variance': np.float32(4.6546197), 'max_total_reward': np.float32(14.511112), 'min_total_reward': np.float32(6.655556), 'average_n_step': np.float32(11.0), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05571477459743619), 'actor_loss': np.float64(-0.9670403718948364), 'hyper_actor_loss': np.float64(0.000650525966193527), 'behavior_loss': np.float64(0.2931045711040497)}
step: 16060 @ episode report: {'average_total_reward': np.float32(10.995557), 'reward_variance': np.float32(2.8544493), 'max_total_reward': np.float32(14.388889), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(11.9), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06600692085921764), 'actor_loss': np.float64(-0.9909704983234405), 'hyper_actor_loss': np.float64(0.0006226729601621628), 'behavior_loss': np.float64(0.2936126619577408)}
step: 16070 @ episode report: {'average_total_reward': np.float32(11.046667), 'reward_variance': np.float32(3.255328), 'max_total_reward': np.float32(14.388889), 'min_total_reward': np.float32(8.655556), 'average_n_step': np.float32(12.0), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06150020286440849), 'actor_loss': np.float64(-0.9894843399524689), 'hyper_actor_loss': np.float64(0.0005911245418246836), 'behavior_loss': np.float64(0.28331094831228254)}
step: 16080 @ episode report: {'average_total_reward': np.float32(9.836668), 'reward_variance': np.float32(2.0616066), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(7.533334), 'average_n_step': np.float32(10.9), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06024029608815908), 'actor_loss': np.float64(-0.9834827601909637), 'hyper_actor_loss': np.float64(0.0005838602199219167), 'behavior_loss': np.float64(0.2948440104722977)}
step: 16090 @ episode report: {'average_total_reward': np.float32(11.344445), 'reward_variance': np.float32(5.0005198), 'max_total_reward': np.float32(14.511112), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(12.2), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07312354724854231), 'actor_loss': np.float64(-0.9844284892082215), 'hyper_actor_loss': np.float64(0.0005720900429878384), 'behavior_loss': np.float64(0.2864178568124771)}
step: 16100 @ episode report: {'average_total_reward': np.float32(11.134445), 'reward_variance': np.float32(3.4515672), 'max_total_reward': np.float32(14.266666), 'min_total_reward': np.float32(8.655556), 'average_n_step': np.float32(12.1), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07939630001783371), 'actor_loss': np.float64(-1.0120572805404664), 'hyper_actor_loss': np.float64(0.0006096912722568959), 'behavior_loss': np.float64(0.29585510194301606)}
step: 16110 @ episode report: {'average_total_reward': np.float32(9.736668), 'reward_variance': np.float32(4.016792), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.8), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06128139160573483), 'actor_loss': np.float64(-0.9875130236148835), 'hyper_actor_loss': np.float64(0.0005996009684167802), 'behavior_loss': np.float64(0.289509579539299)}
step: 16120 @ episode report: {'average_total_reward': np.float32(10.634445), 'reward_variance': np.float32(4.481148), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(11.6), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07095539942383766), 'actor_loss': np.float64(-0.9754741311073303), 'hyper_actor_loss': np.float64(0.0005649590399116278), 'behavior_loss': np.float64(0.31297959089279176)}
step: 16130 @ episode report: {'average_total_reward': np.float32(9.985556), 'reward_variance': np.float32(2.4670386), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(11.0), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06080796271562576), 'actor_loss': np.float64(-0.9865094900131226), 'hyper_actor_loss': np.float64(0.0005693089391570538), 'behavior_loss': np.float64(0.2832453832030296)}
step: 16140 @ episode report: {'average_total_reward': np.float32(10.112224), 'reward_variance': np.float32(2.482183), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.5333343), 'average_n_step': np.float32(11.2), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07263198271393775), 'actor_loss': np.float64(-1.0024288177490235), 'hyper_actor_loss': np.float64(0.0005511773400940001), 'behavior_loss': np.float64(0.3032752275466919)}
step: 16150 @ episode report: {'average_total_reward': np.float32(10.097778), 'reward_variance': np.float32(3.513823), 'max_total_reward': np.float32(14.38889), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(11.1), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07349115945398807), 'actor_loss': np.float64(-0.9929903149604797), 'hyper_actor_loss': np.float64(0.0005465895199449732), 'behavior_loss': np.float64(0.3063651159405708)}
step: 16160 @ episode report: {'average_total_reward': np.float32(9.848889), 'reward_variance': np.float32(0.7826711), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(8.777779), 'average_n_step': np.float32(10.9), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06485748514533043), 'actor_loss': np.float64(-0.9906937420368195), 'hyper_actor_loss': np.float64(0.0005523580795852468), 'behavior_loss': np.float64(0.29084928780794145)}
step: 16170 @ episode report: {'average_total_reward': np.float32(10.546667), 'reward_variance': np.float32(2.8230324), 'max_total_reward': np.float32(13.266668), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(11.5), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06157133802771568), 'actor_loss': np.float64(-0.9897833883762359), 'hyper_actor_loss': np.float64(0.0005720719636883587), 'behavior_loss': np.float64(0.29015497118234634)}
step: 16180 @ episode report: {'average_total_reward': np.float32(10.3977785), 'reward_variance': np.float32(2.5348098), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(11.4), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06109466385096311), 'actor_loss': np.float64(-0.9924684286117553), 'hyper_actor_loss': np.float64(0.0005780166189651937), 'behavior_loss': np.float64(0.3086851954460144)}
step: 16190 @ episode report: {'average_total_reward': np.float32(10.410001), 'reward_variance': np.float32(4.0980864), 'max_total_reward': np.float32(15.511112), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(11.4), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06287168860435485), 'actor_loss': np.float64(-0.9831809341907501), 'hyper_actor_loss': np.float64(0.0006681446277070791), 'behavior_loss': np.float64(0.3091172128915787)}
step: 16200 @ episode report: {'average_total_reward': np.float32(11.544446), 'reward_variance': np.float32(4.86405), 'max_total_reward': np.float32(15.511112), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(12.4), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07046786211431026), 'actor_loss': np.float64(-0.9952631056308746), 'hyper_actor_loss': np.float64(0.0006897651008330285), 'behavior_loss': np.float64(0.31843367516994475)}
step: 16210 @ episode report: {'average_total_reward': np.float32(10.497779), 'reward_variance': np.float32(2.3536747), 'max_total_reward': np.float32(13.38889), 'min_total_reward': np.float32(7.533334), 'average_n_step': np.float32(11.5), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07359464094042778), 'actor_loss': np.float64(-1.0096307516098022), 'hyper_actor_loss': np.float64(0.0006708220054861159), 'behavior_loss': np.float64(0.30767929553985596)}
step: 16220 @ episode report: {'average_total_reward': np.float32(9.636667), 'reward_variance': np.float32(2.0805695), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(10.7), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05994330421090126), 'actor_loss': np.float64(-0.9838455855846405), 'hyper_actor_loss': np.float64(0.0007076884969137609), 'behavior_loss': np.float64(0.2975472629070282)}
step: 16230 @ episode report: {'average_total_reward': np.float32(10.422223), 'reward_variance': np.float32(1.7268152), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(11.4), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0704507116228342), 'actor_loss': np.float64(-0.994385176897049), 'hyper_actor_loss': np.float64(0.000696282705757767), 'behavior_loss': np.float64(0.3079779237508774)}
step: 16240 @ episode report: {'average_total_reward': np.float32(10.024446), 'reward_variance': np.float32(4.385328), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(7.2888894), 'average_n_step': np.float32(11.1), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06381827779114246), 'actor_loss': np.float64(-0.9941833674907684), 'hyper_actor_loss': np.float64(0.0006727216474246234), 'behavior_loss': np.float64(0.2936215832829475)}
step: 16250 @ episode report: {'average_total_reward': np.float32(10.422223), 'reward_variance': np.float32(1.8061234), 'max_total_reward': np.float32(12.266666), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(11.4), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06473272629082202), 'actor_loss': np.float64(-0.9895361423492431), 'hyper_actor_loss': np.float64(0.0006837631284724921), 'behavior_loss': np.float64(0.3221325069665909)}
step: 16260 @ episode report: {'average_total_reward': np.float32(10.036667), 'reward_variance': np.float32(1.8274829), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(7.6555552), 'average_n_step': np.float32(11.1), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05020657144486904), 'actor_loss': np.float64(-0.9813042521476746), 'hyper_actor_loss': np.float64(0.0006716782168950886), 'behavior_loss': np.float64(0.27287954539060594)}
step: 16270 @ episode report: {'average_total_reward': np.float32(8.990001), 'reward_variance': np.float32(6.048851), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(10.2), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05787037946283817), 'actor_loss': np.float64(-0.9817286252975463), 'hyper_actor_loss': np.float64(0.0006410278612747789), 'behavior_loss': np.float64(0.2793645143508911)}
step: 16280 @ episode report: {'average_total_reward': np.float32(9.724445), 'reward_variance': np.float32(2.7627375), 'max_total_reward': np.float32(13.022223), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(10.8), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05746410302817821), 'actor_loss': np.float64(-0.983021467924118), 'hyper_actor_loss': np.float64(0.000658367550931871), 'behavior_loss': np.float64(0.2903939962387085)}
step: 16290 @ episode report: {'average_total_reward': np.float32(10.51), 'reward_variance': np.float32(1.301493), 'max_total_reward': np.float32(12.266668), 'min_total_reward': np.float32(8.777779), 'average_n_step': np.float32(11.5), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06391550209373235), 'actor_loss': np.float64(-0.9988714694976807), 'hyper_actor_loss': np.float64(0.0005905222147703171), 'behavior_loss': np.float64(0.2888659745454788)}
step: 16300 @ episode report: {'average_total_reward': np.float32(9.561111), 'reward_variance': np.float32(1.8313148), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(10.6), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06416482925415039), 'actor_loss': np.float64(-0.9909176230430603), 'hyper_actor_loss': np.float64(0.0005584400874795392), 'behavior_loss': np.float64(0.29881936609745025)}
step: 16310 @ episode report: {'average_total_reward': np.float32(8.73889), 'reward_variance': np.float32(2.2112417), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.9), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07061395347118378), 'actor_loss': np.float64(-0.9902025401592255), 'hyper_actor_loss': np.float64(0.0005604017816949636), 'behavior_loss': np.float64(0.3044376909732819)}
step: 16320 @ episode report: {'average_total_reward': np.float32(9.412223), 'reward_variance': np.float32(1.3837892), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(10.5), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06962676793336868), 'actor_loss': np.float64(-1.0043471217155457), 'hyper_actor_loss': np.float64(0.0005517181765753776), 'behavior_loss': np.float64(0.30050172209739684)}
step: 16330 @ episode report: {'average_total_reward': np.float32(10.224445), 'reward_variance': np.float32(3.5683658), 'max_total_reward': np.float32(14.144445), 'min_total_reward': np.float32(7.5333333), 'average_n_step': np.float32(11.3), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0626514881849289), 'actor_loss': np.float64(-0.9806053638458252), 'hyper_actor_loss': np.float64(0.0005558452336117625), 'behavior_loss': np.float64(0.31200561821460726)}
step: 16340 @ episode report: {'average_total_reward': np.float32(9.636667), 'reward_variance': np.float32(5.1414843), 'max_total_reward': np.float32(13.38889), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.7), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06567585207521916), 'actor_loss': np.float64(-0.9753469705581665), 'hyper_actor_loss': np.float64(0.0005760886881034822), 'behavior_loss': np.float64(0.3126712888479233)}
step: 16350 @ episode report: {'average_total_reward': np.float32(11.320002), 'reward_variance': np.float32(3.1946871), 'max_total_reward': np.float32(14.38889), 'min_total_reward': np.float32(8.777779), 'average_n_step': np.float32(12.2), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0673267513513565), 'actor_loss': np.float64(-1.0020315170288085), 'hyper_actor_loss': np.float64(0.0006545091106090695), 'behavior_loss': np.float64(0.312952584028244)}
step: 16360 @ episode report: {'average_total_reward': np.float32(11.183333), 'reward_variance': np.float32(4.5858583), 'max_total_reward': np.float32(15.633334), 'min_total_reward': np.float32(7.533334), 'average_n_step': np.float32(12.1), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05889427810907364), 'actor_loss': np.float64(-0.9739671587944031), 'hyper_actor_loss': np.float64(0.0007440748217049986), 'behavior_loss': np.float64(0.3064733505249023)}
step: 16370 @ episode report: {'average_total_reward': np.float32(10.297778), 'reward_variance': np.float32(1.9931816), 'max_total_reward': np.float32(13.266668), 'min_total_reward': np.float32(8.777778), 'average_n_step': np.float32(11.3), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06555118262767792), 'actor_loss': np.float64(-0.9724573910236358), 'hyper_actor_loss': np.float64(0.0009248532413039356), 'behavior_loss': np.float64(0.31104871034622195)}
step: 16380 @ episode report: {'average_total_reward': np.float32(11.544446), 'reward_variance': np.float32(1.0779264), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(9.9), 'average_n_step': np.float32(12.4), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(11.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0625061621889472), 'actor_loss': np.float64(-1.0023289501667023), 'hyper_actor_loss': np.float64(0.0009353435132652521), 'behavior_loss': np.float64(0.30452642738819125)}
step: 16390 @ episode report: {'average_total_reward': np.float32(10.558889), 'reward_variance': np.float32(0.8484214), 'max_total_reward': np.float32(12.266668), 'min_total_reward': np.float32(8.9), 'average_n_step': np.float32(11.5), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06359075270593166), 'actor_loss': np.float64(-0.99274240732193), 'hyper_actor_loss': np.float64(0.0008986853586975485), 'behavior_loss': np.float64(0.2885732874274254)}
step: 16400 @ episode report: {'average_total_reward': np.float32(10.734446), 'reward_variance': np.float32(1.1528502), 'max_total_reward': np.float32(12.266666), 'min_total_reward': np.float32(8.900001), 'average_n_step': np.float32(11.7), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06001218445599079), 'actor_loss': np.float64(-0.9969734668731689), 'hyper_actor_loss': np.float64(0.0009212761942762882), 'behavior_loss': np.float64(0.3163018226623535)}
step: 16410 @ episode report: {'average_total_reward': np.float32(10.3977785), 'reward_variance': np.float32(4.7772546), 'max_total_reward': np.float32(15.633334), 'min_total_reward': np.float32(7.655556), 'average_n_step': np.float32(11.4), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07349213734269142), 'actor_loss': np.float64(-0.9943570971488953), 'hyper_actor_loss': np.float64(0.0008610870223492384), 'behavior_loss': np.float64(0.3020552068948746)}
step: 16420 @ episode report: {'average_total_reward': np.float32(11.071112), 'reward_variance': np.float32(4.09445), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(7.5333343), 'average_n_step': np.float32(12.0), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07007126100361347), 'actor_loss': np.float64(-1.010741114616394), 'hyper_actor_loss': np.float64(0.0008918534440454096), 'behavior_loss': np.float64(0.2992692679166794)}
step: 16430 @ episode report: {'average_total_reward': np.float32(11.332224), 'reward_variance': np.float32(2.0665298), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(8.777778), 'average_n_step': np.float32(12.2), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06964705623686314), 'actor_loss': np.float64(-1.0020157873630524), 'hyper_actor_loss': np.float64(0.0008539305534213781), 'behavior_loss': np.float64(0.3119907945394516)}
step: 16440 @ episode report: {'average_total_reward': np.float32(10.573334), 'reward_variance': np.float32(2.4389431), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(8.533334), 'average_n_step': np.float32(11.6), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06892068684101105), 'actor_loss': np.float64(-0.999214482307434), 'hyper_actor_loss': np.float64(0.0008559176814742387), 'behavior_loss': np.float64(0.2964122980833054)}
step: 16450 @ episode report: {'average_total_reward': np.float32(9.475556), 'reward_variance': np.float32(1.0029082), 'max_total_reward': np.float32(11.0222225), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(10.6), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08184018544852734), 'actor_loss': np.float64(-1.009993326663971), 'hyper_actor_loss': np.float64(0.0008397747704293578), 'behavior_loss': np.float64(0.31216626465320585)}
step: 16460 @ episode report: {'average_total_reward': np.float32(10.922223), 'reward_variance': np.float32(2.414742), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(8.655556), 'average_n_step': np.float32(11.9), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0735424965620041), 'actor_loss': np.float64(-1.0208764553070069), 'hyper_actor_loss': np.float64(0.0007974898209795356), 'behavior_loss': np.float64(0.31784889101982117)}
step: 16470 @ episode report: {'average_total_reward': np.float32(10.085557), 'reward_variance': np.float32(3.9913354), 'max_total_reward': np.float32(13.38889), 'min_total_reward': np.float32(6.5333333), 'average_n_step': np.float32(11.1), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06010204181075096), 'actor_loss': np.float64(-0.9744724214076996), 'hyper_actor_loss': np.float64(0.00088298634509556), 'behavior_loss': np.float64(0.30638886988162994)}
step: 16480 @ episode report: {'average_total_reward': np.float32(10.585556), 'reward_variance': np.float32(2.7355578), 'max_total_reward': np.float32(13.266668), 'min_total_reward': np.float32(7.777778), 'average_n_step': np.float32(11.6), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06344360392540693), 'actor_loss': np.float64(-0.9835946261882782), 'hyper_actor_loss': np.float64(0.001102257810998708), 'behavior_loss': np.float64(0.3295141965150833)}
step: 16490 @ episode report: {'average_total_reward': np.float32(8.851111), 'reward_variance': np.float32(1.4874125), 'max_total_reward': np.float32(11.022223), 'min_total_reward': np.float32(7.655556), 'average_n_step': np.float32(10.0), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0671585563570261), 'actor_loss': np.float64(-1.0100451946258544), 'hyper_actor_loss': np.float64(0.001095949299633503), 'behavior_loss': np.float64(0.313372465968132)}
step: 16500 @ episode report: {'average_total_reward': np.float32(9.973333), 'reward_variance': np.float32(2.1911654), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(11.0), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07619741559028625), 'actor_loss': np.float64(-1.0172264218330382), 'hyper_actor_loss': np.float64(0.001047869271133095), 'behavior_loss': np.float64(0.32084697782993316)}
step: 16510 @ episode report: {'average_total_reward': np.float32(11.420001), 'reward_variance': np.float32(3.0879703), 'max_total_reward': np.float32(13.266668), 'min_total_reward': np.float32(8.900001), 'average_n_step': np.float32(12.3), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07090226914733648), 'actor_loss': np.float64(-1.0006905972957612), 'hyper_actor_loss': np.float64(0.0010082272870931774), 'behavior_loss': np.float64(0.33463951349258425)}
step: 16520 @ episode report: {'average_total_reward': np.float32(10.110001), 'reward_variance': np.float32(2.8369992), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(11.1), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06103171482682228), 'actor_loss': np.float64(-0.9825350940227509), 'hyper_actor_loss': np.float64(0.0010328149888664483), 'behavior_loss': np.float64(0.33152776062488554)}
step: 16530 @ episode report: {'average_total_reward': np.float32(9.861112), 'reward_variance': np.float32(1.8416599), 'max_total_reward': np.float32(12.144444), 'min_total_reward': np.float32(7.6555567), 'average_n_step': np.float32(10.9), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07616690546274185), 'actor_loss': np.float64(-0.9986101567745209), 'hyper_actor_loss': np.float64(0.0009514609235338866), 'behavior_loss': np.float64(0.2986651808023453)}
step: 16540 @ episode report: {'average_total_reward': np.float32(10.895556), 'reward_variance': np.float32(1.2552893), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(8.777778), 'average_n_step': np.float32(11.8), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0757819164544344), 'actor_loss': np.float64(-1.0238112211227417), 'hyper_actor_loss': np.float64(0.0008687542635016143), 'behavior_loss': np.float64(0.31614032089710237)}
step: 16550 @ episode report: {'average_total_reward': np.float32(11.320002), 'reward_variance': np.float32(2.5792053), 'max_total_reward': np.float32(13.38889), 'min_total_reward': np.float32(8.655556), 'average_n_step': np.float32(12.2), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06991803459823132), 'actor_loss': np.float64(-0.9890860021114349), 'hyper_actor_loss': np.float64(0.0007512905052863061), 'behavior_loss': np.float64(0.33341154754161834)}
step: 16560 @ episode report: {'average_total_reward': np.float32(10.995557), 'reward_variance': np.float32(3.2679303), 'max_total_reward': np.float32(14.511111), 'min_total_reward': np.float32(7.6555567), 'average_n_step': np.float32(11.9), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07643305584788322), 'actor_loss': np.float64(-0.99231858253479), 'hyper_actor_loss': np.float64(0.0007354069792199879), 'behavior_loss': np.float64(0.3391678065061569)}
step: 16570 @ episode report: {'average_total_reward': np.float32(10.422223), 'reward_variance': np.float32(1.806124), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(11.4), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07192590311169625), 'actor_loss': np.float64(-1.0278712630271911), 'hyper_actor_loss': np.float64(0.000749738048762083), 'behavior_loss': np.float64(0.3055875837802887)}
step: 16580 @ episode report: {'average_total_reward': np.float32(9.275557), 'reward_variance': np.float32(3.2296004), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(10.4), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08502839915454388), 'actor_loss': np.float64(-1.0184544205665589), 'hyper_actor_loss': np.float64(0.0007818044978193939), 'behavior_loss': np.float64(0.3229108974337578)}
step: 16590 @ episode report: {'average_total_reward': np.float32(9.64889), 'reward_variance': np.float32(2.4823756), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.7), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06781307458877564), 'actor_loss': np.float64(-1.007010668516159), 'hyper_actor_loss': np.float64(0.000746613770024851), 'behavior_loss': np.float64(0.323083633184433)}
step: 16600 @ episode report: {'average_total_reward': np.float32(9.2), 'reward_variance': np.float32(0.5441731), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(10.3), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0582082150503993), 'actor_loss': np.float64(-0.976395708322525), 'hyper_actor_loss': np.float64(0.0006242433737497777), 'behavior_loss': np.float64(0.3046431303024292)}
step: 16610 @ episode report: {'average_total_reward': np.float32(9.761111), 'reward_variance': np.float32(1.8964508), 'max_total_reward': np.float32(12.144444), 'min_total_reward': np.float32(7.777778), 'average_n_step': np.float32(10.8), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05218166783452034), 'actor_loss': np.float64(-0.982251501083374), 'hyper_actor_loss': np.float64(0.0006202132906764745), 'behavior_loss': np.float64(0.2808865889906883)}
step: 16620 @ episode report: {'average_total_reward': np.float32(9.326668), 'reward_variance': np.float32(2.0745738), 'max_total_reward': np.float32(11.022224), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.5), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07370433323085308), 'actor_loss': np.float64(-1.0020214796066285), 'hyper_actor_loss': np.float64(0.0005776995269116015), 'behavior_loss': np.float64(0.31789183914661406)}
step: 16630 @ episode report: {'average_total_reward': np.float32(9.84889), 'reward_variance': np.float32(1.3138566), 'max_total_reward': np.float32(12.0222225), 'min_total_reward': np.float32(8.655557), 'average_n_step': np.float32(10.9), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06025891862809658), 'actor_loss': np.float64(-0.9920822381973267), 'hyper_actor_loss': np.float64(0.0005254354618955404), 'behavior_loss': np.float64(0.31207293570041655)}
step: 16640 @ episode report: {'average_total_reward': np.float32(10.236667), 'reward_variance': np.float32(2.7951863), 'max_total_reward': np.float32(13.266666), 'min_total_reward': np.float32(7.411111), 'average_n_step': np.float32(11.3), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.057260519452393056), 'actor_loss': np.float64(-0.9809104263782501), 'hyper_actor_loss': np.float64(0.000540110853035003), 'behavior_loss': np.float64(0.32367916107177735)}
step: 16650 @ episode report: {'average_total_reward': np.float32(9.824445), 'reward_variance': np.float32(2.3427103), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(10.9), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06124639920890331), 'actor_loss': np.float64(-0.9933577597141265), 'hyper_actor_loss': np.float64(0.0005726398318074644), 'behavior_loss': np.float64(0.3144484609365463)}
step: 16660 @ episode report: {'average_total_reward': np.float32(9.014444), 'reward_variance': np.float32(1.1863962), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(6.6555567), 'average_n_step': np.float32(10.2), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05952720642089844), 'actor_loss': np.float64(-0.9891900062561035), 'hyper_actor_loss': np.float64(0.0005586068262346088), 'behavior_loss': np.float64(0.3026831552386284)}
step: 16670 @ episode report: {'average_total_reward': np.float32(9.151113), 'reward_variance': np.float32(3.2105732), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(6.533334), 'average_n_step': np.float32(10.3), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07127950079739094), 'actor_loss': np.float64(-0.9828851461410523), 'hyper_actor_loss': np.float64(0.0005627437145449221), 'behavior_loss': np.float64(0.31173695623874664)}
step: 16680 @ episode report: {'average_total_reward': np.float32(9.824445), 'reward_variance': np.float32(2.1671567), 'max_total_reward': np.float32(12.266668), 'min_total_reward': np.float32(7.6555567), 'average_n_step': np.float32(10.9), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05199456587433815), 'actor_loss': np.float64(-0.997645914554596), 'hyper_actor_loss': np.float64(0.0005374175641918554), 'behavior_loss': np.float64(0.31652858257293703)}
step: 16690 @ episode report: {'average_total_reward': np.float32(10.297778), 'reward_variance': np.float32(2.3303409), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(11.3), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.062224782258272174), 'actor_loss': np.float64(-0.9625054478645325), 'hyper_actor_loss': np.float64(0.0005317539442330598), 'behavior_loss': np.float64(0.3189027816057205)}
step: 16700 @ episode report: {'average_total_reward': np.float32(10.446667), 'reward_variance': np.float32(2.7904882), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.777778), 'average_n_step': np.float32(11.4), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05678685270249843), 'actor_loss': np.float64(-0.988175505399704), 'hyper_actor_loss': np.float64(0.0005053728353232145), 'behavior_loss': np.float64(0.32621570229530333)}
step: 16710 @ episode report: {'average_total_reward': np.float32(10.497778), 'reward_variance': np.float32(2.7172792), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.6555567), 'average_n_step': np.float32(11.5), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07868170700967311), 'actor_loss': np.float64(-0.999107962846756), 'hyper_actor_loss': np.float64(0.0005224222870310769), 'behavior_loss': np.float64(0.3140281707048416)}
step: 16720 @ episode report: {'average_total_reward': np.float32(10.8955555), 'reward_variance': np.float32(3.8014865), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(11.8), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06362984143197536), 'actor_loss': np.float64(-1.0125054001808167), 'hyper_actor_loss': np.float64(0.0005776478094048799), 'behavior_loss': np.float64(0.2955386683344841)}
step: 16730 @ episode report: {'average_total_reward': np.float32(11.183334), 'reward_variance': np.float32(2.0690923), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(7.777779), 'average_n_step': np.float32(12.1), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0532441433519125), 'actor_loss': np.float64(-0.9893519163131714), 'hyper_actor_loss': np.float64(0.0005954330204986036), 'behavior_loss': np.float64(0.3029758036136627)}
step: 16740 @ episode report: {'average_total_reward': np.float32(11.620001), 'reward_variance': np.float32(3.4395013), 'max_total_reward': np.float32(15.633334), 'min_total_reward': np.float32(8.777779), 'average_n_step': np.float32(12.5), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07519718855619431), 'actor_loss': np.float64(-0.9897281348705291), 'hyper_actor_loss': np.float64(0.0006169594533275812), 'behavior_loss': np.float64(0.3168856456875801)}
step: 16750 @ episode report: {'average_total_reward': np.float32(10.734446), 'reward_variance': np.float32(0.69798625), 'max_total_reward': np.float32(12.0222225), 'min_total_reward': np.float32(8.900001), 'average_n_step': np.float32(11.7), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07348574995994568), 'actor_loss': np.float64(-1.0181580424308776), 'hyper_actor_loss': np.float64(0.0006455655209720134), 'behavior_loss': np.float64(0.3055761486291885)}
step: 16760 @ episode report: {'average_total_reward': np.float32(10.073334), 'reward_variance': np.float32(3.9667954), 'max_total_reward': np.float32(13.38889), 'min_total_reward': np.float32(7.655556), 'average_n_step': np.float32(11.1), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06474429108202458), 'actor_loss': np.float64(-0.99741051197052), 'hyper_actor_loss': np.float64(0.0006224858516361564), 'behavior_loss': np.float64(0.3016015365719795)}
step: 16770 @ episode report: {'average_total_reward': np.float32(10.922223), 'reward_variance': np.float32(3.3673832), 'max_total_reward': np.float32(14.38889), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(11.9), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06143484972417355), 'actor_loss': np.float64(-0.9822826504707336), 'hyper_actor_loss': np.float64(0.0005683673487510532), 'behavior_loss': np.float64(0.2995430439710617)}
step: 16780 @ episode report: {'average_total_reward': np.float32(10.771112), 'reward_variance': np.float32(6.044054), 'max_total_reward': np.float32(15.511111), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(11.7), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07120933122932911), 'actor_loss': np.float64(-0.999730360507965), 'hyper_actor_loss': np.float64(0.0005375449603889137), 'behavior_loss': np.float64(0.29513280987739565)}
step: 16790 @ episode report: {'average_total_reward': np.float32(11.407779), 'reward_variance': np.float32(2.3628662), 'max_total_reward': np.float32(13.38889), 'min_total_reward': np.float32(8.900001), 'average_n_step': np.float32(12.3), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06189535576850176), 'actor_loss': np.float64(-1.0026555895805358), 'hyper_actor_loss': np.float64(0.0005453993042465299), 'behavior_loss': np.float64(0.31314178109169005)}
step: 16800 @ episode report: {'average_total_reward': np.float32(10.910001), 'reward_variance': np.float32(4.604208), 'max_total_reward': np.float32(16.633333), 'min_total_reward': np.float32(8.777779), 'average_n_step': np.float32(11.9), 'max_n_step': np.float32(17.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05239605735987425), 'actor_loss': np.float64(-0.9793453097343445), 'hyper_actor_loss': np.float64(0.0005929586593993008), 'behavior_loss': np.float64(0.3231364369392395)}
step: 16810 @ episode report: {'average_total_reward': np.float32(10.497778), 'reward_variance': np.float32(2.322266), 'max_total_reward': np.float32(12.1444435), 'min_total_reward': np.float32(6.533334), 'average_n_step': np.float32(11.5), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0634840339422226), 'actor_loss': np.float64(-0.976260632276535), 'hyper_actor_loss': np.float64(0.0006288229080382735), 'behavior_loss': np.float64(0.33815303444862366)}
step: 16820 @ episode report: {'average_total_reward': np.float32(10.734446), 'reward_variance': np.float32(1.3693197), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(8.655556), 'average_n_step': np.float32(11.7), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06827814504504204), 'actor_loss': np.float64(-0.9930597126483918), 'hyper_actor_loss': np.float64(0.0006106301036197693), 'behavior_loss': np.float64(0.3017314046621323)}
step: 16830 @ episode report: {'average_total_reward': np.float32(10.871112), 'reward_variance': np.float32(4.8296347), 'max_total_reward': np.float32(14.511111), 'min_total_reward': np.float32(7.5333333), 'average_n_step': np.float32(11.8), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0849584374576807), 'actor_loss': np.float64(-1.0339226722717285), 'hyper_actor_loss': np.float64(0.0005770851799752563), 'behavior_loss': np.float64(0.30141419768333433)}
step: 16840 @ episode report: {'average_total_reward': np.float32(10.634445), 'reward_variance': np.float32(3.6980846), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(6.6555567), 'average_n_step': np.float32(11.6), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0728521965444088), 'actor_loss': np.float64(-1.0089202344417572), 'hyper_actor_loss': np.float64(0.000531598343513906), 'behavior_loss': np.float64(0.30993800759315493)}
step: 16850 @ episode report: {'average_total_reward': np.float32(9.6), 'reward_variance': np.float32(2.7896054), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(10.7), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06061271652579307), 'actor_loss': np.float64(-0.9774940490722657), 'hyper_actor_loss': np.float64(0.0005087908386485652), 'behavior_loss': np.float64(0.31276724189519883)}
step: 16860 @ episode report: {'average_total_reward': np.float32(10.907779), 'reward_variance': np.float32(4.424397), 'max_total_reward': np.float32(15.633334), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(11.8), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.059896521642804144), 'actor_loss': np.float64(-0.9792925119400024), 'hyper_actor_loss': np.float64(0.0005221595783950761), 'behavior_loss': np.float64(0.3051377236843109)}
step: 16870 @ episode report: {'average_total_reward': np.float32(9.224444), 'reward_variance': np.float32(3.1898222), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.3), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06034586764872074), 'actor_loss': np.float64(-0.9925999701023102), 'hyper_actor_loss': np.float64(0.0005181316781090572), 'behavior_loss': np.float64(0.3001908972859383)}
step: 16880 @ episode report: {'average_total_reward': np.float32(10.634445), 'reward_variance': np.float32(3.0307274), 'max_total_reward': np.float32(14.388889), 'min_total_reward': np.float32(8.9), 'average_n_step': np.float32(11.6), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07112878300249577), 'actor_loss': np.float64(-0.9852413654327392), 'hyper_actor_loss': np.float64(0.0005699876986909657), 'behavior_loss': np.float64(0.3138593673706055)}
step: 16890 @ episode report: {'average_total_reward': np.float32(10.110001), 'reward_variance': np.float32(3.0614438), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(11.1), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0645497364923358), 'actor_loss': np.float64(-0.9960020899772644), 'hyper_actor_loss': np.float64(0.0005168319039512426), 'behavior_loss': np.float64(0.30594093948602674)}
step: 16900 @ episode report: {'average_total_reward': np.float32(10.846667), 'reward_variance': np.float32(6.1054773), 'max_total_reward': np.float32(15.633334), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(11.8), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07828969359397889), 'actor_loss': np.float64(-1.0101187229156494), 'hyper_actor_loss': np.float64(0.0004941826307913288), 'behavior_loss': np.float64(0.30536976754665374)}
step: 16910 @ episode report: {'average_total_reward': np.float32(11.693334), 'reward_variance': np.float32(3.379858), 'max_total_reward': np.float32(15.633334), 'min_total_reward': np.float32(9.900001), 'average_n_step': np.float32(12.5), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(11.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0720208466053009), 'actor_loss': np.float64(-1.007165825366974), 'hyper_actor_loss': np.float64(0.0004819042980670929), 'behavior_loss': np.float64(0.3215352386236191)}
step: 16920 @ episode report: {'average_total_reward': np.float32(10.261111), 'reward_variance': np.float32(2.03445), 'max_total_reward': np.float32(13.1444435), 'min_total_reward': np.float32(8.411112), 'average_n_step': np.float32(11.3), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07310421951115131), 'actor_loss': np.float64(-1.0022370994091034), 'hyper_actor_loss': np.float64(0.0004664332896936685), 'behavior_loss': np.float64(0.32951439917087555)}
step: 16930 @ episode report: {'average_total_reward': np.float32(11.071112), 'reward_variance': np.float32(2.7597327), 'max_total_reward': np.float32(14.511111), 'min_total_reward': np.float32(8.411112), 'average_n_step': np.float32(12.0), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07734176069498062), 'actor_loss': np.float64(-0.9974411725997925), 'hyper_actor_loss': np.float64(0.0004925002809613943), 'behavior_loss': np.float64(0.3327164053916931)}
step: 16940 @ episode report: {'average_total_reward': np.float32(11.507778), 'reward_variance': np.float32(3.804718), 'max_total_reward': np.float32(14.388889), 'min_total_reward': np.float32(8.9), 'average_n_step': np.float32(12.4), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07398686334490776), 'actor_loss': np.float64(-1.018785333633423), 'hyper_actor_loss': np.float64(0.0005374092754209415), 'behavior_loss': np.float64(0.3026792347431183)}
step: 16950 @ episode report: {'average_total_reward': np.float32(10.485556), 'reward_variance': np.float32(1.6160015), 'max_total_reward': np.float32(13.266666), 'min_total_reward': np.float32(8.777777), 'average_n_step': np.float32(11.5), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06675329804420471), 'actor_loss': np.float64(-1.0100422620773315), 'hyper_actor_loss': np.float64(0.0006408231129171327), 'behavior_loss': np.float64(0.32360618412494657)}
step: 16960 @ episode report: {'average_total_reward': np.float32(9.424444), 'reward_variance': np.float32(1.0873286), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(10.5), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07717958502471448), 'actor_loss': np.float64(-1.003095132112503), 'hyper_actor_loss': np.float64(0.0008715870906598866), 'behavior_loss': np.float64(0.3295285224914551)}
step: 16970 @ episode report: {'average_total_reward': np.float32(9.363334), 'reward_variance': np.float32(2.3382244), 'max_total_reward': np.float32(11.022223), 'min_total_reward': np.float32(6.4111114), 'average_n_step': np.float32(10.5), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.061747950688004496), 'actor_loss': np.float64(-1.002487987279892), 'hyper_actor_loss': np.float64(0.0008150761015713215), 'behavior_loss': np.float64(0.32189137041568755)}
step: 16980 @ episode report: {'average_total_reward': np.float32(9.287778), 'reward_variance': np.float32(1.3823072), 'max_total_reward': np.float32(11.900001), 'min_total_reward': np.float32(7.6555567), 'average_n_step': np.float32(10.4), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0685841303318739), 'actor_loss': np.float64(-0.9875165402889252), 'hyper_actor_loss': np.float64(0.0006403528444934636), 'behavior_loss': np.float64(0.3088193416595459)}
step: 16990 @ episode report: {'average_total_reward': np.float32(9.84889), 'reward_variance': np.float32(1.5323259), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(10.9), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06811174601316453), 'actor_loss': np.float64(-1.0054361164569854), 'hyper_actor_loss': np.float64(0.0005075679044239223), 'behavior_loss': np.float64(0.34449527561664584)}
step: 17000 @ episode report: {'average_total_reward': np.float32(9.612223), 'reward_variance': np.float32(0.7009739), 'max_total_reward': np.float32(11.0222225), 'min_total_reward': np.float32(8.655556), 'average_n_step': np.float32(10.7), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06401066333055497), 'actor_loss': np.float64(-0.9819105088710784), 'hyper_actor_loss': np.float64(0.0004648445319617167), 'behavior_loss': np.float64(0.3070010423660278)}
step: 17010 @ episode report: {'average_total_reward': np.float32(10.85889), 'reward_variance': np.float32(3.4521985), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(11.8), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06375802718102933), 'actor_loss': np.float64(-0.9846574425697326), 'hyper_actor_loss': np.float64(0.00042617547733243556), 'behavior_loss': np.float64(0.320329812169075)}
step: 17020 @ episode report: {'average_total_reward': np.float32(9.9366665), 'reward_variance': np.float32(1.859532), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(11.0), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0654809033498168), 'actor_loss': np.float64(-0.9961077928543091), 'hyper_actor_loss': np.float64(0.00043719021196011456), 'behavior_loss': np.float64(0.2867762565612793)}
step: 17030 @ episode report: {'average_total_reward': np.float32(10.14889), 'reward_variance': np.float32(4.33566), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(6.533334), 'average_n_step': np.float32(11.2), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07208742834627628), 'actor_loss': np.float64(-1.0085053622722626), 'hyper_actor_loss': np.float64(0.0004411152214743197), 'behavior_loss': np.float64(0.31586443930864333)}
step: 17040 @ episode report: {'average_total_reward': np.float32(10.173334), 'reward_variance': np.float32(3.1353145), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(11.2), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.060844316706061365), 'actor_loss': np.float64(-0.9783164143562317), 'hyper_actor_loss': np.float64(0.00042318458145018667), 'behavior_loss': np.float64(0.31338544487953185)}
step: 17050 @ episode report: {'average_total_reward': np.float32(8.626668), 'reward_variance': np.float32(4.278993), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(9.8), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.058248305693268776), 'actor_loss': np.float64(-0.9742054998874664), 'hyper_actor_loss': np.float64(0.0004185503930784762), 'behavior_loss': np.float64(0.3060323089361191)}
step: 17060 @ episode report: {'average_total_reward': np.float32(8.526667), 'reward_variance': np.float32(1.0259806), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(9.7), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06824534609913827), 'actor_loss': np.float64(-1.000676542520523), 'hyper_actor_loss': np.float64(0.00044739697768818586), 'behavior_loss': np.float64(0.3044593960046768)}
step: 17070 @ episode report: {'average_total_reward': np.float32(9.363335), 'reward_variance': np.float32(4.168175), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(6.5333333), 'average_n_step': np.float32(10.5), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0671298585832119), 'actor_loss': np.float64(-1.0001872181892395), 'hyper_actor_loss': np.float64(0.0004501019255258143), 'behavior_loss': np.float64(0.33185779452323916)}
step: 17080 @ episode report: {'average_total_reward': np.float32(9.612223), 'reward_variance': np.float32(4.0870986), 'max_total_reward': np.float32(13.266668), 'min_total_reward': np.float32(5.655556), 'average_n_step': np.float32(10.7), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05451681017875672), 'actor_loss': np.float64(-0.9812855422496796), 'hyper_actor_loss': np.float64(0.0004836634878301993), 'behavior_loss': np.float64(0.288222374022007)}
step: 17090 @ episode report: {'average_total_reward': np.float32(9.587778), 'reward_variance': np.float32(2.8220105), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(5.655556), 'average_n_step': np.float32(10.7), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.062114284560084346), 'actor_loss': np.float64(-1.0033673405647279), 'hyper_actor_loss': np.float64(0.0005012293957406655), 'behavior_loss': np.float64(0.2965726599097252)}
step: 17100 @ episode report: {'average_total_reward': np.float32(10.000001), 'reward_variance': np.float32(2.4237046), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(8.533334), 'average_n_step': np.float32(11.1), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07101628072559833), 'actor_loss': np.float64(-1.0105066299438477), 'hyper_actor_loss': np.float64(0.0004978022770956159), 'behavior_loss': np.float64(0.3124637931585312)}
step: 17110 @ episode report: {'average_total_reward': np.float32(9.763334), 'reward_variance': np.float32(3.5906193), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(6.4111114), 'average_n_step': np.float32(10.9), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05399924237281084), 'actor_loss': np.float64(-0.9834002435207367), 'hyper_actor_loss': np.float64(0.0005178095219889655), 'behavior_loss': np.float64(0.32622556686401366)}
step: 17120 @ episode report: {'average_total_reward': np.float32(8.351111), 'reward_variance': np.float32(3.9464488), 'max_total_reward': np.float32(12.266666), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.5), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06734175998717547), 'actor_loss': np.float64(-0.9851601481437683), 'hyper_actor_loss': np.float64(0.0005359903996577486), 'behavior_loss': np.float64(0.3202491909265518)}
step: 17130 @ episode report: {'average_total_reward': np.float32(9.712222), 'reward_variance': np.float32(5.162852), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.8), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05737114436924458), 'actor_loss': np.float64(-0.991526198387146), 'hyper_actor_loss': np.float64(0.00048718189646024257), 'behavior_loss': np.float64(0.3377796083688736)}
step: 17140 @ episode report: {'average_total_reward': np.float32(8.277779), 'reward_variance': np.float32(4.288988), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(9.5), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0680095098912716), 'actor_loss': np.float64(-0.984628963470459), 'hyper_actor_loss': np.float64(0.00047609543544240295), 'behavior_loss': np.float64(0.2940377056598663)}
step: 17150 @ episode report: {'average_total_reward': np.float32(8.8144455), 'reward_variance': np.float32(3.3658047), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(10.0), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05909147188067436), 'actor_loss': np.float64(-0.9952717959880829), 'hyper_actor_loss': np.float64(0.0004879307438386604), 'behavior_loss': np.float64(0.328671059012413)}
step: 17160 @ episode report: {'average_total_reward': np.float32(9.038889), 'reward_variance': np.float32(2.77576), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.2), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07286996021866798), 'actor_loss': np.float64(-0.9794861853122712), 'hyper_actor_loss': np.float64(0.000475181607180275), 'behavior_loss': np.float64(0.32844712138175963)}
step: 17170 @ episode report: {'average_total_reward': np.float32(8.702223), 'reward_variance': np.float32(5.3702183), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.9), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.049751606211066245), 'actor_loss': np.float64(-0.9971709012985229), 'hyper_actor_loss': np.float64(0.0004959161393344403), 'behavior_loss': np.float64(0.30025395154953005)}
step: 17180 @ episode report: {'average_total_reward': np.float32(9.636667), 'reward_variance': np.float32(3.874124), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(6.533334), 'average_n_step': np.float32(10.7), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.061739420890808104), 'actor_loss': np.float64(-0.9753455936908721), 'hyper_actor_loss': np.float64(0.0004768892627907917), 'behavior_loss': np.float64(0.3156112313270569)}
step: 17190 @ episode report: {'average_total_reward': np.float32(10.073334), 'reward_variance': np.float32(1.1383013), 'max_total_reward': np.float32(12.144444), 'min_total_reward': np.float32(8.777778), 'average_n_step': np.float32(11.1), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06519094407558441), 'actor_loss': np.float64(-0.9955007433891296), 'hyper_actor_loss': np.float64(0.0004447798972250894), 'behavior_loss': np.float64(0.33390330970287324)}
step: 17200 @ episode report: {'average_total_reward': np.float32(9.424444), 'reward_variance': np.float32(3.7267864), 'max_total_reward': np.float32(12.266668), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.5), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06019640155136585), 'actor_loss': np.float64(-0.9934626996517182), 'hyper_actor_loss': np.float64(0.00044851425336673857), 'behavior_loss': np.float64(0.28320560455322263)}
step: 17210 @ episode report: {'average_total_reward': np.float32(9.4366665), 'reward_variance': np.float32(3.1701741), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(10.5), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06816219501197338), 'actor_loss': np.float64(-1.0134076833724976), 'hyper_actor_loss': np.float64(0.00042056088568642735), 'behavior_loss': np.float64(0.31595455706119535)}
step: 17220 @ episode report: {'average_total_reward': np.float32(7.753333), 'reward_variance': np.float32(1.4892051), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.0), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07946589328348637), 'actor_loss': np.float64(-0.9997286677360535), 'hyper_actor_loss': np.float64(0.0004842258611461148), 'behavior_loss': np.float64(0.323479625582695)}
step: 17230 @ episode report: {'average_total_reward': np.float32(9.263334), 'reward_variance': np.float32(2.8660264), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.4), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06808750741183758), 'actor_loss': np.float64(-1.0077030777931213), 'hyper_actor_loss': np.float64(0.0004884526308160276), 'behavior_loss': np.float64(0.3162654846906662)}
step: 17240 @ episode report: {'average_total_reward': np.float32(9.712222), 'reward_variance': np.float32(1.6834685), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(10.8), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07090603448450565), 'actor_loss': np.float64(-1.0019449293613434), 'hyper_actor_loss': np.float64(0.0004628135822713375), 'behavior_loss': np.float64(0.31184772551059725)}
step: 17250 @ episode report: {'average_total_reward': np.float32(9.126668), 'reward_variance': np.float32(2.539412), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.5333333), 'average_n_step': np.float32(10.3), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.060550708509981635), 'actor_loss': np.float64(-0.9931423664093018), 'hyper_actor_loss': np.float64(0.0005171289056306704), 'behavior_loss': np.float64(0.31418738067150115)}
step: 17260 @ episode report: {'average_total_reward': np.float32(9.163333), 'reward_variance': np.float32(3.6801002), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.3), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.061820102669298646), 'actor_loss': np.float64(-0.9839857637882232), 'hyper_actor_loss': np.float64(0.0006168777938000858), 'behavior_loss': np.float64(0.3285135507583618)}
step: 17270 @ episode report: {'average_total_reward': np.float32(9.424444), 'reward_variance': np.float32(2.3192792), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(10.5), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06585485506802798), 'actor_loss': np.float64(-0.9888824582099914), 'hyper_actor_loss': np.float64(0.0006317520223092288), 'behavior_loss': np.float64(0.3337398707866669)}
step: 17280 @ episode report: {'average_total_reward': np.float32(9.712222), 'reward_variance': np.float32(1.5797151), 'max_total_reward': np.float32(11.900001), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(10.8), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.058847392350435256), 'actor_loss': np.float64(-0.9901369094848633), 'hyper_actor_loss': np.float64(0.0006349659932311624), 'behavior_loss': np.float64(0.3078128948807716)}
step: 17290 @ episode report: {'average_total_reward': np.float32(8.538889), 'reward_variance': np.float32(2.8868709), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(9.7), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0700557291507721), 'actor_loss': np.float64(-0.9939131438732147), 'hyper_actor_loss': np.float64(0.000602307339431718), 'behavior_loss': np.float64(0.3437220424413681)}
step: 17300 @ episode report: {'average_total_reward': np.float32(10.036668), 'reward_variance': np.float32(4.0639524), 'max_total_reward': np.float32(14.388889), 'min_total_reward': np.float32(7.5333333), 'average_n_step': np.float32(11.1), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05923719070851803), 'actor_loss': np.float64(-0.9803123235702514), 'hyper_actor_loss': np.float64(0.0006181126518640667), 'behavior_loss': np.float64(0.3074263155460358)}
step: 17310 @ episode report: {'average_total_reward': np.float32(9.997778), 'reward_variance': np.float32(2.5241427), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(11.0), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06082945838570595), 'actor_loss': np.float64(-0.9820515096187592), 'hyper_actor_loss': np.float64(0.0005568842258071527), 'behavior_loss': np.float64(0.3204765111207962)}
step: 17320 @ episode report: {'average_total_reward': np.float32(10.746668), 'reward_variance': np.float32(1.8206131), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(8.9), 'average_n_step': np.float32(11.7), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07322440035641194), 'actor_loss': np.float64(-0.9955617010593414), 'hyper_actor_loss': np.float64(0.0005280115990899503), 'behavior_loss': np.float64(0.3232940942049026)}
step: 17330 @ episode report: {'average_total_reward': np.float32(10.722223), 'reward_variance': np.float32(2.1132836), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(8.777778), 'average_n_step': np.float32(11.7), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06744777373969554), 'actor_loss': np.float64(-0.9957206428050995), 'hyper_actor_loss': np.float64(0.00043804155429825185), 'behavior_loss': np.float64(0.29337343126535415)}
step: 17340 @ episode report: {'average_total_reward': np.float32(9.824445), 'reward_variance': np.float32(1.6115263), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(8.655556), 'average_n_step': np.float32(10.9), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06303245685994625), 'actor_loss': np.float64(-0.9884377121925354), 'hyper_actor_loss': np.float64(0.0004071664297953248), 'behavior_loss': np.float64(0.3227952986955643)}
step: 17350 @ episode report: {'average_total_reward': np.float32(10.061112), 'reward_variance': np.float32(2.1144512), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(11.1), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06315077152103185), 'actor_loss': np.float64(-0.9912398517131805), 'hyper_actor_loss': np.float64(0.0004004627640824765), 'behavior_loss': np.float64(0.3059534773230553)}
step: 17360 @ episode report: {'average_total_reward': np.float32(9.748889), 'reward_variance': np.float32(1.86398), 'max_total_reward': np.float32(12.144444), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(10.8), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06279221586883069), 'actor_loss': np.float64(-0.998036128282547), 'hyper_actor_loss': np.float64(0.0004079747595824301), 'behavior_loss': np.float64(0.31627882122993467)}
step: 17370 @ episode report: {'average_total_reward': np.float32(9.824446), 'reward_variance': np.float32(1.8908345), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(10.9), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06846879571676254), 'actor_loss': np.float64(-0.983297860622406), 'hyper_actor_loss': np.float64(0.0004074360796948895), 'behavior_loss': np.float64(0.3178157925605774)}
step: 17380 @ episode report: {'average_total_reward': np.float32(9.7), 'reward_variance': np.float32(3.0817533), 'max_total_reward': np.float32(13.0222225), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(10.8), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06110063306987286), 'actor_loss': np.float64(-1.0027795076370238), 'hyper_actor_loss': np.float64(0.0004209150356473401), 'behavior_loss': np.float64(0.2983185455203056)}
step: 17390 @ episode report: {'average_total_reward': np.float32(9.663334), 'reward_variance': np.float32(2.1968904), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(6.5333333), 'average_n_step': np.float32(10.8), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06345526035875082), 'actor_loss': np.float64(-0.989215487241745), 'hyper_actor_loss': np.float64(0.0004130735353101045), 'behavior_loss': np.float64(0.3096471935510635)}
step: 17400 @ episode report: {'average_total_reward': np.float32(10.3977785), 'reward_variance': np.float32(4.3782415), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(6.5333333), 'average_n_step': np.float32(11.4), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06280819550156594), 'actor_loss': np.float64(-0.9866517782211304), 'hyper_actor_loss': np.float64(0.0004272492980817333), 'behavior_loss': np.float64(0.32724183797836304)}
step: 17410 @ episode report: {'average_total_reward': np.float32(11.120001), 'reward_variance': np.float32(2.0174022), 'max_total_reward': np.float32(13.38889), 'min_total_reward': np.float32(8.900001), 'average_n_step': np.float32(12.0), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0734636690467596), 'actor_loss': np.float64(-0.999562269449234), 'hyper_actor_loss': np.float64(0.0003991498553659767), 'behavior_loss': np.float64(0.3093206316232681)}
step: 17420 @ episode report: {'average_total_reward': np.float32(10.534445), 'reward_variance': np.float32(1.7778137), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(8.9), 'average_n_step': np.float32(11.5), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07162113822996616), 'actor_loss': np.float64(-1.008452045917511), 'hyper_actor_loss': np.float64(0.0003871088847517967), 'behavior_loss': np.float64(0.3174093395471573)}
step: 17430 @ episode report: {'average_total_reward': np.float32(10.297778), 'reward_variance': np.float32(2.272489), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(11.3), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06360359266400337), 'actor_loss': np.float64(-0.9853722929954529), 'hyper_actor_loss': np.float64(0.0003795988275669515), 'behavior_loss': np.float64(0.3324554979801178)}
step: 17440 @ episode report: {'average_total_reward': np.float32(9.912224), 'reward_variance': np.float32(1.9644814), 'max_total_reward': np.float32(13.266668), 'min_total_reward': np.float32(7.777778), 'average_n_step': np.float32(11.0), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.062034950405359265), 'actor_loss': np.float64(-0.9890778720378876), 'hyper_actor_loss': np.float64(0.0003897066955687478), 'behavior_loss': np.float64(0.31414694488048556)}
step: 17450 @ episode report: {'average_total_reward': np.float32(9.400001), 'reward_variance': np.float32(3.4949632), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(7.533334), 'average_n_step': np.float32(10.5), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07067871801555156), 'actor_loss': np.float64(-0.9882049441337586), 'hyper_actor_loss': np.float64(0.000363681698217988), 'behavior_loss': np.float64(0.3575061082839966)}
step: 17460 @ episode report: {'average_total_reward': np.float32(10.422223), 'reward_variance': np.float32(3.764272), 'max_total_reward': np.float32(14.511111), 'min_total_reward': np.float32(7.533334), 'average_n_step': np.float32(11.4), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06302931234240532), 'actor_loss': np.float64(-0.9957827806472779), 'hyper_actor_loss': np.float64(0.0003209288406651467), 'behavior_loss': np.float64(0.2984733283519745)}
step: 17470 @ episode report: {'average_total_reward': np.float32(11.171112), 'reward_variance': np.float32(3.0190425), 'max_total_reward': np.float32(15.633334), 'min_total_reward': np.float32(9.777777), 'average_n_step': np.float32(12.1), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(11.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06768295541405678), 'actor_loss': np.float64(-0.9781368136405945), 'hyper_actor_loss': np.float64(0.00036913352960254997), 'behavior_loss': np.float64(0.3249421030282974)}
step: 17480 @ episode report: {'average_total_reward': np.float32(10.871112), 'reward_variance': np.float32(1.4729431), 'max_total_reward': np.float32(13.38889), 'min_total_reward': np.float32(8.900002), 'average_n_step': np.float32(11.8), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07444198876619339), 'actor_loss': np.float64(-0.9890044748783111), 'hyper_actor_loss': np.float64(0.0003812004841165617), 'behavior_loss': np.float64(0.3210555285215378)}
step: 17490 @ episode report: {'average_total_reward': np.float32(11.071112), 'reward_variance': np.float32(3.3877082), 'max_total_reward': np.float32(14.511112), 'min_total_reward': np.float32(7.6555567), 'average_n_step': np.float32(12.0), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06723816804587841), 'actor_loss': np.float64(-0.9972437262535095), 'hyper_actor_loss': np.float64(0.00037516460579354314), 'behavior_loss': np.float64(0.3204171508550644)}
step: 17500 @ episode report: {'average_total_reward': np.float32(11.171112), 'reward_variance': np.float32(2.3536844), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(8.9), 'average_n_step': np.float32(12.1), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07153712175786495), 'actor_loss': np.float64(-0.9958720862865448), 'hyper_actor_loss': np.float64(0.00036534579703584313), 'behavior_loss': np.float64(0.29379733353853227)}
step: 17510 @ episode report: {'average_total_reward': np.float32(11.071112), 'reward_variance': np.float32(1.0963751), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(9.777779), 'average_n_step': np.float32(12.0), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(11.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.061711077392101285), 'actor_loss': np.float64(-0.987372201681137), 'hyper_actor_loss': np.float64(0.0003341458534123376), 'behavior_loss': np.float64(0.3214379966259003)}
step: 17520 @ episode report: {'average_total_reward': np.float32(10.024446), 'reward_variance': np.float32(3.7314763), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(11.1), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0577697578817606), 'actor_loss': np.float64(-0.9752756178379058), 'hyper_actor_loss': np.float64(0.00033960142463911324), 'behavior_loss': np.float64(0.30484133660793306)}
step: 17530 @ episode report: {'average_total_reward': np.float32(8.451111), 'reward_variance': np.float32(4.852968), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.6), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0715192511677742), 'actor_loss': np.float64(-0.9979020595550537), 'hyper_actor_loss': np.float64(0.0003506330220261589), 'behavior_loss': np.float64(0.30403422713279726)}
step: 17540 @ episode report: {'average_total_reward': np.float32(8.9388895), 'reward_variance': np.float32(1.7104756), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(5.655556), 'average_n_step': np.float32(10.1), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06656268574297428), 'actor_loss': np.float64(-1.0058690905570984), 'hyper_actor_loss': np.float64(0.0003512881638016552), 'behavior_loss': np.float64(0.3069668233394623)}
step: 17550 @ episode report: {'average_total_reward': np.float32(9.512223), 'reward_variance': np.float32(5.1494923), 'max_total_reward': np.float32(14.511111), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(10.6), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06029981002211571), 'actor_loss': np.float64(-0.9832100749015809), 'hyper_actor_loss': np.float64(0.00034597217454575003), 'behavior_loss': np.float64(0.289944651722908)}
step: 17560 @ episode report: {'average_total_reward': np.float32(9.051112), 'reward_variance': np.float32(1.4210664), 'max_total_reward': np.float32(10.9), 'min_total_reward': np.float32(6.5333343), 'average_n_step': np.float32(10.2), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0677349504083395), 'actor_loss': np.float64(-0.9824199914932251), 'hyper_actor_loss': np.float64(0.00032961276883725077), 'behavior_loss': np.float64(0.31340465843677523)}
step: 17570 @ episode report: {'average_total_reward': np.float32(9.163334), 'reward_variance': np.float32(1.1633346), 'max_total_reward': np.float32(11.022223), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(10.3), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06474868170917034), 'actor_loss': np.float64(-0.9964730739593506), 'hyper_actor_loss': np.float64(0.0003357202600454912), 'behavior_loss': np.float64(0.2821656197309494)}
step: 17580 @ episode report: {'average_total_reward': np.float32(9.512222), 'reward_variance': np.float32(1.9898142), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(10.6), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05569109320640564), 'actor_loss': np.float64(-0.9928340792655945), 'hyper_actor_loss': np.float64(0.0003318183677038178), 'behavior_loss': np.float64(0.2933136343955994)}
step: 17590 @ episode report: {'average_total_reward': np.float32(9.736667), 'reward_variance': np.float32(1.1334329), 'max_total_reward': np.float32(12.022222), 'min_total_reward': np.float32(8.777778), 'average_n_step': np.float32(10.8), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05989309921860695), 'actor_loss': np.float64(-0.9595571100711823), 'hyper_actor_loss': np.float64(0.0003411395417060703), 'behavior_loss': np.float64(0.32574295699596406)}
step: 17600 @ episode report: {'average_total_reward': np.float32(10.51), 'reward_variance': np.float32(1.8052452), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(11.5), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06255072243511677), 'actor_loss': np.float64(-0.9790341973304748), 'hyper_actor_loss': np.float64(0.0003436580707784742), 'behavior_loss': np.float64(0.3070970445871353)}
step: 17610 @ episode report: {'average_total_reward': np.float32(10.061111), 'reward_variance': np.float32(3.699042), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(11.1), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07091053053736687), 'actor_loss': np.float64(-0.9920177578926086), 'hyper_actor_loss': np.float64(0.0003397657274035737), 'behavior_loss': np.float64(0.31950927078723906)}
step: 17620 @ episode report: {'average_total_reward': np.float32(10.646667), 'reward_variance': np.float32(2.537797), 'max_total_reward': np.float32(14.388889), 'min_total_reward': np.float32(8.900001), 'average_n_step': np.float32(11.6), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.04963527247309685), 'actor_loss': np.float64(-0.9791697084903717), 'hyper_actor_loss': np.float64(0.0003515572112519294), 'behavior_loss': np.float64(0.2892424315214157)}
step: 17630 @ episode report: {'average_total_reward': np.float32(10.061111), 'reward_variance': np.float32(3.0795872), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(7.5333333), 'average_n_step': np.float32(11.1), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.059507342614233495), 'actor_loss': np.float64(-0.9728592038154602), 'hyper_actor_loss': np.float64(0.0003286059101810679), 'behavior_loss': np.float64(0.2910355806350708)}
step: 17640 @ episode report: {'average_total_reward': np.float32(10.024446), 'reward_variance': np.float32(4.573378), 'max_total_reward': np.float32(15.633334), 'min_total_reward': np.float32(7.5333343), 'average_n_step': np.float32(11.1), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07004190236330032), 'actor_loss': np.float64(-1.0138095319271088), 'hyper_actor_loss': np.float64(0.0003833879483863711), 'behavior_loss': np.float64(0.2762963637709618)}
step: 17650 @ episode report: {'average_total_reward': np.float32(10.722223), 'reward_variance': np.float32(2.3132846), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.777778), 'average_n_step': np.float32(11.7), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05481038857251406), 'actor_loss': np.float64(-0.9876277148723602), 'hyper_actor_loss': np.float64(0.0003408226009923965), 'behavior_loss': np.float64(0.31582565158605574)}
step: 17660 @ episode report: {'average_total_reward': np.float32(10.385556), 'reward_variance': np.float32(4.8730636), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(7.533334), 'average_n_step': np.float32(11.4), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07756760716438293), 'actor_loss': np.float64(-0.9634235560894012), 'hyper_actor_loss': np.float64(0.0003510765760438517), 'behavior_loss': np.float64(0.3026730760931969)}
step: 17670 @ episode report: {'average_total_reward': np.float32(10.422223), 'reward_variance': np.float32(2.0335557), 'max_total_reward': np.float32(13.38889), 'min_total_reward': np.float32(8.9), 'average_n_step': np.float32(11.4), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06039434410631657), 'actor_loss': np.float64(-1.0203723430633544), 'hyper_actor_loss': np.float64(0.0003196642908733338), 'behavior_loss': np.float64(0.2851338073611259)}
step: 17680 @ episode report: {'average_total_reward': np.float32(10.734446), 'reward_variance': np.float32(3.747937), 'max_total_reward': np.float32(14.388889), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(11.7), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06029511857777834), 'actor_loss': np.float64(-0.9745314478874206), 'hyper_actor_loss': np.float64(0.0003162612294545397), 'behavior_loss': np.float64(0.2872097000479698)}
step: 17690 @ episode report: {'average_total_reward': np.float32(10.173334), 'reward_variance': np.float32(1.7003748), 'max_total_reward': np.float32(12.266668), 'min_total_reward': np.float32(8.655556), 'average_n_step': np.float32(11.2), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06561720445752144), 'actor_loss': np.float64(-0.9823958456516266), 'hyper_actor_loss': np.float64(0.000315930022043176), 'behavior_loss': np.float64(0.28936774134635923)}
step: 17700 @ episode report: {'average_total_reward': np.float32(10.558889), 'reward_variance': np.float32(5.362744), 'max_total_reward': np.float32(14.38889), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(11.5), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07527473904192447), 'actor_loss': np.float64(-1.0236076593399048), 'hyper_actor_loss': np.float64(0.0003160988533636555), 'behavior_loss': np.float64(0.3090143859386444)}
step: 17710 @ episode report: {'average_total_reward': np.float32(10.610001), 'reward_variance': np.float32(0.4894188), 'max_total_reward': np.float32(11.900001), 'min_total_reward': np.float32(9.9), 'average_n_step': np.float32(11.6), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(11.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07038882039487362), 'actor_loss': np.float64(-1.0067974388599397), 'hyper_actor_loss': np.float64(0.00032241489680018276), 'behavior_loss': np.float64(0.3121701955795288)}
step: 17720 @ episode report: {'average_total_reward': np.float32(11.107779), 'reward_variance': np.float32(4.367336), 'max_total_reward': np.float32(15.633334), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(12.0), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06559001915156841), 'actor_loss': np.float64(-0.9781030118465424), 'hyper_actor_loss': np.float64(0.0003491233044769615), 'behavior_loss': np.float64(0.3012715667486191)}
step: 17730 @ episode report: {'average_total_reward': np.float32(9.536667), 'reward_variance': np.float32(2.9638035), 'max_total_reward': np.float32(12.266666), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.6), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07597723342478276), 'actor_loss': np.float64(-1.0104506969451905), 'hyper_actor_loss': np.float64(0.00034615141048561783), 'behavior_loss': np.float64(0.3105055779218674)}
step: 17740 @ episode report: {'average_total_reward': np.float32(9.077778), 'reward_variance': np.float32(3.4748886), 'max_total_reward': np.float32(12.0222225), 'min_total_reward': np.float32(6.5333333), 'average_n_step': np.float32(10.3), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.058999210223555566), 'actor_loss': np.float64(-0.9974621653556823), 'hyper_actor_loss': np.float64(0.0005603493307717144), 'behavior_loss': np.float64(0.30187232196331026)}
step: 17750 @ episode report: {'average_total_reward': np.float32(7.667778), 'reward_variance': np.float32(4.486233), 'max_total_reward': np.float32(11.0222225), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(9.0), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06547796614468097), 'actor_loss': np.float64(-0.9851381599903106), 'hyper_actor_loss': np.float64(0.0004923959786538035), 'behavior_loss': np.float64(0.2845247179269791)}
step: 17760 @ episode report: {'average_total_reward': np.float32(6.4066668), 'reward_variance': np.float32(3.0822523), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(4.166667), 'average_n_step': np.float32(7.8), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.068430832400918), 'actor_loss': np.float64(-0.9956789255142212), 'hyper_actor_loss': np.float64(0.0004242266179062426), 'behavior_loss': np.float64(0.31212429106235506)}
step: 17770 @ episode report: {'average_total_reward': np.float32(6.694444), 'reward_variance': np.float32(3.84166), 'max_total_reward': np.float32(10.9), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.1), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07001109477132558), 'actor_loss': np.float64(-0.9923983216285706), 'hyper_actor_loss': np.float64(0.0003566368541214615), 'behavior_loss': np.float64(0.3172346591949463)}
step: 17780 @ episode report: {'average_total_reward': np.float32(7.0066667), 'reward_variance': np.float32(2.9281285), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(8.4), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0664336659014225), 'actor_loss': np.float64(-0.9958266019821167), 'hyper_actor_loss': np.float64(0.0003871893364703283), 'behavior_loss': np.float64(0.30713523328304293)}
step: 17790 @ episode report: {'average_total_reward': np.float32(6.3333335), 'reward_variance': np.float32(2.0637527), 'max_total_reward': np.float32(8.655556), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.8), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06739093959331513), 'actor_loss': np.float64(-0.992030245065689), 'hyper_actor_loss': np.float64(0.0003705294599058107), 'behavior_loss': np.float64(0.3209327161312103)}
step: 17800 @ episode report: {'average_total_reward': np.float32(5.7822227), 'reward_variance': np.float32(1.7729927), 'max_total_reward': np.float32(7.777778), 'min_total_reward': np.float32(3.411111), 'average_n_step': np.float32(7.2), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06055099293589592), 'actor_loss': np.float64(-0.9796908259391784), 'hyper_actor_loss': np.float64(0.00036079118435736743), 'behavior_loss': np.float64(0.32997637093067167)}
step: 17810 @ episode report: {'average_total_reward': np.float32(6.0455556), 'reward_variance': np.float32(1.6281593), 'max_total_reward': np.float32(7.777778), 'min_total_reward': np.float32(3.2888892), 'average_n_step': np.float32(7.5), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06942411661148071), 'actor_loss': np.float64(-0.9918147563934326), 'hyper_actor_loss': np.float64(0.0003729100048076361), 'behavior_loss': np.float64(0.2870361328125)}
step: 17820 @ episode report: {'average_total_reward': np.float32(6.8555555), 'reward_variance': np.float32(2.3675056), 'max_total_reward': np.float32(9.777778), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.2), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05489476956427097), 'actor_loss': np.float64(-0.997667109966278), 'hyper_actor_loss': np.float64(0.000375324793276377), 'behavior_loss': np.float64(0.2987934619188309)}
step: 17830 @ episode report: {'average_total_reward': np.float32(5.6966667), 'reward_variance': np.float32(1.1453842), 'max_total_reward': np.float32(7.7777786), 'min_total_reward': np.float32(4.166667), 'average_n_step': np.float32(7.2), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.061841707676649094), 'actor_loss': np.float64(-0.9688516557216644), 'hyper_actor_loss': np.float64(0.00039822971739340575), 'behavior_loss': np.float64(0.32020014226436616)}
step: 17840 @ episode report: {'average_total_reward': np.float32(6.5577784), 'reward_variance': np.float32(2.9351063), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.0), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0672588225454092), 'actor_loss': np.float64(-1.0040936470031738), 'hyper_actor_loss': np.float64(0.0004220462084049359), 'behavior_loss': np.float64(0.3138511151075363)}
step: 17850 @ episode report: {'average_total_reward': np.float32(7.4677787), 'reward_variance': np.float32(5.79327), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.8), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05826906226575375), 'actor_loss': np.float64(-0.98546884059906), 'hyper_actor_loss': np.float64(0.00042810944141820074), 'behavior_loss': np.float64(0.3257842600345612)}
step: 17860 @ episode report: {'average_total_reward': np.float32(8.59), 'reward_variance': np.float32(3.42216), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.8), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06737733036279678), 'actor_loss': np.float64(-0.9641501009464264), 'hyper_actor_loss': np.float64(0.0003786349348956719), 'behavior_loss': np.float64(0.33227840065956116)}
step: 17870 @ episode report: {'average_total_reward': np.float32(7.965556), 'reward_variance': np.float32(3.8191724), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(9.2), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.058411114290356635), 'actor_loss': np.float64(-0.9980004310607911), 'hyper_actor_loss': np.float64(0.00036352383613120766), 'behavior_loss': np.float64(0.3192525625228882)}
step: 17880 @ episode report: {'average_total_reward': np.float32(9.375557), 'reward_variance': np.float32(3.5297737), 'max_total_reward': np.float32(12.144446), 'min_total_reward': np.float32(6.533334), 'average_n_step': np.float32(10.5), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07030033357441426), 'actor_loss': np.float64(-0.9775484323501586), 'hyper_actor_loss': np.float64(0.0003443609923124313), 'behavior_loss': np.float64(0.31156103909015653)}
step: 17890 @ episode report: {'average_total_reward': np.float32(9.512223), 'reward_variance': np.float32(2.099542), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.6555567), 'average_n_step': np.float32(10.6), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06038007084280252), 'actor_loss': np.float64(-0.9881092488765717), 'hyper_actor_loss': np.float64(0.00032429911952931435), 'behavior_loss': np.float64(0.31530116498470306)}
step: 17900 @ episode report: {'average_total_reward': np.float32(8.902224), 'reward_variance': np.float32(1.571328), 'max_total_reward': np.float32(11.0222225), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(10.1), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06898595951497555), 'actor_loss': np.float64(-0.9799020051956177), 'hyper_actor_loss': np.float64(0.0003114890801953152), 'behavior_loss': np.float64(0.31433664858341215)}
step: 17910 @ episode report: {'average_total_reward': np.float32(10.710001), 'reward_variance': np.float32(2.1731217), 'max_total_reward': np.float32(13.144444), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(11.7), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06270826198160648), 'actor_loss': np.float64(-0.9985536456108093), 'hyper_actor_loss': np.float64(0.0003102238348219544), 'behavior_loss': np.float64(0.2927591517567635)}
step: 17920 @ episode report: {'average_total_reward': np.float32(10.14889), 'reward_variance': np.float32(3.9605718), 'max_total_reward': np.float32(14.144444), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(11.2), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06528021171689033), 'actor_loss': np.float64(-0.9921219527721405), 'hyper_actor_loss': np.float64(0.0002965216466691345), 'behavior_loss': np.float64(0.3185356616973877)}
step: 17930 @ episode report: {'average_total_reward': np.float32(10.297778), 'reward_variance': np.float32(2.7488105), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(11.3), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.056042372807860376), 'actor_loss': np.float64(-0.975644463300705), 'hyper_actor_loss': np.float64(0.0002956976240966469), 'behavior_loss': np.float64(0.2952857449650764)}
step: 17940 @ episode report: {'average_total_reward': np.float32(9.948889), 'reward_variance': np.float32(1.866943), 'max_total_reward': np.float32(12.266666), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(11.0), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05859468095004559), 'actor_loss': np.float64(-0.9667962908744812), 'hyper_actor_loss': np.float64(0.0002986542269354686), 'behavior_loss': np.float64(0.31312904953956605)}
step: 17950 @ episode report: {'average_total_reward': np.float32(10.75889), 'reward_variance': np.float32(2.0835576), 'max_total_reward': np.float32(13.38889), 'min_total_reward': np.float32(8.900001), 'average_n_step': np.float32(11.7), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06249901242554188), 'actor_loss': np.float64(-0.9730124592781066), 'hyper_actor_loss': np.float64(0.0003014383837580681), 'behavior_loss': np.float64(0.3113953351974487)}
step: 17960 @ episode report: {'average_total_reward': np.float32(10.085556), 'reward_variance': np.float32(2.2606192), 'max_total_reward': np.float32(13.266668), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(11.1), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06161792688071728), 'actor_loss': np.float64(-0.9911847531795501), 'hyper_actor_loss': np.float64(0.0003169122530380264), 'behavior_loss': np.float64(0.3114355802536011)}
step: 17970 @ episode report: {'average_total_reward': np.float32(8.863335), 'reward_variance': np.float32(1.7418289), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.0), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06684457585215568), 'actor_loss': np.float64(-0.9876044511795044), 'hyper_actor_loss': np.float64(0.00031090234115254133), 'behavior_loss': np.float64(0.3056504249572754)}
step: 17980 @ episode report: {'average_total_reward': np.float32(7.7922225), 'reward_variance': np.float32(3.239977), 'max_total_reward': np.float32(10.900001), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(9.1), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06579363122582435), 'actor_loss': np.float64(-0.9876292049884796), 'hyper_actor_loss': np.float64(0.0003177056758431718), 'behavior_loss': np.float64(0.3163180351257324)}
step: 17990 @ episode report: {'average_total_reward': np.float32(7.2433333), 'reward_variance': np.float32(1.5597641), 'max_total_reward': np.float32(9.777778), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06466177739202976), 'actor_loss': np.float64(-0.9934765815734863), 'hyper_actor_loss': np.float64(0.00030740102811250837), 'behavior_loss': np.float64(0.31756353974342344)}
step: 18000 @ episode report: {'average_total_reward': np.float32(7.9288893), 'reward_variance': np.float32(2.8924003), 'max_total_reward': np.float32(11.0222225), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(9.2), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0667639471590519), 'actor_loss': np.float64(-0.9781238615512848), 'hyper_actor_loss': np.float64(0.000314786346280016), 'behavior_loss': np.float64(0.2973696976900101)}
step: 18010 @ episode report: {'average_total_reward': np.float32(6.1700006), 'reward_variance': np.float32(2.8874826), 'max_total_reward': np.float32(8.777778), 'min_total_reward': np.float32(3.2888892), 'average_n_step': np.float32(7.6), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06429412886500359), 'actor_loss': np.float64(-0.9829765498638153), 'hyper_actor_loss': np.float64(0.0003141785564366728), 'behavior_loss': np.float64(0.33517105877399445)}
step: 18020 @ episode report: {'average_total_reward': np.float32(6.3844447), 'reward_variance': np.float32(2.2803512), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(7.9), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0703220620751381), 'actor_loss': np.float64(-0.9909654080867767), 'hyper_actor_loss': np.float64(0.00034547943796496837), 'behavior_loss': np.float64(0.30211571156978606)}
step: 18030 @ episode report: {'average_total_reward': np.float32(5.808889), 'reward_variance': np.float32(2.1552548), 'max_total_reward': np.float32(8.533334), 'min_total_reward': np.float32(3.4111114), 'average_n_step': np.float32(7.3), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06264880131930113), 'actor_loss': np.float64(-1.0011145532131196), 'hyper_actor_loss': np.float64(0.00035010275605600326), 'behavior_loss': np.float64(0.3115643084049225)}
step: 18040 @ episode report: {'average_total_reward': np.float32(5.0477777), 'reward_variance': np.float32(0.9028905), 'max_total_reward': np.float32(7.533334), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(6.6), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06813369430601597), 'actor_loss': np.float64(-0.9885976672172546), 'hyper_actor_loss': np.float64(0.00035119898384436963), 'behavior_loss': np.float64(0.3097618520259857)}
step: 18050 @ episode report: {'average_total_reward': np.float32(4.998889), 'reward_variance': np.float32(0.7198384), 'max_total_reward': np.float32(6.411112), 'min_total_reward': np.float32(4.166667), 'average_n_step': np.float32(6.6), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07382559515535832), 'actor_loss': np.float64(-0.9901724517345428), 'hyper_actor_loss': np.float64(0.0003482276079012081), 'behavior_loss': np.float64(0.3287098199129105)}
step: 18060 @ episode report: {'average_total_reward': np.float32(4.884444), 'reward_variance': np.float32(0.7071407), 'max_total_reward': np.float32(6.5333333), 'min_total_reward': np.float32(3.4111114), 'average_n_step': np.float32(6.4), 'max_n_step': np.float32(8.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06413117796182632), 'actor_loss': np.float64(-0.9830916106700898), 'hyper_actor_loss': np.float64(0.0003098521672654897), 'behavior_loss': np.float64(0.32331925332546235)}
step: 18070 @ episode report: {'average_total_reward': np.float32(5.957778), 'reward_variance': np.float32(1.3430567), 'max_total_reward': np.float32(7.777778), 'min_total_reward': np.float32(4.166667), 'average_n_step': np.float32(7.4), 'max_n_step': np.float32(9.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07162553295493126), 'actor_loss': np.float64(-0.9909659326076508), 'hyper_actor_loss': np.float64(0.0003281540877651423), 'behavior_loss': np.float64(0.3213346630334854)}
step: 18080 @ episode report: {'average_total_reward': np.float32(6.1066675), 'reward_variance': np.float32(3.144919), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(3.288889), 'average_n_step': np.float32(7.5), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06167218349874019), 'actor_loss': np.float64(-0.9867593705654144), 'hyper_actor_loss': np.float64(0.000392934720730409), 'behavior_loss': np.float64(0.3132708042860031)}
step: 18090 @ episode report: {'average_total_reward': np.float32(7.8655562), 'reward_variance': np.float32(2.7088015), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(9.1), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07844992317259311), 'actor_loss': np.float64(-0.9876602411270141), 'hyper_actor_loss': np.float64(0.00036817974178120493), 'behavior_loss': np.float64(0.32967221140861513)}
step: 18100 @ episode report: {'average_total_reward': np.float32(8.890001), 'reward_variance': np.float32(1.4944063), 'max_total_reward': np.float32(11.022223), 'min_total_reward': np.float32(7.411112), 'average_n_step': np.float32(10.1), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.070367525331676), 'actor_loss': np.float64(-0.9751162827014923), 'hyper_actor_loss': np.float64(0.00028800954460166394), 'behavior_loss': np.float64(0.32869575917720795)}
step: 18110 @ episode report: {'average_total_reward': np.float32(9.075557), 'reward_variance': np.float32(3.7258728), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(6.533334), 'average_n_step': np.float32(10.2), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05840152055025101), 'actor_loss': np.float64(-0.9833329081535339), 'hyper_actor_loss': np.float64(0.00027824353892356155), 'behavior_loss': np.float64(0.3159052848815918)}
step: 18120 @ episode report: {'average_total_reward': np.float32(8.265556), 'reward_variance': np.float32(4.3604064), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(4.2888894), 'average_n_step': np.float32(9.5), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06290133260190486), 'actor_loss': np.float64(-0.9804832100868225), 'hyper_actor_loss': np.float64(0.0002869410585844889), 'behavior_loss': np.float64(0.33685178458690646)}
step: 18130 @ episode report: {'average_total_reward': np.float32(9.051111), 'reward_variance': np.float32(3.411635), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.2), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.053591382689774036), 'actor_loss': np.float64(-0.9627552449703216), 'hyper_actor_loss': np.float64(0.0002912534138886258), 'behavior_loss': np.float64(0.32782813608646394)}
step: 18140 @ episode report: {'average_total_reward': np.float32(9.985556), 'reward_variance': np.float32(1.4869645), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(11.0), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07287257201969624), 'actor_loss': np.float64(-0.9742741167545319), 'hyper_actor_loss': np.float64(0.00030636007722932844), 'behavior_loss': np.float64(0.34478779733181)}
step: 18150 @ episode report: {'average_total_reward': np.float32(10.161112), 'reward_variance': np.float32(1.5408204), 'max_total_reward': np.float32(12.022222), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(11.2), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06987108252942562), 'actor_loss': np.float64(-0.9921192824840546), 'hyper_actor_loss': np.float64(0.0003115318191703409), 'behavior_loss': np.float64(0.321281886100769)}
step: 18160 @ episode report: {'average_total_reward': np.float32(9.985556), 'reward_variance': np.float32(2.8012109), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.655556), 'average_n_step': np.float32(11.0), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07460774332284928), 'actor_loss': np.float64(-0.9894975781440735), 'hyper_actor_loss': np.float64(0.0002951188536826521), 'behavior_loss': np.float64(0.33911789059638975)}
step: 18170 @ episode report: {'average_total_reward': np.float32(10.061111), 'reward_variance': np.float32(1.9299326), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.655556), 'average_n_step': np.float32(11.1), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07336243130266666), 'actor_loss': np.float64(-0.9844291985034943), 'hyper_actor_loss': np.float64(0.000291724520502612), 'behavior_loss': np.float64(0.35345191359519956)}
step: 18180 @ episode report: {'average_total_reward': np.float32(10.373334), 'reward_variance': np.float32(3.5356362), 'max_total_reward': np.float32(13.144445), 'min_total_reward': np.float32(6.5333333), 'average_n_step': np.float32(11.4), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05387974251061678), 'actor_loss': np.float64(-0.9701618850231171), 'hyper_actor_loss': np.float64(0.0003123748872894794), 'behavior_loss': np.float64(0.3348877400159836)}
step: 18190 @ episode report: {'average_total_reward': np.float32(10.185556), 'reward_variance': np.float32(2.8367178), 'max_total_reward': np.float32(12.266666), 'min_total_reward': np.float32(6.5333343), 'average_n_step': np.float32(11.2), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05155334807932377), 'actor_loss': np.float64(-0.953745287656784), 'hyper_actor_loss': np.float64(0.00034210446174256506), 'behavior_loss': np.float64(0.35083492994308474)}
step: 18200 @ episode report: {'average_total_reward': np.float32(11.295557), 'reward_variance': np.float32(4.165265), 'max_total_reward': np.float32(14.511112), 'min_total_reward': np.float32(8.655556), 'average_n_step': np.float32(12.2), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06565954871475696), 'actor_loss': np.float64(-0.9788698375225067), 'hyper_actor_loss': np.float64(0.0003498356702039018), 'behavior_loss': np.float64(0.33599472641944883)}
step: 18210 @ episode report: {'average_total_reward': np.float32(10.285556), 'reward_variance': np.float32(5.4756556), 'max_total_reward': np.float32(14.511111), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(11.3), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05721147283911705), 'actor_loss': np.float64(-0.9798546075820923), 'hyper_actor_loss': np.float64(0.0003437870414927602), 'behavior_loss': np.float64(0.3371404141187668)}
step: 18220 @ episode report: {'average_total_reward': np.float32(10.124445), 'reward_variance': np.float32(1.9491556), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(7.655556), 'average_n_step': np.float32(11.2), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05724194943904877), 'actor_loss': np.float64(-0.9654563903808594), 'hyper_actor_loss': np.float64(0.0003274171001976356), 'behavior_loss': np.float64(0.32587067484855653)}
step: 18230 @ episode report: {'average_total_reward': np.float32(10.846667), 'reward_variance': np.float32(3.5622668), 'max_total_reward': np.float32(14.511111), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(11.8), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.055715576745569706), 'actor_loss': np.float64(-0.9754727005958557), 'hyper_actor_loss': np.float64(0.0003258742799516767), 'behavior_loss': np.float64(0.33161412328481676)}
step: 18240 @ episode report: {'average_total_reward': np.float32(10.65889), 'reward_variance': np.float32(3.6097054), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(11.6), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06264080591499806), 'actor_loss': np.float64(-0.9748651206493377), 'hyper_actor_loss': np.float64(0.00035640482674352824), 'behavior_loss': np.float64(0.3276993453502655)}
step: 18250 @ episode report: {'average_total_reward': np.float32(10.434445), 'reward_variance': np.float32(3.8920124), 'max_total_reward': np.float32(14.511112), 'min_total_reward': np.float32(7.6555552), 'average_n_step': np.float32(11.4), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07026810385286808), 'actor_loss': np.float64(-0.9830009639263153), 'hyper_actor_loss': np.float64(0.00035647956538014113), 'behavior_loss': np.float64(0.3338160037994385)}
step: 18260 @ episode report: {'average_total_reward': np.float32(10.297778), 'reward_variance': np.float32(2.1273541), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(8.777777), 'average_n_step': np.float32(11.3), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06567583382129669), 'actor_loss': np.float64(-0.9779186844825745), 'hyper_actor_loss': np.float64(0.00036867505696136504), 'behavior_loss': np.float64(0.34679036140441893)}
step: 18270 @ episode report: {'average_total_reward': np.float32(11.371112), 'reward_variance': np.float32(3.7115123), 'max_total_reward': np.float32(14.266666), 'min_total_reward': np.float32(8.655555), 'average_n_step': np.float32(12.3), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07047718279063701), 'actor_loss': np.float64(-0.9811589300632477), 'hyper_actor_loss': np.float64(0.0004367728601209819), 'behavior_loss': np.float64(0.3545455992221832)}
step: 18280 @ episode report: {'average_total_reward': np.float32(10.883334), 'reward_variance': np.float32(1.7817348), 'max_total_reward': np.float32(13.38889), 'min_total_reward': np.float32(8.777779), 'average_n_step': np.float32(11.8), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06247032880783081), 'actor_loss': np.float64(-0.977020388841629), 'hyper_actor_loss': np.float64(0.0003975143772549927), 'behavior_loss': np.float64(0.34772693514823916)}
step: 18290 @ episode report: {'average_total_reward': np.float32(10.797778), 'reward_variance': np.float32(4.2758956), 'max_total_reward': np.float32(14.144444), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(11.8), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06216316930949688), 'actor_loss': np.float64(-0.9717500150203705), 'hyper_actor_loss': np.float64(0.00037980723427608607), 'behavior_loss': np.float64(0.3380635529756546)}
step: 18300 @ episode report: {'average_total_reward': np.float32(10.722223), 'reward_variance': np.float32(2.728765), 'max_total_reward': np.float32(13.266666), 'min_total_reward': np.float32(7.6555567), 'average_n_step': np.float32(11.7), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.060345759615302086), 'actor_loss': np.float64(-0.9719029486179351), 'hyper_actor_loss': np.float64(0.00038720905431546273), 'behavior_loss': np.float64(0.33626759946346285)}
step: 18310 @ episode report: {'average_total_reward': np.float32(10.622223), 'reward_variance': np.float32(2.1757026), 'max_total_reward': np.float32(13.144444), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(11.6), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07074648700654507), 'actor_loss': np.float64(-0.9828467011451721), 'hyper_actor_loss': np.float64(0.00034967435349244627), 'behavior_loss': np.float64(0.3450393557548523)}
step: 18320 @ episode report: {'average_total_reward': np.float32(10.634445), 'reward_variance': np.float32(2.3838391), 'max_total_reward': np.float32(13.266668), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(11.6), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05360156036913395), 'actor_loss': np.float64(-0.9809457063674927), 'hyper_actor_loss': np.float64(0.00034686166909523306), 'behavior_loss': np.float64(0.32821000516414645)}
step: 18330 @ episode report: {'average_total_reward': np.float32(11.320001), 'reward_variance': np.float32(3.5592797), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(12.2), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0644802637398243), 'actor_loss': np.float64(-0.9668492615222931), 'hyper_actor_loss': np.float64(0.0003749463241547346), 'behavior_loss': np.float64(0.3192215323448181)}
step: 18340 @ episode report: {'average_total_reward': np.float32(11.607778), 'reward_variance': np.float32(7.548323), 'max_total_reward': np.float32(15.633334), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(12.5), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06793879643082619), 'actor_loss': np.float64(-0.9873109459877014), 'hyper_actor_loss': np.float64(0.00037222793325781823), 'behavior_loss': np.float64(0.33858729898929596)}
step: 18350 @ episode report: {'average_total_reward': np.float32(12.305557), 'reward_variance': np.float32(3.186328), 'max_total_reward': np.float32(15.633334), 'min_total_reward': np.float32(9.900001), 'average_n_step': np.float32(13.1), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(11.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05916009657084942), 'actor_loss': np.float64(-0.9911991953849792), 'hyper_actor_loss': np.float64(0.00041806182125583293), 'behavior_loss': np.float64(0.33201884776353835)}
step: 18360 @ episode report: {'average_total_reward': np.float32(11.495557), 'reward_variance': np.float32(1.5999311), 'max_total_reward': np.float32(14.38889), 'min_total_reward': np.float32(9.900001), 'average_n_step': np.float32(12.4), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(11.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07555492892861367), 'actor_loss': np.float64(-0.9746441841125488), 'hyper_actor_loss': np.float64(0.00040550162375438956), 'behavior_loss': np.float64(0.335032194852829)}
step: 18370 @ episode report: {'average_total_reward': np.float32(10.85889), 'reward_variance': np.float32(3.794347), 'max_total_reward': np.float32(14.38889), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(11.8), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06459978278726339), 'actor_loss': np.float64(-0.9890409409999847), 'hyper_actor_loss': np.float64(0.0003252066788263619), 'behavior_loss': np.float64(0.35427031815052035)}
step: 18380 @ episode report: {'average_total_reward': np.float32(10.883334), 'reward_variance': np.float32(1.4231174), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.777778), 'average_n_step': np.float32(11.8), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07081652469933034), 'actor_loss': np.float64(-0.9814378976821899), 'hyper_actor_loss': np.float64(0.00031408298236783593), 'behavior_loss': np.float64(0.32722158432006837)}
step: 18390 @ episode report: {'average_total_reward': np.float32(10.3977785), 'reward_variance': np.float32(0.936267), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(8.655556), 'average_n_step': np.float32(11.4), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0680898804217577), 'actor_loss': np.float64(-0.9974756836891174), 'hyper_actor_loss': np.float64(0.0003175681602442637), 'behavior_loss': np.float64(0.33942619562149046)}
step: 18400 @ episode report: {'average_total_reward': np.float32(10.185556), 'reward_variance': np.float32(4.8322735), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(5.533333), 'average_n_step': np.float32(11.2), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07814887650310993), 'actor_loss': np.float64(-0.9693592071533204), 'hyper_actor_loss': np.float64(0.00031263678101822734), 'behavior_loss': np.float64(0.3611206620931625)}
step: 18410 @ episode report: {'average_total_reward': np.float32(10.95889), 'reward_variance': np.float32(2.8741), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(7.777778), 'average_n_step': np.float32(11.9), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07308735884726048), 'actor_loss': np.float64(-0.9955294191837311), 'hyper_actor_loss': np.float64(0.0003012106870301068), 'behavior_loss': np.float64(0.32954799830913545)}
step: 18420 @ episode report: {'average_total_reward': np.float32(10.846666), 'reward_variance': np.float32(2.4694762), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(8.777778), 'average_n_step': np.float32(11.8), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07125792726874351), 'actor_loss': np.float64(-0.9905824065208435), 'hyper_actor_loss': np.float64(0.000294457288691774), 'behavior_loss': np.float64(0.3363602846860886)}
step: 18430 @ episode report: {'average_total_reward': np.float32(11.220001), 'reward_variance': np.float32(6.838095), 'max_total_reward': np.float32(14.511112), 'min_total_reward': np.float32(6.5333333), 'average_n_step': np.float32(12.1), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0620353989303112), 'actor_loss': np.float64(-0.9785676240921021), 'hyper_actor_loss': np.float64(0.00031049101962707935), 'behavior_loss': np.float64(0.3368842571973801)}
step: 18440 @ episode report: {'average_total_reward': np.float32(9.973333), 'reward_variance': np.float32(2.4949183), 'max_total_reward': np.float32(12.144444), 'min_total_reward': np.float32(6.5333333), 'average_n_step': np.float32(11.0), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0684744231402874), 'actor_loss': np.float64(-0.9818843901157379), 'hyper_actor_loss': np.float64(0.00030007667373865843), 'behavior_loss': np.float64(0.3080084800720215)}
step: 18450 @ episode report: {'average_total_reward': np.float32(11.420001), 'reward_variance': np.float32(5.571328), 'max_total_reward': np.float32(14.511111), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(12.3), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07397670969367028), 'actor_loss': np.float64(-1.002078378200531), 'hyper_actor_loss': np.float64(0.00029495231865439564), 'behavior_loss': np.float64(0.3404203623533249)}
step: 18460 @ episode report: {'average_total_reward': np.float32(11.207779), 'reward_variance': np.float32(2.4850633), 'max_total_reward': np.float32(13.266666), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(12.1), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06445012651383877), 'actor_loss': np.float64(-0.972412395477295), 'hyper_actor_loss': np.float64(0.000320456808549352), 'behavior_loss': np.float64(0.3358806908130646)}
step: 18470 @ episode report: {'average_total_reward': np.float32(11.1466675), 'reward_variance': np.float32(5.131996), 'max_total_reward': np.float32(14.511111), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(12.1), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07429680936038494), 'actor_loss': np.float64(-0.9814569473266601), 'hyper_actor_loss': np.float64(0.00032636054675094783), 'behavior_loss': np.float64(0.33640168607234955)}
step: 18480 @ episode report: {'average_total_reward': np.float32(11.420001), 'reward_variance': np.float32(2.3323412), 'max_total_reward': np.float32(15.388889), 'min_total_reward': np.float32(10.022222), 'average_n_step': np.float32(12.3), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(11.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0763592291623354), 'actor_loss': np.float64(-1.0010296642780303), 'hyper_actor_loss': np.float64(0.0002979698736453429), 'behavior_loss': np.float64(0.3539375215768814)}
step: 18490 @ episode report: {'average_total_reward': np.float32(11.307779), 'reward_variance': np.float32(4.4606924), 'max_total_reward': np.float32(14.511112), 'min_total_reward': np.float32(7.533334), 'average_n_step': np.float32(12.2), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07074637562036515), 'actor_loss': np.float64(-0.9984392642974853), 'hyper_actor_loss': np.float64(0.00030470039346255364), 'behavior_loss': np.float64(0.3365760535001755)}
step: 18500 @ episode report: {'average_total_reward': np.float32(11.071112), 'reward_variance': np.float32(0.9896353), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(8.9), 'average_n_step': np.float32(12.0), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07007781080901623), 'actor_loss': np.float64(-0.984858363866806), 'hyper_actor_loss': np.float64(0.00030385318968910723), 'behavior_loss': np.float64(0.34117637276649476)}
step: 18510 @ episode report: {'average_total_reward': np.float32(12.156668), 'reward_variance': np.float32(1.8372713), 'max_total_reward': np.float32(14.511112), 'min_total_reward': np.float32(10.0222225), 'average_n_step': np.float32(13.0), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(11.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07284018099308014), 'actor_loss': np.float64(-0.9792591810226441), 'hyper_actor_loss': np.float64(0.0003035052999621257), 'behavior_loss': np.float64(0.3517428785562515)}
step: 18520 @ episode report: {'average_total_reward': np.float32(11.632223), 'reward_variance': np.float32(5.197345), 'max_total_reward': np.float32(14.511112), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(12.5), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.060462775826454165), 'actor_loss': np.float64(-0.9752020120620728), 'hyper_actor_loss': np.float64(0.0003329286730149761), 'behavior_loss': np.float64(0.34323233366012573)}
step: 18530 @ episode report: {'average_total_reward': np.float32(9.836667), 'reward_variance': np.float32(2.3733346), 'max_total_reward': np.float32(12.266666), 'min_total_reward': np.float32(7.533334), 'average_n_step': np.float32(10.9), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07098792418837548), 'actor_loss': np.float64(-0.9711087107658386), 'hyper_actor_loss': np.float64(0.00033071350189857186), 'behavior_loss': np.float64(0.35320129096508024)}
step: 18540 @ episode report: {'average_total_reward': np.float32(10.983335), 'reward_variance': np.float32(9.370526), 'max_total_reward': np.float32(15.633334), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(11.9), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07715671397745609), 'actor_loss': np.float64(-0.9997779309749604), 'hyper_actor_loss': np.float64(0.00029662984306924047), 'behavior_loss': np.float64(0.3198682129383087)}
step: 18550 @ episode report: {'average_total_reward': np.float32(11.520001), 'reward_variance': np.float32(5.110416), 'max_total_reward': np.float32(13.38889), 'min_total_reward': np.float32(6.1666665), 'average_n_step': np.float32(12.4), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06571191549301147), 'actor_loss': np.float64(-0.9940681278705596), 'hyper_actor_loss': np.float64(0.00031871718820184467), 'behavior_loss': np.float64(0.34476245641708375)}
step: 18560 @ episode report: {'average_total_reward': np.float32(10.85889), 'reward_variance': np.float32(5.60736), 'max_total_reward': np.float32(15.633334), 'min_total_reward': np.float32(7.655556), 'average_n_step': np.float32(11.8), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0801557157188654), 'actor_loss': np.float64(-0.9713334977626801), 'hyper_actor_loss': np.float64(0.0004564317816402763), 'behavior_loss': np.float64(0.36483265459537506)}
step: 18570 @ episode report: {'average_total_reward': np.float32(10.558889), 'reward_variance': np.float32(2.0529397), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(11.5), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07010645121335983), 'actor_loss': np.float64(-1.0079528570175171), 'hyper_actor_loss': np.float64(0.00048568892525509), 'behavior_loss': np.float64(0.35162085592746734)}
step: 18580 @ episode report: {'average_total_reward': np.float32(10.983335), 'reward_variance': np.float32(1.8995135), 'max_total_reward': np.float32(13.38889), 'min_total_reward': np.float32(8.900001), 'average_n_step': np.float32(11.9), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05825054310262203), 'actor_loss': np.float64(-0.9806245326995849), 'hyper_actor_loss': np.float64(0.0003636020497651771), 'behavior_loss': np.float64(0.3680535048246384)}
step: 18590 @ episode report: {'average_total_reward': np.float32(11.395556), 'reward_variance': np.float32(2.0668948), 'max_total_reward': np.float32(14.38889), 'min_total_reward': np.float32(9.777778), 'average_n_step': np.float32(12.3), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(11.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07398491464555264), 'actor_loss': np.float64(-0.9585170328617096), 'hyper_actor_loss': np.float64(0.0003381052432814613), 'behavior_loss': np.float64(0.33421704173088074)}
step: 18600 @ episode report: {'average_total_reward': np.float32(11.195557), 'reward_variance': np.float32(3.1288693), 'max_total_reward': np.float32(14.511111), 'min_total_reward': np.float32(8.777779), 'average_n_step': np.float32(12.1), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.061330271884799004), 'actor_loss': np.float64(-1.0082375347614287), 'hyper_actor_loss': np.float64(0.00027435953670646996), 'behavior_loss': np.float64(0.30115694403648374)}
step: 18610 @ episode report: {'average_total_reward': np.float32(11.007778), 'reward_variance': np.float32(1.8459513), 'max_total_reward': np.float32(13.388888), 'min_total_reward': np.float32(8.900001), 'average_n_step': np.float32(11.9), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05564122125506401), 'actor_loss': np.float64(-0.9817743241786957), 'hyper_actor_loss': np.float64(0.00028273184434510765), 'behavior_loss': np.float64(0.33356539309024813)}
step: 18620 @ episode report: {'average_total_reward': np.float32(12.2300005), 'reward_variance': np.float32(1.6241243), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(9.900001), 'average_n_step': np.float32(13.0), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(11.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08188258707523347), 'actor_loss': np.float64(-0.976999831199646), 'hyper_actor_loss': np.float64(0.0002781291594146751), 'behavior_loss': np.float64(0.3386110246181488)}
step: 18630 @ episode report: {'average_total_reward': np.float32(11.744446), 'reward_variance': np.float32(5.275532), 'max_total_reward': np.float32(15.633334), 'min_total_reward': np.float32(8.655555), 'average_n_step': np.float32(12.6), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08480056114494801), 'actor_loss': np.float64(-1.0180813550949097), 'hyper_actor_loss': np.float64(0.000270295818336308), 'behavior_loss': np.float64(0.3103362530469894)}
step: 18640 @ episode report: {'average_total_reward': np.float32(10.51), 'reward_variance': np.float32(2.1089997), 'max_total_reward': np.float32(13.38889), 'min_total_reward': np.float32(8.777778), 'average_n_step': np.float32(11.5), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0731439832597971), 'actor_loss': np.float64(-0.9976216852664948), 'hyper_actor_loss': np.float64(0.0002611354721011594), 'behavior_loss': np.float64(0.35201391875743865)}
step: 18650 @ episode report: {'average_total_reward': np.float32(9.612223), 'reward_variance': np.float32(1.3937644), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(8.655556), 'average_n_step': np.float32(10.7), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05932989977300167), 'actor_loss': np.float64(-0.97075856924057), 'hyper_actor_loss': np.float64(0.00026658944407245146), 'behavior_loss': np.float64(0.3305211067199707)}
step: 18660 @ episode report: {'average_total_reward': np.float32(10.8977785), 'reward_variance': np.float32(1.4216743), 'max_total_reward': np.float32(12.0222225), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(11.9), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07277499102056026), 'actor_loss': np.float64(-0.9865120768547058), 'hyper_actor_loss': np.float64(0.0002692524722078815), 'behavior_loss': np.float64(0.34204149544239043)}
step: 18670 @ episode report: {'average_total_reward': np.float32(10.995557), 'reward_variance': np.float32(1.0883262), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(8.900001), 'average_n_step': np.float32(11.9), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06508190929889679), 'actor_loss': np.float64(-0.992612338066101), 'hyper_actor_loss': np.float64(0.00029775671428069474), 'behavior_loss': np.float64(0.3591756194829941)}
step: 18680 @ episode report: {'average_total_reward': np.float32(10.048889), 'reward_variance': np.float32(3.027018), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(6.5333333), 'average_n_step': np.float32(11.1), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06973250806331635), 'actor_loss': np.float64(-0.9698203325271606), 'hyper_actor_loss': np.float64(0.00035668321361299605), 'behavior_loss': np.float64(0.36900708079338074)}
step: 18690 @ episode report: {'average_total_reward': np.float32(10.858889), 'reward_variance': np.float32(4.9938784), 'max_total_reward': np.float32(14.511112), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(11.8), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07296128235757351), 'actor_loss': np.float64(-0.987544983625412), 'hyper_actor_loss': np.float64(0.0003828482236713171), 'behavior_loss': np.float64(0.3671234607696533)}
step: 18700 @ episode report: {'average_total_reward': np.float32(10.161112), 'reward_variance': np.float32(1.2565248), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(8.655556), 'average_n_step': np.float32(11.2), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05737997479736805), 'actor_loss': np.float64(-0.9801037430763244), 'hyper_actor_loss': np.float64(0.0003336797031806782), 'behavior_loss': np.float64(0.33657858073711394)}
step: 18710 @ episode report: {'average_total_reward': np.float32(11.120001), 'reward_variance': np.float32(3.276785), 'max_total_reward': np.float32(13.38889), 'min_total_reward': np.float32(8.777779), 'average_n_step': np.float32(12.0), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07215378284454346), 'actor_loss': np.float64(-0.9743550062179566), 'hyper_actor_loss': np.float64(0.00037291447806637735), 'behavior_loss': np.float64(0.35468685030937197)}
step: 18720 @ episode report: {'average_total_reward': np.float32(11.058889), 'reward_variance': np.float32(5.493533), 'max_total_reward': np.float32(14.511111), 'min_total_reward': np.float32(6.533334), 'average_n_step': np.float32(12.0), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07174549624323845), 'actor_loss': np.float64(-0.9885279595851898), 'hyper_actor_loss': np.float64(0.00041883293888531623), 'behavior_loss': np.float64(0.36332681477069856)}
step: 18730 @ episode report: {'average_total_reward': np.float32(11.107779), 'reward_variance': np.float32(1.8485689), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(8.777779), 'average_n_step': np.float32(12.0), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06288928575813771), 'actor_loss': np.float64(-0.9907459139823913), 'hyper_actor_loss': np.float64(0.00042579003784339877), 'behavior_loss': np.float64(0.3485980272293091)}
step: 18740 @ episode report: {'average_total_reward': np.float32(11.707778), 'reward_variance': np.float32(3.1520257), 'max_total_reward': np.float32(14.511112), 'min_total_reward': np.float32(8.900001), 'average_n_step': np.float32(12.6), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0725297074764967), 'actor_loss': np.float64(-0.9842097997665405), 'hyper_actor_loss': np.float64(0.0004150373657466844), 'behavior_loss': np.float64(0.32787263989448545)}
step: 18750 @ episode report: {'average_total_reward': np.float32(10.385556), 'reward_variance': np.float32(2.8844948), 'max_total_reward': np.float32(14.266666), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(11.4), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07038362547755242), 'actor_loss': np.float64(-0.9979731619358063), 'hyper_actor_loss': np.float64(0.0004076036770129576), 'behavior_loss': np.float64(0.3309101402759552)}
step: 18760 @ episode report: {'average_total_reward': np.float32(11.195557), 'reward_variance': np.float32(2.1487956), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(12.1), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06062116920948028), 'actor_loss': np.float64(-0.9841756403446198), 'hyper_actor_loss': np.float64(0.00036969008797314016), 'behavior_loss': np.float64(0.34146833419799805)}
step: 18770 @ episode report: {'average_total_reward': np.float32(11.007779), 'reward_variance': np.float32(1.3970635), 'max_total_reward': np.float32(12.266668), 'min_total_reward': np.float32(8.9), 'average_n_step': np.float32(11.9), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07427877187728882), 'actor_loss': np.float64(-0.9877593874931335), 'hyper_actor_loss': np.float64(0.00038649944472126665), 'behavior_loss': np.float64(0.34974345266819)}
step: 18780 @ episode report: {'average_total_reward': np.float32(11.483335), 'reward_variance': np.float32(2.1500077), 'max_total_reward': np.float32(14.388889), 'min_total_reward': np.float32(9.655555), 'average_n_step': np.float32(12.4), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(11.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07056948859244586), 'actor_loss': np.float64(-1.0006128430366517), 'hyper_actor_loss': np.float64(0.0003490258619422093), 'behavior_loss': np.float64(0.34448306560516356)}
step: 18790 @ episode report: {'average_total_reward': np.float32(10.6466675), 'reward_variance': np.float32(3.4570327), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(11.6), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07007663175463677), 'actor_loss': np.float64(-0.9866955816745758), 'hyper_actor_loss': np.float64(0.0003265242819907144), 'behavior_loss': np.float64(0.344262021780014)}
step: 18800 @ episode report: {'average_total_reward': np.float32(12.056667), 'reward_variance': np.float32(3.0644307), 'max_total_reward': np.float32(15.511112), 'min_total_reward': np.float32(9.900001), 'average_n_step': np.float32(12.9), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(11.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0693787194788456), 'actor_loss': np.float64(-0.9831933975219727), 'hyper_actor_loss': np.float64(0.0003257522970670834), 'behavior_loss': np.float64(0.3563908040523529)}
step: 18810 @ episode report: {'average_total_reward': np.float32(11.407779), 'reward_variance': np.float32(4.982865), 'max_total_reward': np.float32(14.388889), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(12.3), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06171622909605503), 'actor_loss': np.float64(-0.978389436006546), 'hyper_actor_loss': np.float64(0.00031942015630193055), 'behavior_loss': np.float64(0.35053011775016785)}
step: 18820 @ episode report: {'average_total_reward': np.float32(10.334445), 'reward_variance': np.float32(2.8020847), 'max_total_reward': np.float32(12.266668), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(11.3), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06658035777509212), 'actor_loss': np.float64(-0.977560567855835), 'hyper_actor_loss': np.float64(0.00029783805075567216), 'behavior_loss': np.float64(0.34970634877681733)}
step: 18830 @ episode report: {'average_total_reward': np.float32(10.983334), 'reward_variance': np.float32(2.1758342), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(8.777778), 'average_n_step': np.float32(11.9), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07280046902596951), 'actor_loss': np.float64(-0.9918201804161072), 'hyper_actor_loss': np.float64(0.00029802130884490905), 'behavior_loss': np.float64(0.363082492351532)}
step: 18840 @ episode report: {'average_total_reward': np.float32(11.607779), 'reward_variance': np.float32(3.9681747), 'max_total_reward': np.float32(14.511112), 'min_total_reward': np.float32(8.533334), 'average_n_step': np.float32(12.5), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06435460429638624), 'actor_loss': np.float64(-0.9825919508934021), 'hyper_actor_loss': np.float64(0.0002746152720646933), 'behavior_loss': np.float64(0.34157003462314606)}
step: 18850 @ episode report: {'average_total_reward': np.float32(10.14889), 'reward_variance': np.float32(0.94203025), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(11.2), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07158408276736736), 'actor_loss': np.float64(-0.992585027217865), 'hyper_actor_loss': np.float64(0.00028503382636699823), 'behavior_loss': np.float64(0.3388667404651642)}
step: 18860 @ episode report: {'average_total_reward': np.float32(10.771112), 'reward_variance': np.float32(1.2229922), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(8.900001), 'average_n_step': np.float32(11.7), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07354996576905251), 'actor_loss': np.float64(-0.9947080135345459), 'hyper_actor_loss': np.float64(0.0002888374699978158), 'behavior_loss': np.float64(0.3612985372543335)}
step: 18870 @ episode report: {'average_total_reward': np.float32(10.336667), 'reward_variance': np.float32(2.7580016), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.4111114), 'average_n_step': np.float32(11.4), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05860813185572624), 'actor_loss': np.float64(-0.9818018138408661), 'hyper_actor_loss': np.float64(0.0002970055618789047), 'behavior_loss': np.float64(0.36826473474502563)}
step: 18880 @ episode report: {'average_total_reward': np.float32(10.248889), 'reward_variance': np.float32(4.2202525), 'max_total_reward': np.float32(13.38889), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(11.3), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06480161584913731), 'actor_loss': np.float64(-0.9616042792797088), 'hyper_actor_loss': np.float64(0.0003287310304585844), 'behavior_loss': np.float64(0.34510785937309263)}
step: 18890 @ episode report: {'average_total_reward': np.float32(11.183334), 'reward_variance': np.float32(2.7454147), 'max_total_reward': np.float32(14.38889), 'min_total_reward': np.float32(8.9), 'average_n_step': np.float32(12.1), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06982228066772223), 'actor_loss': np.float64(-1.00134996175766), 'hyper_actor_loss': np.float64(0.0003378172608790919), 'behavior_loss': np.float64(0.3776366949081421)}
step: 18900 @ episode report: {'average_total_reward': np.float32(9.961111), 'reward_variance': np.float32(1.1289451), 'max_total_reward': np.float32(12.022223), 'min_total_reward': np.float32(8.777778), 'average_n_step': np.float32(11.0), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05704321525990963), 'actor_loss': np.float64(-0.9866061091423035), 'hyper_actor_loss': np.float64(0.00032431723666377367), 'behavior_loss': np.float64(0.351476189494133)}
step: 18910 @ episode report: {'average_total_reward': np.float32(10.65889), 'reward_variance': np.float32(2.3697793), 'max_total_reward': np.float32(13.38889), 'min_total_reward': np.float32(8.777778), 'average_n_step': np.float32(11.6), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07778688371181489), 'actor_loss': np.float64(-0.9743043124675751), 'hyper_actor_loss': np.float64(0.00030679616902489214), 'behavior_loss': np.float64(0.36614049673080445)}
step: 18920 @ episode report: {'average_total_reward': np.float32(11.344446), 'reward_variance': np.float32(2.6513333), 'max_total_reward': np.float32(14.38889), 'min_total_reward': np.float32(8.900001), 'average_n_step': np.float32(12.2), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06583187505602836), 'actor_loss': np.float64(-0.9887301564216614), 'hyper_actor_loss': np.float64(0.0003387268545338884), 'behavior_loss': np.float64(0.3716380953788757)}
step: 18930 @ episode report: {'average_total_reward': np.float32(10.161112), 'reward_variance': np.float32(4.7074637), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(6.2888894), 'average_n_step': np.float32(11.2), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08185988813638687), 'actor_loss': np.float64(-0.997857391834259), 'hyper_actor_loss': np.float64(0.0003414689184864983), 'behavior_loss': np.float64(0.37136845886707304)}
step: 18940 @ episode report: {'average_total_reward': np.float32(11.76889), 'reward_variance': np.float32(4.456564), 'max_total_reward': np.float32(15.633334), 'min_total_reward': np.float32(8.777779), 'average_n_step': np.float32(12.6), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07041240893304349), 'actor_loss': np.float64(-0.9951258897781372), 'hyper_actor_loss': np.float64(0.0003831045964034274), 'behavior_loss': np.float64(0.3885611712932587)}
step: 18950 @ episode report: {'average_total_reward': np.float32(10.822223), 'reward_variance': np.float32(1.4921725), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(8.777779), 'average_n_step': np.float32(11.8), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07983772531151771), 'actor_loss': np.float64(-0.992994076013565), 'hyper_actor_loss': np.float64(0.0005120264191646129), 'behavior_loss': np.float64(0.3616158694028854)}
step: 18960 @ episode report: {'average_total_reward': np.float32(10.734446), 'reward_variance': np.float32(1.7663323), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(8.777778), 'average_n_step': np.float32(11.7), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06532761715352535), 'actor_loss': np.float64(-1.012891376018524), 'hyper_actor_loss': np.float64(0.0005348452454200014), 'behavior_loss': np.float64(0.36070024967193604)}
step: 18970 @ episode report: {'average_total_reward': np.float32(9.973333), 'reward_variance': np.float32(3.2779808), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(6.5333333), 'average_n_step': np.float32(11.0), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06425707750022411), 'actor_loss': np.float64(-0.9750782012939453), 'hyper_actor_loss': np.float64(0.00047143840347416697), 'behavior_loss': np.float64(0.3543843239545822)}
step: 18980 @ episode report: {'average_total_reward': np.float32(10.746668), 'reward_variance': np.float32(2.6615262), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(8.655556), 'average_n_step': np.float32(11.7), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07013203352689742), 'actor_loss': np.float64(-0.9918783605098724), 'hyper_actor_loss': np.float64(0.0004548666503978893), 'behavior_loss': np.float64(0.38291302919387815)}
step: 18990 @ episode report: {'average_total_reward': np.float32(10.710001), 'reward_variance': np.float32(3.642999), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(11.7), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06823759712278843), 'actor_loss': np.float64(-0.9890838146209717), 'hyper_actor_loss': np.float64(0.0004518212401308119), 'behavior_loss': np.float64(0.41440813839435575)}
step: 19000 @ episode report: {'average_total_reward': np.float32(10.1), 'reward_variance': np.float32(1.1639755), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(8.777778), 'average_n_step': np.float32(11.2), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.079397177323699), 'actor_loss': np.float64(-0.983291631937027), 'hyper_actor_loss': np.float64(0.0004970880982000381), 'behavior_loss': np.float64(0.37281920909881594)}
step: 19010 @ episode report: {'average_total_reward': np.float32(9.263333), 'reward_variance': np.float32(1.4525442), 'max_total_reward': np.float32(11.022223), 'min_total_reward': np.float32(7.6555567), 'average_n_step': np.float32(10.4), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07080910615622997), 'actor_loss': np.float64(-0.9956271886825562), 'hyper_actor_loss': np.float64(0.00045406821591313927), 'behavior_loss': np.float64(0.39220036268234254)}
step: 19020 @ episode report: {'average_total_reward': np.float32(8.814445), 'reward_variance': np.float32(3.2071872), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.0), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06219227071851492), 'actor_loss': np.float64(-0.9788687229156494), 'hyper_actor_loss': np.float64(0.0003754499339265749), 'behavior_loss': np.float64(0.4023631036281586)}
step: 19030 @ episode report: {'average_total_reward': np.float32(9.4388895), 'reward_variance': np.float32(3.214377), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(6.5333333), 'average_n_step': np.float32(10.6), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06442642994225026), 'actor_loss': np.float64(-0.9813906610012054), 'hyper_actor_loss': np.float64(0.00036692449066322297), 'behavior_loss': np.float64(0.37595023214817047)}
step: 19040 @ episode report: {'average_total_reward': np.float32(8.114445), 'reward_variance': np.float32(5.5129647), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(9.3), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06546760462224484), 'actor_loss': np.float64(-0.9853234171867371), 'hyper_actor_loss': np.float64(0.0003588682360714301), 'behavior_loss': np.float64(0.37664628624916074)}
step: 19050 @ episode report: {'average_total_reward': np.float32(7.953334), 'reward_variance': np.float32(1.579674), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.2), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06616738848388196), 'actor_loss': np.float64(-0.9862509608268738), 'hyper_actor_loss': np.float64(0.00037597348855342714), 'behavior_loss': np.float64(0.37270013689994813)}
step: 19060 @ episode report: {'average_total_reward': np.float32(8.565557), 'reward_variance': np.float32(1.7589748), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(9.8), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06257861852645874), 'actor_loss': np.float64(-0.9895657479763031), 'hyper_actor_loss': np.float64(0.0003606262995162979), 'behavior_loss': np.float64(0.3891347497701645)}
step: 19070 @ episode report: {'average_total_reward': np.float32(8.253334), 'reward_variance': np.float32(1.6354516), 'max_total_reward': np.float32(10.9), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.5), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06355975903570651), 'actor_loss': np.float64(-0.9795145571231842), 'hyper_actor_loss': np.float64(0.00033029103360604495), 'behavior_loss': np.float64(0.38196735382080077)}
step: 19080 @ episode report: {'average_total_reward': np.float32(7.604445), 'reward_variance': np.float32(1.5383012), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(8.9), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06682473570108413), 'actor_loss': np.float64(-0.9658977508544921), 'hyper_actor_loss': np.float64(0.00033049851190298797), 'behavior_loss': np.float64(0.3924741119146347)}
step: 19090 @ episode report: {'average_total_reward': np.float32(8.092222), 'reward_variance': np.float32(1.6133343), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(6.288889), 'average_n_step': np.float32(9.4), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07391445450484753), 'actor_loss': np.float64(-0.9932716667652131), 'hyper_actor_loss': np.float64(0.0003542195918271318), 'behavior_loss': np.float64(0.39955560564994813)}
step: 19100 @ episode report: {'average_total_reward': np.float32(7.7655554), 'reward_variance': np.float32(3.0542827), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(4.288889), 'average_n_step': np.float32(9.0), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07613800130784512), 'actor_loss': np.float64(-0.9935874164104461), 'hyper_actor_loss': np.float64(0.00034476510772947223), 'behavior_loss': np.float64(0.38040336668491365)}
step: 19110 @ episode report: {'average_total_reward': np.float32(8.626667), 'reward_variance': np.float32(2.4804497), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(9.8), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07205536216497421), 'actor_loss': np.float64(-1.0032429695129395), 'hyper_actor_loss': np.float64(0.0003283127036411315), 'behavior_loss': np.float64(0.39052545130252836)}
step: 19120 @ episode report: {'average_total_reward': np.float32(8.690001), 'reward_variance': np.float32(1.4169987), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(9.9), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06632102690637112), 'actor_loss': np.float64(-0.9821747422218323), 'hyper_actor_loss': np.float64(0.00035512077156454327), 'behavior_loss': np.float64(0.3647447407245636)}
step: 19130 @ episode report: {'average_total_reward': np.float32(7.816667), 'reward_variance': np.float32(2.0396614), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(5.2888894), 'average_n_step': np.float32(9.1), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06917350254952907), 'actor_loss': np.float64(-0.9931654095649719), 'hyper_actor_loss': np.float64(0.00037209743168205024), 'behavior_loss': np.float64(0.37632605731487273)}
step: 19140 @ episode report: {'average_total_reward': np.float32(8.402224), 'reward_variance': np.float32(2.6739702), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(9.6), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0727062277495861), 'actor_loss': np.float64(-0.9960034608840942), 'hyper_actor_loss': np.float64(0.00030045133316889403), 'behavior_loss': np.float64(0.4055859476327896)}
step: 19150 @ episode report: {'average_total_reward': np.float32(8.402224), 'reward_variance': np.float32(2.452514), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(9.6), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05625589974224567), 'actor_loss': np.float64(-0.9750701248645782), 'hyper_actor_loss': np.float64(0.0002828765340382233), 'behavior_loss': np.float64(0.37577562034130096)}
step: 19160 @ episode report: {'average_total_reward': np.float32(8.963334), 'reward_variance': np.float32(2.9838285), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(6.5333333), 'average_n_step': np.float32(10.1), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07658986710011959), 'actor_loss': np.float64(-0.9837652206420898), 'hyper_actor_loss': np.float64(0.0002799541238346137), 'behavior_loss': np.float64(0.35341785550117494)}
step: 19170 @ episode report: {'average_total_reward': np.float32(9.114445), 'reward_variance': np.float32(1.1956556), 'max_total_reward': np.float32(11.0222225), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(10.3), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06209571771323681), 'actor_loss': np.float64(-0.9973330795764923), 'hyper_actor_loss': np.float64(0.0002843667854904197), 'behavior_loss': np.float64(0.3787727147340775)}
step: 19180 @ episode report: {'average_total_reward': np.float32(10.124445), 'reward_variance': np.float32(2.4284637), 'max_total_reward': np.float32(12.0222225), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(11.2), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06759683564305305), 'actor_loss': np.float64(-0.9906976997852326), 'hyper_actor_loss': np.float64(0.00027132552640978246), 'behavior_loss': np.float64(0.376376149058342)}
step: 19190 @ episode report: {'average_total_reward': np.float32(8.738889), 'reward_variance': np.float32(2.890549), 'max_total_reward': np.float32(10.9), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(9.9), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06677932888269425), 'actor_loss': np.float64(-0.9858839392662049), 'hyper_actor_loss': np.float64(0.000277611066121608), 'behavior_loss': np.float64(0.37096880972385404)}
step: 19200 @ episode report: {'average_total_reward': np.float32(8.253333), 'reward_variance': np.float32(2.1526859), 'max_total_reward': np.float32(12.266666), 'min_total_reward': np.float32(6.533334), 'average_n_step': np.float32(9.5), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06407845765352249), 'actor_loss': np.float64(-0.9906368434429169), 'hyper_actor_loss': np.float64(0.0002521204558433965), 'behavior_loss': np.float64(0.3722353607416153)}
step: 19210 @ episode report: {'average_total_reward': np.float32(8.890001), 'reward_variance': np.float32(1.9098877), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(7.5333333), 'average_n_step': np.float32(10.1), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06898902021348477), 'actor_loss': np.float64(-0.9778802931308747), 'hyper_actor_loss': np.float64(0.0002669456633157097), 'behavior_loss': np.float64(0.37612763941287997)}
step: 19220 @ episode report: {'average_total_reward': np.float32(9.375555), 'reward_variance': np.float32(2.6015747), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(10.5), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07323117181658745), 'actor_loss': np.float64(-0.9945302367210388), 'hyper_actor_loss': np.float64(0.0003156854334520176), 'behavior_loss': np.float64(0.352218297123909)}
step: 19230 @ episode report: {'average_total_reward': np.float32(8.83889), 'reward_variance': np.float32(3.1469455), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.0), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06262814216315746), 'actor_loss': np.float64(-1.0045171976089478), 'hyper_actor_loss': np.float64(0.00028533109871204944), 'behavior_loss': np.float64(0.366918158531189)}
step: 19240 @ episode report: {'average_total_reward': np.float32(8.514445), 'reward_variance': np.float32(2.370841), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.7), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06940596178174019), 'actor_loss': np.float64(-0.9749322652816772), 'hyper_actor_loss': np.float64(0.0002730552456341684), 'behavior_loss': np.float64(0.34841513335704805)}
step: 19250 @ episode report: {'average_total_reward': np.float32(8.677778), 'reward_variance': np.float32(2.7089884), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(5.411111), 'average_n_step': np.float32(9.9), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05505430269986391), 'actor_loss': np.float64(-0.986499035358429), 'hyper_actor_loss': np.float64(0.0002515173066058196), 'behavior_loss': np.float64(0.36194968819618223)}
step: 19260 @ episode report: {'average_total_reward': np.float32(9.463333), 'reward_variance': np.float32(3.7320995), 'max_total_reward': np.float32(13.388888), 'min_total_reward': np.float32(6.5333333), 'average_n_step': np.float32(10.6), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07125962041318416), 'actor_loss': np.float64(-0.9647517919540405), 'hyper_actor_loss': np.float64(0.0002697782576433383), 'behavior_loss': np.float64(0.3674640566110611)}
step: 19270 @ episode report: {'average_total_reward': np.float32(8.838889), 'reward_variance': np.float32(6.8427973), 'max_total_reward': np.float32(14.38889), 'min_total_reward': np.float32(4.5333333), 'average_n_step': np.float32(10.0), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0737602360546589), 'actor_loss': np.float64(-0.9998794317245483), 'hyper_actor_loss': np.float64(0.00027658087929012255), 'behavior_loss': np.float64(0.38190551698207853)}
step: 19280 @ episode report: {'average_total_reward': np.float32(9.712222), 'reward_variance': np.float32(4.0925045), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(6.533334), 'average_n_step': np.float32(10.8), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08619055934250355), 'actor_loss': np.float64(-1.0061789989471435), 'hyper_actor_loss': np.float64(0.0002492989631718956), 'behavior_loss': np.float64(0.33996522426605225)}
step: 19290 @ episode report: {'average_total_reward': np.float32(8.23889), 'reward_variance': np.float32(3.9640305), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(9.4), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.073219321295619), 'actor_loss': np.float64(-1.0040367662906646), 'hyper_actor_loss': np.float64(0.00023911531607154757), 'behavior_loss': np.float64(0.3745471268892288)}
step: 19300 @ episode report: {'average_total_reward': np.float32(8.39), 'reward_variance': np.float32(1.1009989), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(7.4111114), 'average_n_step': np.float32(9.6), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07093909159302711), 'actor_loss': np.float64(-0.9939815700054169), 'hyper_actor_loss': np.float64(0.00026830553833860903), 'behavior_loss': np.float64(0.35659153163433077)}
step: 19310 @ episode report: {'average_total_reward': np.float32(9.287778), 'reward_variance': np.float32(1.5134926), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(10.4), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07891377098858357), 'actor_loss': np.float64(-0.9824308395385742), 'hyper_actor_loss': np.float64(0.0002705490987864323), 'behavior_loss': np.float64(0.3759315550327301)}
step: 19320 @ episode report: {'average_total_reward': np.float32(8.79), 'reward_variance': np.float32(3.0682333), 'max_total_reward': np.float32(12.0222225), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(10.0), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07214679345488548), 'actor_loss': np.float64(-0.9998546302318573), 'hyper_actor_loss': np.float64(0.0002638412246596999), 'behavior_loss': np.float64(0.37496383786201476)}
step: 19330 @ episode report: {'average_total_reward': np.float32(8.790001), 'reward_variance': np.float32(0.99635696), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.0), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07137441039085388), 'actor_loss': np.float64(-0.9989189147949219), 'hyper_actor_loss': np.float64(0.000338892953004688), 'behavior_loss': np.float64(0.3691782206296921)}
step: 19340 @ episode report: {'average_total_reward': np.float32(9.5), 'reward_variance': np.float32(1.329802), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(7.655556), 'average_n_step': np.float32(10.6), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06875681132078171), 'actor_loss': np.float64(-0.9999415040016174), 'hyper_actor_loss': np.float64(0.0009575764706823975), 'behavior_loss': np.float64(0.37902897596359253)}
step: 19350 @ episode report: {'average_total_reward': np.float32(10.497778), 'reward_variance': np.float32(2.8045628), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(11.5), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07026777416467667), 'actor_loss': np.float64(-0.9758817672729492), 'hyper_actor_loss': np.float64(0.0013653578935191035), 'behavior_loss': np.float64(0.36623617112636564)}
step: 19360 @ episode report: {'average_total_reward': np.float32(10.210001), 'reward_variance': np.float32(3.8022335), 'max_total_reward': np.float32(14.511111), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(11.2), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06561153568327427), 'actor_loss': np.float64(-0.9816475093364716), 'hyper_actor_loss': np.float64(0.0011589965433813632), 'behavior_loss': np.float64(0.38357571363449094)}
step: 19370 @ episode report: {'average_total_reward': np.float32(10.097778), 'reward_variance': np.float32(1.104785), 'max_total_reward': np.float32(12.144444), 'min_total_reward': np.float32(8.777779), 'average_n_step': np.float32(11.1), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05801863595843315), 'actor_loss': np.float64(-0.9667932987213135), 'hyper_actor_loss': np.float64(0.0006364926492096856), 'behavior_loss': np.float64(0.3733405232429504)}
step: 19380 @ episode report: {'average_total_reward': np.float32(10.497778), 'reward_variance': np.float32(1.7696251), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(11.5), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07003788836300373), 'actor_loss': np.float64(-0.9894170522689819), 'hyper_actor_loss': np.float64(0.00038923344982322305), 'behavior_loss': np.float64(0.37895157039165495)}
step: 19390 @ episode report: {'average_total_reward': np.float32(11.046668), 'reward_variance': np.float32(2.8124146), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(12.0), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.070401132106781), 'actor_loss': np.float64(-0.9937210202217102), 'hyper_actor_loss': np.float64(0.00028885921637993305), 'behavior_loss': np.float64(0.38229995369911196)}
step: 19400 @ episode report: {'average_total_reward': np.float32(11.107779), 'reward_variance': np.float32(3.277532), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(8.900001), 'average_n_step': np.float32(12.0), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06978476420044899), 'actor_loss': np.float64(-0.9878104984760284), 'hyper_actor_loss': np.float64(0.0002879726642277092), 'behavior_loss': np.float64(0.37056815028190615)}
step: 19410 @ episode report: {'average_total_reward': np.float32(10.51), 'reward_variance': np.float32(2.5608754), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(8.777778), 'average_n_step': np.float32(11.5), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06719969399273396), 'actor_loss': np.float64(-0.9899547815322876), 'hyper_actor_loss': np.float64(0.0003018132614670321), 'behavior_loss': np.float64(0.39009983241558077)}
step: 19420 @ episode report: {'average_total_reward': np.float32(9.94889), 'reward_variance': np.float32(0.78963506), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(8.777778), 'average_n_step': np.float32(11.0), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.057021908648312095), 'actor_loss': np.float64(-0.9662215769290924), 'hyper_actor_loss': np.float64(0.00029367460520006715), 'behavior_loss': np.float64(0.39092021584510805)}
step: 19430 @ episode report: {'average_total_reward': np.float32(10.871112), 'reward_variance': np.float32(2.8754616), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(11.8), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0694093368947506), 'actor_loss': np.float64(-0.9771555364131927), 'hyper_actor_loss': np.float64(0.0003006660146638751), 'behavior_loss': np.float64(0.3939733237028122)}
step: 19440 @ episode report: {'average_total_reward': np.float32(10.6466675), 'reward_variance': np.float32(1.2998717), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(8.777779), 'average_n_step': np.float32(11.6), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08727975636720657), 'actor_loss': np.float64(-1.0136656522750855), 'hyper_actor_loss': np.float64(0.00029294191335793585), 'behavior_loss': np.float64(0.3760148674249649)}
step: 19450 @ episode report: {'average_total_reward': np.float32(11.295556), 'reward_variance': np.float32(3.096918), 'max_total_reward': np.float32(14.511111), 'min_total_reward': np.float32(8.777778), 'average_n_step': np.float32(12.2), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06492619514465332), 'actor_loss': np.float64(-1.0104085028171539), 'hyper_actor_loss': np.float64(0.0002751151449047029), 'behavior_loss': np.float64(0.3764541268348694)}
step: 19460 @ episode report: {'average_total_reward': np.float32(10.44889), 'reward_variance': np.float32(2.7294374), 'max_total_reward': np.float32(13.144444), 'min_total_reward': np.float32(7.777778), 'average_n_step': np.float32(11.5), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07374620512127876), 'actor_loss': np.float64(-0.9692728102207184), 'hyper_actor_loss': np.float64(0.00029314020357560364), 'behavior_loss': np.float64(0.4025729805231094)}
step: 19470 @ episode report: {'average_total_reward': np.float32(10.185556), 'reward_variance': np.float32(1.4127419), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(8.777778), 'average_n_step': np.float32(11.2), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0647878360003233), 'actor_loss': np.float64(-0.9849174857139588), 'hyper_actor_loss': np.float64(0.00031593995518051086), 'behavior_loss': np.float64(0.3892251491546631)}
step: 19480 @ episode report: {'average_total_reward': np.float32(9.724444), 'reward_variance': np.float32(1.7168338), 'max_total_reward': np.float32(12.144444), 'min_total_reward': np.float32(7.5333343), 'average_n_step': np.float32(10.8), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05119631327688694), 'actor_loss': np.float64(-0.9835948586463928), 'hyper_actor_loss': np.float64(0.00028959289484191685), 'behavior_loss': np.float64(0.3919691532850266)}
step: 19490 @ episode report: {'average_total_reward': np.float32(10.197778), 'reward_variance': np.float32(5.0675497), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(6.6555567), 'average_n_step': np.float32(11.2), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06809592097997666), 'actor_loss': np.float64(-0.9560925602912903), 'hyper_actor_loss': np.float64(0.0002852266828995198), 'behavior_loss': np.float64(0.41349533200263977)}
step: 19500 @ episode report: {'average_total_reward': np.float32(9.861112), 'reward_variance': np.float32(3.0766003), 'max_total_reward': np.float32(12.266668), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(10.9), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07865966446697711), 'actor_loss': np.float64(-0.9883630812168122), 'hyper_actor_loss': np.float64(0.0002693617469049059), 'behavior_loss': np.float64(0.4339110732078552)}
step: 19510 @ episode report: {'average_total_reward': np.float32(10.434445), 'reward_variance': np.float32(4.510481), 'max_total_reward': np.float32(14.511112), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(11.4), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07461933009326457), 'actor_loss': np.float64(-1.0060658693313598), 'hyper_actor_loss': np.float64(0.0002724237594520673), 'behavior_loss': np.float64(0.4064364552497864)}
step: 19520 @ episode report: {'average_total_reward': np.float32(9.785556), 'reward_variance': np.float32(1.9330631), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.777778), 'average_n_step': np.float32(10.8), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06670108959078788), 'actor_loss': np.float64(-0.985379421710968), 'hyper_actor_loss': np.float64(0.0003035420639207587), 'behavior_loss': np.float64(0.40973901748657227)}
step: 19530 @ episode report: {'average_total_reward': np.float32(10.995556), 'reward_variance': np.float32(2.4025736), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(11.9), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08010048549622298), 'actor_loss': np.float64(-0.984192717075348), 'hyper_actor_loss': np.float64(0.00028643807745538653), 'behavior_loss': np.float64(0.4235007166862488)}
step: 19540 @ episode report: {'average_total_reward': np.float32(9.487778), 'reward_variance': np.float32(1.3792212), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(10.6), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07243916988372803), 'actor_loss': np.float64(-1.022406768798828), 'hyper_actor_loss': np.float64(0.0002779575894237496), 'behavior_loss': np.float64(0.4097584456205368)}
step: 19550 @ episode report: {'average_total_reward': np.float32(10.585556), 'reward_variance': np.float32(2.0836797), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(8.777779), 'average_n_step': np.float32(11.6), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0845188744366169), 'actor_loss': np.float64(-0.999104768037796), 'hyper_actor_loss': np.float64(0.00027676300087478014), 'behavior_loss': np.float64(0.4235711008310318)}
step: 19560 @ episode report: {'average_total_reward': np.float32(10.497778), 'reward_variance': np.float32(4.5432544), 'max_total_reward': np.float32(14.388889), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(11.5), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06808334290981292), 'actor_loss': np.float64(-1.0047576606273652), 'hyper_actor_loss': np.float64(0.0002704270431422628), 'behavior_loss': np.float64(0.4196274966001511)}
step: 19570 @ episode report: {'average_total_reward': np.float32(9.936667), 'reward_variance': np.float32(2.1662726), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(11.0), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06572099840268493), 'actor_loss': np.float64(-0.9776781499385834), 'hyper_actor_loss': np.float64(0.00027496498951222746), 'behavior_loss': np.float64(0.4390681266784668)}
step: 19580 @ episode report: {'average_total_reward': np.float32(11.083334), 'reward_variance': np.float32(2.2157598), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(12.0), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06570441238582134), 'actor_loss': np.float64(-0.9584977865219116), 'hyper_actor_loss': np.float64(0.00028146947588538753), 'behavior_loss': np.float64(0.4401722639799118)}
step: 19590 @ episode report: {'average_total_reward': np.float32(10.558889), 'reward_variance': np.float32(4.0130887), 'max_total_reward': np.float32(14.38889), 'min_total_reward': np.float32(6.655556), 'average_n_step': np.float32(11.5), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07223417200148105), 'actor_loss': np.float64(-0.997108006477356), 'hyper_actor_loss': np.float64(0.0002920874539995566), 'behavior_loss': np.float64(0.46309750378131864)}
step: 19600 @ episode report: {'average_total_reward': np.float32(9.487779), 'reward_variance': np.float32(4.443124), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(10.6), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0621887493878603), 'actor_loss': np.float64(-0.9693375945091247), 'hyper_actor_loss': np.float64(0.0002847704396117479), 'behavior_loss': np.float64(0.4437233120203018)}
step: 19610 @ episode report: {'average_total_reward': np.float32(9.3), 'reward_variance': np.float32(5.8451123), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(5.5333333), 'average_n_step': np.float32(10.4), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06947592310607434), 'actor_loss': np.float64(-0.9764163494110107), 'hyper_actor_loss': np.float64(0.00026410358404973524), 'behavior_loss': np.float64(0.4424784302711487)}
step: 19620 @ episode report: {'average_total_reward': np.float32(10.061112), 'reward_variance': np.float32(1.987784), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(8.533335), 'average_n_step': np.float32(11.1), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07081948481500148), 'actor_loss': np.float64(-0.9942817330360413), 'hyper_actor_loss': np.float64(0.0002842126734321937), 'behavior_loss': np.float64(0.4251425415277481)}
step: 19630 @ episode report: {'average_total_reward': np.float32(9.414445), 'reward_variance': np.float32(2.7433343), 'max_total_reward': np.float32(13.388889), 'min_total_reward': np.float32(7.6555567), 'average_n_step': np.float32(10.6), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07932951711118222), 'actor_loss': np.float64(-0.9979780972003937), 'hyper_actor_loss': np.float64(0.0002583437948487699), 'behavior_loss': np.float64(0.4436300486326218)}
step: 19640 @ episode report: {'average_total_reward': np.float32(9.400001), 'reward_variance': np.float32(3.4176548), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.5), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07083399184048175), 'actor_loss': np.float64(-1.0076226890087128), 'hyper_actor_loss': np.float64(0.0002734744921326637), 'behavior_loss': np.float64(0.43299393355846405)}
step: 19650 @ episode report: {'average_total_reward': np.float32(8.751112), 'reward_variance': np.float32(1.8713872), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(9.9), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07418711073696613), 'actor_loss': np.float64(-0.9856368243694306), 'hyper_actor_loss': np.float64(0.0002656029697391205), 'behavior_loss': np.float64(0.41757823824882506)}
step: 19660 @ episode report: {'average_total_reward': np.float32(10.585556), 'reward_variance': np.float32(2.8697302), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.6555557), 'average_n_step': np.float32(11.6), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0721471730619669), 'actor_loss': np.float64(-0.9938513100147247), 'hyper_actor_loss': np.float64(0.0002693528542295098), 'behavior_loss': np.float64(0.41637989282608034)}
step: 19670 @ episode report: {'average_total_reward': np.float32(9.512223), 'reward_variance': np.float32(1.9025301), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(7.533334), 'average_n_step': np.float32(10.6), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06092393733561039), 'actor_loss': np.float64(-0.9983380019664765), 'hyper_actor_loss': np.float64(0.0002622221320052631), 'behavior_loss': np.float64(0.36956129372119906)}
step: 19680 @ episode report: {'average_total_reward': np.float32(9.575556), 'reward_variance': np.float32(0.92890894), 'max_total_reward': np.float32(11.022223), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(10.7), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0673324815928936), 'actor_loss': np.float64(-0.9841017425060272), 'hyper_actor_loss': np.float64(0.00028630302258534355), 'behavior_loss': np.float64(0.4457059681415558)}
step: 19690 @ episode report: {'average_total_reward': np.float32(9.800001), 'reward_variance': np.float32(1.0760496), 'max_total_reward': np.float32(12.144445), 'min_total_reward': np.float32(8.777778), 'average_n_step': np.float32(10.9), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07016365677118301), 'actor_loss': np.float64(-0.9765772581100464), 'hyper_actor_loss': np.float64(0.0003615280147641897), 'behavior_loss': np.float64(0.49527632296085355)}
step: 19700 @ episode report: {'average_total_reward': np.float32(11.295557), 'reward_variance': np.float32(3.3507965), 'max_total_reward': np.float32(15.511112), 'min_total_reward': np.float32(9.777778), 'average_n_step': np.float32(12.2), 'max_n_step': np.float32(16.0), 'min_n_step': np.float32(11.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07441238686442375), 'actor_loss': np.float64(-1.0077474534511566), 'hyper_actor_loss': np.float64(0.00035489695728756486), 'behavior_loss': np.float64(0.4192063957452774)}
step: 19710 @ episode report: {'average_total_reward': np.float32(9.973333), 'reward_variance': np.float32(1.517832), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(8.655556), 'average_n_step': np.float32(11.0), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06311992034316063), 'actor_loss': np.float64(-1.007782870531082), 'hyper_actor_loss': np.float64(0.00030955729307606815), 'behavior_loss': np.float64(0.4301732450723648)}
step: 19720 @ episode report: {'average_total_reward': np.float32(9.636667), 'reward_variance': np.float32(2.6441743), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(10.7), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05383569784462452), 'actor_loss': np.float64(-0.9651086926460266), 'hyper_actor_loss': np.float64(0.00027899158012587575), 'behavior_loss': np.float64(0.4428567111492157)}
step: 19730 @ episode report: {'average_total_reward': np.float32(10.5222225), 'reward_variance': np.float32(3.8066921), 'max_total_reward': np.float32(13.266667), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(11.5), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07832530327141285), 'actor_loss': np.float64(-0.9722858190536499), 'hyper_actor_loss': np.float64(0.00029332760750548913), 'behavior_loss': np.float64(0.4460433483123779)}
step: 19740 @ episode report: {'average_total_reward': np.float32(10.434446), 'reward_variance': np.float32(2.9149256), 'max_total_reward': np.float32(13.38889), 'min_total_reward': np.float32(7.7777786), 'average_n_step': np.float32(11.4), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.05877708327025175), 'actor_loss': np.float64(-1.014442354440689), 'hyper_actor_loss': np.float64(0.00028460677567636593), 'behavior_loss': np.float64(0.4596655428409576)}
step: 19750 @ episode report: {'average_total_reward': np.float32(10.322223), 'reward_variance': np.float32(5.135804), 'max_total_reward': np.float32(13.38889), 'min_total_reward': np.float32(7.533334), 'average_n_step': np.float32(11.3), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07791519723832607), 'actor_loss': np.float64(-0.9709477543830871), 'hyper_actor_loss': np.float64(0.0002744673329289071), 'behavior_loss': np.float64(0.4609982132911682)}
step: 19760 @ episode report: {'average_total_reward': np.float32(8.838889), 'reward_variance': np.float32(1.7424263), 'max_total_reward': np.float32(11.144445), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.0), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0718983095139265), 'actor_loss': np.float64(-0.9919225871562958), 'hyper_actor_loss': np.float64(0.00029210743377916515), 'behavior_loss': np.float64(0.46706363260746003)}
step: 19770 @ episode report: {'average_total_reward': np.float32(9.6877775), 'reward_variance': np.float32(3.1136153), 'max_total_reward': np.float32(13.0222225), 'min_total_reward': np.float32(6.6555567), 'average_n_step': np.float32(10.8), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06653563193976879), 'actor_loss': np.float64(-0.9865804612636566), 'hyper_actor_loss': np.float64(0.00029728553199674933), 'behavior_loss': np.float64(0.4799043834209442)}
step: 19780 @ episode report: {'average_total_reward': np.float32(10.497778), 'reward_variance': np.float32(0.78656316), 'max_total_reward': np.float32(12.266667), 'min_total_reward': np.float32(8.9), 'average_n_step': np.float32(11.5), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(10.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.055722626298666), 'actor_loss': np.float64(-0.9690456807613372), 'hyper_actor_loss': np.float64(0.00030917320982553064), 'behavior_loss': np.float64(0.4761323481798172)}
step: 19790 @ episode report: {'average_total_reward': np.float32(10.14889), 'reward_variance': np.float32(3.31766), 'max_total_reward': np.float32(14.38889), 'min_total_reward': np.float32(7.7777777), 'average_n_step': np.float32(11.2), 'max_n_step': np.float32(15.0), 'min_n_step': np.float32(9.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06595545373857022), 'actor_loss': np.float64(-0.976554024219513), 'hyper_actor_loss': np.float64(0.0003801723592914641), 'behavior_loss': np.float64(0.4990919500589371)}
step: 19800 @ episode report: {'average_total_reward': np.float32(9.736667), 'reward_variance': np.float32(3.3424714), 'max_total_reward': np.float32(13.266668), 'min_total_reward': np.float32(6.655556), 'average_n_step': np.float32(10.8), 'max_n_step': np.float32(14.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07084021270275116), 'actor_loss': np.float64(-0.9824909031391144), 'hyper_actor_loss': np.float64(0.00045264070213306694), 'behavior_loss': np.float64(0.4610689848661423)}
step: 19810 @ episode report: {'average_total_reward': np.float32(9.363333), 'reward_variance': np.float32(2.483359), 'max_total_reward': np.float32(12.0222225), 'min_total_reward': np.float32(6.6555557), 'average_n_step': np.float32(10.5), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0693012110888958), 'actor_loss': np.float64(-1.0017950356006622), 'hyper_actor_loss': np.float64(0.0004638371814507991), 'behavior_loss': np.float64(0.5221090495586396)}
step: 19820 @ episode report: {'average_total_reward': np.float32(8.077779), 'reward_variance': np.float32(2.1516795), 'max_total_reward': np.float32(10.022223), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(9.3), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08022875729948283), 'actor_loss': np.float64(-1.0083789706230164), 'hyper_actor_loss': np.float64(0.0003615153604187071), 'behavior_loss': np.float64(0.5032247304916382)}
step: 19830 @ episode report: {'average_total_reward': np.float32(7.704445), 'reward_variance': np.float32(1.92082), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(9.0), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07702795676887035), 'actor_loss': np.float64(-0.9882756769657135), 'hyper_actor_loss': np.float64(0.0003468254551989958), 'behavior_loss': np.float64(0.48183626532554624)}
step: 19840 @ episode report: {'average_total_reward': np.float32(7.567778), 'reward_variance': np.float32(2.6718624), 'max_total_reward': np.float32(9.9), 'min_total_reward': np.float32(5.166667), 'average_n_step': np.float32(8.9), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06629897095263004), 'actor_loss': np.float64(-0.989314979314804), 'hyper_actor_loss': np.float64(0.00032074472110252825), 'behavior_loss': np.float64(0.5339331030845642)}
step: 19850 @ episode report: {'average_total_reward': np.float32(6.7822227), 'reward_variance': np.float32(1.4752153), 'max_total_reward': np.float32(8.777779), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.2), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0706488024443388), 'actor_loss': np.float64(-0.9703191339969635), 'hyper_actor_loss': np.float64(0.00032876297482289376), 'behavior_loss': np.float64(0.47407768964767455)}
step: 19860 @ episode report: {'average_total_reward': np.float32(6.9433336), 'reward_variance': np.float32(3.2825794), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(3.4111114), 'average_n_step': np.float32(8.3), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(5.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07353380396962166), 'actor_loss': np.float64(-0.9854020357131958), 'hyper_actor_loss': np.float64(0.0003559917735401541), 'behavior_loss': np.float64(0.5254377901554108)}
step: 19870 @ episode report: {'average_total_reward': np.float32(7.231111), 'reward_variance': np.float32(3.0622914), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(4.2888894), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07274742163717747), 'actor_loss': np.float64(-0.9862793564796448), 'hyper_actor_loss': np.float64(0.00034281778789591044), 'behavior_loss': np.float64(0.5115410119295121)}
step: 19880 @ episode report: {'average_total_reward': np.float32(8.041111), 'reward_variance': np.float32(3.7783463), 'max_total_reward': np.float32(11.144444), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(9.3), 'max_n_step': np.float32(12.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06299875751137733), 'actor_loss': np.float64(-0.9877107918262482), 'hyper_actor_loss': np.float64(0.00033577413705643266), 'behavior_loss': np.float64(0.48833266496658323)}
step: 19890 @ episode report: {'average_total_reward': np.float32(8.016667), 'reward_variance': np.float32(3.2848709), 'max_total_reward': np.float32(12.266668), 'min_total_reward': np.float32(5.655556), 'average_n_step': np.float32(9.3), 'max_n_step': np.float32(13.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06700668055564166), 'actor_loss': np.float64(-0.9606068909168244), 'hyper_actor_loss': np.float64(0.00031374066602438686), 'behavior_loss': np.float64(0.5298784017562866)}
step: 19900 @ episode report: {'average_total_reward': np.float32(7.2188888), 'reward_variance': np.float32(0.99985313), 'max_total_reward': np.float32(8.777778), 'min_total_reward': np.float32(5.4111114), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07592127919197082), 'actor_loss': np.float64(-0.9847700834274292), 'hyper_actor_loss': np.float64(0.0003389109013369307), 'behavior_loss': np.float64(0.5409891545772553)}
step: 19910 @ episode report: {'average_total_reward': np.float32(7.5433335), 'reward_variance': np.float32(1.050505), 'max_total_reward': np.float32(9.777778), 'min_total_reward': np.float32(6.411111), 'average_n_step': np.float32(8.9), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(8.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.08219753913581371), 'actor_loss': np.float64(-1.0138402581214905), 'hyper_actor_loss': np.float64(0.00031138993508648125), 'behavior_loss': np.float64(0.5349167436361313)}
step: 19920 @ episode report: {'average_total_reward': np.float32(6.6577783), 'reward_variance': np.float32(2.5713294), 'max_total_reward': np.float32(8.77778), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(8.1), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06030992120504379), 'actor_loss': np.float64(-0.974814909696579), 'hyper_actor_loss': np.float64(0.0003390581579878926), 'behavior_loss': np.float64(0.5166552603244782)}
step: 19930 @ episode report: {'average_total_reward': np.float32(7.304445), 'reward_variance': np.float32(1.0383257), 'max_total_reward': np.float32(8.9), 'min_total_reward': np.float32(5.533334), 'average_n_step': np.float32(8.6), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07664634250104427), 'actor_loss': np.float64(-0.9823640584945679), 'hyper_actor_loss': np.float64(0.0003705713228555396), 'behavior_loss': np.float64(0.5209053575992584)}
step: 19940 @ episode report: {'average_total_reward': np.float32(7.167778), 'reward_variance': np.float32(1.2740611), 'max_total_reward': np.float32(8.900001), 'min_total_reward': np.float32(5.411111), 'average_n_step': np.float32(8.5), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0635623037815094), 'actor_loss': np.float64(-1.0062592208385468), 'hyper_actor_loss': np.float64(0.0003702149202581495), 'behavior_loss': np.float64(0.5290576726198196)}
step: 19950 @ episode report: {'average_total_reward': np.float32(7.504445), 'reward_variance': np.float32(1.2320297), 'max_total_reward': np.float32(8.77778), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(8.8), 'max_n_step': np.float32(10.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06449754014611245), 'actor_loss': np.float64(-0.9616634845733643), 'hyper_actor_loss': np.float64(0.00034303720167372376), 'behavior_loss': np.float64(0.516538193821907)}
step: 19960 @ episode report: {'average_total_reward': np.float32(7.6800003), 'reward_variance': np.float32(3.2967114), 'max_total_reward': np.float32(10.0222225), 'min_total_reward': np.float32(4.4111114), 'average_n_step': np.float32(9.0), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.0760733313858509), 'actor_loss': np.float64(-0.9842622816562653), 'hyper_actor_loss': np.float64(0.00034633660688996313), 'behavior_loss': np.float64(0.5173329532146453)}
step: 19970 @ episode report: {'average_total_reward': np.float32(7.667778), 'reward_variance': np.float32(2.13253), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(5.6555557), 'average_n_step': np.float32(9.0), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(7.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.07423100247979164), 'actor_loss': np.float64(-1.0197688460350036), 'hyper_actor_loss': np.float64(0.00031131026335060594), 'behavior_loss': np.float64(0.4901959538459778)}
step: 19980 @ episode report: {'average_total_reward': np.float32(7.11889), 'reward_variance': np.float32(2.431483), 'max_total_reward': np.float32(9.900001), 'min_total_reward': np.float32(4.533334), 'average_n_step': np.float32(8.5), 'max_n_step': np.float32(11.0), 'min_n_step': np.float32(6.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(0.06975189745426177), 'actor_loss': np.float64(-0.9936460077762603), 'hyper_actor_loss': np.float64(0.00029160292760934683), 'behavior_loss': np.float64(0.5643780559301377)}

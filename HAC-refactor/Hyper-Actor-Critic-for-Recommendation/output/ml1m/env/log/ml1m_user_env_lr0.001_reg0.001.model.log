Namespace(model='ML1MUserResponse', reader='ML1MDataReader')
Namespace(seed=19, batch_size=128, lr=0.001, epoch=2, model_path='output/ml1m/env/ml1m_user_env_lr0.001_reg0.001.model', loss='bce', l2_coef=0.001, feature_dim=16, attn_n_head=2, hidden_dims=[256], dropout_rate=0.2, train_file='dataset/ml1m/ml1m_b_train.csv', val_file='dataset/ml1m/ml1m_b_test.csv', test_file='', n_worker=0, data_separator='@', user_meta_file='dataset/ml1m/user_info.npy', item_meta_file='dataset/ml1m/item_info.npy', max_seq_len=50, meta_data_separator=' ')
init ml1m reader
Loading data filesLoad item meta data
{'length': 5078, 'n_item': 1682, 'item_vec_size': 19, 'user_portrait_len': 24, 'max_seq_len': 50}
{'length': 5078, 'n_item': 1682, 'item_vec_size': 19, 'user_portrait_len': 24, 'max_seq_len': 50}
epoch 1 training
self.sigmoid(preds):  tensor([0.4950, 0.4985, 0.4985,  ..., 0.5107, 0.5021, 0.5073],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.6731, grad_fn=<MeanBackward0>) l2:  tensor(0.3466, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4990, 0.5090, 0.4953,  ..., 0.5288, 0.5114, 0.4854],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 0., 1.])
loss:  tensor(0.6988, grad_fn=<MeanBackward0>) l2:  tensor(0.3457, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4982, 0.4931, 0.4821,  ..., 0.4936, 0.4779, 0.5049],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 1., 1., 0.])
loss:  tensor(0.7194, grad_fn=<MeanBackward0>) l2:  tensor(0.3450, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.5156, 0.5101, 0.4922,  ..., 0.4665, 0.4882, 0.4729],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6935, grad_fn=<MeanBackward0>) l2:  tensor(0.3443, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4952, 0.4879, 0.4575,  ..., 0.4593, 0.4909, 0.4646],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 0.])
loss:  tensor(0.6820, grad_fn=<MeanBackward0>) l2:  tensor(0.3436, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4909, 0.4769, 0.4805,  ..., 0.4810, 0.4860, 0.4775],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 0.,  ..., 1., 0., 0.])
loss:  tensor(0.6789, grad_fn=<MeanBackward0>) l2:  tensor(0.3430, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.5034, 0.5082, 0.4877,  ..., 0.4929, 0.4752, 0.4875],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 1.,  ..., 1., 1., 0.])
loss:  tensor(0.7061, grad_fn=<MeanBackward0>) l2:  tensor(0.3424, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4678, 0.4716, 0.4752,  ..., 0.4528, 0.4854, 0.4854],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0.,  ..., 0., 1., 1.])
loss:  tensor(0.6709, grad_fn=<MeanBackward0>) l2:  tensor(0.3418, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4629, 0.4607, 0.4629,  ..., 0.4671, 0.4631, 0.4612],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.6908, grad_fn=<MeanBackward0>) l2:  tensor(0.3413, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4871, 0.4521, 0.4521,  ..., 0.4370, 0.4604, 0.4315],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0.,  ..., 0., 0., 0.])
loss:  tensor(0.6884, grad_fn=<MeanBackward0>) l2:  tensor(0.3408, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
Iteration 10, loss: 0.6905285656452179
self.sigmoid(preds):  tensor([0.4187, 0.4569, 0.4195,  ..., 0.4653, 0.4244, 0.4737],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 0., 0., 1.])
loss:  tensor(0.6757, grad_fn=<MeanBackward0>) l2:  tensor(0.3403, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4505, 0.4493, 0.4438,  ..., 0.4107, 0.4408, 0.4252],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 0.,  ..., 1., 0., 1.])
loss:  tensor(0.6921, grad_fn=<MeanBackward0>) l2:  tensor(0.3398, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4681, 0.4793, 0.4674,  ..., 0.4421, 0.4455, 0.4408],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 0., 1.])
loss:  tensor(0.6826, grad_fn=<MeanBackward0>) l2:  tensor(0.3394, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4759, 0.4121, 0.4464,  ..., 0.4222, 0.3902, 0.4552],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.6875, grad_fn=<MeanBackward0>) l2:  tensor(0.3390, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4286, 0.4452, 0.4644,  ..., 0.3968, 0.4271, 0.4297],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.7020, grad_fn=<MeanBackward0>) l2:  tensor(0.3386, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4109, 0.4284, 0.4719,  ..., 0.4591, 0.3954, 0.3481],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.6647, grad_fn=<MeanBackward0>) l2:  tensor(0.3383, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3801, 0.4076, 0.3888,  ..., 0.4323, 0.3936, 0.4333],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 0.,  ..., 1., 1., 1.])
loss:  tensor(0.6833, grad_fn=<MeanBackward0>) l2:  tensor(0.3379, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4298, 0.4724, 0.4038,  ..., 0.4360, 0.3936, 0.4138],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 0., 0.])
loss:  tensor(0.6836, grad_fn=<MeanBackward0>) l2:  tensor(0.3376, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3899, 0.4669, 0.4016,  ..., 0.4206, 0.4206, 0.3904],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.6908, grad_fn=<MeanBackward0>) l2:  tensor(0.3373, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4574, 0.3422, 0.4296,  ..., 0.4179, 0.3823, 0.4029],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.6777, grad_fn=<MeanBackward0>) l2:  tensor(0.3370, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
Iteration 20, loss: 0.6874265372753143
self.sigmoid(preds):  tensor([0.4064, 0.3865, 0.4064,  ..., 0.3695, 0.3531, 0.3686],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 1.,  ..., 1., 0., 1.])
loss:  tensor(0.6884, grad_fn=<MeanBackward0>) l2:  tensor(0.3367, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4009, 0.3466, 0.4155,  ..., 0.3564, 0.4045, 0.4525],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 1., 0., 1.])
loss:  tensor(0.6812, grad_fn=<MeanBackward0>) l2:  tensor(0.3365, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4022, 0.3758, 0.3758,  ..., 0.3441, 0.2934, 0.3904],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 0., 1.])
loss:  tensor(0.6719, grad_fn=<MeanBackward0>) l2:  tensor(0.3363, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3943, 0.3943, 0.3375,  ..., 0.3727, 0.3773, 0.3773],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 0.,  ..., 1., 1., 1.])
loss:  tensor(0.6795, grad_fn=<MeanBackward0>) l2:  tensor(0.3361, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3418, 0.3075, 0.3657,  ..., 0.3719, 0.3142, 0.3514],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 1., 1., 1.])
loss:  tensor(0.6826, grad_fn=<MeanBackward0>) l2:  tensor(0.3359, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3260, 0.3860, 0.3860,  ..., 0.5094, 0.3060, 0.3060],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 0.])
loss:  tensor(0.6868, grad_fn=<MeanBackward0>) l2:  tensor(0.3358, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3674, 0.1890, 0.2827,  ..., 0.3649, 0.2714, 0.4438],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 0., 1.])
loss:  tensor(0.6699, grad_fn=<MeanBackward0>) l2:  tensor(0.3357, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3003, 0.3036, 0.2654,  ..., 0.4850, 0.3688, 0.2924],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 0., 1., 1.])
loss:  tensor(0.6853, grad_fn=<MeanBackward0>) l2:  tensor(0.3355, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4158, 0.2672, 0.4114,  ..., 0.3571, 0.3582, 0.2514],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 1.,  ..., 1., 0., 0.])
loss:  tensor(0.6760, grad_fn=<MeanBackward0>) l2:  tensor(0.3353, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.2016, 0.2242, 0.2090,  ..., 0.2694, 0.3732, 0.1624],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 0., 0., 1.])
loss:  tensor(0.6648, grad_fn=<MeanBackward0>) l2:  tensor(0.3352, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
Iteration 30, loss: 0.6846088031927745
self.sigmoid(preds):  tensor([0.2055, 0.3106, 0.4550,  ..., 0.2456, 0.2247, 0.3657],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6712, grad_fn=<MeanBackward0>) l2:  tensor(0.3349, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3654, 0.1942, 0.2755,  ..., 0.3380, 0.3073, 0.2978],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 1., 1., 1.])
loss:  tensor(0.6784, grad_fn=<MeanBackward0>) l2:  tensor(0.3347, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3564, 0.3602, 0.3798,  ..., 0.3777, 0.2337, 0.3725],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0.,  ..., 1., 0., 0.])
loss:  tensor(0.6833, grad_fn=<MeanBackward0>) l2:  tensor(0.3344, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3833, 0.2133, 0.3916,  ..., 0.2014, 0.2213, 0.1986],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 1.,  ..., 0., 0., 1.])
loss:  tensor(0.6791, grad_fn=<MeanBackward0>) l2:  tensor(0.3342, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4675, 0.2095, 0.3634,  ..., 0.1927, 0.4508, 0.3734],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.6791, grad_fn=<MeanBackward0>) l2:  tensor(0.3340, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3677, 0.4837, 0.5769,  ..., 0.5968, 0.3746, 0.1252],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6753, grad_fn=<MeanBackward0>) l2:  tensor(0.3338, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3014, 0.3726, 0.2131,  ..., 0.3969, 0.4755, 0.3015],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0.,  ..., 1., 1., 0.])
loss:  tensor(0.6709, grad_fn=<MeanBackward0>) l2:  tensor(0.3337, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.1797, 0.3885, 0.2879,  ..., 0.2164, 0.2771, 0.3094],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 0.,  ..., 1., 0., 0.])
loss:  tensor(0.6581, grad_fn=<MeanBackward0>) l2:  tensor(0.3334, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.2174, 0.3858, 0.2867,  ..., 0.1811, 0.2693, 0.1600],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 0., 0.])
loss:  tensor(0.6805, grad_fn=<MeanBackward0>) l2:  tensor(0.3331, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.1172, 0.1749, 0.3688, 0.1675, 0.1749, 0.1636, 0.1505, 0.3688, 0.1505,
        0.3688, 0.1747, 0.2602, 0.3495, 0.2538, 0.1777, 0.3761, 0.2538, 0.5231,
        0.1518, 0.1602, 0.2618, 0.3031, 0.1630, 0.0933, 0.0892, 0.1636, 0.1890,
        0.1718, 0.1636, 0.1636, 0.6542, 0.3829, 0.2903, 0.0867, 0.3829, 0.5163,
        0.5308, 0.5426, 0.3829, 0.1619, 0.1681, 0.0959, 0.3855, 0.1964, 0.2060,
        0.4297, 0.1953, 0.1616, 0.3855, 0.4297, 0.2153, 0.4454, 0.1081, 0.3806,
        0.3812, 0.1991, 0.4235, 0.1556, 0.1814, 0.2542, 0.3799, 0.4209, 0.3813,
        0.2005, 0.3813, 0.3590, 0.2841, 0.1647, 0.5060, 0.4876, 0.2717, 0.2717,
        0.4091, 0.2717, 0.3040, 0.1875, 0.2524, 0.2717, 0.2717, 0.2717, 0.1964,
        0.1722, 0.0985, 0.1751, 0.3128, 0.2682, 0.3859, 0.5147, 0.3859, 0.2898,
        0.3820, 0.2640, 0.4276, 0.2640, 0.1659, 0.2933, 0.3699, 0.4151, 0.4656,
        0.1659, 0.1649, 0.1857, 0.1600, 0.1109, 0.1857, 0.1857, 0.3787, 0.4219,
        0.1600, 0.1083, 0.5247, 0.6849, 0.6455, 0.0711, 0.3739, 0.3480, 0.2272,
        0.1388, 0.5247, 0.2059, 0.1655, 0.1401, 0.0696, 0.0768, 0.2393, 0.3710,
        0.0506, 0.2441, 0.3582, 0.1806, 0.6843, 0.1609, 0.3878, 0.3138, 0.1677,
        0.1609, 0.3878, 0.4016, 0.4065, 0.1609, 0.2091, 0.1706, 0.3965, 0.1706,
        0.0978, 0.3867, 0.3546, 0.1657, 0.1915, 0.1472, 0.1640, 0.5159, 0.4050,
        0.1552, 0.3840, 0.6740, 0.1640, 0.3817, 0.5397, 0.3817, 0.2432, 0.1582,
        0.1860, 0.3177, 0.1860, 0.1689, 0.2822, 0.1064, 0.1623, 0.3825, 0.1471,
        0.4268, 0.0793, 0.4268, 0.3783, 0.2289, 0.1835, 0.4068, 0.2011, 0.1835,
        0.4478, 0.4807, 0.4480, 0.6287, 0.1724, 0.2735, 0.5126, 0.2735, 0.2735,
        0.2735, 0.1740, 0.1661, 0.1661, 0.1661, 0.4052, 0.2669, 0.4052, 0.3659,
        0.1661, 0.1661, 0.4377, 0.1760, 0.1808, 0.3061, 0.3609, 0.4991, 0.2142,
        0.1760, 0.2790, 0.4185, 0.2525, 0.1701, 0.2082, 0.2259, 0.4149, 0.1444,
        0.2525, 0.1778, 0.2525, 0.2186, 0.3920, 0.2161, 0.5482, 0.2044, 0.1958,
        0.3865, 0.1637, 0.6880, 0.5173, 0.3865, 0.3494, 0.5162, 0.3913, 0.3222,
        0.5207, 0.5162, 0.2033, 0.5139, 0.5582, 0.4315, 0.2804, 0.3749, 0.4389,
        0.1693, 0.2574, 0.4028, 0.1534, 0.2574, 0.2574, 0.2574, 0.1489, 0.1489,
        0.4152, 0.3778, 0.3739, 0.1489, 0.1571, 0.6362, 0.1853, 0.1010, 0.4067,
        0.3025, 0.4304, 0.5142, 0.2447, 0.4147, 0.5142, 0.2477, 0.4304, 0.6471,
        0.6491, 0.3797, 0.1905, 0.5186, 0.2917, 0.1808, 0.1550, 0.1919, 0.2356,
        0.3479, 0.3419, 0.2588, 0.3986, 0.5513, 0.1878, 0.2906, 0.6564, 0.3745,
        0.4174, 0.6564, 0.1641, 0.3759, 0.2717, 0.3759, 0.2694, 0.3759, 0.3759,
        0.1658, 0.3759, 0.1641, 0.1367, 0.6970, 0.4089, 0.6524, 0.1367, 0.3605,
        0.1327, 0.4086, 0.3605, 0.3811, 0.1479, 0.1754, 0.2252, 0.2252, 0.2252,
        0.2252, 0.2252, 0.2252, 0.2252, 0.2252, 0.1847, 0.1574, 0.2346, 0.2599,
        0.2028, 0.4138, 0.3360, 0.2738, 0.1513, 0.1847, 0.1670, 0.3508, 0.2288,
        0.3983, 0.3234, 0.1325, 0.1670, 0.1303, 0.1303, 0.1303, 0.1603, 0.3798,
        0.1603, 0.3407, 0.3798, 0.1020, 0.2421, 0.3930, 0.2510, 0.1977, 0.2804,
        0.5645, 0.3965, 0.3964, 0.5188, 0.1775, 0.5186, 0.2604, 0.5173, 0.4537,
        0.5189, 0.6381, 0.1459, 0.2110, 0.5108, 0.3744, 0.4201, 0.3744, 0.3812,
        0.6381, 0.3092, 0.2249, 0.5109, 0.4502, 0.2243, 0.3453, 0.0787, 0.3925,
        0.4192, 0.2249, 0.2502, 0.4896, 0.2502, 0.2502, 0.5327, 0.2502, 0.2502,
        0.2502, 0.2502, 0.2502, 0.0591, 0.7086, 0.3617, 0.3617, 0.5558, 0.2646,
        0.1578, 0.3617, 0.2124, 0.2234, 0.4325, 0.5036, 0.4099, 0.3673, 0.0913,
        0.1842, 0.4099, 0.4099, 0.1487, 0.5112, 0.2594, 0.2454, 0.3618, 0.4622,
        0.1430, 0.3618, 0.3618, 0.2454, 0.1430, 0.1430, 0.3140, 0.3830, 0.1682,
        0.1969, 0.3535, 0.1703, 0.3830, 0.3677, 0.6669, 0.3830, 0.1744, 0.2784,
        0.3996, 0.1713, 0.2203, 0.0952, 0.3866, 0.2085, 0.1997, 0.2662, 0.1281,
        0.5712, 0.5368, 0.3720, 0.3720, 0.1576, 0.5095, 0.4642, 0.3919, 0.3778,
        0.1350, 0.5261, 0.1549, 0.4105, 0.3654, 0.4105, 0.3654, 0.2467, 0.2475,
        0.1350, 0.3866, 0.1955, 0.5150, 0.4307, 0.3866, 0.1628, 0.1628, 0.4084,
        0.0562, 0.1888, 0.4964, 0.2445, 0.4312, 0.1366, 0.1366, 0.1668, 0.4309,
        0.4051, 0.3627, 0.4849, 0.2504, 0.1241, 0.0392, 0.2504, 0.0614, 0.1274,
        0.0614, 0.1464, 0.0666, 0.0614, 0.2267, 0.2267, 0.2321, 0.1853, 0.1445,
        0.0694, 0.1836, 0.1445, 0.2514, 0.1445, 0.3752, 0.3752, 0.1489, 0.3839,
        0.3839, 0.3433, 0.4195, 0.3752, 0.1539, 0.4416, 0.2402, 0.0556, 0.1958,
        0.5190, 0.5194, 0.3800, 0.4088, 0.2008, 0.4234, 0.4405, 0.0817, 0.2501,
        0.3695, 0.2459, 0.5097, 0.0742, 0.3646, 0.2351, 0.3695, 0.5149, 0.2713,
        0.1989, 0.0858, 0.3520, 0.5150, 0.2704, 0.3802, 0.4421, 0.2477, 0.1599,
        0.3870, 0.4291, 0.1944, 0.6737, 0.3986, 0.1833, 0.0667, 0.5388, 0.0624,
        0.1803, 0.0520, 0.4229, 0.2696, 0.3801, 0.3801, 0.1814, 0.1714, 0.1050,
        0.2681, 0.1557, 0.5103, 0.2616, 0.1038, 0.1744, 0.3870, 0.3870, 0.5143,
        0.3870, 0.2087, 0.3416, 0.2582, 0.2412, 0.5176, 0.3552, 0.3743, 0.5573,
        0.7009, 0.2412, 0.2412, 0.3743, 0.3742, 0.3742, 0.5045, 0.3742, 0.4113,
        0.3742, 0.2928, 0.0936, 0.1621, 0.0940, 0.2967, 0.2879, 0.1729, 0.3126,
        0.2552, 0.1729, 0.2085, 0.1729, 0.3344, 0.1729, 0.3690, 0.3866, 0.3866,
        0.3866, 0.3457, 0.1995, 0.2701, 0.2760, 0.2701, 0.1540, 0.0480, 0.2603,
        0.3735, 0.4176, 0.5157, 0.3735, 0.1486, 0.2440, 0.2352, 0.2296, 0.1601,
        0.3986, 0.1946, 0.1547, 0.2530, 0.1601, 0.1811, 0.3814, 0.3814, 0.0851,
        0.4450, 0.5434, 0.2435, 0.1418, 0.1483, 0.5260, 0.1753, 0.2550, 0.2389,
        0.5260, 0.7010, 0.2610, 0.1476, 0.4079, 0.0806, 0.3834, 0.3862, 0.4279,
        0.5502, 0.3834, 0.3953, 0.1505, 0.1233, 0.4019, 0.2325, 0.2179, 0.4251,
        0.3953, 0.6479, 0.2499, 0.6646, 0.3854, 0.6248, 0.2629, 0.3854, 0.5630,
        0.3819, 0.3819, 0.3819, 0.2824, 0.3817, 0.4192, 0.3764, 0.4192, 0.1689,
        0.1575, 0.1546, 0.3817, 0.6406, 0.3817, 0.3700, 0.4071, 0.4159, 0.3732,
        0.4159, 0.1712, 0.0447, 0.2327, 0.1434, 0.0923, 0.2771, 0.2900, 0.3914,
        0.3994, 0.3914, 0.2771, 0.3078, 0.2743, 0.3914, 0.3914, 0.6871, 0.4077,
        0.0433, 0.5004, 0.3619, 0.5106, 0.6440, 0.3912, 0.3619, 0.3606, 0.1681,
        0.3899, 0.1942, 0.1734, 0.1676, 0.5234, 0.1936, 0.4324, 0.1681, 0.3931,
        0.3903, 0.1576, 0.1576, 0.5263, 0.5263, 0.1583, 0.4296, 0.1935, 0.1576,
        0.1576, 0.1617, 0.2539, 0.4085, 0.4170, 0.3760, 0.3998, 0.2033, 0.1624,
        0.2009, 0.1282, 0.5142, 0.2994, 0.1698, 0.1680, 0.0571, 0.3590, 0.6325,
        0.5041, 0.2439, 0.1360, 0.1754, 0.1754, 0.1754, 0.1754, 0.1754, 0.1754,
        0.0990, 0.3936, 0.1754, 0.1754, 0.5716, 0.4316, 0.1614, 0.2526, 0.1604,
        0.5169, 0.2850, 0.3829, 0.1971, 0.2774, 0.4427, 0.1957, 0.5133, 0.5152,
        0.3813, 0.2435, 0.3770, 0.3588, 0.1992, 0.6394, 0.1469, 0.1312, 0.1868,
        0.1473, 0.5838, 0.3697, 0.6526, 0.2303, 0.1469, 0.1718, 0.3922, 0.3257,
        0.4359, 0.2874, 0.3257, 0.2148, 0.3922, 0.4359, 0.3922, 0.3590, 0.3713,
        0.5235, 0.4151, 0.1603, 0.1531, 0.3713, 0.5235, 0.3713, 0.4675, 0.3913,
        0.1567, 0.3738, 0.1567, 0.4164, 0.2645, 0.1567, 0.1817, 0.3738, 0.3738,
        0.2002, 0.2148, 0.3144, 0.2423, 0.2599, 0.2599, 0.1698, 0.2530, 0.3030,
        0.4369, 0.3944, 0.3686, 0.1876, 0.3686, 0.3686, 0.4124, 0.4124, 0.3686,
        0.6461, 0.3686, 0.4124, 0.5140, 0.1573, 0.4305, 0.3854, 0.6406, 0.4305,
        0.6406, 0.6406, 0.1654, 0.2515, 0.4504, 0.1761, 0.3938, 0.3938, 0.2910,
        0.6356, 0.3303, 0.1776, 0.1777, 0.1761], grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0.,
        0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0.,
        0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0.,
        0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1.,
        0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,
        1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.])
loss:  tensor(0.6747, grad_fn=<MeanBackward0>) l2:  tensor(0.3328, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
Iteration 40, loss: 0.6823030769824981
Epoch 1; time 1.0275
epoch 1 validating; auc: 0.5882
Model (checkpoint) saved to output/ml1m/env/ml1m_user_env_lr0.001_reg0.001.model
epoch 2 training
self.sigmoid(preds):  tensor([0.2851, 0.6509, 0.1782,  ..., 0.1728, 0.3858, 0.2937],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 0.,  ..., 1., 1., 1.])
loss:  tensor(0.6708, grad_fn=<MeanBackward0>) l2:  tensor(0.3325, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.1874, 0.3962, 0.6074,  ..., 0.1926, 0.4117, 0.5444],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 0.,  ..., 1., 0., 1.])
loss:  tensor(0.6734, grad_fn=<MeanBackward0>) l2:  tensor(0.3322, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4137, 0.1601, 0.4666,  ..., 0.2474, 0.3987, 0.4029],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 0., 0., 0.])
loss:  tensor(0.6753, grad_fn=<MeanBackward0>) l2:  tensor(0.3320, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3419, 0.3921, 0.3921,  ..., 0.5232, 0.0983, 0.4576],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6824, grad_fn=<MeanBackward0>) l2:  tensor(0.3317, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4036, 0.8088, 0.5858,  ..., 0.4115, 0.0539, 0.4115],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 0.,  ..., 1., 0., 0.])
loss:  tensor(0.6812, grad_fn=<MeanBackward0>) l2:  tensor(0.3314, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.1688, 0.0278, 0.4896,  ..., 0.4370, 0.5254, 0.1531],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6672, grad_fn=<MeanBackward0>) l2:  tensor(0.3313, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.7515, 0.4225, 0.4225,  ..., 0.1915, 0.5158, 0.1959],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 0.])
loss:  tensor(0.6613, grad_fn=<MeanBackward0>) l2:  tensor(0.3311, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.1553, 0.5350, 0.1629,  ..., 0.5262, 0.1684, 0.2938],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.6769, grad_fn=<MeanBackward0>) l2:  tensor(0.3309, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.1456, 0.1828, 0.5276,  ..., 0.7713, 0.4455, 0.2658],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 0., 0., 0.])
loss:  tensor(0.6790, grad_fn=<MeanBackward0>) l2:  tensor(0.3307, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.1171, 0.2548, 0.4278,  ..., 0.0419, 0.5501, 0.6129],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.6839, grad_fn=<MeanBackward0>) l2:  tensor(0.3305, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
Iteration 10, loss: 0.6754846274852753
self.sigmoid(preds):  tensor([0.6099, 0.0908, 0.0908,  ..., 0.4345, 0.1548, 0.4345],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6746, grad_fn=<MeanBackward0>) l2:  tensor(0.3304, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4354, 0.2154, 0.2732,  ..., 0.1637, 0.3364, 0.2616],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0.,  ..., 0., 1., 0.])
loss:  tensor(0.6760, grad_fn=<MeanBackward0>) l2:  tensor(0.3304, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.2566, 0.4279, 0.4279,  ..., 0.1762, 0.5724, 0.1188],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6743, grad_fn=<MeanBackward0>) l2:  tensor(0.3302, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4323, 0.0725, 0.2254,  ..., 0.5908, 0.4016, 0.4411],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6696, grad_fn=<MeanBackward0>) l2:  tensor(0.3300, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.9125, 0.4327, 0.5774,  ..., 0.4332, 0.3360, 0.3360],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 0.,  ..., 1., 1., 1.])
loss:  tensor(0.6895, grad_fn=<MeanBackward0>) l2:  tensor(0.3297, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4575, 0.1445, 0.1445,  ..., 0.0668, 0.0668, 0.2154],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 1.,  ..., 0., 0., 1.])
loss:  tensor(0.6880, grad_fn=<MeanBackward0>) l2:  tensor(0.3294, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.7022, 0.9255, 0.2326,  ..., 0.4512, 0.6455, 0.4512],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 0.])
loss:  tensor(0.6699, grad_fn=<MeanBackward0>) l2:  tensor(0.3292, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.0945, 0.0166, 0.0914,  ..., 0.6451, 0.8379, 0.6167],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6673, grad_fn=<MeanBackward0>) l2:  tensor(0.3289, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.9101, 0.0738, 0.6495,  ..., 0.1270, 0.3916, 0.3916],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 0.,  ..., 1., 1., 1.])
loss:  tensor(0.6830, grad_fn=<MeanBackward0>) l2:  tensor(0.3286, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.0224, 0.0672, 0.0146,  ..., 0.1132, 0.5899, 0.0963],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0.,  ..., 1., 1., 1.])
loss:  tensor(0.6623, grad_fn=<MeanBackward0>) l2:  tensor(0.3283, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
Iteration 20, loss: 0.6756295025348663
self.sigmoid(preds):  tensor([0.6047, 0.0371, 0.0911,  ..., 0.1268, 0.4559, 0.6146],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0.,  ..., 0., 0., 0.])
loss:  tensor(0.6659, grad_fn=<MeanBackward0>) l2:  tensor(0.3280, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.0686, 0.4219, 0.1029,  ..., 0.4384, 0.6371, 0.4384],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6602, grad_fn=<MeanBackward0>) l2:  tensor(0.3277, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.9342, 0.0504, 0.4675,  ..., 0.1273, 0.8358, 0.4361],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 0.])
loss:  tensor(0.6698, grad_fn=<MeanBackward0>) l2:  tensor(0.3273, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.8689, 0.0533, 0.9377,  ..., 0.4269, 0.1199, 0.7295],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 0.,  ..., 1., 0., 1.])
loss:  tensor(0.6789, grad_fn=<MeanBackward0>) l2:  tensor(0.3269, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.6567, 0.1573, 0.1459,  ..., 0.4268, 0.1600, 0.0401],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0.,  ..., 0., 0., 1.])
loss:  tensor(0.6648, grad_fn=<MeanBackward0>) l2:  tensor(0.3265, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.0666, 0.0147, 0.4187,  ..., 0.9329, 0.2197, 0.4736],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 1., 1., 1.])
loss:  tensor(0.6761, grad_fn=<MeanBackward0>) l2:  tensor(0.3260, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.1717, 0.1364, 0.0625,  ..., 0.1697, 0.0529, 0.4442],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 0., 1.])
loss:  tensor(0.6736, grad_fn=<MeanBackward0>) l2:  tensor(0.3257, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.0145, 0.1160, 0.4334,  ..., 0.6431, 0.9075, 0.5752],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 0.])
loss:  tensor(0.6653, grad_fn=<MeanBackward0>) l2:  tensor(0.3253, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.7515, 0.0652, 0.6199,  ..., 0.0420, 0.1279, 0.0420],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 1.,  ..., 0., 0., 0.])
loss:  tensor(0.6824, grad_fn=<MeanBackward0>) l2:  tensor(0.3249, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.0522, 0.0522, 0.0522,  ..., 0.0998, 0.1066, 0.2427],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 0.,  ..., 1., 0., 0.])
loss:  tensor(0.6662, grad_fn=<MeanBackward0>) l2:  tensor(0.3244, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
Iteration 30, loss: 0.6739639242490133
self.sigmoid(preds):  tensor([0.6756, 0.4768, 0.2563,  ..., 0.0629, 0.2463, 0.5094],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 0.,  ..., 1., 1., 0.])
loss:  tensor(0.6666, grad_fn=<MeanBackward0>) l2:  tensor(0.3240, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.6334, 0.0280, 0.8017,  ..., 0.8696, 0.1208, 0.0327],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6646, grad_fn=<MeanBackward0>) l2:  tensor(0.3235, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4720, 0.7618, 0.4720,  ..., 0.3510, 0.8936, 0.0973],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 1.,  ..., 1., 0., 1.])
loss:  tensor(0.6762, grad_fn=<MeanBackward0>) l2:  tensor(0.3230, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3930, 0.4992, 0.6960,  ..., 0.3309, 0.0403, 0.4495],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 0., 0., 0.])
loss:  tensor(0.6699, grad_fn=<MeanBackward0>) l2:  tensor(0.3224, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.8830, 0.0149, 0.4789,  ..., 0.5101, 0.3469, 0.1394],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 0., 0.])
loss:  tensor(0.6646, grad_fn=<MeanBackward0>) l2:  tensor(0.3219, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.7401, 0.0115, 0.3220,  ..., 0.0505, 0.2033, 0.8706],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 0.])
loss:  tensor(0.6728, grad_fn=<MeanBackward0>) l2:  tensor(0.3214, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.9674, 0.4062, 0.1129,  ..., 0.9599, 0.1674, 0.3126],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0.,  ..., 1., 1., 0.])
loss:  tensor(0.6688, grad_fn=<MeanBackward0>) l2:  tensor(0.3208, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.0623, 0.0623, 0.1185,  ..., 0.3003, 0.5094, 0.5094],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 0., 1., 1.])
loss:  tensor(0.6822, grad_fn=<MeanBackward0>) l2:  tensor(0.3203, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.0240, 0.7952, 0.1451,  ..., 0.0346, 0.4151, 0.3745],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 1., 0., 1.])
loss:  tensor(0.6862, grad_fn=<MeanBackward0>) l2:  tensor(0.3199, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.9632, 0.2644, 0.0070, 0.1832, 0.1636, 0.1658, 0.3771, 0.0754, 0.0310,
        0.2735, 0.0079, 0.0624, 0.1336, 0.1370, 0.0440, 0.1383, 0.5036, 0.0440,
        0.1383, 0.0624, 0.7408, 0.0253, 0.1682, 0.1901, 0.5649, 0.0451, 0.1568,
        0.0750, 0.0036, 0.0741, 0.2427, 0.8884, 0.7638, 0.2936, 0.2979, 0.7417,
        0.0717, 0.1240, 0.2092, 0.5258, 0.5156, 0.2232, 0.0154, 0.5156, 0.0988,
        0.3883, 0.2164, 0.8215, 0.2809, 0.6905, 0.5164, 0.4357, 0.1162, 0.1053,
        0.3447, 0.0756, 0.8744, 0.5164, 0.5164, 0.3479, 0.5217, 0.2861, 0.2254,
        0.8480, 0.9535, 0.4955, 0.6914, 0.0842, 0.7394, 0.9040, 0.2290, 0.0652,
        0.0381, 0.1025, 0.1455, 0.0447, 0.0734, 0.2136, 0.0107, 0.0244, 0.3886,
        0.7406, 0.1784, 0.0705, 0.0362, 0.1219, 0.1925, 0.6078, 0.0532, 0.0938,
        0.1395, 0.3867, 0.4653, 0.7153, 0.4953, 0.0871, 0.5593, 0.4953, 0.0613,
        0.0750, 0.1464, 0.5559, 0.3120, 0.3018, 0.9428, 0.3120, 0.7818, 0.1051,
        0.4631, 0.4912, 0.6094, 0.4131, 0.5243, 0.9068, 0.0879, 0.7267, 0.3997,
        0.2968, 0.6998, 0.8612, 0.0764, 0.1124, 0.4997, 0.8187, 0.0576, 0.4997,
        0.1116, 0.8668, 0.4741, 0.4997, 0.6473, 0.1000, 0.0457, 0.4888, 0.3862,
        0.0652, 0.1391, 0.7854, 0.5842, 0.0761, 0.4696, 0.1245, 0.6988, 0.9472,
        0.1982, 0.7166, 0.0262, 0.0873, 0.8792, 0.8792, 0.7398, 0.0531, 0.0822,
        0.4379, 0.2402, 0.6119, 0.5313, 0.7260, 0.2141, 0.0863, 0.1009, 0.0922,
        0.1504, 0.1411, 0.1789, 0.0922, 0.3103, 0.1789, 0.1614, 0.3103, 0.0495,
        0.1197, 0.3514, 0.1197, 0.3514, 0.4045, 0.0884, 0.2680, 0.6148, 0.2590,
        0.0657, 0.6934, 0.3885, 0.6934, 0.1043, 0.8749, 0.0916, 0.4911, 0.6934,
        0.4911, 0.0740, 0.8648, 0.0529, 0.2121, 0.5751, 0.1520, 0.7760, 0.1906,
        0.1906, 0.1906, 0.1159, 0.3269, 0.1230, 0.0192, 0.0721, 0.9642, 0.5966,
        0.0358, 0.6592, 0.3247, 0.3363, 0.5099, 0.5099, 0.6110, 0.7409, 0.7306,
        0.5099, 0.8247, 0.0462, 0.1798, 0.0469, 0.9661, 0.7343, 0.0118, 0.5146,
        0.8450, 0.7343, 0.9163, 0.1685, 0.1787, 0.0757, 0.8837, 0.5177, 0.0757,
        0.5177, 0.5177, 0.4169, 0.2941, 0.5177, 0.7503, 0.5147, 0.2669, 0.0526,
        0.5147, 0.5147, 0.8608, 0.0526, 0.8155, 0.2042, 0.5147, 0.8331, 0.0892,
        0.5077, 0.7716, 0.3769, 0.5077, 0.5077, 0.1703, 0.8154, 0.7635, 0.5245,
        0.0545, 0.1996, 0.1074, 0.0306, 0.1918, 0.0545, 0.2932, 0.5302, 0.0915,
        0.4913, 0.4521, 0.0544, 0.1050, 0.7019, 0.8909, 0.1650, 0.0544, 0.0154,
        0.8909, 0.0683, 0.4421, 0.5362, 0.0683, 0.1079, 0.7354, 0.0683, 0.6835,
        0.9567, 0.5362, 0.3981, 0.5089, 0.7094, 0.2610, 0.0048, 0.1198, 0.7809,
        0.1047, 0.1198, 0.7232, 0.0956, 0.0602, 0.0602, 0.0602, 0.0393, 0.5163,
        0.0602, 0.0602, 0.0404, 0.0602, 0.0437, 0.3732, 0.0303, 0.2636, 0.6253,
        0.0437, 0.0437, 0.7085, 0.0806, 0.3103, 0.0423, 0.0071, 0.2833, 0.1421,
        0.0918, 0.0444, 0.3777, 0.0397, 0.5266, 0.8225, 0.0531, 0.4813, 0.9014,
        0.0245, 0.0460, 0.6569, 0.1747, 0.6382, 0.7549, 0.1360, 0.9133, 0.0443,
        0.0443, 0.0215, 0.0443, 0.0443, 0.0059, 0.0443, 0.0694, 0.0365, 0.0597,
        0.4084, 0.7610, 0.3429, 0.0836, 0.9544, 0.8241, 0.0597, 0.0689, 0.1177,
        0.1504, 0.7127, 0.2040, 0.7050, 0.6620, 0.3208, 0.3208, 0.3859, 0.1013,
        0.1069, 0.9658, 0.8651, 0.0560, 0.0479, 0.6896, 0.2790, 0.1154, 0.1154,
        0.3925, 0.0754, 0.0677, 0.4975, 0.9429, 0.4975, 0.4623, 0.4975, 0.6951,
        0.6951, 0.4975, 0.4975, 0.1000, 0.8790, 0.5102, 0.7891, 0.8790, 0.4171,
        0.0436, 0.4171, 0.1914, 0.0927, 0.1801, 0.0394, 0.0394, 0.1016, 0.5930,
        0.0641, 0.0960, 0.1896, 0.1801, 0.3906, 0.0587, 0.8213, 0.7782, 0.6472,
        0.3841, 0.6152, 0.9660, 0.8213, 0.0887, 0.0374, 0.6995, 0.0663, 0.3116,
        0.2188, 0.6147, 0.0483, 0.2859, 0.0511, 0.6685, 0.1063, 0.9149, 0.5350,
        0.1940, 0.1001, 0.3055, 0.0574, 0.7485, 0.5058, 0.5350, 0.1314, 0.0461,
        0.5334, 0.1407, 0.0761, 0.7253, 0.1407, 0.5276, 0.2220, 0.4079, 0.0648,
        0.2171, 0.4260, 0.5082, 0.9543, 0.2055, 0.7379, 0.1096, 0.0503, 0.0713,
        0.0954, 0.0011, 0.3973, 0.0152, 0.0443, 0.1332, 0.0020, 0.5105, 0.0294,
        0.0443, 0.2510, 0.4903, 0.9492, 0.9412, 0.4903, 0.1810, 0.7862, 0.0088,
        0.1114, 0.6919, 0.6919, 0.5193, 0.3611, 0.4240, 0.2789, 0.4087, 0.5193,
        0.2789, 0.2789, 0.2789, 0.5193, 0.9012, 0.0209, 0.0690, 0.0490, 0.4260,
        0.0690, 0.3164, 0.0490, 0.7380, 0.1175, 0.6277, 0.7049, 0.8251, 0.1267,
        0.8251, 0.0662, 0.0809, 0.1966, 0.0852, 0.2217, 0.0521, 0.0262, 0.1203,
        0.2539, 0.0314, 0.1027, 0.1203, 0.0521, 0.0130, 0.0521, 0.5308, 0.1085,
        0.4362, 0.0077, 0.1121, 0.4152, 0.0450, 0.5444, 0.2257, 0.2019, 0.0656,
        0.2531, 0.7286, 0.3963, 0.7335, 0.8270, 0.0551, 0.7001, 0.0465, 0.0465,
        0.4590, 0.0479, 0.0479, 0.0479, 0.2819, 0.0079, 0.0515, 0.0079, 0.4590,
        0.0224, 0.4768, 0.1745, 0.1745, 0.1745, 0.1745, 0.6899, 0.1745, 0.0899,
        0.0510, 0.0510, 0.4644, 0.1066, 0.1066, 0.0762, 0.3429, 0.4644, 0.1745,
        0.0762, 0.2767, 0.0064, 0.5161, 0.5161, 0.5161, 0.5161, 0.7378, 0.1424,
        0.5161, 0.7563, 0.2805, 0.8920, 0.4867, 0.0441, 0.7307, 0.4867, 0.3905,
        0.4867, 0.3905, 0.4867, 0.0441, 0.1073, 0.9566, 0.2465, 0.7535, 0.6077,
        0.2465, 0.7972, 0.1527, 0.0711, 0.7473, 0.1527, 0.4286, 0.3137, 0.5277,
        0.5749, 0.5277, 0.7221, 0.8863, 0.2983, 0.5277, 0.5277, 0.3930, 0.5278,
        0.5278, 0.5610, 0.5278, 0.5278, 0.1348, 0.9671, 0.5278, 0.5278, 0.0983,
        0.5151, 0.8094, 0.9692, 0.0563, 0.9063, 0.0409, 0.2072, 0.5151, 0.7252,
        0.2021, 0.6620, 0.8382, 0.3674, 0.4948, 0.7155, 0.6620, 0.7047, 0.4948,
        0.0169, 0.5253, 0.0602, 0.3972, 0.0602, 0.9100, 0.0602, 0.5049, 0.0602,
        0.4180, 0.0406, 0.2847, 0.3771, 0.7133, 0.1024, 0.4896, 0.1024, 0.0421,
        0.7133, 0.3943, 0.0147, 0.2768, 0.5258, 0.2883, 0.7731, 0.7238, 0.2883,
        0.5258, 0.5258, 0.4261, 0.5258, 0.0210, 0.8022, 0.1084, 0.0059, 0.0371,
        0.0301, 0.0442, 0.7417, 0.0844, 0.0165, 0.6571, 0.9074, 0.0429, 0.8079,
        0.7434, 0.2036, 0.9570, 0.2871, 0.0707, 0.0400, 0.7046, 0.0188, 0.4817,
        0.4817, 0.3797, 0.6699, 0.4817, 0.4817, 0.4817, 0.0394, 0.5104, 0.0432,
        0.0104, 0.4342, 0.0022, 0.0810, 0.2399, 0.8334, 0.8334, 0.5338, 0.0452,
        0.6641, 0.6864, 0.1902, 0.2663, 0.4987, 0.0390, 0.3336, 0.0896, 0.0633,
        0.0294, 0.5161, 0.0294, 0.2504, 0.5161, 0.0735, 0.0408, 0.5667, 0.5161,
        0.0019, 0.1391, 0.3214, 0.0353, 0.7303, 0.2749, 0.9018, 0.1061, 0.3214,
        0.0165, 0.2207, 0.0081, 0.6852, 0.5143, 0.0537, 0.0537, 0.0143, 0.5143,
        0.0080, 0.0594, 0.1272, 0.9512, 0.7532, 0.0449, 0.0247, 0.0723, 0.4008,
        0.0631, 0.0631, 0.7333, 0.5102, 0.4954, 0.0705, 0.0746, 0.4954, 0.6890,
        0.2835, 0.2853, 0.4954, 0.1539, 0.7774, 0.0935, 0.2674, 0.1671, 0.5346,
        0.0555, 0.8445, 0.0448, 0.7332, 0.9166, 0.6989, 0.0493, 0.3612, 0.0772,
        0.0772, 0.2028, 0.0863, 0.8875, 0.3704, 0.3967, 0.1918, 0.4014, 0.0892,
        0.0892, 0.0892, 0.0892, 0.2002, 0.0892, 0.1758, 0.2587, 0.0609, 0.7852,
        0.0532, 0.0079, 0.4918, 0.4918, 0.0732, 0.8479, 0.0334, 0.4918, 0.7377,
        0.4877, 0.0763, 0.4877, 0.4877, 0.4877, 0.3745, 0.0657, 0.6882, 0.1093,
        0.0657, 0.1232, 0.0933, 0.0016, 0.1611, 0.0952, 0.0933, 0.0081, 0.0532,
        0.1228, 0.1913, 0.0509, 0.3493, 0.1131, 0.4908, 0.0479, 0.0588, 0.0479,
        0.6924, 0.0509, 0.3493, 0.7852, 0.1311, 0.4053, 0.3477, 0.6730, 0.5086,
        0.0791, 0.0791, 0.5535, 0.8693, 0.6100, 0.8947, 0.3573, 0.2034, 0.5120,
        0.0329, 0.1317, 0.0602, 0.7619, 0.2153], grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0.,
        0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0.,
        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0.,
        1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0.,
        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0.,
        1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.])
loss:  tensor(0.6571, grad_fn=<MeanBackward0>) l2:  tensor(0.3196, grad_fn=<AddBackward0>) l2*coef tensor(0.0003, grad_fn=<MulBackward0>)
Iteration 40, loss: 0.6732758700847625
Epoch 2; time 1.0646
epoch 2 validating; auc: 0.5938
Model (checkpoint) saved to output/ml1m/env/ml1m_user_env_lr0.001_reg0.001.model

Namespace(model='ML1MUserResponse', reader='ML1MDataReader')
Namespace(seed=19, batch_size=128, lr=0.001, epoch=2, model_path='output/ml1m/env/ml1m_user_env_lr0.001_reg0.0003.model', loss='bce', l2_coef=0.0003, feature_dim=16, attn_n_head=2, hidden_dims=[256], dropout_rate=0.2, train_file='dataset/ml1m/ml1m_b_train.csv', val_file='dataset/ml1m/ml1m_b_test.csv', test_file='', n_worker=0, data_separator='@', user_meta_file='dataset/ml1m/user_info.npy', item_meta_file='dataset/ml1m/item_info.npy', max_seq_len=50, meta_data_separator=' ')
init ml1m reader
Loading data filesLoad item meta data
{'length': 5078, 'n_item': 1682, 'item_vec_size': 19, 'user_portrait_len': 24, 'max_seq_len': 50}
{'length': 5078, 'n_item': 1682, 'item_vec_size': 19, 'user_portrait_len': 24, 'max_seq_len': 50}
epoch 1 training
self.sigmoid(preds):  tensor([0.4950, 0.4985, 0.4985,  ..., 0.5107, 0.5021, 0.5073],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.6731, grad_fn=<MeanBackward0>) l2:  tensor(0.3466, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4990, 0.5090, 0.4953,  ..., 0.5288, 0.5114, 0.4855],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 0., 1.])
loss:  tensor(0.6988, grad_fn=<MeanBackward0>) l2:  tensor(0.3459, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4982, 0.4931, 0.4821,  ..., 0.4936, 0.4779, 0.5049],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 1., 1., 0.])
loss:  tensor(0.7194, grad_fn=<MeanBackward0>) l2:  tensor(0.3453, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.5157, 0.5102, 0.4922,  ..., 0.4666, 0.4882, 0.4729],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6935, grad_fn=<MeanBackward0>) l2:  tensor(0.3448, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4952, 0.4879, 0.4575,  ..., 0.4593, 0.4909, 0.4646],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 0.])
loss:  tensor(0.6820, grad_fn=<MeanBackward0>) l2:  tensor(0.3443, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4909, 0.4769, 0.4805,  ..., 0.4810, 0.4860, 0.4775],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 0.,  ..., 1., 0., 0.])
loss:  tensor(0.6789, grad_fn=<MeanBackward0>) l2:  tensor(0.3438, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.5035, 0.5083, 0.4878,  ..., 0.4929, 0.4752, 0.4875],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 1.,  ..., 1., 1., 0.])
loss:  tensor(0.7061, grad_fn=<MeanBackward0>) l2:  tensor(0.3434, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4678, 0.4715, 0.4752,  ..., 0.4527, 0.4855, 0.4855],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0.,  ..., 0., 1., 1.])
loss:  tensor(0.6709, grad_fn=<MeanBackward0>) l2:  tensor(0.3430, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4628, 0.4607, 0.4628,  ..., 0.4671, 0.4630, 0.4612],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.6908, grad_fn=<MeanBackward0>) l2:  tensor(0.3426, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4871, 0.4520, 0.4520,  ..., 0.4369, 0.4604, 0.4314],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0.,  ..., 0., 0., 0.])
loss:  tensor(0.6884, grad_fn=<MeanBackward0>) l2:  tensor(0.3422, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
Iteration 10, loss: 0.6902871429920197
self.sigmoid(preds):  tensor([0.4185, 0.4568, 0.4194,  ..., 0.4652, 0.4243, 0.4738],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 0., 0., 1.])
loss:  tensor(0.6757, grad_fn=<MeanBackward0>) l2:  tensor(0.3419, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4504, 0.4492, 0.4437,  ..., 0.4105, 0.4407, 0.4250],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 0.,  ..., 1., 0., 1.])
loss:  tensor(0.6921, grad_fn=<MeanBackward0>) l2:  tensor(0.3416, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4681, 0.4793, 0.4673,  ..., 0.4420, 0.4454, 0.4407],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 0., 1.])
loss:  tensor(0.6826, grad_fn=<MeanBackward0>) l2:  tensor(0.3413, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4760, 0.4121, 0.4464,  ..., 0.4220, 0.3899, 0.4551],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.6875, grad_fn=<MeanBackward0>) l2:  tensor(0.3411, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4284, 0.4451, 0.4644,  ..., 0.3965, 0.4270, 0.4296],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.7020, grad_fn=<MeanBackward0>) l2:  tensor(0.3408, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4106, 0.4281, 0.4719,  ..., 0.4591, 0.3951, 0.3475],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.6647, grad_fn=<MeanBackward0>) l2:  tensor(0.3407, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3798, 0.4074, 0.3884,  ..., 0.4322, 0.3933, 0.4332],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 0.,  ..., 1., 1., 1.])
loss:  tensor(0.6833, grad_fn=<MeanBackward0>) l2:  tensor(0.3405, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4298, 0.4726, 0.4034,  ..., 0.4359, 0.3933, 0.4136],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 0., 0.])
loss:  tensor(0.6836, grad_fn=<MeanBackward0>) l2:  tensor(0.3403, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3896, 0.4672, 0.4013,  ..., 0.4204, 0.4204, 0.3900],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.6907, grad_fn=<MeanBackward0>) l2:  tensor(0.3401, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4576, 0.3417, 0.4295,  ..., 0.4178, 0.3820, 0.4026],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.6777, grad_fn=<MeanBackward0>) l2:  tensor(0.3400, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
Iteration 20, loss: 0.6871821790933609
self.sigmoid(preds):  tensor([0.4063, 0.3861, 0.4063,  ..., 0.3691, 0.3527, 0.3682],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 1.,  ..., 1., 0., 1.])
loss:  tensor(0.6883, grad_fn=<MeanBackward0>) l2:  tensor(0.3398, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4008, 0.3460, 0.4153,  ..., 0.3559, 0.4044, 0.4527],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 1., 0., 1.])
loss:  tensor(0.6812, grad_fn=<MeanBackward0>) l2:  tensor(0.3398, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4022, 0.3756, 0.3756,  ..., 0.3435, 0.2925, 0.3900],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 0., 1.])
loss:  tensor(0.6719, grad_fn=<MeanBackward0>) l2:  tensor(0.3397, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3941, 0.3941, 0.3367,  ..., 0.3725, 0.3770, 0.3770],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 0.,  ..., 1., 1., 1.])
loss:  tensor(0.6795, grad_fn=<MeanBackward0>) l2:  tensor(0.3397, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3414, 0.3067, 0.3654,  ..., 0.3717, 0.3136, 0.3512],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 1., 1., 1.])
loss:  tensor(0.6825, grad_fn=<MeanBackward0>) l2:  tensor(0.3396, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3257, 0.3860, 0.3860,  ..., 0.5104, 0.3052, 0.3052],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 0.])
loss:  tensor(0.6867, grad_fn=<MeanBackward0>) l2:  tensor(0.3396, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3674, 0.1876, 0.2818,  ..., 0.3649, 0.2704, 0.4444],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 0., 1.])
loss:  tensor(0.6699, grad_fn=<MeanBackward0>) l2:  tensor(0.3396, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.2995, 0.3031, 0.2643,  ..., 0.4862, 0.3688, 0.2915],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 0., 1., 1.])
loss:  tensor(0.6852, grad_fn=<MeanBackward0>) l2:  tensor(0.3396, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4166, 0.2662, 0.4120,  ..., 0.3571, 0.3582, 0.2503],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 1.,  ..., 1., 0., 0.])
loss:  tensor(0.6760, grad_fn=<MeanBackward0>) l2:  tensor(0.3396, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.2004, 0.2232, 0.2079,  ..., 0.2683, 0.3732, 0.1608],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 0., 0., 1.])
loss:  tensor(0.6648, grad_fn=<MeanBackward0>) l2:  tensor(0.3396, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
Iteration 30, loss: 0.684358545144399
self.sigmoid(preds):  tensor([0.2044, 0.3099, 0.4558,  ..., 0.2445, 0.2236, 0.3658],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6712, grad_fn=<MeanBackward0>) l2:  tensor(0.3394, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3655, 0.1930, 0.2746,  ..., 0.3381, 0.3070, 0.2975],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 1., 1., 1.])
loss:  tensor(0.6784, grad_fn=<MeanBackward0>) l2:  tensor(0.3393, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3572, 0.3605, 0.3804,  ..., 0.3784, 0.2328, 0.3730],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0.,  ..., 1., 0., 0.])
loss:  tensor(0.6832, grad_fn=<MeanBackward0>) l2:  tensor(0.3392, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3841, 0.2120, 0.3923,  ..., 0.2001, 0.2201, 0.1974],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 1.,  ..., 0., 0., 1.])
loss:  tensor(0.6790, grad_fn=<MeanBackward0>) l2:  tensor(0.3391, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4692, 0.2085, 0.3640,  ..., 0.1916, 0.4529, 0.3745],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.6791, grad_fn=<MeanBackward0>) l2:  tensor(0.3390, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3680, 0.4858, 0.5800,  ..., 0.6009, 0.3753, 0.1236],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6752, grad_fn=<MeanBackward0>) l2:  tensor(0.3390, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3009, 0.3733, 0.2119,  ..., 0.3977, 0.4781, 0.3013],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0.,  ..., 1., 1., 0.])
loss:  tensor(0.6708, grad_fn=<MeanBackward0>) l2:  tensor(0.3389, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.1783, 0.3898, 0.2880,  ..., 0.2154, 0.2769, 0.3095],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 0.,  ..., 1., 0., 0.])
loss:  tensor(0.6580, grad_fn=<MeanBackward0>) l2:  tensor(0.3388, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.2162, 0.3867, 0.2867,  ..., 0.1797, 0.2687, 0.1585],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 0., 0.])
loss:  tensor(0.6804, grad_fn=<MeanBackward0>) l2:  tensor(0.3386, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.1156, 0.1736, 0.3699, 0.1665, 0.1736, 0.1620, 0.1489, 0.3699, 0.1489,
        0.3699, 0.1734, 0.2598, 0.3505, 0.2536, 0.1767, 0.3773, 0.2528, 0.5264,
        0.1505, 0.1593, 0.2612, 0.3037, 0.1618, 0.0917, 0.0876, 0.1621, 0.1881,
        0.1707, 0.1621, 0.1621, 0.6587, 0.3841, 0.2905, 0.0851, 0.3841, 0.5191,
        0.5347, 0.5458, 0.3841, 0.1604, 0.1667, 0.0943, 0.3868, 0.1954, 0.2053,
        0.4319, 0.1943, 0.1603, 0.3868, 0.4319, 0.2152, 0.4476, 0.1065, 0.3818,
        0.3826, 0.1984, 0.4256, 0.1544, 0.1802, 0.2542, 0.3810, 0.4227, 0.3823,
        0.1993, 0.3823, 0.3593, 0.2834, 0.1637, 0.5087, 0.4905, 0.2707, 0.2707,
        0.4102, 0.2707, 0.3036, 0.1857, 0.2514, 0.2707, 0.2707, 0.2707, 0.1953,
        0.1707, 0.0968, 0.1738, 0.3134, 0.2682, 0.3871, 0.5172, 0.3871, 0.2901,
        0.3832, 0.2630, 0.4297, 0.2630, 0.1644, 0.2928, 0.3712, 0.4171, 0.4686,
        0.1644, 0.1633, 0.1843, 0.1582, 0.1091, 0.1843, 0.1843, 0.3797, 0.4239,
        0.1582, 0.1066, 0.5284, 0.6898, 0.6501, 0.0697, 0.3750, 0.3493, 0.2263,
        0.1377, 0.5284, 0.2051, 0.1643, 0.1386, 0.0681, 0.0753, 0.2393, 0.3723,
        0.0493, 0.2432, 0.3602, 0.1797, 0.6894, 0.1595, 0.3892, 0.3147, 0.1665,
        0.1595, 0.3892, 0.4033, 0.4084, 0.1595, 0.2085, 0.1695, 0.3982, 0.1695,
        0.0962, 0.3879, 0.3547, 0.1642, 0.1903, 0.1463, 0.1627, 0.5194, 0.4066,
        0.1543, 0.3856, 0.6794, 0.1627, 0.3830, 0.5429, 0.3830, 0.2422, 0.1566,
        0.1848, 0.3184, 0.1848, 0.1676, 0.2817, 0.1049, 0.1607, 0.3838, 0.1459,
        0.4292, 0.0779, 0.4292, 0.3797, 0.2285, 0.1826, 0.4086, 0.2010, 0.1826,
        0.4500, 0.4835, 0.4501, 0.6326, 0.1714, 0.2728, 0.5152, 0.2728, 0.2728,
        0.2728, 0.1731, 0.1650, 0.1650, 0.1650, 0.4072, 0.2668, 0.4072, 0.3671,
        0.1650, 0.1650, 0.4395, 0.1745, 0.1795, 0.3059, 0.3618, 0.5022, 0.2138,
        0.1745, 0.2789, 0.4203, 0.2520, 0.1689, 0.2073, 0.2249, 0.4165, 0.1427,
        0.2520, 0.1765, 0.2520, 0.2180, 0.3936, 0.2150, 0.5516, 0.2031, 0.1948,
        0.3877, 0.1624, 0.6929, 0.5201, 0.3877, 0.3499, 0.5196, 0.3929, 0.3231,
        0.5238, 0.5196, 0.2023, 0.5166, 0.5616, 0.4336, 0.2802, 0.3761, 0.4409,
        0.1678, 0.2564, 0.4040, 0.1520, 0.2564, 0.2566, 0.2564, 0.1473, 0.1473,
        0.4172, 0.3793, 0.3751, 0.1473, 0.1558, 0.6408, 0.1839, 0.0994, 0.4091,
        0.3029, 0.4326, 0.5171, 0.2437, 0.4166, 0.5171, 0.2471, 0.4326, 0.6517,
        0.6538, 0.3810, 0.1896, 0.5219, 0.2918, 0.1800, 0.1536, 0.1911, 0.2352,
        0.3484, 0.3423, 0.2589, 0.3997, 0.5546, 0.1864, 0.2906, 0.6612, 0.3757,
        0.4195, 0.6612, 0.1626, 0.3769, 0.2717, 0.3769, 0.2690, 0.3769, 0.3769,
        0.1644, 0.3769, 0.1626, 0.1354, 0.7021, 0.4112, 0.6570, 0.1354, 0.3618,
        0.1316, 0.4109, 0.3618, 0.3829, 0.1463, 0.1741, 0.2247, 0.2247, 0.2247,
        0.2247, 0.2247, 0.2247, 0.2247, 0.2247, 0.1837, 0.1561, 0.2342, 0.2592,
        0.2021, 0.4159, 0.3370, 0.2738, 0.1504, 0.1837, 0.1657, 0.3518, 0.2278,
        0.4002, 0.3238, 0.1312, 0.1657, 0.1287, 0.1287, 0.1287, 0.1585, 0.3811,
        0.1585, 0.3413, 0.3811, 0.1003, 0.2418, 0.3942, 0.2507, 0.1968, 0.2798,
        0.5683, 0.3979, 0.3976, 0.5222, 0.1761, 0.5216, 0.2598, 0.5200, 0.4559,
        0.5227, 0.6425, 0.1450, 0.2103, 0.5142, 0.3756, 0.4222, 0.3756, 0.3827,
        0.6425, 0.3091, 0.2239, 0.5135, 0.4520, 0.2233, 0.3460, 0.0770, 0.3935,
        0.4209, 0.2239, 0.2499, 0.4927, 0.2499, 0.2499, 0.5365, 0.2499, 0.2499,
        0.2499, 0.2499, 0.2499, 0.0579, 0.7141, 0.3630, 0.3630, 0.5597, 0.2644,
        0.1566, 0.3630, 0.2114, 0.2227, 0.4344, 0.5069, 0.4117, 0.3682, 0.0899,
        0.1833, 0.4117, 0.4117, 0.1475, 0.5142, 0.2586, 0.2448, 0.3627, 0.4644,
        0.1412, 0.3627, 0.3627, 0.2448, 0.1412, 0.1412, 0.3145, 0.3843, 0.1667,
        0.1958, 0.3542, 0.1691, 0.3843, 0.3690, 0.6717, 0.3843, 0.1729, 0.2785,
        0.4010, 0.1701, 0.2200, 0.0935, 0.3878, 0.2077, 0.1989, 0.2662, 0.1270,
        0.5757, 0.5413, 0.3737, 0.3737, 0.1563, 0.5126, 0.4677, 0.3932, 0.3797,
        0.1335, 0.5293, 0.1535, 0.4126, 0.3667, 0.4126, 0.3667, 0.2460, 0.2473,
        0.1335, 0.3880, 0.1945, 0.5180, 0.4330, 0.3880, 0.1614, 0.1614, 0.4101,
        0.0547, 0.1876, 0.4999, 0.2437, 0.4332, 0.1349, 0.1349, 0.1655, 0.4330,
        0.4067, 0.3636, 0.4885, 0.2501, 0.1224, 0.0380, 0.2501, 0.0598, 0.1257,
        0.0598, 0.1449, 0.0651, 0.0598, 0.2258, 0.2258, 0.2317, 0.1843, 0.1430,
        0.0680, 0.1825, 0.1430, 0.2509, 0.1430, 0.3765, 0.3765, 0.1474, 0.3856,
        0.3856, 0.3439, 0.4217, 0.3765, 0.1527, 0.4438, 0.2397, 0.0543, 0.1945,
        0.5225, 0.5223, 0.3810, 0.4104, 0.2000, 0.4251, 0.4423, 0.0803, 0.2496,
        0.3704, 0.2455, 0.5125, 0.0727, 0.3656, 0.2348, 0.3704, 0.5177, 0.2713,
        0.1980, 0.0842, 0.3522, 0.5181, 0.2701, 0.3814, 0.4442, 0.2472, 0.1584,
        0.3881, 0.4310, 0.1932, 0.6784, 0.4000, 0.1823, 0.0652, 0.5419, 0.0609,
        0.1788, 0.0505, 0.4244, 0.2689, 0.3810, 0.3810, 0.1800, 0.1698, 0.1033,
        0.2675, 0.1541, 0.5135, 0.2608, 0.1022, 0.1730, 0.3882, 0.3882, 0.5169,
        0.3882, 0.2079, 0.3422, 0.2581, 0.2412, 0.5210, 0.3569, 0.3756, 0.5611,
        0.7061, 0.2412, 0.2412, 0.3756, 0.3752, 0.3752, 0.5078, 0.3752, 0.4131,
        0.3752, 0.2931, 0.0920, 0.1606, 0.0923, 0.2969, 0.2873, 0.1714, 0.3133,
        0.2543, 0.1714, 0.2079, 0.1714, 0.3353, 0.1714, 0.3705, 0.3879, 0.3879,
        0.3879, 0.3463, 0.1985, 0.2694, 0.2758, 0.2694, 0.1529, 0.0468, 0.2599,
        0.3745, 0.4195, 0.5187, 0.3745, 0.1470, 0.2437, 0.2342, 0.2290, 0.1588,
        0.4005, 0.1944, 0.1536, 0.2531, 0.1588, 0.1803, 0.3830, 0.3830, 0.0836,
        0.4473, 0.5480, 0.2434, 0.1402, 0.1471, 0.5296, 0.1745, 0.2544, 0.2387,
        0.5296, 0.7061, 0.2606, 0.1462, 0.4100, 0.0793, 0.3849, 0.3880, 0.4302,
        0.5539, 0.3849, 0.3972, 0.1490, 0.1217, 0.4039, 0.2316, 0.2172, 0.4274,
        0.3972, 0.6526, 0.2490, 0.6694, 0.3866, 0.6291, 0.2628, 0.3866, 0.5663,
        0.3833, 0.3833, 0.3833, 0.2824, 0.3828, 0.4210, 0.3774, 0.4210, 0.1673,
        0.1561, 0.1529, 0.3828, 0.6451, 0.3828, 0.3710, 0.4088, 0.4177, 0.3744,
        0.4177, 0.1698, 0.0435, 0.2320, 0.1420, 0.0907, 0.2770, 0.2899, 0.3925,
        0.4008, 0.3925, 0.2770, 0.3084, 0.2736, 0.3925, 0.3925, 0.6922, 0.4098,
        0.0422, 0.5036, 0.3631, 0.5144, 0.6486, 0.3930, 0.3631, 0.3620, 0.1668,
        0.3912, 0.1933, 0.1719, 0.1662, 0.5272, 0.1925, 0.4347, 0.1668, 0.3945,
        0.3920, 0.1563, 0.1563, 0.5301, 0.5301, 0.1573, 0.4319, 0.1927, 0.1563,
        0.1563, 0.1603, 0.2537, 0.4101, 0.4190, 0.3771, 0.4011, 0.2020, 0.1611,
        0.1999, 0.1267, 0.5171, 0.2995, 0.1684, 0.1670, 0.0557, 0.3593, 0.6368,
        0.5074, 0.2435, 0.1345, 0.1741, 0.1741, 0.1741, 0.1741, 0.1741, 0.1741,
        0.0974, 0.3948, 0.1741, 0.1741, 0.5757, 0.4339, 0.1605, 0.2525, 0.1590,
        0.5199, 0.2848, 0.3843, 0.1965, 0.2775, 0.4446, 0.1942, 0.5167, 0.5180,
        0.3824, 0.2426, 0.3780, 0.3593, 0.1982, 0.6437, 0.1453, 0.1299, 0.1858,
        0.1461, 0.5874, 0.3708, 0.6575, 0.2295, 0.1453, 0.1706, 0.3935, 0.3264,
        0.4381, 0.2874, 0.3264, 0.2137, 0.3935, 0.4381, 0.3935, 0.3597, 0.3723,
        0.5273, 0.4169, 0.1587, 0.1516, 0.3723, 0.5273, 0.3723, 0.4708, 0.3933,
        0.1555, 0.3751, 0.1555, 0.4184, 0.2645, 0.1555, 0.1808, 0.3751, 0.3751,
        0.1996, 0.2140, 0.3148, 0.2417, 0.2597, 0.2597, 0.1682, 0.2521, 0.3028,
        0.4390, 0.3957, 0.3699, 0.1869, 0.3699, 0.3699, 0.4146, 0.4146, 0.3699,
        0.6508, 0.3699, 0.4146, 0.5167, 0.1562, 0.4326, 0.3865, 0.6451, 0.4326,
        0.6451, 0.6451, 0.1639, 0.2511, 0.4525, 0.1747, 0.3951, 0.3951, 0.2911,
        0.6398, 0.3311, 0.1764, 0.1763, 0.1747], grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0.,
        0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0.,
        0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0.,
        0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1.,
        0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,
        1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.])
loss:  tensor(0.6747, grad_fn=<MeanBackward0>) l2:  tensor(0.3384, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
Iteration 40, loss: 0.6820428654551506
Epoch 1; time 1.0038
epoch 1 validating; auc: 0.5882
Model (checkpoint) saved to output/ml1m/env/ml1m_user_env_lr0.001_reg0.0003.model
epoch 2 training
self.sigmoid(preds):  tensor([0.2852, 0.6559, 0.1772,  ..., 0.1716, 0.3872, 0.2945],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 0.,  ..., 1., 1., 1.])
loss:  tensor(0.6707, grad_fn=<MeanBackward0>) l2:  tensor(0.3383, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.1863, 0.3978, 0.6125,  ..., 0.1911, 0.4133, 0.5483],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 0.,  ..., 1., 0., 1.])
loss:  tensor(0.6734, grad_fn=<MeanBackward0>) l2:  tensor(0.3381, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4155, 0.1586, 0.4699,  ..., 0.2464, 0.4001, 0.4044],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 0., 0., 0.])
loss:  tensor(0.6753, grad_fn=<MeanBackward0>) l2:  tensor(0.3380, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3425, 0.3935, 0.3935,  ..., 0.5273, 0.0964, 0.4603],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6824, grad_fn=<MeanBackward0>) l2:  tensor(0.3378, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4051, 0.8146, 0.5905,  ..., 0.4136, 0.0525, 0.4136],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 0.,  ..., 1., 0., 0.])
loss:  tensor(0.6812, grad_fn=<MeanBackward0>) l2:  tensor(0.3377, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.1675, 0.0267, 0.4932,  ..., 0.4390, 0.5292, 0.1513],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6671, grad_fn=<MeanBackward0>) l2:  tensor(0.3377, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.7567, 0.4243, 0.4243,  ..., 0.1902, 0.5194, 0.1950],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 0.])
loss:  tensor(0.6612, grad_fn=<MeanBackward0>) l2:  tensor(0.3376, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.1537, 0.5388, 0.1611,  ..., 0.5293, 0.1670, 0.2939],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.6769, grad_fn=<MeanBackward0>) l2:  tensor(0.3375, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.1444, 0.1812, 0.5311,  ..., 0.7765, 0.4478, 0.2653],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 0., 0., 0.])
loss:  tensor(0.6790, grad_fn=<MeanBackward0>) l2:  tensor(0.3374, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.1152, 0.2544, 0.4294,  ..., 0.0405, 0.5544, 0.6168],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.6839, grad_fn=<MeanBackward0>) l2:  tensor(0.3374, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
Iteration 10, loss: 0.6752077639102936
self.sigmoid(preds):  tensor([0.6135, 0.0893, 0.0893,  ..., 0.4361, 0.1532, 0.4361],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6746, grad_fn=<MeanBackward0>) l2:  tensor(0.3374, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4369, 0.2142, 0.2719,  ..., 0.1616, 0.3367, 0.2610],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0.,  ..., 0., 1., 0.])
loss:  tensor(0.6760, grad_fn=<MeanBackward0>) l2:  tensor(0.3375, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.2555, 0.4295, 0.4295,  ..., 0.1752, 0.5765, 0.1160],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6743, grad_fn=<MeanBackward0>) l2:  tensor(0.3375, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4340, 0.0712, 0.2236,  ..., 0.5942, 0.4023, 0.4420],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6696, grad_fn=<MeanBackward0>) l2:  tensor(0.3373, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.9159, 0.4346, 0.5803,  ..., 0.4344, 0.3367, 0.3367],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 0.,  ..., 1., 1., 1.])
loss:  tensor(0.6895, grad_fn=<MeanBackward0>) l2:  tensor(0.3371, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4593, 0.1436, 0.1436,  ..., 0.0649, 0.0649, 0.2132],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 1.,  ..., 0., 0., 1.])
loss:  tensor(0.6880, grad_fn=<MeanBackward0>) l2:  tensor(0.3370, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.7058, 0.9281, 0.2311,  ..., 0.4526, 0.6482, 0.4526],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 0.])
loss:  tensor(0.6699, grad_fn=<MeanBackward0>) l2:  tensor(0.3369, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.0930, 0.0158, 0.0894,  ..., 0.6479, 0.8423, 0.6209],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6673, grad_fn=<MeanBackward0>) l2:  tensor(0.3367, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.9131, 0.0727, 0.6511,  ..., 0.1249, 0.3909, 0.3909],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 0.,  ..., 1., 1., 1.])
loss:  tensor(0.6830, grad_fn=<MeanBackward0>) l2:  tensor(0.3365, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.0215, 0.0647, 0.0140,  ..., 0.1119, 0.5919, 0.0940],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0.,  ..., 1., 1., 1.])
loss:  tensor(0.6622, grad_fn=<MeanBackward0>) l2:  tensor(0.3363, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
Iteration 20, loss: 0.6753686219453812
self.sigmoid(preds):  tensor([0.6083, 0.0356, 0.0897,  ..., 0.1238, 0.4559, 0.6178],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0.,  ..., 0., 0., 0.])
loss:  tensor(0.6658, grad_fn=<MeanBackward0>) l2:  tensor(0.3361, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.0670, 0.4224, 0.1017,  ..., 0.4387, 0.6387, 0.4387],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6601, grad_fn=<MeanBackward0>) l2:  tensor(0.3359, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.9366, 0.0488, 0.4689,  ..., 0.1260, 0.8394, 0.4368],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 0.])
loss:  tensor(0.6698, grad_fn=<MeanBackward0>) l2:  tensor(0.3357, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.8720, 0.0522, 0.9399,  ..., 0.4275, 0.1175, 0.7324],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 0.,  ..., 1., 0., 1.])
loss:  tensor(0.6789, grad_fn=<MeanBackward0>) l2:  tensor(0.3354, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.6600, 0.1565, 0.1446,  ..., 0.4271, 0.1595, 0.0388],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0.,  ..., 0., 0., 1.])
loss:  tensor(0.6648, grad_fn=<MeanBackward0>) l2:  tensor(0.3350, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.0654, 0.0140, 0.4177,  ..., 0.9350, 0.2193, 0.4750],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 1., 1., 1.])
loss:  tensor(0.6761, grad_fn=<MeanBackward0>) l2:  tensor(0.3347, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.1712, 0.1356, 0.0615,  ..., 0.1680, 0.0519, 0.4448],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 0., 1.])
loss:  tensor(0.6735, grad_fn=<MeanBackward0>) l2:  tensor(0.3344, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.0139, 0.1152, 0.4326,  ..., 0.6457, 0.9097, 0.5758],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 0.])
loss:  tensor(0.6653, grad_fn=<MeanBackward0>) l2:  tensor(0.3342, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.7549, 0.0636, 0.6215,  ..., 0.0407, 0.1266, 0.0407],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 1.,  ..., 0., 0., 0.])
loss:  tensor(0.6824, grad_fn=<MeanBackward0>) l2:  tensor(0.3338, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.0514, 0.0514, 0.0514,  ..., 0.0978, 0.1038, 0.2418],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 0.,  ..., 1., 0., 0.])
loss:  tensor(0.6661, grad_fn=<MeanBackward0>) l2:  tensor(0.3334, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
Iteration 30, loss: 0.6737059573332469
self.sigmoid(preds):  tensor([0.6772, 0.4775, 0.2557,  ..., 0.0624, 0.2470, 0.5111],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 0.,  ..., 1., 1., 0.])
loss:  tensor(0.6666, grad_fn=<MeanBackward0>) l2:  tensor(0.3331, grad_fn=<AddBackward0>) l2*coef tensor(9.9933e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.6345, 0.0271, 0.8039,  ..., 0.8719, 0.1200, 0.0314],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6646, grad_fn=<MeanBackward0>) l2:  tensor(0.3327, grad_fn=<AddBackward0>) l2*coef tensor(9.9822e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4725, 0.7654, 0.4725,  ..., 0.3498, 0.8957, 0.0957],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 1.,  ..., 1., 0., 1.])
loss:  tensor(0.6762, grad_fn=<MeanBackward0>) l2:  tensor(0.3323, grad_fn=<AddBackward0>) l2*coef tensor(9.9687e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3904, 0.5001, 0.6990,  ..., 0.3273, 0.0396, 0.4495],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 0., 0., 0.])
loss:  tensor(0.6699, grad_fn=<MeanBackward0>) l2:  tensor(0.3318, grad_fn=<AddBackward0>) l2*coef tensor(9.9543e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.8855, 0.0143, 0.4797,  ..., 0.5153, 0.3436, 0.1372],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 0., 0.])
loss:  tensor(0.6645, grad_fn=<MeanBackward0>) l2:  tensor(0.3314, grad_fn=<AddBackward0>) l2*coef tensor(9.9423e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.7431, 0.0110, 0.3229,  ..., 0.0492, 0.2019, 0.8724],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 0.])
loss:  tensor(0.6729, grad_fn=<MeanBackward0>) l2:  tensor(0.3310, grad_fn=<AddBackward0>) l2*coef tensor(9.9290e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.9684, 0.4059, 0.1122,  ..., 0.9611, 0.1641, 0.3120],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0.,  ..., 1., 1., 0.])
loss:  tensor(0.6687, grad_fn=<MeanBackward0>) l2:  tensor(0.3305, grad_fn=<AddBackward0>) l2*coef tensor(9.9146e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.0616, 0.0616, 0.1176,  ..., 0.3003, 0.5104, 0.5104],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 0., 1., 1.])
loss:  tensor(0.6821, grad_fn=<MeanBackward0>) l2:  tensor(0.3301, grad_fn=<AddBackward0>) l2*coef tensor(9.9023e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.0234, 0.7987, 0.1434,  ..., 0.0336, 0.4130, 0.3784],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 1., 0., 1.])
loss:  tensor(0.6862, grad_fn=<MeanBackward0>) l2:  tensor(0.3298, grad_fn=<AddBackward0>) l2*coef tensor(9.8934e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.9652, 0.2656, 0.0067, 0.1821, 0.1615, 0.1639, 0.3744, 0.0736, 0.0300,
        0.2735, 0.0074, 0.0616, 0.1311, 0.1365, 0.0427, 0.1377, 0.5043, 0.0427,
        0.1377, 0.0616, 0.7434, 0.0243, 0.1648, 0.1868, 0.5682, 0.0429, 0.1551,
        0.0736, 0.0034, 0.0728, 0.2426, 0.8904, 0.7656, 0.2949, 0.2983, 0.7444,
        0.0711, 0.1226, 0.2083, 0.5273, 0.5167, 0.2213, 0.0147, 0.5167, 0.0981,
        0.3921, 0.2154, 0.8237, 0.2807, 0.6927, 0.5173, 0.4344, 0.1147, 0.1038,
        0.3451, 0.0748, 0.8764, 0.5173, 0.5173, 0.3486, 0.5228, 0.2866, 0.2253,
        0.8532, 0.9543, 0.4953, 0.6931, 0.0829, 0.7413, 0.9064, 0.2283, 0.0647,
        0.0373, 0.1007, 0.1453, 0.0436, 0.0717, 0.2129, 0.0102, 0.0235, 0.3857,
        0.7420, 0.1748, 0.0685, 0.0349, 0.1210, 0.1932, 0.6091, 0.0523, 0.0919,
        0.1380, 0.3877, 0.4649, 0.7173, 0.4963, 0.0857, 0.5583, 0.4963, 0.0607,
        0.0734, 0.1463, 0.5591, 0.3119, 0.3021, 0.9441, 0.3119, 0.7851, 0.1038,
        0.4690, 0.4920, 0.6109, 0.4140, 0.5251, 0.9082, 0.0871, 0.7289, 0.3980,
        0.2981, 0.7010, 0.8626, 0.0758, 0.1118, 0.5005, 0.8244, 0.0563, 0.5005,
        0.1097, 0.8687, 0.4738, 0.5005, 0.6487, 0.0982, 0.0446, 0.4897, 0.3873,
        0.0646, 0.1388, 0.7872, 0.5864, 0.0751, 0.4696, 0.1240, 0.7002, 0.9484,
        0.1972, 0.7188, 0.0255, 0.0860, 0.8808, 0.8808, 0.7426, 0.0519, 0.0807,
        0.4393, 0.2402, 0.6146, 0.5335, 0.7293, 0.2152, 0.0853, 0.0989, 0.0915,
        0.1487, 0.1399, 0.1785, 0.0915, 0.3099, 0.1785, 0.1608, 0.3099, 0.0490,
        0.1193, 0.3532, 0.1193, 0.3532, 0.4059, 0.0872, 0.2680, 0.6173, 0.2601,
        0.0648, 0.6955, 0.3860, 0.6955, 0.1028, 0.8770, 0.0904, 0.4915, 0.6955,
        0.4915, 0.0733, 0.8666, 0.0516, 0.2088, 0.5750, 0.1515, 0.7775, 0.1889,
        0.1889, 0.1889, 0.1137, 0.3276, 0.1224, 0.0187, 0.0704, 0.9649, 0.5991,
        0.0348, 0.6665, 0.3229, 0.3372, 0.5104, 0.5104, 0.6132, 0.7445, 0.7327,
        0.5104, 0.8282, 0.0454, 0.1804, 0.0462, 0.9672, 0.7364, 0.0113, 0.5154,
        0.8472, 0.7364, 0.9181, 0.1668, 0.1793, 0.0753, 0.8855, 0.5189, 0.0753,
        0.5189, 0.5189, 0.4182, 0.2956, 0.5189, 0.7516, 0.5158, 0.2666, 0.0519,
        0.5158, 0.5158, 0.8666, 0.0519, 0.8189, 0.2034, 0.5158, 0.8357, 0.0877,
        0.5085, 0.7735, 0.3774, 0.5085, 0.5085, 0.1689, 0.8192, 0.7668, 0.5257,
        0.0540, 0.1993, 0.1068, 0.0300, 0.1929, 0.0540, 0.2936, 0.5304, 0.0903,
        0.4921, 0.4533, 0.0537, 0.1034, 0.7042, 0.8929, 0.1631, 0.0537, 0.0148,
        0.8929, 0.0677, 0.4430, 0.5381, 0.0677, 0.1073, 0.7385, 0.0677, 0.6855,
        0.9581, 0.5381, 0.3963, 0.5100, 0.7119, 0.2620, 0.0045, 0.1193, 0.7828,
        0.1040, 0.1193, 0.7256, 0.0943, 0.0595, 0.0595, 0.0595, 0.0386, 0.5176,
        0.0595, 0.0595, 0.0397, 0.0595, 0.0428, 0.3707, 0.0292, 0.2629, 0.6274,
        0.0428, 0.0428, 0.7108, 0.0792, 0.3080, 0.0417, 0.0068, 0.2843, 0.1418,
        0.0905, 0.0436, 0.3764, 0.0389, 0.5277, 0.8240, 0.0517, 0.4820, 0.9034,
        0.0233, 0.0454, 0.6582, 0.1736, 0.6395, 0.7564, 0.1342, 0.9158, 0.0435,
        0.0435, 0.0208, 0.0435, 0.0435, 0.0057, 0.0435, 0.0681, 0.0356, 0.0590,
        0.4066, 0.7627, 0.3442, 0.0816, 0.9556, 0.8262, 0.0590, 0.0663, 0.1169,
        0.1482, 0.7144, 0.2030, 0.7117, 0.6699, 0.3213, 0.3213, 0.3836, 0.1001,
        0.1054, 0.9669, 0.8709, 0.0545, 0.0472, 0.6914, 0.2805, 0.1147, 0.1147,
        0.3920, 0.0734, 0.0672, 0.4981, 0.9440, 0.4981, 0.4615, 0.4981, 0.6968,
        0.6968, 0.4981, 0.4981, 0.0990, 0.8809, 0.5112, 0.7924, 0.8809, 0.4157,
        0.0428, 0.4157, 0.1897, 0.0908, 0.1787, 0.0383, 0.0383, 0.1001, 0.5936,
        0.0626, 0.0949, 0.1876, 0.1787, 0.3885, 0.0570, 0.8227, 0.7796, 0.6531,
        0.3829, 0.6171, 0.9666, 0.8227, 0.0868, 0.0368, 0.7020, 0.0659, 0.3137,
        0.2181, 0.6155, 0.0473, 0.2842, 0.0500, 0.6703, 0.1047, 0.9168, 0.5368,
        0.1951, 0.0987, 0.3056, 0.0569, 0.7508, 0.5083, 0.5368, 0.1312, 0.0450,
        0.5336, 0.1406, 0.0747, 0.7272, 0.1406, 0.5286, 0.2221, 0.4105, 0.0644,
        0.2165, 0.4239, 0.5090, 0.9552, 0.2042, 0.7389, 0.1082, 0.0491, 0.0706,
        0.0935, 0.0010, 0.3958, 0.0147, 0.0435, 0.1305, 0.0019, 0.5111, 0.0285,
        0.0435, 0.2498, 0.4911, 0.9501, 0.9426, 0.4911, 0.1792, 0.7880, 0.0084,
        0.1103, 0.6942, 0.6942, 0.5210, 0.3626, 0.4234, 0.2794, 0.4091, 0.5210,
        0.2794, 0.2794, 0.2794, 0.5210, 0.9037, 0.0202, 0.0681, 0.0476, 0.4287,
        0.0681, 0.3171, 0.0476, 0.7406, 0.1156, 0.6307, 0.7072, 0.8271, 0.1253,
        0.8271, 0.0656, 0.0794, 0.1952, 0.0842, 0.2220, 0.0514, 0.0255, 0.1196,
        0.2536, 0.0306, 0.1019, 0.1196, 0.0514, 0.0125, 0.0514, 0.5324, 0.1073,
        0.4353, 0.0074, 0.1111, 0.4166, 0.0444, 0.5457, 0.2230, 0.2008, 0.0639,
        0.2523, 0.7319, 0.3938, 0.7355, 0.8303, 0.0536, 0.7016, 0.0459, 0.0459,
        0.4585, 0.0472, 0.0472, 0.0472, 0.2825, 0.0075, 0.0499, 0.0075, 0.4585,
        0.0216, 0.4760, 0.1728, 0.1728, 0.1728, 0.1728, 0.6913, 0.1728, 0.0887,
        0.0504, 0.0504, 0.4643, 0.1059, 0.1059, 0.0745, 0.3395, 0.4643, 0.1754,
        0.0745, 0.2764, 0.0060, 0.5174, 0.5174, 0.5174, 0.5174, 0.7402, 0.1421,
        0.5174, 0.7579, 0.2802, 0.8939, 0.4877, 0.0434, 0.7332, 0.4877, 0.3933,
        0.4877, 0.3933, 0.4877, 0.0434, 0.1065, 0.9579, 0.2466, 0.7562, 0.6148,
        0.2466, 0.7999, 0.1525, 0.0706, 0.7499, 0.1525, 0.4277, 0.3138, 0.5293,
        0.5783, 0.5293, 0.7248, 0.8882, 0.2987, 0.5293, 0.5293, 0.3973, 0.5293,
        0.5293, 0.5640, 0.5293, 0.5293, 0.1345, 0.9679, 0.5293, 0.5293, 0.0967,
        0.5160, 0.8127, 0.9699, 0.0557, 0.9081, 0.0398, 0.2064, 0.5160, 0.7283,
        0.2014, 0.6636, 0.8440, 0.3678, 0.4959, 0.7174, 0.6636, 0.7071, 0.4959,
        0.0164, 0.5258, 0.0596, 0.3951, 0.0596, 0.9124, 0.0596, 0.5057, 0.0596,
        0.4210, 0.0394, 0.2856, 0.3747, 0.7156, 0.1012, 0.4903, 0.1012, 0.0413,
        0.7156, 0.3973, 0.0140, 0.2770, 0.5274, 0.2899, 0.7749, 0.7263, 0.2899,
        0.5274, 0.5274, 0.4253, 0.5274, 0.0204, 0.8041, 0.1076, 0.0057, 0.0363,
        0.0291, 0.0435, 0.7441, 0.0831, 0.0158, 0.6590, 0.9105, 0.0419, 0.8116,
        0.7463, 0.2028, 0.9592, 0.2863, 0.0692, 0.0394, 0.7061, 0.0181, 0.4817,
        0.4817, 0.3768, 0.6725, 0.4817, 0.4817, 0.4817, 0.0385, 0.5111, 0.0422,
        0.0101, 0.4335, 0.0021, 0.0796, 0.2374, 0.8355, 0.8355, 0.5356, 0.0439,
        0.6714, 0.6881, 0.1884, 0.2654, 0.4994, 0.0381, 0.3340, 0.0883, 0.0624,
        0.0283, 0.5170, 0.0283, 0.2494, 0.5170, 0.0719, 0.0394, 0.5697, 0.5170,
        0.0018, 0.1388, 0.3218, 0.0347, 0.7328, 0.2750, 0.9036, 0.1049, 0.3218,
        0.0159, 0.2179, 0.0078, 0.6867, 0.5155, 0.0533, 0.0533, 0.0138, 0.5155,
        0.0077, 0.0580, 0.1271, 0.9526, 0.7552, 0.0437, 0.0241, 0.0706, 0.4009,
        0.0624, 0.0624, 0.7360, 0.5116, 0.4961, 0.0689, 0.0740, 0.4961, 0.6912,
        0.2833, 0.2861, 0.4961, 0.1537, 0.7808, 0.0923, 0.2664, 0.1653, 0.5354,
        0.0538, 0.8468, 0.0440, 0.7353, 0.9186, 0.7007, 0.0478, 0.3613, 0.0755,
        0.0755, 0.2041, 0.0855, 0.8895, 0.3741, 0.3955, 0.1912, 0.4005, 0.0880,
        0.0880, 0.0880, 0.0880, 0.1990, 0.0880, 0.1744, 0.2587, 0.0594, 0.7867,
        0.0516, 0.0076, 0.4926, 0.4926, 0.0721, 0.8500, 0.0321, 0.4926, 0.7397,
        0.4882, 0.0752, 0.4882, 0.4882, 0.4882, 0.3731, 0.0653, 0.6899, 0.1078,
        0.0653, 0.1207, 0.0920, 0.0015, 0.1590, 0.0936, 0.0920, 0.0078, 0.0525,
        0.1222, 0.1879, 0.0494, 0.3462, 0.1125, 0.4908, 0.0473, 0.0571, 0.0473,
        0.6942, 0.0494, 0.3462, 0.7886, 0.1294, 0.4069, 0.3481, 0.6748, 0.5094,
        0.0783, 0.0783, 0.5545, 0.8713, 0.6122, 0.8965, 0.3551, 0.2023, 0.5125,
        0.0320, 0.1308, 0.0594, 0.7632, 0.2139], grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0.,
        0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0.,
        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0.,
        1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0.,
        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0.,
        1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.])
loss:  tensor(0.6570, grad_fn=<MeanBackward0>) l2:  tensor(0.3295, grad_fn=<AddBackward0>) l2*coef tensor(9.8861e-05, grad_fn=<MulBackward0>)
Iteration 40, loss: 0.6730229422450066
Epoch 2; time 1.0476
epoch 2 validating; auc: 0.5938
Model (checkpoint) saved to output/ml1m/env/ml1m_user_env_lr0.001_reg0.0003.model

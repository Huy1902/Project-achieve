Namespace(model='ML1MUserResponse', reader='ML1MDataReader')
Namespace(seed=19, batch_size=128, lr=0.0003, epoch=2, model_path='output/ml1m/env/ml1m_user_env_lr0.0003_reg0.0003.model', loss='bce', l2_coef=0.0003, feature_dim=16, attn_n_head=2, hidden_dims=[256], dropout_rate=0.2, train_file='dataset/ml1m/ml1m_b_train.csv', val_file='dataset/ml1m/ml1m_b_test.csv', test_file='', n_worker=0, data_separator='@', user_meta_file='dataset/ml1m/user_info.npy', item_meta_file='dataset/ml1m/item_info.npy', max_seq_len=50, meta_data_separator=' ')
init ml1m reader
Loading data filesLoad item meta data
{'length': 5078, 'n_item': 1682, 'item_vec_size': 19, 'user_portrait_len': 24, 'max_seq_len': 50}
{'length': 5078, 'n_item': 1682, 'item_vec_size': 19, 'user_portrait_len': 24, 'max_seq_len': 50}
epoch 1 training
self.sigmoid(preds):  tensor([0.4950, 0.4985, 0.4985,  ..., 0.5107, 0.5021, 0.5073],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.6731, grad_fn=<MeanBackward0>) l2:  tensor(0.3466, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4995, 0.5087, 0.4963,  ..., 0.5290, 0.5126, 0.4862],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 0., 1.])
loss:  tensor(0.6990, grad_fn=<MeanBackward0>) l2:  tensor(0.3464, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.5004, 0.5006, 0.4900,  ..., 0.4979, 0.4797, 0.5100],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 1., 1., 0.])
loss:  tensor(0.7200, grad_fn=<MeanBackward0>) l2:  tensor(0.3462, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.5224, 0.5112, 0.4957,  ..., 0.4777, 0.4955, 0.4863],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6941, grad_fn=<MeanBackward0>) l2:  tensor(0.3460, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.5114, 0.4979, 0.4687,  ..., 0.4743, 0.5002, 0.4821],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 0.])
loss:  tensor(0.6825, grad_fn=<MeanBackward0>) l2:  tensor(0.3458, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.5005, 0.4785, 0.4956,  ..., 0.4954, 0.4962, 0.4925],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 0.,  ..., 1., 0., 0.])
loss:  tensor(0.6795, grad_fn=<MeanBackward0>) l2:  tensor(0.3456, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.5255, 0.5252, 0.4962,  ..., 0.5080, 0.4941, 0.5075],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 1.,  ..., 1., 1., 0.])
loss:  tensor(0.7080, grad_fn=<MeanBackward0>) l2:  tensor(0.3455, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4895, 0.5041, 0.4934,  ..., 0.4852, 0.4974, 0.4974],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0.,  ..., 0., 1., 1.])
loss:  tensor(0.6713, grad_fn=<MeanBackward0>) l2:  tensor(0.3453, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4883, 0.4996, 0.4883,  ..., 0.4935, 0.4902, 0.4874],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.6926, grad_fn=<MeanBackward0>) l2:  tensor(0.3451, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.5016, 0.4867, 0.4867,  ..., 0.4780, 0.4901, 0.4810],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0.,  ..., 0., 0., 0.])
loss:  tensor(0.6900, grad_fn=<MeanBackward0>) l2:  tensor(0.3450, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
Iteration 10, loss: 0.6911068856716156
self.sigmoid(preds):  tensor([0.4690, 0.4974, 0.4638,  ..., 0.5039, 0.4731, 0.4889],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 0., 0., 1.])
loss:  tensor(0.6768, grad_fn=<MeanBackward0>) l2:  tensor(0.3448, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4791, 0.4857, 0.4811,  ..., 0.4699, 0.4789, 0.4710],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 0.,  ..., 1., 0., 1.])
loss:  tensor(0.6948, grad_fn=<MeanBackward0>) l2:  tensor(0.3447, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4992, 0.5050, 0.5014,  ..., 0.4958, 0.4907, 0.4766],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 0., 1.])
loss:  tensor(0.6848, grad_fn=<MeanBackward0>) l2:  tensor(0.3445, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4954, 0.4722, 0.4968,  ..., 0.4834, 0.4638, 0.4925],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.6902, grad_fn=<MeanBackward0>) l2:  tensor(0.3444, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.5015, 0.4967, 0.4988,  ..., 0.4601, 0.4781, 0.4798],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.7075, grad_fn=<MeanBackward0>) l2:  tensor(0.3442, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4794, 0.4847, 0.5079,  ..., 0.4956, 0.4784, 0.4450],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.6649, grad_fn=<MeanBackward0>) l2:  tensor(0.3441, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4618, 0.4817, 0.4690,  ..., 0.4939, 0.4741, 0.4831],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 0.,  ..., 1., 1., 1.])
loss:  tensor(0.6859, grad_fn=<MeanBackward0>) l2:  tensor(0.3440, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4758, 0.4772, 0.4855,  ..., 0.4989, 0.4749, 0.4749],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 0., 0.])
loss:  tensor(0.6877, grad_fn=<MeanBackward0>) l2:  tensor(0.3438, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4674, 0.5037, 0.4791,  ..., 0.4819, 0.4819, 0.4773],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.6959, grad_fn=<MeanBackward0>) l2:  tensor(0.3437, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4915, 0.4527, 0.4882,  ..., 0.4890, 0.4740, 0.4774],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.6814, grad_fn=<MeanBackward0>) l2:  tensor(0.3436, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
Iteration 20, loss: 0.6890979677438736
self.sigmoid(preds):  tensor([0.4776, 0.4752, 0.4776,  ..., 0.4671, 0.4573, 0.4762],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 1.,  ..., 1., 0., 1.])
loss:  tensor(0.6949, grad_fn=<MeanBackward0>) l2:  tensor(0.3435, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4775, 0.4669, 0.4821,  ..., 0.4710, 0.4758, 0.4978],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 1., 0., 1.])
loss:  tensor(0.6856, grad_fn=<MeanBackward0>) l2:  tensor(0.3433, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4835, 0.4681, 0.4681,  ..., 0.4683, 0.4496, 0.4683],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 0., 1.])
loss:  tensor(0.6749, grad_fn=<MeanBackward0>) l2:  tensor(0.3432, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4736, 0.4736, 0.4738,  ..., 0.4800, 0.4677, 0.4677],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 0.,  ..., 1., 1., 1.])
loss:  tensor(0.6854, grad_fn=<MeanBackward0>) l2:  tensor(0.3431, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4612, 0.4606, 0.4614,  ..., 0.4684, 0.4700, 0.4525],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 1., 1., 1.])
loss:  tensor(0.6898, grad_fn=<MeanBackward0>) l2:  tensor(0.3430, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4574, 0.4725, 0.4725,  ..., 0.5132, 0.4627, 0.4627],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 0.])
loss:  tensor(0.6937, grad_fn=<MeanBackward0>) l2:  tensor(0.3429, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4812, 0.4209, 0.4605,  ..., 0.4638, 0.4436, 0.4961],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 0., 1.])
loss:  tensor(0.6709, grad_fn=<MeanBackward0>) l2:  tensor(0.3428, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4640, 0.4543, 0.4533,  ..., 0.4992, 0.4817, 0.4652],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 0., 1., 1.])
loss:  tensor(0.6939, grad_fn=<MeanBackward0>) l2:  tensor(0.3428, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4748, 0.4585, 0.4752,  ..., 0.4591, 0.4635, 0.4505],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 1.,  ..., 1., 0., 0.])
loss:  tensor(0.6821, grad_fn=<MeanBackward0>) l2:  tensor(0.3427, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4371, 0.4412, 0.4258,  ..., 0.4595, 0.4708, 0.4287],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 0., 0., 1.])
loss:  tensor(0.6664, grad_fn=<MeanBackward0>) l2:  tensor(0.3426, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
Iteration 30, loss: 0.6873522738615672
self.sigmoid(preds):  tensor([0.4396, 0.4577, 0.4845,  ..., 0.4500, 0.4394, 0.4621],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6771, grad_fn=<MeanBackward0>) l2:  tensor(0.3425, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4612, 0.4357, 0.4569,  ..., 0.4495, 0.4345, 0.4460],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 1., 1., 1.])
loss:  tensor(0.6837, grad_fn=<MeanBackward0>) l2:  tensor(0.3424, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4481, 0.4586, 0.4739,  ..., 0.4812, 0.4377, 0.4647],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0.,  ..., 1., 0., 0.])
loss:  tensor(0.6946, grad_fn=<MeanBackward0>) l2:  tensor(0.3423, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4577, 0.4459, 0.4661,  ..., 0.4267, 0.4522, 0.4335],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 1.,  ..., 0., 0., 1.])
loss:  tensor(0.6887, grad_fn=<MeanBackward0>) l2:  tensor(0.3423, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4821, 0.4357, 0.4539,  ..., 0.4417, 0.4660, 0.4525],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.6887, grad_fn=<MeanBackward0>) l2:  tensor(0.3422, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4857, 0.5028, 0.4964,  ..., 0.4987, 0.4634, 0.4051],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6801, grad_fn=<MeanBackward0>) l2:  tensor(0.3421, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4609, 0.4594, 0.4420,  ..., 0.4880, 0.4766, 0.4729],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0.,  ..., 1., 1., 0.])
loss:  tensor(0.6786, grad_fn=<MeanBackward0>) l2:  tensor(0.3421, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4602, 0.4460, 0.4647,  ..., 0.4426, 0.4486, 0.4681],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 0.,  ..., 1., 0., 0.])
loss:  tensor(0.6586, grad_fn=<MeanBackward0>) l2:  tensor(0.3420, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4457, 0.4551, 0.4381,  ..., 0.4311, 0.4385, 0.4382],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 0., 0.])
loss:  tensor(0.6941, grad_fn=<MeanBackward0>) l2:  tensor(0.3419, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3861, 0.4256, 0.4453, 0.4118, 0.4256, 0.4259, 0.4287, 0.4453, 0.4287,
        0.4453, 0.4257, 0.4425, 0.4734, 0.4565, 0.4177, 0.4516, 0.4659, 0.4979,
        0.4190, 0.4030, 0.4658, 0.4199, 0.4170, 0.3853, 0.4089, 0.4306, 0.4167,
        0.4141, 0.4306, 0.4306, 0.4974, 0.4525, 0.4584, 0.3893, 0.4525, 0.4864,
        0.4764, 0.4912, 0.4525, 0.4219, 0.4380, 0.3949, 0.4562, 0.4239, 0.4325,
        0.4565, 0.4384, 0.4131, 0.4562, 0.4565, 0.4139, 0.4633, 0.4214, 0.4490,
        0.4537, 0.4288, 0.4464, 0.4151, 0.4266, 0.4281, 0.4540, 0.4480, 0.4503,
        0.4326, 0.4503, 0.4739, 0.4514, 0.4181, 0.4864, 0.4887, 0.4678, 0.4678,
        0.4860, 0.4678, 0.4655, 0.4617, 0.4527, 0.4678, 0.4678, 0.4678, 0.4282,
        0.4313, 0.4136, 0.4228, 0.4416, 0.4317, 0.4515, 0.4852, 0.4515, 0.4513,
        0.4521, 0.4683, 0.4507, 0.4683, 0.4352, 0.4548, 0.4610, 0.4727, 0.4636,
        0.4352, 0.4217, 0.4239, 0.4254, 0.4148, 0.4239, 0.4239, 0.4488, 0.4473,
        0.4254, 0.4005, 0.4693, 0.4846, 0.4881, 0.3748, 0.4478, 0.4441, 0.4528,
        0.4071, 0.4693, 0.4568, 0.4220, 0.4239, 0.3965, 0.3819, 0.4276, 0.4497,
        0.3598, 0.4642, 0.4358, 0.4199, 0.4916, 0.4256, 0.4513, 0.4215, 0.4186,
        0.4256, 0.4513, 0.4958, 0.4617, 0.4256, 0.4351, 0.4269, 0.4662, 0.4269,
        0.3958, 0.4535, 0.4706, 0.4280, 0.4244, 0.4354, 0.4301, 0.4666, 0.4569,
        0.4139, 0.4569, 0.4829, 0.4301, 0.4503, 0.4836, 0.4503, 0.4662, 0.4364,
        0.4357, 0.4542, 0.4357, 0.4464, 0.4503, 0.4211, 0.4251, 0.4548, 0.4053,
        0.4526, 0.4070, 0.4526, 0.4515, 0.4293, 0.4345, 0.4612, 0.4052, 0.4345,
        0.4783, 0.4809, 0.4741, 0.4923, 0.4231, 0.4693, 0.4878, 0.4693, 0.4693,
        0.4693, 0.4235, 0.4171, 0.4171, 0.4171, 0.4373, 0.4320, 0.4373, 0.4444,
        0.4171, 0.4171, 0.4646, 0.4309, 0.4255, 0.4607, 0.4581, 0.4619, 0.4087,
        0.4309, 0.4381, 0.4474, 0.4369, 0.4275, 0.4292, 0.4578, 0.4643, 0.4003,
        0.4369, 0.4245, 0.4369, 0.4089, 0.4627, 0.4545, 0.4894, 0.4218, 0.4366,
        0.4546, 0.4193, 0.4967, 0.4876, 0.4546, 0.4574, 0.4688, 0.4608, 0.4504,
        0.4965, 0.4688, 0.4245, 0.4858, 0.4850, 0.4547, 0.4504, 0.4557, 0.4668,
        0.4413, 0.4664, 0.4789, 0.4185, 0.4664, 0.4717, 0.4664, 0.4215, 0.4215,
        0.4441, 0.4567, 0.4486, 0.4215, 0.4193, 0.4876, 0.4361, 0.4097, 0.4437,
        0.4627, 0.4528, 0.4849, 0.4599, 0.4672, 0.4849, 0.4502, 0.4528, 0.4982,
        0.4938, 0.4524, 0.4305, 0.4939, 0.4539, 0.4176, 0.4311, 0.4201, 0.4342,
        0.4761, 0.4705, 0.4235, 0.4803, 0.4990, 0.4418, 0.4664, 0.4992, 0.4460,
        0.4407, 0.4992, 0.4309, 0.4497, 0.4287, 0.4497, 0.4449, 0.4497, 0.4497,
        0.4149, 0.4497, 0.4309, 0.4235, 0.4909, 0.4523, 0.4908, 0.4235, 0.4436,
        0.4079, 0.4437, 0.4436, 0.4590, 0.4297, 0.4324, 0.4292, 0.4292, 0.4292,
        0.4292, 0.4292, 0.4292, 0.4292, 0.4292, 0.4342, 0.4348, 0.4341, 0.4710,
        0.4552, 0.4690, 0.4642, 0.4511, 0.4213, 0.4342, 0.4332, 0.4356, 0.4520,
        0.4357, 0.4540, 0.4079, 0.4332, 0.4173, 0.4173, 0.4173, 0.4336, 0.4593,
        0.4336, 0.4563, 0.4593, 0.3938, 0.4415, 0.4734, 0.4270, 0.4274, 0.4731,
        0.4922, 0.4593, 0.4569, 0.4679, 0.4188, 0.4895, 0.4479, 0.4863, 0.4684,
        0.4731, 0.4899, 0.4122, 0.4625, 0.4623, 0.4491, 0.4495, 0.4491, 0.4603,
        0.4899, 0.4537, 0.4498, 0.4937, 0.4774, 0.4280, 0.4656, 0.3917, 0.4593,
        0.4749, 0.4498, 0.4424, 0.4825, 0.4424, 0.4424, 0.4798, 0.4424, 0.4424,
        0.4424, 0.4424, 0.4424, 0.3671, 0.4945, 0.4421, 0.4421, 0.4907, 0.4376,
        0.4193, 0.4421, 0.4520, 0.4372, 0.4608, 0.4563, 0.4397, 0.4433, 0.3962,
        0.4203, 0.4397, 0.4397, 0.4244, 0.4891, 0.4437, 0.4302, 0.4416, 0.4638,
        0.4172, 0.4416, 0.4416, 0.4302, 0.4172, 0.4172, 0.4523, 0.4557, 0.4363,
        0.4401, 0.4746, 0.4247, 0.4557, 0.4593, 0.4881, 0.4557, 0.4408, 0.4330,
        0.4590, 0.4231, 0.4226, 0.4155, 0.4563, 0.4256, 0.4257, 0.4332, 0.4075,
        0.4932, 0.4812, 0.4555, 0.4555, 0.4173, 0.4809, 0.4615, 0.4825, 0.4617,
        0.4153, 0.4921, 0.4544, 0.4360, 0.4416, 0.4360, 0.4416, 0.4369, 0.4326,
        0.4153, 0.4493, 0.4223, 0.4838, 0.4470, 0.4493, 0.4299, 0.4299, 0.4604,
        0.3721, 0.4121, 0.4956, 0.4689, 0.4604, 0.4195, 0.4195, 0.4229, 0.4659,
        0.4382, 0.4428, 0.4798, 0.4253, 0.4006, 0.3716, 0.4253, 0.3915, 0.4185,
        0.3915, 0.4232, 0.4074, 0.3915, 0.4392, 0.4392, 0.4435, 0.4203, 0.4249,
        0.3790, 0.4313, 0.4249, 0.4364, 0.4249, 0.4499, 0.4499, 0.4277, 0.4626,
        0.4626, 0.4665, 0.4464, 0.4499, 0.4348, 0.4690, 0.4361, 0.3816, 0.4439,
        0.4700, 0.4956, 0.4516, 0.4627, 0.4303, 0.4499, 0.4662, 0.3845, 0.4308,
        0.4443, 0.4223, 0.4861, 0.3961, 0.4455, 0.4454, 0.4443, 0.4849, 0.4479,
        0.4238, 0.4073, 0.4710, 0.4920, 0.4420, 0.4510, 0.4664, 0.4554, 0.4272,
        0.4522, 0.4505, 0.4273, 0.4900, 0.4665, 0.4245, 0.3918, 0.4871, 0.3807,
        0.4275, 0.3767, 0.4685, 0.4519, 0.4536, 0.4536, 0.4293, 0.4588, 0.4157,
        0.4470, 0.4306, 0.4698, 0.4695, 0.4253, 0.4377, 0.4580, 0.4580, 0.4900,
        0.4580, 0.4377, 0.4518, 0.4404, 0.4246, 0.4922, 0.4580, 0.4486, 0.4942,
        0.4953, 0.4246, 0.4246, 0.4486, 0.4498, 0.4498, 0.4604, 0.4498, 0.4444,
        0.4498, 0.4436, 0.4189, 0.4334, 0.3946, 0.4574, 0.4399, 0.4328, 0.4679,
        0.4631, 0.4328, 0.4358, 0.4328, 0.4561, 0.4328, 0.4556, 0.4520, 0.4520,
        0.4520, 0.4702, 0.4236, 0.4469, 0.4477, 0.4469, 0.4187, 0.3789, 0.4447,
        0.4503, 0.4478, 0.4923, 0.4503, 0.4296, 0.4280, 0.4636, 0.4336, 0.4297,
        0.4634, 0.3999, 0.4112, 0.4271, 0.4297, 0.4104, 0.4568, 0.4568, 0.4060,
        0.4711, 0.4887, 0.4289, 0.4217, 0.4189, 0.4998, 0.4175, 0.4766, 0.4530,
        0.4998, 0.5028, 0.4779, 0.4218, 0.4734, 0.3804, 0.4566, 0.4630, 0.4534,
        0.4909, 0.4566, 0.4714, 0.4261, 0.4091, 0.4680, 0.4387, 0.4733, 0.4520,
        0.4714, 0.4945, 0.4608, 0.4917, 0.4584, 0.4916, 0.4333, 0.4584, 0.4985,
        0.4606, 0.4606, 0.4606, 0.4548, 0.4589, 0.4478, 0.4504, 0.4478, 0.4568,
        0.4213, 0.4299, 0.4589, 0.4891, 0.4589, 0.4468, 0.4646, 0.4446, 0.4543,
        0.4446, 0.4260, 0.3705, 0.4505, 0.4127, 0.3941, 0.4369, 0.4527, 0.4585,
        0.4663, 0.4585, 0.4369, 0.4332, 0.4707, 0.4585, 0.4585, 0.4846, 0.4412,
        0.3661, 0.4806, 0.4416, 0.4584, 0.4850, 0.4680, 0.4416, 0.4467, 0.4120,
        0.4504, 0.4092, 0.4189, 0.4297, 0.4753, 0.4269, 0.4475, 0.4120, 0.4563,
        0.4649, 0.4306, 0.4306, 0.4724, 0.4724, 0.4279, 0.4547, 0.4317, 0.4306,
        0.4306, 0.4343, 0.4301, 0.4648, 0.4492, 0.4516, 0.4776, 0.4286, 0.4221,
        0.4397, 0.4325, 0.4904, 0.4545, 0.4384, 0.4329, 0.3783, 0.4763, 0.4852,
        0.4557, 0.4347, 0.4353, 0.4342, 0.4342, 0.4342, 0.4342, 0.4342, 0.4342,
        0.4114, 0.4558, 0.4342, 0.4342, 0.4966, 0.4544, 0.4335, 0.4236, 0.4343,
        0.4872, 0.4493, 0.4527, 0.4277, 0.4520, 0.4683, 0.4176, 0.4645, 0.4871,
        0.4586, 0.4621, 0.4498, 0.4831, 0.4399, 0.4891, 0.4247, 0.4382, 0.4330,
        0.4134, 0.5055, 0.4461, 0.4920, 0.4412, 0.4247, 0.4226, 0.4626, 0.4578,
        0.4635, 0.4569, 0.4578, 0.4546, 0.4626, 0.4635, 0.4626, 0.4676, 0.4481,
        0.4688, 0.4437, 0.4553, 0.4198, 0.4481, 0.4688, 0.4481, 0.4634, 0.4342,
        0.4261, 0.4484, 0.4261, 0.4463, 0.4420, 0.4261, 0.4239, 0.4484, 0.4484,
        0.4316, 0.4362, 0.4654, 0.4154, 0.4489, 0.4489, 0.4341, 0.4460, 0.4588,
        0.4544, 0.4562, 0.4500, 0.4318, 0.4500, 0.4500, 0.4465, 0.4465, 0.4500,
        0.4912, 0.4500, 0.4465, 0.4793, 0.4162, 0.4490, 0.4489, 0.4870, 0.4490,
        0.4870, 0.4870, 0.4319, 0.4411, 0.4703, 0.4380, 0.4597, 0.4597, 0.4569,
        0.4934, 0.4583, 0.4281, 0.4147, 0.4380], grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0.,
        0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0.,
        0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0.,
        0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1.,
        0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,
        1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.])
loss:  tensor(0.6852, grad_fn=<MeanBackward0>) l2:  tensor(0.3419, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
Iteration 40, loss: 0.6862761288881302
Epoch 1; time 1.0895
epoch 1 validating; auc: 0.5632
Model (checkpoint) saved to output/ml1m/env/ml1m_user_env_lr0.0003_reg0.0003.model
epoch 2 training
self.sigmoid(preds):  tensor([0.4518, 0.4804, 0.4159,  ..., 0.4195, 0.4515, 0.4270],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 0.,  ..., 1., 1., 1.])
loss:  tensor(0.6753, grad_fn=<MeanBackward0>) l2:  tensor(0.3418, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4314, 0.4504, 0.4679,  ..., 0.4445, 0.4444, 0.4664],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 0.,  ..., 1., 0., 1.])
loss:  tensor(0.6847, grad_fn=<MeanBackward0>) l2:  tensor(0.3418, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4593, 0.4333, 0.4810,  ..., 0.4700, 0.4460, 0.4521],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 0., 0., 0.])
loss:  tensor(0.6801, grad_fn=<MeanBackward0>) l2:  tensor(0.3417, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4638, 0.4418, 0.4418,  ..., 0.4646, 0.3950, 0.4489],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6906, grad_fn=<MeanBackward0>) l2:  tensor(0.3417, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4450, 0.4887, 0.4517,  ..., 0.4384, 0.3846, 0.4384],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 0.,  ..., 1., 0., 0.])
loss:  tensor(0.6985, grad_fn=<MeanBackward0>) l2:  tensor(0.3417, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4031, 0.3490, 0.4373,  ..., 0.4514, 0.4565, 0.4261],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6749, grad_fn=<MeanBackward0>) l2:  tensor(0.3416, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4928, 0.4472, 0.4472,  ..., 0.4363, 0.4529, 0.4278],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 0.])
loss:  tensor(0.6692, grad_fn=<MeanBackward0>) l2:  tensor(0.3416, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4090, 0.4413, 0.4114,  ..., 0.4503, 0.4050, 0.4419],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.6819, grad_fn=<MeanBackward0>) l2:  tensor(0.3416, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3924, 0.4196, 0.4617,  ..., 0.4797, 0.4071, 0.4328],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 0., 0., 0.])
loss:  tensor(0.6894, grad_fn=<MeanBackward0>) l2:  tensor(0.3415, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3917, 0.4101, 0.4334,  ..., 0.3504, 0.4347, 0.4849],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.6970, grad_fn=<MeanBackward0>) l2:  tensor(0.3415, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
Iteration 10, loss: 0.6842496037483216
self.sigmoid(preds):  tensor([0.4822, 0.3963, 0.3963,  ..., 0.4436, 0.4046, 0.4436],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6870, grad_fn=<MeanBackward0>) l2:  tensor(0.3415, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4327, 0.3959, 0.4397,  ..., 0.4138, 0.4508, 0.4269],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0.,  ..., 0., 1., 0.])
loss:  tensor(0.6802, grad_fn=<MeanBackward0>) l2:  tensor(0.3415, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4481, 0.4309, 0.4309,  ..., 0.4157, 0.4397, 0.3805],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6756, grad_fn=<MeanBackward0>) l2:  tensor(0.3415, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4244, 0.3860, 0.3862,  ..., 0.4355, 0.3965, 0.4354],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6725, grad_fn=<MeanBackward0>) l2:  tensor(0.3415, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.5026, 0.3944, 0.4444,  ..., 0.4206, 0.4453, 0.4453],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 0.,  ..., 1., 1., 1.])
loss:  tensor(0.7039, grad_fn=<MeanBackward0>) l2:  tensor(0.3415, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4267, 0.3859, 0.3859,  ..., 0.3668, 0.3668, 0.4187],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 1.,  ..., 0., 0., 1.])
loss:  tensor(0.6990, grad_fn=<MeanBackward0>) l2:  tensor(0.3415, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4556, 0.4989, 0.4187,  ..., 0.4221, 0.4684, 0.4221],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 0.])
loss:  tensor(0.6740, grad_fn=<MeanBackward0>) l2:  tensor(0.3415, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3933, 0.3124, 0.3789,  ..., 0.4767, 0.5006, 0.4228],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6779, grad_fn=<MeanBackward0>) l2:  tensor(0.3415, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4960, 0.3808, 0.4540,  ..., 0.4270, 0.4469, 0.4469],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 0.,  ..., 1., 1., 1.])
loss:  tensor(0.6916, grad_fn=<MeanBackward0>) l2:  tensor(0.3415, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3488, 0.3465, 0.3292,  ..., 0.3678, 0.4730, 0.3424],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0.,  ..., 1., 1., 1.])
loss:  tensor(0.6764, grad_fn=<MeanBackward0>) l2:  tensor(0.3415, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
Iteration 20, loss: 0.6840763241052628
self.sigmoid(preds):  tensor([0.4028, 0.3086, 0.3492,  ..., 0.3830, 0.4381, 0.4203],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0.,  ..., 0., 0., 0.])
loss:  tensor(0.6764, grad_fn=<MeanBackward0>) l2:  tensor(0.3415, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3279, 0.4053, 0.3555,  ..., 0.4227, 0.4733, 0.4227],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6649, grad_fn=<MeanBackward0>) l2:  tensor(0.3415, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.5096, 0.3331, 0.4192,  ..., 0.3552, 0.4880, 0.4128],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 0.])
loss:  tensor(0.6788, grad_fn=<MeanBackward0>) l2:  tensor(0.3415, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4947, 0.3547, 0.4956,  ..., 0.4027, 0.3478, 0.4484],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 0.,  ..., 1., 0., 1.])
loss:  tensor(0.6859, grad_fn=<MeanBackward0>) l2:  tensor(0.3415, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4092, 0.4005, 0.3339,  ..., 0.4076, 0.4038, 0.3486],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0.,  ..., 0., 0., 1.])
loss:  tensor(0.6737, grad_fn=<MeanBackward0>) l2:  tensor(0.3416, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3409, 0.2911, 0.4154,  ..., 0.5091, 0.4171, 0.4222],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 1., 1., 1.])
loss:  tensor(0.6931, grad_fn=<MeanBackward0>) l2:  tensor(0.3416, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3916, 0.3440, 0.3389,  ..., 0.3463, 0.3377, 0.3997],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 0., 1.])
loss:  tensor(0.6813, grad_fn=<MeanBackward0>) l2:  tensor(0.3416, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3052, 0.3361, 0.4083,  ..., 0.4292, 0.4999, 0.4375],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 0.])
loss:  tensor(0.6696, grad_fn=<MeanBackward0>) l2:  tensor(0.3416, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4655, 0.3316, 0.4224,  ..., 0.3150, 0.3185, 0.3150],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 1.,  ..., 0., 0., 0.])
loss:  tensor(0.6881, grad_fn=<MeanBackward0>) l2:  tensor(0.3416, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3235, 0.3235, 0.3235,  ..., 0.3252, 0.3442, 0.3899],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 0.,  ..., 1., 0., 0.])
loss:  tensor(0.6781, grad_fn=<MeanBackward0>) l2:  tensor(0.3416, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
Iteration 30, loss: 0.6824124256769816
self.sigmoid(preds):  tensor([0.4568, 0.4008, 0.3909,  ..., 0.3224, 0.3756, 0.4064],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 0.,  ..., 1., 1., 0.])
loss:  tensor(0.6697, grad_fn=<MeanBackward0>) l2:  tensor(0.3417, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4129, 0.2787, 0.4504,  ..., 0.4920, 0.3290, 0.2942],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6685, grad_fn=<MeanBackward0>) l2:  tensor(0.3417, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3965, 0.4650, 0.3965,  ..., 0.3593, 0.5097, 0.3465],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 1.,  ..., 1., 0., 1.])
loss:  tensor(0.6805, grad_fn=<MeanBackward0>) l2:  tensor(0.3417, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3909, 0.3949, 0.4280,  ..., 0.3676, 0.2879, 0.3738],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 0., 0., 0.])
loss:  tensor(0.6835, grad_fn=<MeanBackward0>) l2:  tensor(0.3417, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4951, 0.2713, 0.3912,  ..., 0.3917, 0.3808, 0.3224],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 0., 0.])
loss:  tensor(0.6698, grad_fn=<MeanBackward0>) l2:  tensor(0.3417, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4110, 0.2365, 0.3577,  ..., 0.2895, 0.2905, 0.5110],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 0.])
loss:  tensor(0.6772, grad_fn=<MeanBackward0>) l2:  tensor(0.3417, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.5312, 0.4155, 0.2922,  ..., 0.5347, 0.3886, 0.4107],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0.,  ..., 1., 1., 0.])
loss:  tensor(0.6814, grad_fn=<MeanBackward0>) l2:  tensor(0.3417, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3012, 0.3012, 0.3200,  ..., 0.3594, 0.4017, 0.4017],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 0., 1., 1.])
loss:  tensor(0.6923, grad_fn=<MeanBackward0>) l2:  tensor(0.3417, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.2406, 0.4729, 0.3641,  ..., 0.2546, 0.3799, 0.3935],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 1., 0., 1.])
loss:  tensor(0.6912, grad_fn=<MeanBackward0>) l2:  tensor(0.3417, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.5489, 0.3158, 0.2104, 0.3122, 0.3397, 0.2559, 0.3816, 0.2610, 0.2525,
        0.3313, 0.1821, 0.2918, 0.3144, 0.3190, 0.2667, 0.3039, 0.3903, 0.2667,
        0.3039, 0.2918, 0.3899, 0.2434, 0.2983, 0.3350, 0.4021, 0.2370, 0.3084,
        0.3555, 0.1662, 0.3403, 0.3343, 0.5242, 0.4533, 0.3585, 0.3516, 0.4795,
        0.2936, 0.3370, 0.3256, 0.4002, 0.3945, 0.3361, 0.1962, 0.3945, 0.3188,
        0.4017, 0.3609, 0.4540, 0.3477, 0.4292, 0.4027, 0.4038, 0.3035, 0.2425,
        0.4081, 0.2999, 0.5192, 0.4027, 0.4027, 0.4068, 0.4014, 0.3535, 0.3333,
        0.4723, 0.5339, 0.3413, 0.4264, 0.3270, 0.4708, 0.4656, 0.3378, 0.3007,
        0.2420, 0.2827, 0.3116, 0.2725, 0.3032, 0.3032, 0.2284, 0.2329, 0.3897,
        0.4411, 0.3104, 0.2738, 0.2582, 0.2910, 0.3529, 0.4225, 0.2822, 0.3214,
        0.3575, 0.4292, 0.3329, 0.4663, 0.3956, 0.2637, 0.4165, 0.3956, 0.2964,
        0.3228, 0.3057, 0.4256, 0.3970, 0.3444, 0.5352, 0.3970, 0.4682, 0.3666,
        0.3991, 0.3944, 0.3867, 0.3397, 0.3958, 0.5312, 0.2639, 0.5034, 0.3493,
        0.3325, 0.4286, 0.5522, 0.3058, 0.3338, 0.4011, 0.4696, 0.3049, 0.4011,
        0.2867, 0.5152, 0.3429, 0.4011, 0.4138, 0.2790, 0.2720, 0.3933, 0.4314,
        0.2899, 0.2972, 0.4428, 0.3980, 0.2735, 0.3865, 0.2959, 0.4612, 0.5224,
        0.3579, 0.4658, 0.1902, 0.2925, 0.5104, 0.5104, 0.4750, 0.2660, 0.3651,
        0.4275, 0.3291, 0.3979, 0.4013, 0.4113, 0.3498, 0.2722, 0.3234, 0.3255,
        0.3623, 0.3794, 0.3380, 0.3255, 0.3762, 0.3380, 0.3494, 0.3762, 0.2703,
        0.2795, 0.4094, 0.2795, 0.4094, 0.3795, 0.2847, 0.3322, 0.3772, 0.3356,
        0.2880, 0.3989, 0.3785, 0.3989, 0.3652, 0.5133, 0.2614, 0.3882, 0.3989,
        0.3882, 0.3096, 0.5212, 0.2902, 0.3415, 0.3771, 0.3170, 0.4528, 0.3360,
        0.3360, 0.3360, 0.3085, 0.4058, 0.3052, 0.2207, 0.2806, 0.5083, 0.3910,
        0.2639, 0.4277, 0.2781, 0.4033, 0.3850, 0.3850, 0.3835, 0.5036, 0.3950,
        0.3850, 0.4687, 0.2759, 0.3494, 0.2791, 0.5389, 0.4011, 0.2391, 0.3912,
        0.4548, 0.4011, 0.5285, 0.3145, 0.3481, 0.3033, 0.5239, 0.3983, 0.3033,
        0.3983, 0.3983, 0.4324, 0.3609, 0.3983, 0.4468, 0.3884, 0.3353, 0.2727,
        0.3884, 0.3884, 0.4681, 0.2727, 0.4650, 0.3145, 0.3884, 0.4511, 0.2935,
        0.3918, 0.4397, 0.3926, 0.3918, 0.3918, 0.2788, 0.4708, 0.4852, 0.3912,
        0.2796, 0.2839, 0.2972, 0.2195, 0.3479, 0.2796, 0.3551, 0.3964, 0.2860,
        0.3888, 0.3412, 0.2795, 0.2805, 0.3964, 0.5169, 0.3097, 0.2795, 0.2434,
        0.5169, 0.2810, 0.4259, 0.3983, 0.2810, 0.3140, 0.4088, 0.2810, 0.4148,
        0.5547, 0.3983, 0.3745, 0.3806, 0.4305, 0.3373, 0.2171, 0.2760, 0.4462,
        0.2937, 0.2760, 0.3884, 0.3035, 0.2949, 0.2949, 0.2949, 0.2629, 0.4004,
        0.2949, 0.2949, 0.3158, 0.2949, 0.2718, 0.3786, 0.2521, 0.3479, 0.4189,
        0.2718, 0.2718, 0.3932, 0.2851, 0.2624, 0.3209, 0.2548, 0.3661, 0.3129,
        0.2490, 0.3006, 0.3013, 0.3264, 0.4069, 0.4579, 0.3499, 0.3753, 0.5144,
        0.2218, 0.2676, 0.4000, 0.3019, 0.4327, 0.4281, 0.3482, 0.4984, 0.2764,
        0.2764, 0.1774, 0.2764, 0.2764, 0.2074, 0.2764, 0.3026, 0.2632, 0.2880,
        0.3897, 0.4475, 0.4072, 0.2883, 0.5375, 0.4640, 0.2880, 0.2620, 0.3140,
        0.3711, 0.4639, 0.3178, 0.4892, 0.3960, 0.4091, 0.4091, 0.3812, 0.3654,
        0.3302, 0.5451, 0.4627, 0.3456, 0.2644, 0.3993, 0.3126, 0.2721, 0.2721,
        0.4043, 0.2389, 0.3048, 0.3977, 0.5242, 0.3977, 0.3322, 0.3977, 0.4066,
        0.4066, 0.3977, 0.3977, 0.2627, 0.5186, 0.3947, 0.4674, 0.5186, 0.3918,
        0.2334, 0.3918, 0.3157, 0.2847, 0.3227, 0.2614, 0.2614, 0.3285, 0.3735,
        0.2902, 0.2992, 0.3532, 0.3227, 0.3805, 0.3199, 0.4550, 0.4591, 0.4219,
        0.2930, 0.3993, 0.5276, 0.4550, 0.2884, 0.2061, 0.4187, 0.2848, 0.3298,
        0.2673, 0.4141, 0.2630, 0.3785, 0.2917, 0.4452, 0.2697, 0.5355, 0.3868,
        0.3369, 0.3108, 0.3798, 0.2723, 0.4542, 0.3469, 0.3868, 0.2810, 0.2717,
        0.4095, 0.3010, 0.3039, 0.4124, 0.3010, 0.4042, 0.3065, 0.4035, 0.2940,
        0.3035, 0.4009, 0.3963, 0.5042, 0.3693, 0.4354, 0.3049, 0.2764, 0.3047,
        0.2960, 0.1306, 0.4271, 0.2102, 0.2734, 0.3676, 0.1712, 0.3867, 0.2845,
        0.2734, 0.3328, 0.3993, 0.5103, 0.5318, 0.3993, 0.3237, 0.4499, 0.2537,
        0.3637, 0.4111, 0.4111, 0.3965, 0.3643, 0.3956, 0.3448, 0.4165, 0.3965,
        0.3448, 0.3448, 0.3448, 0.3965, 0.4885, 0.2623, 0.3004, 0.2747, 0.4149,
        0.3004, 0.3750, 0.2747, 0.4828, 0.3388, 0.3967, 0.4219, 0.4553, 0.2804,
        0.4553, 0.2875, 0.2975, 0.3140, 0.2742, 0.2925, 0.2872, 0.1927, 0.2988,
        0.3547, 0.3068, 0.3051, 0.2988, 0.2872, 0.2619, 0.2872, 0.3893, 0.2897,
        0.3843, 0.2362, 0.3523, 0.3750, 0.3052, 0.4026, 0.3071, 0.3132, 0.2769,
        0.3373, 0.3885, 0.3834, 0.4012, 0.4737, 0.2888, 0.4190, 0.2817, 0.2817,
        0.3723, 0.2675, 0.2675, 0.2675, 0.3591, 0.2101, 0.2769, 0.2101, 0.3723,
        0.2483, 0.3240, 0.3202, 0.3202, 0.3202, 0.3202, 0.4158, 0.3202, 0.2979,
        0.2875, 0.2875, 0.3797, 0.2831, 0.2831, 0.3143, 0.3740, 0.3797, 0.3460,
        0.3143, 0.3902, 0.2117, 0.3963, 0.3963, 0.3963, 0.3963, 0.4728, 0.3021,
        0.3963, 0.4416, 0.3654, 0.5227, 0.3805, 0.2716, 0.4573, 0.3805, 0.3920,
        0.3805, 0.3920, 0.3805, 0.2716, 0.2839, 0.5511, 0.3293, 0.4741, 0.3963,
        0.3293, 0.4193, 0.3000, 0.2904, 0.4825, 0.3000, 0.3804, 0.3405, 0.3900,
        0.4206, 0.3900, 0.3993, 0.4539, 0.3418, 0.3900, 0.3900, 0.3968, 0.3903,
        0.3903, 0.4053, 0.3903, 0.3903, 0.2838, 0.5183, 0.3903, 0.3903, 0.3242,
        0.3899, 0.4648, 0.5187, 0.2842, 0.5260, 0.2798, 0.3178, 0.3899, 0.4950,
        0.3253, 0.4176, 0.4670, 0.3945, 0.3924, 0.4627, 0.4176, 0.4024, 0.3924,
        0.2554, 0.4006, 0.2837, 0.3767, 0.2837, 0.4830, 0.2837, 0.3866, 0.2837,
        0.4061, 0.2537, 0.3570, 0.3798, 0.3934, 0.2808, 0.3826, 0.2808, 0.2717,
        0.3934, 0.3965, 0.2087, 0.3491, 0.3894, 0.3511, 0.4452, 0.4002, 0.3511,
        0.3894, 0.3894, 0.3815, 0.3894, 0.2524, 0.4139, 0.2819, 0.2076, 0.2636,
        0.2521, 0.2751, 0.4008, 0.2936, 0.2197, 0.4373, 0.4629, 0.2658, 0.4696,
        0.4715, 0.2712, 0.5468, 0.3233, 0.3625, 0.3074, 0.4639, 0.2541, 0.3914,
        0.3914, 0.3869, 0.3878, 0.3914, 0.3914, 0.3914, 0.3171, 0.3320, 0.2573,
        0.2200, 0.3892, 0.1615, 0.3086, 0.3517, 0.4524, 0.4524, 0.3941, 0.2679,
        0.4390, 0.3662, 0.3214, 0.3397, 0.3881, 0.3121, 0.3979, 0.2664, 0.2908,
        0.2498, 0.3898, 0.2498, 0.3325, 0.3898, 0.2612, 0.2531, 0.4093, 0.3898,
        0.1710, 0.2871, 0.3921, 0.1811, 0.3995, 0.3473, 0.5218, 0.2894, 0.3921,
        0.1977, 0.3070, 0.2225, 0.4122, 0.3955, 0.2904, 0.2904, 0.2523, 0.3955,
        0.2192, 0.2882, 0.3022, 0.5330, 0.4370, 0.2612, 0.2259, 0.3589, 0.4106,
        0.2879, 0.2879, 0.4641, 0.3907, 0.3995, 0.2850, 0.3011, 0.3995, 0.4101,
        0.3557, 0.3628, 0.3995, 0.3104, 0.4718, 0.2942, 0.3449, 0.3111, 0.4022,
        0.2870, 0.4512, 0.2724, 0.3972, 0.5274, 0.4144, 0.3087, 0.3848, 0.2782,
        0.2782, 0.3540, 0.2588, 0.5227, 0.3977, 0.3892, 0.3638, 0.4283, 0.3606,
        0.3606, 0.3606, 0.3606, 0.3706, 0.3606, 0.3861, 0.3510, 0.3583, 0.4371,
        0.2526, 0.2167, 0.3736, 0.3736, 0.3339, 0.4504, 0.2870, 0.3736, 0.4506,
        0.4006, 0.2845, 0.4006, 0.4006, 0.4006, 0.4325, 0.2996, 0.4094, 0.3404,
        0.2996, 0.3165, 0.2993, 0.1662, 0.2783, 0.3289, 0.2993, 0.2237, 0.2885,
        0.2948, 0.3099, 0.2690, 0.3594, 0.2743, 0.3905, 0.2665, 0.2523, 0.2665,
        0.3817, 0.2690, 0.3594, 0.4757, 0.3477, 0.3610, 0.4167, 0.4322, 0.4037,
        0.3110, 0.3110, 0.4000, 0.5170, 0.4037, 0.5212, 0.2935, 0.3053, 0.4015,
        0.2090, 0.3053, 0.2991, 0.4479, 0.3702], grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0.,
        0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0.,
        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0.,
        1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0.,
        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0.,
        1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.])
loss:  tensor(0.6724, grad_fn=<MeanBackward0>) l2:  tensor(0.3418, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
Iteration 40, loss: 0.6814967706799507
Epoch 2; time 1.2098
epoch 2 validating; auc: 0.5809
Model (checkpoint) saved to output/ml1m/env/ml1m_user_env_lr0.0003_reg0.0003.model

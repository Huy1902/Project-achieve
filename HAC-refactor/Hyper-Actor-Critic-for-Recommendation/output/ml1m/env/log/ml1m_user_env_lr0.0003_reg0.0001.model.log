Namespace(model='ML1MUserResponse', reader='ML1MDataReader')
Namespace(seed=19, batch_size=128, lr=0.0003, epoch=2, model_path='output/ml1m/env/ml1m_user_env_lr0.0003_reg0.0001.model', loss='bce', l2_coef=0.0001, feature_dim=16, attn_n_head=2, hidden_dims=[256], dropout_rate=0.2, train_file='dataset/ml1m/ml1m_b_train.csv', val_file='dataset/ml1m/ml1m_b_test.csv', test_file='', n_worker=0, data_separator='@', user_meta_file='dataset/ml1m/user_info.npy', item_meta_file='dataset/ml1m/item_info.npy', max_seq_len=50, meta_data_separator=' ')
init ml1m reader
Loading data filesLoad item meta data
{'length': 5078, 'n_item': 1682, 'item_vec_size': 19, 'user_portrait_len': 24, 'max_seq_len': 50}
{'length': 5078, 'n_item': 1682, 'item_vec_size': 19, 'user_portrait_len': 24, 'max_seq_len': 50}
epoch 1 training
self.sigmoid(preds):  tensor([0.4950, 0.4985, 0.4985,  ..., 0.5107, 0.5021, 0.5073],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.6731, grad_fn=<MeanBackward0>) l2:  tensor(0.3466, grad_fn=<AddBackward0>) l2*coef tensor(3.4657e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4995, 0.5087, 0.4963,  ..., 0.5290, 0.5126, 0.4862],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 0., 1.])
loss:  tensor(0.6990, grad_fn=<MeanBackward0>) l2:  tensor(0.3464, grad_fn=<AddBackward0>) l2*coef tensor(3.4645e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.5004, 0.5006, 0.4900,  ..., 0.4979, 0.4797, 0.5100],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 1., 1., 0.])
loss:  tensor(0.7200, grad_fn=<MeanBackward0>) l2:  tensor(0.3463, grad_fn=<AddBackward0>) l2*coef tensor(3.4632e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.5224, 0.5112, 0.4957,  ..., 0.4777, 0.4955, 0.4863],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6941, grad_fn=<MeanBackward0>) l2:  tensor(0.3462, grad_fn=<AddBackward0>) l2*coef tensor(3.4620e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.5114, 0.4979, 0.4687,  ..., 0.4743, 0.5002, 0.4821],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 0.])
loss:  tensor(0.6825, grad_fn=<MeanBackward0>) l2:  tensor(0.3461, grad_fn=<AddBackward0>) l2*coef tensor(3.4609e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.5005, 0.4785, 0.4956,  ..., 0.4954, 0.4962, 0.4925],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 0.,  ..., 1., 0., 0.])
loss:  tensor(0.6795, grad_fn=<MeanBackward0>) l2:  tensor(0.3460, grad_fn=<AddBackward0>) l2*coef tensor(3.4597e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.5255, 0.5252, 0.4963,  ..., 0.5080, 0.4941, 0.5076],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 1.,  ..., 1., 1., 0.])
loss:  tensor(0.7080, grad_fn=<MeanBackward0>) l2:  tensor(0.3459, grad_fn=<AddBackward0>) l2*coef tensor(3.4587e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4895, 0.5041, 0.4934,  ..., 0.4852, 0.4974, 0.4974],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0.,  ..., 0., 1., 1.])
loss:  tensor(0.6713, grad_fn=<MeanBackward0>) l2:  tensor(0.3458, grad_fn=<AddBackward0>) l2*coef tensor(3.4577e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4883, 0.4996, 0.4883,  ..., 0.4935, 0.4902, 0.4874],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.6926, grad_fn=<MeanBackward0>) l2:  tensor(0.3457, grad_fn=<AddBackward0>) l2*coef tensor(3.4567e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.5016, 0.4867, 0.4867,  ..., 0.4780, 0.4901, 0.4810],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0.,  ..., 0., 0., 0.])
loss:  tensor(0.6900, grad_fn=<MeanBackward0>) l2:  tensor(0.3456, grad_fn=<AddBackward0>) l2*coef tensor(3.4558e-05, grad_fn=<MulBackward0>)
Iteration 10, loss: 0.6910378992557525
self.sigmoid(preds):  tensor([0.4690, 0.4974, 0.4638,  ..., 0.5039, 0.4730, 0.4890],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 0., 0., 1.])
loss:  tensor(0.6768, grad_fn=<MeanBackward0>) l2:  tensor(0.3455, grad_fn=<AddBackward0>) l2*coef tensor(3.4548e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4791, 0.4857, 0.4811,  ..., 0.4699, 0.4789, 0.4710],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 0.,  ..., 1., 0., 1.])
loss:  tensor(0.6948, grad_fn=<MeanBackward0>) l2:  tensor(0.3454, grad_fn=<AddBackward0>) l2*coef tensor(3.4539e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4992, 0.5051, 0.5014,  ..., 0.4958, 0.4908, 0.4765],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 0., 1.])
loss:  tensor(0.6848, grad_fn=<MeanBackward0>) l2:  tensor(0.3453, grad_fn=<AddBackward0>) l2*coef tensor(3.4531e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4954, 0.4722, 0.4968,  ..., 0.4834, 0.4637, 0.4925],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.6902, grad_fn=<MeanBackward0>) l2:  tensor(0.3452, grad_fn=<AddBackward0>) l2*coef tensor(3.4523e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.5015, 0.4967, 0.4988,  ..., 0.4601, 0.4781, 0.4798],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.7075, grad_fn=<MeanBackward0>) l2:  tensor(0.3451, grad_fn=<AddBackward0>) l2*coef tensor(3.4515e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4794, 0.4847, 0.5080,  ..., 0.4956, 0.4784, 0.4450],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.6649, grad_fn=<MeanBackward0>) l2:  tensor(0.3451, grad_fn=<AddBackward0>) l2*coef tensor(3.4508e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4618, 0.4817, 0.4690,  ..., 0.4939, 0.4741, 0.4831],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 0.,  ..., 1., 1., 1.])
loss:  tensor(0.6859, grad_fn=<MeanBackward0>) l2:  tensor(0.3450, grad_fn=<AddBackward0>) l2*coef tensor(3.4500e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4758, 0.4772, 0.4855,  ..., 0.4989, 0.4748, 0.4749],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 0., 0.])
loss:  tensor(0.6877, grad_fn=<MeanBackward0>) l2:  tensor(0.3449, grad_fn=<AddBackward0>) l2*coef tensor(3.4493e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4673, 0.5037, 0.4791,  ..., 0.4819, 0.4819, 0.4773],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.6959, grad_fn=<MeanBackward0>) l2:  tensor(0.3449, grad_fn=<AddBackward0>) l2*coef tensor(3.4486e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4916, 0.4527, 0.4882,  ..., 0.4890, 0.4739, 0.4774],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.6814, grad_fn=<MeanBackward0>) l2:  tensor(0.3448, grad_fn=<AddBackward0>) l2*coef tensor(3.4480e-05, grad_fn=<MulBackward0>)
Iteration 20, loss: 0.6890286982059479
self.sigmoid(preds):  tensor([0.4776, 0.4751, 0.4776,  ..., 0.4671, 0.4572, 0.4761],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 1.,  ..., 1., 0., 1.])
loss:  tensor(0.6949, grad_fn=<MeanBackward0>) l2:  tensor(0.3447, grad_fn=<AddBackward0>) l2*coef tensor(3.4475e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4775, 0.4669, 0.4821,  ..., 0.4710, 0.4758, 0.4979],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 1., 0., 1.])
loss:  tensor(0.6855, grad_fn=<MeanBackward0>) l2:  tensor(0.3447, grad_fn=<AddBackward0>) l2*coef tensor(3.4470e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4835, 0.4680, 0.4680,  ..., 0.4682, 0.4495, 0.4682],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 0., 1.])
loss:  tensor(0.6749, grad_fn=<MeanBackward0>) l2:  tensor(0.3446, grad_fn=<AddBackward0>) l2*coef tensor(3.4465e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4736, 0.4736, 0.4738,  ..., 0.4799, 0.4677, 0.4677],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 0.,  ..., 1., 1., 1.])
loss:  tensor(0.6854, grad_fn=<MeanBackward0>) l2:  tensor(0.3446, grad_fn=<AddBackward0>) l2*coef tensor(3.4460e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4612, 0.4605, 0.4613,  ..., 0.4683, 0.4700, 0.4524],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 1., 1., 1.])
loss:  tensor(0.6898, grad_fn=<MeanBackward0>) l2:  tensor(0.3446, grad_fn=<AddBackward0>) l2*coef tensor(3.4456e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4574, 0.4725, 0.4725,  ..., 0.5133, 0.4627, 0.4627],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 0.])
loss:  tensor(0.6937, grad_fn=<MeanBackward0>) l2:  tensor(0.3445, grad_fn=<AddBackward0>) l2*coef tensor(3.4453e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4812, 0.4207, 0.4604,  ..., 0.4637, 0.4435, 0.4961],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 0., 1.])
loss:  tensor(0.6709, grad_fn=<MeanBackward0>) l2:  tensor(0.3445, grad_fn=<AddBackward0>) l2*coef tensor(3.4451e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4640, 0.4542, 0.4532,  ..., 0.4992, 0.4817, 0.4651],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 0., 1., 1.])
loss:  tensor(0.6939, grad_fn=<MeanBackward0>) l2:  tensor(0.3445, grad_fn=<AddBackward0>) l2*coef tensor(3.4448e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4748, 0.4585, 0.4753,  ..., 0.4591, 0.4635, 0.4505],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 1.,  ..., 1., 0., 0.])
loss:  tensor(0.6821, grad_fn=<MeanBackward0>) l2:  tensor(0.3445, grad_fn=<AddBackward0>) l2*coef tensor(3.4445e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4370, 0.4411, 0.4256,  ..., 0.4595, 0.4708, 0.4285],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 0., 0., 1.])
loss:  tensor(0.6664, grad_fn=<MeanBackward0>) l2:  tensor(0.3444, grad_fn=<AddBackward0>) l2*coef tensor(3.4443e-05, grad_fn=<MulBackward0>)
Iteration 30, loss: 0.6872822503248851
self.sigmoid(preds):  tensor([0.4395, 0.4576, 0.4846,  ..., 0.4499, 0.4393, 0.4621],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6771, grad_fn=<MeanBackward0>) l2:  tensor(0.3444, grad_fn=<AddBackward0>) l2*coef tensor(3.4441e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4611, 0.4356, 0.4569,  ..., 0.4494, 0.4344, 0.4459],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 1., 1., 1.])
loss:  tensor(0.6837, grad_fn=<MeanBackward0>) l2:  tensor(0.3444, grad_fn=<AddBackward0>) l2*coef tensor(3.4439e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4480, 0.4585, 0.4739,  ..., 0.4812, 0.4375, 0.4646],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0.,  ..., 1., 0., 0.])
loss:  tensor(0.6946, grad_fn=<MeanBackward0>) l2:  tensor(0.3444, grad_fn=<AddBackward0>) l2*coef tensor(3.4437e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4577, 0.4458, 0.4661,  ..., 0.4266, 0.4521, 0.4334],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 1.,  ..., 0., 0., 1.])
loss:  tensor(0.6886, grad_fn=<MeanBackward0>) l2:  tensor(0.3444, grad_fn=<AddBackward0>) l2*coef tensor(3.4436e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4821, 0.4356, 0.4538,  ..., 0.4417, 0.4660, 0.4525],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.6887, grad_fn=<MeanBackward0>) l2:  tensor(0.3444, grad_fn=<AddBackward0>) l2*coef tensor(3.4436e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4858, 0.5029, 0.4965,  ..., 0.4989, 0.4634, 0.4048],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6801, grad_fn=<MeanBackward0>) l2:  tensor(0.3444, grad_fn=<AddBackward0>) l2*coef tensor(3.4436e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4609, 0.4593, 0.4419,  ..., 0.4881, 0.4767, 0.4729],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0.,  ..., 1., 1., 0.])
loss:  tensor(0.6786, grad_fn=<MeanBackward0>) l2:  tensor(0.3444, grad_fn=<AddBackward0>) l2*coef tensor(3.4436e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4602, 0.4459, 0.4647,  ..., 0.4426, 0.4486, 0.4681],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 0.,  ..., 1., 0., 0.])
loss:  tensor(0.6586, grad_fn=<MeanBackward0>) l2:  tensor(0.3444, grad_fn=<AddBackward0>) l2*coef tensor(3.4437e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4456, 0.4551, 0.4380,  ..., 0.4309, 0.4384, 0.4380],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 0., 0.])
loss:  tensor(0.6941, grad_fn=<MeanBackward0>) l2:  tensor(0.3444, grad_fn=<AddBackward0>) l2*coef tensor(3.4436e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3858, 0.4254, 0.4452, 0.4116, 0.4254, 0.4258, 0.4285, 0.4452, 0.4285,
        0.4452, 0.4255, 0.4424, 0.4734, 0.4565, 0.4175, 0.4515, 0.4660, 0.4981,
        0.4188, 0.4027, 0.4658, 0.4197, 0.4168, 0.3850, 0.4086, 0.4305, 0.4165,
        0.4138, 0.4305, 0.4305, 0.4975, 0.4525, 0.4584, 0.3889, 0.4525, 0.4865,
        0.4765, 0.4914, 0.4525, 0.4217, 0.4379, 0.3946, 0.4561, 0.4237, 0.4324,
        0.4565, 0.4383, 0.4129, 0.4561, 0.4565, 0.4137, 0.4633, 0.4213, 0.4490,
        0.4536, 0.4287, 0.4464, 0.4149, 0.4264, 0.4279, 0.4539, 0.4479, 0.4502,
        0.4324, 0.4502, 0.4739, 0.4513, 0.4179, 0.4864, 0.4888, 0.4677, 0.4677,
        0.4861, 0.4677, 0.4654, 0.4617, 0.4525, 0.4677, 0.4677, 0.4677, 0.4281,
        0.4312, 0.4134, 0.4227, 0.4415, 0.4316, 0.4515, 0.4853, 0.4515, 0.4513,
        0.4520, 0.4683, 0.4507, 0.4683, 0.4350, 0.4548, 0.4610, 0.4728, 0.4637,
        0.4350, 0.4215, 0.4237, 0.4252, 0.4145, 0.4237, 0.4237, 0.4487, 0.4472,
        0.4252, 0.4002, 0.4694, 0.4847, 0.4883, 0.3744, 0.4477, 0.4441, 0.4528,
        0.4068, 0.4694, 0.4568, 0.4218, 0.4238, 0.3961, 0.3815, 0.4274, 0.4497,
        0.3593, 0.4642, 0.4357, 0.4198, 0.4917, 0.4254, 0.4513, 0.4213, 0.4184,
        0.4254, 0.4513, 0.4960, 0.4617, 0.4254, 0.4351, 0.4268, 0.4662, 0.4268,
        0.3955, 0.4535, 0.4707, 0.4278, 0.4242, 0.4353, 0.4300, 0.4667, 0.4569,
        0.4137, 0.4568, 0.4830, 0.4300, 0.4502, 0.4837, 0.4502, 0.4662, 0.4363,
        0.4356, 0.4541, 0.4356, 0.4463, 0.4503, 0.4209, 0.4250, 0.4547, 0.4050,
        0.4526, 0.4067, 0.4526, 0.4515, 0.4292, 0.4343, 0.4612, 0.4050, 0.4343,
        0.4783, 0.4810, 0.4741, 0.4924, 0.4229, 0.4693, 0.4879, 0.4693, 0.4693,
        0.4693, 0.4233, 0.4169, 0.4169, 0.4169, 0.4372, 0.4319, 0.4372, 0.4443,
        0.4169, 0.4169, 0.4646, 0.4307, 0.4253, 0.4607, 0.4581, 0.4619, 0.4084,
        0.4307, 0.4380, 0.4473, 0.4368, 0.4274, 0.4290, 0.4577, 0.4643, 0.4000,
        0.4368, 0.4244, 0.4368, 0.4087, 0.4627, 0.4544, 0.4896, 0.4216, 0.4365,
        0.4545, 0.4191, 0.4969, 0.4877, 0.4545, 0.4574, 0.4689, 0.4608, 0.4504,
        0.4966, 0.4689, 0.4244, 0.4859, 0.4851, 0.4546, 0.4504, 0.4556, 0.4668,
        0.4413, 0.4664, 0.4789, 0.4183, 0.4664, 0.4717, 0.4664, 0.4212, 0.4212,
        0.4440, 0.4567, 0.4486, 0.4212, 0.4191, 0.4877, 0.4359, 0.4094, 0.4436,
        0.4627, 0.4528, 0.4850, 0.4599, 0.4672, 0.4850, 0.4501, 0.4528, 0.4984,
        0.4939, 0.4524, 0.4304, 0.4941, 0.4540, 0.4174, 0.4310, 0.4200, 0.4341,
        0.4761, 0.4706, 0.4233, 0.4804, 0.4992, 0.4417, 0.4664, 0.4994, 0.4459,
        0.4406, 0.4994, 0.4307, 0.4496, 0.4286, 0.4496, 0.4447, 0.4496, 0.4496,
        0.4147, 0.4496, 0.4307, 0.4233, 0.4910, 0.4522, 0.4910, 0.4233, 0.4435,
        0.4076, 0.4436, 0.4435, 0.4590, 0.4296, 0.4323, 0.4291, 0.4291, 0.4291,
        0.4291, 0.4291, 0.4291, 0.4291, 0.4291, 0.4341, 0.4347, 0.4340, 0.4710,
        0.4552, 0.4690, 0.4642, 0.4511, 0.4212, 0.4341, 0.4331, 0.4355, 0.4520,
        0.4356, 0.4539, 0.4077, 0.4331, 0.4171, 0.4171, 0.4171, 0.4334, 0.4592,
        0.4334, 0.4563, 0.4592, 0.3935, 0.4414, 0.4734, 0.4268, 0.4273, 0.4732,
        0.4923, 0.4593, 0.4568, 0.4679, 0.4186, 0.4896, 0.4478, 0.4864, 0.4685,
        0.4732, 0.4900, 0.4121, 0.4624, 0.4623, 0.4491, 0.4494, 0.4491, 0.4603,
        0.4900, 0.4537, 0.4497, 0.4937, 0.4775, 0.4278, 0.4655, 0.3913, 0.4592,
        0.4749, 0.4497, 0.4423, 0.4826, 0.4423, 0.4423, 0.4799, 0.4423, 0.4423,
        0.4423, 0.4423, 0.4423, 0.3667, 0.4947, 0.4420, 0.4420, 0.4909, 0.4375,
        0.4191, 0.4420, 0.4519, 0.4371, 0.4608, 0.4563, 0.4396, 0.4432, 0.3959,
        0.4202, 0.4396, 0.4396, 0.4243, 0.4892, 0.4435, 0.4301, 0.4415, 0.4638,
        0.4170, 0.4415, 0.4415, 0.4301, 0.4170, 0.4170, 0.4522, 0.4557, 0.4361,
        0.4400, 0.4747, 0.4245, 0.4557, 0.4593, 0.4882, 0.4557, 0.4407, 0.4328,
        0.4589, 0.4229, 0.4224, 0.4152, 0.4562, 0.4255, 0.4255, 0.4331, 0.4073,
        0.4934, 0.4814, 0.4555, 0.4555, 0.4171, 0.4809, 0.4616, 0.4827, 0.4617,
        0.4151, 0.4923, 0.4543, 0.4359, 0.4415, 0.4359, 0.4415, 0.4368, 0.4325,
        0.4151, 0.4492, 0.4221, 0.4839, 0.4469, 0.4492, 0.4297, 0.4297, 0.4604,
        0.3716, 0.4119, 0.4958, 0.4689, 0.4603, 0.4193, 0.4193, 0.4227, 0.4659,
        0.4380, 0.4427, 0.4800, 0.4251, 0.4002, 0.3711, 0.4251, 0.3911, 0.4183,
        0.3911, 0.4231, 0.4071, 0.3911, 0.4391, 0.4391, 0.4434, 0.4202, 0.4247,
        0.3786, 0.4311, 0.4247, 0.4363, 0.4247, 0.4498, 0.4498, 0.4275, 0.4626,
        0.4626, 0.4666, 0.4463, 0.4498, 0.4347, 0.4690, 0.4361, 0.3812, 0.4438,
        0.4701, 0.4957, 0.4515, 0.4627, 0.4302, 0.4498, 0.4662, 0.3842, 0.4306,
        0.4442, 0.4221, 0.4861, 0.3957, 0.4454, 0.4454, 0.4442, 0.4850, 0.4478,
        0.4237, 0.4069, 0.4710, 0.4921, 0.4419, 0.4510, 0.4664, 0.4554, 0.4270,
        0.4521, 0.4504, 0.4271, 0.4901, 0.4665, 0.4243, 0.3915, 0.4872, 0.3802,
        0.4273, 0.3762, 0.4684, 0.4518, 0.4536, 0.4536, 0.4291, 0.4587, 0.4155,
        0.4469, 0.4304, 0.4698, 0.4695, 0.4250, 0.4375, 0.4579, 0.4579, 0.4901,
        0.4579, 0.4376, 0.4518, 0.4403, 0.4245, 0.4923, 0.4580, 0.4486, 0.4945,
        0.4955, 0.4245, 0.4245, 0.4486, 0.4498, 0.4498, 0.4604, 0.4498, 0.4443,
        0.4498, 0.4434, 0.4187, 0.4332, 0.3943, 0.4573, 0.4398, 0.4326, 0.4679,
        0.4631, 0.4326, 0.4357, 0.4326, 0.4560, 0.4326, 0.4556, 0.4520, 0.4520,
        0.4520, 0.4702, 0.4235, 0.4468, 0.4476, 0.4468, 0.4185, 0.3785, 0.4446,
        0.4503, 0.4478, 0.4924, 0.4503, 0.4294, 0.4278, 0.4636, 0.4335, 0.4295,
        0.4634, 0.3996, 0.4110, 0.4269, 0.4295, 0.4102, 0.4568, 0.4568, 0.4057,
        0.4711, 0.4889, 0.4287, 0.4215, 0.4187, 0.4999, 0.4173, 0.4766, 0.4530,
        0.4999, 0.5030, 0.4779, 0.4216, 0.4735, 0.3799, 0.4566, 0.4630, 0.4534,
        0.4911, 0.4566, 0.4714, 0.4259, 0.4088, 0.4681, 0.4386, 0.4733, 0.4520,
        0.4714, 0.4947, 0.4608, 0.4918, 0.4584, 0.4917, 0.4331, 0.4584, 0.4986,
        0.4606, 0.4606, 0.4606, 0.4547, 0.4588, 0.4477, 0.4504, 0.4477, 0.4567,
        0.4211, 0.4297, 0.4588, 0.4892, 0.4588, 0.4467, 0.4646, 0.4445, 0.4542,
        0.4445, 0.4258, 0.3701, 0.4505, 0.4124, 0.3938, 0.4367, 0.4526, 0.4584,
        0.4663, 0.4584, 0.4367, 0.4330, 0.4707, 0.4584, 0.4584, 0.4848, 0.4412,
        0.3656, 0.4807, 0.4415, 0.4584, 0.4852, 0.4680, 0.4415, 0.4467, 0.4117,
        0.4503, 0.4090, 0.4187, 0.4296, 0.4754, 0.4268, 0.4475, 0.4117, 0.4563,
        0.4649, 0.4305, 0.4305, 0.4725, 0.4725, 0.4278, 0.4547, 0.4316, 0.4305,
        0.4305, 0.4342, 0.4300, 0.4648, 0.4491, 0.4515, 0.4776, 0.4284, 0.4219,
        0.4395, 0.4324, 0.4904, 0.4545, 0.4383, 0.4328, 0.3779, 0.4764, 0.4853,
        0.4557, 0.4347, 0.4351, 0.4341, 0.4341, 0.4341, 0.4341, 0.4341, 0.4341,
        0.4111, 0.4557, 0.4341, 0.4341, 0.4967, 0.4544, 0.4334, 0.4235, 0.4342,
        0.4873, 0.4493, 0.4527, 0.4275, 0.4519, 0.4684, 0.4173, 0.4645, 0.4872,
        0.4586, 0.4621, 0.4498, 0.4832, 0.4398, 0.4893, 0.4245, 0.4381, 0.4329,
        0.4132, 0.5057, 0.4460, 0.4922, 0.4411, 0.4245, 0.4224, 0.4625, 0.4577,
        0.4634, 0.4568, 0.4577, 0.4545, 0.4625, 0.4634, 0.4625, 0.4676, 0.4481,
        0.4689, 0.4436, 0.4552, 0.4196, 0.4481, 0.4689, 0.4481, 0.4635, 0.4341,
        0.4259, 0.4484, 0.4259, 0.4462, 0.4419, 0.4259, 0.4237, 0.4484, 0.4484,
        0.4315, 0.4362, 0.4654, 0.4151, 0.4489, 0.4489, 0.4340, 0.4460, 0.4588,
        0.4543, 0.4562, 0.4500, 0.4318, 0.4500, 0.4500, 0.4465, 0.4465, 0.4500,
        0.4914, 0.4500, 0.4465, 0.4793, 0.4160, 0.4489, 0.4488, 0.4871, 0.4489,
        0.4871, 0.4871, 0.4318, 0.4410, 0.4703, 0.4379, 0.4597, 0.4597, 0.4568,
        0.4936, 0.4583, 0.4280, 0.4146, 0.4379], grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0.,
        0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0.,
        0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0.,
        0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1.,
        0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,
        1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.])
loss:  tensor(0.6852, grad_fn=<MeanBackward0>) l2:  tensor(0.3444, grad_fn=<AddBackward0>) l2*coef tensor(3.4437e-05, grad_fn=<MulBackward0>)
Iteration 40, loss: 0.6862048327922821
Epoch 1; time 0.8565
epoch 1 validating; auc: 0.5632
Model (checkpoint) saved to output/ml1m/env/ml1m_user_env_lr0.0003_reg0.0001.model
epoch 2 training
self.sigmoid(preds):  tensor([0.4518, 0.4805, 0.4158,  ..., 0.4193, 0.4515, 0.4269],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 0.,  ..., 1., 1., 1.])
loss:  tensor(0.6753, grad_fn=<MeanBackward0>) l2:  tensor(0.3444, grad_fn=<AddBackward0>) l2*coef tensor(3.4438e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4312, 0.4503, 0.4679,  ..., 0.4444, 0.4444, 0.4664],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 0.,  ..., 1., 0., 1.])
loss:  tensor(0.6847, grad_fn=<MeanBackward0>) l2:  tensor(0.3444, grad_fn=<AddBackward0>) l2*coef tensor(3.4439e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4593, 0.4332, 0.4810,  ..., 0.4700, 0.4460, 0.4521],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 0., 0., 0.])
loss:  tensor(0.6801, grad_fn=<MeanBackward0>) l2:  tensor(0.3444, grad_fn=<AddBackward0>) l2*coef tensor(3.4440e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4639, 0.4417, 0.4417,  ..., 0.4647, 0.3947, 0.4489],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6905, grad_fn=<MeanBackward0>) l2:  tensor(0.3444, grad_fn=<AddBackward0>) l2*coef tensor(3.4442e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4449, 0.4889, 0.4517,  ..., 0.4383, 0.3841, 0.4383],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 0.,  ..., 1., 0., 0.])
loss:  tensor(0.6985, grad_fn=<MeanBackward0>) l2:  tensor(0.3444, grad_fn=<AddBackward0>) l2*coef tensor(3.4444e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4028, 0.3484, 0.4372,  ..., 0.4514, 0.4565, 0.4259],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6749, grad_fn=<MeanBackward0>) l2:  tensor(0.3445, grad_fn=<AddBackward0>) l2*coef tensor(3.4448e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4930, 0.4471, 0.4471,  ..., 0.4361, 0.4529, 0.4276],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 0.])
loss:  tensor(0.6692, grad_fn=<MeanBackward0>) l2:  tensor(0.3445, grad_fn=<AddBackward0>) l2*coef tensor(3.4451e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4088, 0.4412, 0.4112,  ..., 0.4503, 0.4048, 0.4419],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.6819, grad_fn=<MeanBackward0>) l2:  tensor(0.3445, grad_fn=<AddBackward0>) l2*coef tensor(3.4454e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3921, 0.4194, 0.4618,  ..., 0.4799, 0.4067, 0.4328],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 0., 0., 0.])
loss:  tensor(0.6894, grad_fn=<MeanBackward0>) l2:  tensor(0.3446, grad_fn=<AddBackward0>) l2*coef tensor(3.4457e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3914, 0.4099, 0.4332,  ..., 0.3499, 0.4346, 0.4851],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.6969, grad_fn=<MeanBackward0>) l2:  tensor(0.3446, grad_fn=<AddBackward0>) l2*coef tensor(3.4460e-05, grad_fn=<MulBackward0>)
Iteration 10, loss: 0.6841702938079834
self.sigmoid(preds):  tensor([0.4823, 0.3960, 0.3960,  ..., 0.4436, 0.4043, 0.4436],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6869, grad_fn=<MeanBackward0>) l2:  tensor(0.3447, grad_fn=<AddBackward0>) l2*coef tensor(3.4465e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4326, 0.3956, 0.4396,  ..., 0.4136, 0.4509, 0.4269],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0.,  ..., 0., 1., 0.])
loss:  tensor(0.6802, grad_fn=<MeanBackward0>) l2:  tensor(0.3447, grad_fn=<AddBackward0>) l2*coef tensor(3.4471e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4481, 0.4308, 0.4308,  ..., 0.4155, 0.4396, 0.3798],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6756, grad_fn=<MeanBackward0>) l2:  tensor(0.3448, grad_fn=<AddBackward0>) l2*coef tensor(3.4477e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4243, 0.3857, 0.3858,  ..., 0.4354, 0.3962, 0.4353],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6725, grad_fn=<MeanBackward0>) l2:  tensor(0.3448, grad_fn=<AddBackward0>) l2*coef tensor(3.4482e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.5032, 0.3942, 0.4445,  ..., 0.4205, 0.4454, 0.4454],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 0.,  ..., 1., 1., 1.])
loss:  tensor(0.7038, grad_fn=<MeanBackward0>) l2:  tensor(0.3449, grad_fn=<AddBackward0>) l2*coef tensor(3.4486e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4267, 0.3856, 0.3856,  ..., 0.3664, 0.3664, 0.4186],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 1.,  ..., 0., 0., 1.])
loss:  tensor(0.6990, grad_fn=<MeanBackward0>) l2:  tensor(0.3449, grad_fn=<AddBackward0>) l2*coef tensor(3.4492e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4558, 0.4994, 0.4186,  ..., 0.4220, 0.4686, 0.4220],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 0.])
loss:  tensor(0.6740, grad_fn=<MeanBackward0>) l2:  tensor(0.3450, grad_fn=<AddBackward0>) l2*coef tensor(3.4500e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3930, 0.3116, 0.3785,  ..., 0.4769, 0.5011, 0.4227],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6779, grad_fn=<MeanBackward0>) l2:  tensor(0.3451, grad_fn=<AddBackward0>) l2*coef tensor(3.4507e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4964, 0.3804, 0.4541,  ..., 0.4269, 0.4469, 0.4469],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 0.,  ..., 1., 1., 1.])
loss:  tensor(0.6916, grad_fn=<MeanBackward0>) l2:  tensor(0.3451, grad_fn=<AddBackward0>) l2*coef tensor(3.4514e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3482, 0.3457, 0.3285,  ..., 0.3673, 0.4734, 0.3418],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0.,  ..., 1., 1., 1.])
loss:  tensor(0.6764, grad_fn=<MeanBackward0>) l2:  tensor(0.3452, grad_fn=<AddBackward0>) l2*coef tensor(3.4521e-05, grad_fn=<MulBackward0>)
Iteration 20, loss: 0.6839933395385742
self.sigmoid(preds):  tensor([0.4026, 0.3077, 0.3486,  ..., 0.3827, 0.4382, 0.4202],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0.,  ..., 0., 0., 0.])
loss:  tensor(0.6764, grad_fn=<MeanBackward0>) l2:  tensor(0.3453, grad_fn=<AddBackward0>) l2*coef tensor(3.4529e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3273, 0.4052, 0.3550,  ..., 0.4225, 0.4735, 0.4225],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6649, grad_fn=<MeanBackward0>) l2:  tensor(0.3454, grad_fn=<AddBackward0>) l2*coef tensor(3.4537e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.5104, 0.3324, 0.4192,  ..., 0.3546, 0.4884, 0.4127],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 0.])
loss:  tensor(0.6788, grad_fn=<MeanBackward0>) l2:  tensor(0.3454, grad_fn=<AddBackward0>) l2*coef tensor(3.4542e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4953, 0.3542, 0.4962,  ..., 0.4026, 0.3472, 0.4488],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 0.,  ..., 1., 0., 1.])
loss:  tensor(0.6859, grad_fn=<MeanBackward0>) l2:  tensor(0.3455, grad_fn=<AddBackward0>) l2*coef tensor(3.4549e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4091, 0.4003, 0.3333,  ..., 0.4075, 0.4037, 0.3480],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0.,  ..., 0., 0., 1.])
loss:  tensor(0.6737, grad_fn=<MeanBackward0>) l2:  tensor(0.3456, grad_fn=<AddBackward0>) l2*coef tensor(3.4555e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3403, 0.2901, 0.4153,  ..., 0.5099, 0.4170, 0.4222],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 1., 1., 1.])
loss:  tensor(0.6930, grad_fn=<MeanBackward0>) l2:  tensor(0.3456, grad_fn=<AddBackward0>) l2*coef tensor(3.4561e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3913, 0.3435, 0.3383,  ..., 0.3458, 0.3371, 0.3996],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 0., 1.])
loss:  tensor(0.6813, grad_fn=<MeanBackward0>) l2:  tensor(0.3457, grad_fn=<AddBackward0>) l2*coef tensor(3.4570e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3043, 0.3356, 0.4083,  ..., 0.4292, 0.5004, 0.4375],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 0.])
loss:  tensor(0.6696, grad_fn=<MeanBackward0>) l2:  tensor(0.3458, grad_fn=<AddBackward0>) l2*coef tensor(3.4578e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4659, 0.3310, 0.4225,  ..., 0.3142, 0.3179, 0.3142],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 1.,  ..., 0., 0., 0.])
loss:  tensor(0.6881, grad_fn=<MeanBackward0>) l2:  tensor(0.3459, grad_fn=<AddBackward0>) l2*coef tensor(3.4586e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3228, 0.3228, 0.3228,  ..., 0.3245, 0.3436, 0.3897],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 0.,  ..., 1., 0., 0.])
loss:  tensor(0.6780, grad_fn=<MeanBackward0>) l2:  tensor(0.3459, grad_fn=<AddBackward0>) l2*coef tensor(3.4594e-05, grad_fn=<MulBackward0>)
Iteration 30, loss: 0.6823252578576405
self.sigmoid(preds):  tensor([0.4570, 0.4007, 0.3908,  ..., 0.3217, 0.3752, 0.4065],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 0.,  ..., 1., 1., 0.])
loss:  tensor(0.6696, grad_fn=<MeanBackward0>) l2:  tensor(0.3460, grad_fn=<AddBackward0>) l2*coef tensor(3.4602e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4130, 0.2778, 0.4510,  ..., 0.4927, 0.3283, 0.2932],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6684, grad_fn=<MeanBackward0>) l2:  tensor(0.3461, grad_fn=<AddBackward0>) l2*coef tensor(3.4609e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3965, 0.4656, 0.3965,  ..., 0.3591, 0.5106, 0.3460],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 1.,  ..., 1., 0., 1.])
loss:  tensor(0.6805, grad_fn=<MeanBackward0>) l2:  tensor(0.3461, grad_fn=<AddBackward0>) l2*coef tensor(3.4614e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3908, 0.3949, 0.4284,  ..., 0.3673, 0.2871, 0.3736],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 0., 0., 0.])
loss:  tensor(0.6835, grad_fn=<MeanBackward0>) l2:  tensor(0.3462, grad_fn=<AddBackward0>) l2*coef tensor(3.4619e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4960, 0.2701, 0.3911,  ..., 0.3918, 0.3806, 0.3219],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 0., 0.])
loss:  tensor(0.6698, grad_fn=<MeanBackward0>) l2:  tensor(0.3463, grad_fn=<AddBackward0>) l2*coef tensor(3.4626e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4113, 0.2353, 0.3575,  ..., 0.2885, 0.2896, 0.5120],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 0.])
loss:  tensor(0.6772, grad_fn=<MeanBackward0>) l2:  tensor(0.3463, grad_fn=<AddBackward0>) l2*coef tensor(3.4631e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.5327, 0.4159, 0.2913,  ..., 0.5361, 0.3885, 0.4107],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0.,  ..., 1., 1., 0.])
loss:  tensor(0.6813, grad_fn=<MeanBackward0>) l2:  tensor(0.3464, grad_fn=<AddBackward0>) l2*coef tensor(3.4636e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3004, 0.3004, 0.3194,  ..., 0.3592, 0.4018, 0.4018],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 0., 1., 1.])
loss:  tensor(0.6922, grad_fn=<MeanBackward0>) l2:  tensor(0.3464, grad_fn=<AddBackward0>) l2*coef tensor(3.4643e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.2394, 0.4736, 0.3638,  ..., 0.2536, 0.3800, 0.3936],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 1., 0., 1.])
loss:  tensor(0.6911, grad_fn=<MeanBackward0>) l2:  tensor(0.3465, grad_fn=<AddBackward0>) l2*coef tensor(3.4652e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.5507, 0.3152, 0.2089, 0.3116, 0.3393, 0.2549, 0.3816, 0.2601, 0.2515,
        0.3310, 0.1805, 0.2908, 0.3138, 0.3184, 0.2657, 0.3031, 0.3903, 0.2657,
        0.3031, 0.2908, 0.3901, 0.2423, 0.2976, 0.3345, 0.4023, 0.2356, 0.3079,
        0.3553, 0.1647, 0.3399, 0.3339, 0.5256, 0.4542, 0.3581, 0.3513, 0.4804,
        0.2928, 0.3364, 0.3252, 0.4004, 0.3947, 0.3357, 0.1948, 0.3947, 0.3183,
        0.4019, 0.3608, 0.4550, 0.3474, 0.4299, 0.4029, 0.4040, 0.3029, 0.2414,
        0.4082, 0.2990, 0.5204, 0.4029, 0.4029, 0.4069, 0.4017, 0.3533, 0.3329,
        0.4732, 0.5354, 0.3411, 0.4269, 0.3266, 0.4716, 0.4665, 0.3374, 0.2998,
        0.2407, 0.2818, 0.3108, 0.2715, 0.3025, 0.3026, 0.2270, 0.2316, 0.3898,
        0.4417, 0.3098, 0.2729, 0.2571, 0.2901, 0.3525, 0.4230, 0.2812, 0.3207,
        0.3572, 0.4295, 0.3326, 0.4670, 0.3957, 0.2627, 0.4168, 0.3957, 0.2956,
        0.3223, 0.3050, 0.4260, 0.3970, 0.3441, 0.5368, 0.3970, 0.4690, 0.3664,
        0.3992, 0.3945, 0.3868, 0.3394, 0.3960, 0.5327, 0.2630, 0.5047, 0.3492,
        0.3320, 0.4292, 0.5540, 0.3049, 0.3333, 0.4012, 0.4703, 0.3040, 0.4012,
        0.2858, 0.5164, 0.3426, 0.4012, 0.4141, 0.2782, 0.2710, 0.3934, 0.4318,
        0.2890, 0.2964, 0.4436, 0.3982, 0.2727, 0.3865, 0.2952, 0.4619, 0.5238,
        0.3578, 0.4666, 0.1889, 0.2919, 0.5116, 0.5116, 0.4758, 0.2650, 0.3649,
        0.4280, 0.3287, 0.3981, 0.4016, 0.4117, 0.3494, 0.2714, 0.3228, 0.3248,
        0.3619, 0.3792, 0.3374, 0.3248, 0.3759, 0.3374, 0.3490, 0.3759, 0.2694,
        0.2786, 0.4098, 0.2786, 0.4098, 0.3797, 0.2841, 0.3318, 0.3773, 0.3351,
        0.2871, 0.3991, 0.3784, 0.3991, 0.3650, 0.5146, 0.2605, 0.3882, 0.3991,
        0.3882, 0.3089, 0.5224, 0.2894, 0.3411, 0.3772, 0.3163, 0.4536, 0.3356,
        0.3356, 0.3356, 0.3080, 0.4059, 0.3045, 0.2193, 0.2798, 0.5098, 0.3912,
        0.2629, 0.4282, 0.2773, 0.4035, 0.3851, 0.3851, 0.3835, 0.5050, 0.3953,
        0.3851, 0.4696, 0.2750, 0.3490, 0.2781, 0.5406, 0.4014, 0.2377, 0.3913,
        0.4558, 0.4014, 0.5301, 0.3140, 0.3476, 0.3025, 0.5253, 0.3984, 0.3025,
        0.3984, 0.3984, 0.4327, 0.3606, 0.3984, 0.4475, 0.3886, 0.3349, 0.2716,
        0.3886, 0.3886, 0.4690, 0.2716, 0.4659, 0.3139, 0.3886, 0.4520, 0.2928,
        0.3919, 0.4404, 0.3927, 0.3919, 0.3919, 0.2779, 0.4716, 0.4862, 0.3914,
        0.2787, 0.2833, 0.2963, 0.2182, 0.3475, 0.2787, 0.3549, 0.3966, 0.2853,
        0.3889, 0.3409, 0.2786, 0.2797, 0.3967, 0.5182, 0.3092, 0.2786, 0.2423,
        0.5182, 0.2801, 0.4265, 0.3985, 0.2801, 0.3135, 0.4092, 0.2801, 0.4152,
        0.5566, 0.3985, 0.3745, 0.3808, 0.4313, 0.3368, 0.2158, 0.2752, 0.4471,
        0.2930, 0.2752, 0.3887, 0.3028, 0.2941, 0.2941, 0.2941, 0.2620, 0.4006,
        0.2941, 0.2941, 0.3152, 0.2941, 0.2707, 0.3785, 0.2510, 0.3477, 0.4194,
        0.2707, 0.2707, 0.3934, 0.2844, 0.2614, 0.3202, 0.2535, 0.3658, 0.3122,
        0.2479, 0.2998, 0.3006, 0.3257, 0.4071, 0.4588, 0.3496, 0.3754, 0.5158,
        0.2205, 0.2667, 0.4003, 0.3013, 0.4334, 0.4287, 0.3481, 0.4996, 0.2754,
        0.2754, 0.1759, 0.2754, 0.2754, 0.2058, 0.2754, 0.3019, 0.2620, 0.2872,
        0.3897, 0.4483, 0.4074, 0.2875, 0.5392, 0.4651, 0.2872, 0.2608, 0.3133,
        0.3710, 0.4645, 0.3172, 0.4902, 0.3962, 0.4093, 0.4093, 0.3811, 0.3653,
        0.3297, 0.5470, 0.4636, 0.3453, 0.2634, 0.3995, 0.3121, 0.2712, 0.2712,
        0.4047, 0.2378, 0.3040, 0.3978, 0.5255, 0.3978, 0.3318, 0.3978, 0.4068,
        0.4068, 0.3978, 0.3978, 0.2619, 0.5200, 0.3949, 0.4682, 0.5200, 0.3920,
        0.2324, 0.3920, 0.3152, 0.2839, 0.3223, 0.2604, 0.2604, 0.3279, 0.3734,
        0.2894, 0.2985, 0.3528, 0.3223, 0.3803, 0.3192, 0.4559, 0.4600, 0.4222,
        0.2922, 0.3994, 0.5294, 0.4559, 0.2875, 0.2046, 0.4192, 0.2839, 0.3294,
        0.2665, 0.4144, 0.2620, 0.3786, 0.2908, 0.4461, 0.2688, 0.5372, 0.3870,
        0.3364, 0.3102, 0.3797, 0.2713, 0.4550, 0.3467, 0.3870, 0.2801, 0.2707,
        0.4098, 0.3001, 0.3032, 0.4127, 0.3001, 0.4044, 0.3059, 0.4036, 0.2929,
        0.3027, 0.4010, 0.3963, 0.5055, 0.3691, 0.4359, 0.3043, 0.2755, 0.3039,
        0.2952, 0.1289, 0.4276, 0.2088, 0.2724, 0.3675, 0.1696, 0.3868, 0.2837,
        0.2724, 0.3324, 0.3995, 0.5117, 0.5333, 0.3995, 0.3233, 0.4507, 0.2526,
        0.3636, 0.4115, 0.4115, 0.3967, 0.3641, 0.3958, 0.3445, 0.4169, 0.3967,
        0.3445, 0.3445, 0.3445, 0.3967, 0.4895, 0.2611, 0.2995, 0.2737, 0.4150,
        0.2995, 0.3749, 0.2737, 0.4836, 0.3383, 0.3970, 0.4224, 0.4563, 0.2796,
        0.4563, 0.2866, 0.2969, 0.3136, 0.2733, 0.2920, 0.2863, 0.1913, 0.2980,
        0.3545, 0.3060, 0.3044, 0.2980, 0.2863, 0.2609, 0.2863, 0.3894, 0.2890,
        0.3843, 0.2348, 0.3521, 0.3751, 0.3045, 0.4029, 0.3066, 0.3127, 0.2761,
        0.3369, 0.3887, 0.3834, 0.4015, 0.4746, 0.2881, 0.4193, 0.2809, 0.2809,
        0.3723, 0.2665, 0.2665, 0.2665, 0.3591, 0.2088, 0.2761, 0.2088, 0.3723,
        0.2472, 0.3236, 0.3198, 0.3198, 0.3198, 0.3198, 0.4162, 0.3198, 0.2973,
        0.2866, 0.2866, 0.3798, 0.2823, 0.2823, 0.3138, 0.3739, 0.3798, 0.3456,
        0.3138, 0.3903, 0.2105, 0.3964, 0.3964, 0.3964, 0.3964, 0.4736, 0.3014,
        0.3964, 0.4423, 0.3652, 0.5242, 0.3805, 0.2706, 0.4580, 0.3805, 0.3920,
        0.3805, 0.3920, 0.3805, 0.2706, 0.2831, 0.5530, 0.3289, 0.4750, 0.3966,
        0.3289, 0.4199, 0.2992, 0.2895, 0.4835, 0.2992, 0.3804, 0.3401, 0.3902,
        0.4210, 0.3902, 0.3996, 0.4549, 0.3415, 0.3902, 0.3902, 0.3970, 0.3905,
        0.3905, 0.4056, 0.3905, 0.3905, 0.2830, 0.5200, 0.3905, 0.3905, 0.3237,
        0.3900, 0.4656, 0.5203, 0.2833, 0.5275, 0.2788, 0.3172, 0.3900, 0.4962,
        0.3248, 0.4180, 0.4678, 0.3947, 0.3925, 0.4633, 0.4180, 0.4026, 0.3925,
        0.2543, 0.4010, 0.2829, 0.3766, 0.2829, 0.4841, 0.2829, 0.3867, 0.2829,
        0.4063, 0.2527, 0.3569, 0.3798, 0.3936, 0.2799, 0.3826, 0.2799, 0.2706,
        0.3936, 0.3966, 0.2074, 0.3488, 0.3896, 0.3508, 0.4460, 0.4006, 0.3508,
        0.3896, 0.3896, 0.3816, 0.3896, 0.2513, 0.4142, 0.2810, 0.2061, 0.2624,
        0.2510, 0.2741, 0.4011, 0.2930, 0.2184, 0.4380, 0.4638, 0.2649, 0.4705,
        0.4724, 0.2705, 0.5484, 0.3229, 0.3623, 0.3068, 0.4646, 0.2529, 0.3914,
        0.3914, 0.3869, 0.3879, 0.3914, 0.3914, 0.3914, 0.3164, 0.3318, 0.2563,
        0.2186, 0.3895, 0.1599, 0.3081, 0.3515, 0.4534, 0.4534, 0.3944, 0.2669,
        0.4395, 0.3660, 0.3209, 0.3392, 0.3881, 0.3113, 0.3979, 0.2654, 0.2899,
        0.2487, 0.3900, 0.2487, 0.3320, 0.3900, 0.2603, 0.2519, 0.4096, 0.3900,
        0.1695, 0.2864, 0.3921, 0.1797, 0.3998, 0.3470, 0.5233, 0.2888, 0.3921,
        0.1962, 0.3065, 0.2211, 0.4125, 0.3957, 0.2896, 0.2896, 0.2512, 0.3957,
        0.2179, 0.2875, 0.3015, 0.5346, 0.4376, 0.2601, 0.2245, 0.3585, 0.4109,
        0.2869, 0.2869, 0.4648, 0.3908, 0.3996, 0.2839, 0.3003, 0.3996, 0.4103,
        0.3553, 0.3625, 0.3996, 0.3097, 0.4725, 0.2933, 0.3446, 0.3106, 0.4025,
        0.2862, 0.4522, 0.2713, 0.3975, 0.5290, 0.4148, 0.3081, 0.3849, 0.2773,
        0.2773, 0.3537, 0.2580, 0.5240, 0.3979, 0.3893, 0.3637, 0.4288, 0.3604,
        0.3604, 0.3604, 0.3604, 0.3706, 0.3604, 0.3862, 0.3507, 0.3580, 0.4379,
        0.2516, 0.2154, 0.3736, 0.3736, 0.3336, 0.4515, 0.2861, 0.3736, 0.4514,
        0.4008, 0.2838, 0.4008, 0.4008, 0.4008, 0.4330, 0.2988, 0.4097, 0.3400,
        0.2988, 0.3160, 0.2987, 0.1645, 0.2774, 0.3284, 0.2987, 0.2222, 0.2876,
        0.2940, 0.3092, 0.2682, 0.3592, 0.2735, 0.3908, 0.2656, 0.2513, 0.2656,
        0.3819, 0.2682, 0.3592, 0.4764, 0.3472, 0.3608, 0.4168, 0.4325, 0.4038,
        0.3102, 0.3102, 0.4002, 0.5182, 0.4039, 0.5225, 0.2928, 0.3046, 0.4016,
        0.2077, 0.3045, 0.2983, 0.4486, 0.3701], grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0.,
        0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0.,
        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0.,
        1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0.,
        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0.,
        1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.])
loss:  tensor(0.6723, grad_fn=<MeanBackward0>) l2:  tensor(0.3466, grad_fn=<AddBackward0>) l2*coef tensor(3.4664e-05, grad_fn=<MulBackward0>)
Iteration 40, loss: 0.6814045861363411
Epoch 2; time 0.8308
epoch 2 validating; auc: 0.5810
Model (checkpoint) saved to output/ml1m/env/ml1m_user_env_lr0.0003_reg0.0001.model

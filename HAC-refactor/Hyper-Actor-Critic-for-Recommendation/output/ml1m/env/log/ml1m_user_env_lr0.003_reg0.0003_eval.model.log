Namespace(model='ML1MUserResponse', reader='ML1MDataReader')
Namespace(seed=19, batch_size=128, lr=0.003, epoch=2, model_path='output/ml1m/env/ml1m_user_env_lr0.003_reg0.0003_eval.model', loss='bce', l2_coef=0.0003, feature_dim=16, attn_n_head=2, hidden_dims=[256], dropout_rate=0.2, train_file='dataset/ml1m/ml1m_b_test.csv', val_file='dataset/ml1m/ml1m_b_test.csv', test_file='', n_worker=4, data_separator='@', user_meta_file='dataset/ml1m/user_info.npy', item_meta_file='dataset/ml1m/item_info.npy', max_seq_len=50, meta_data_separator=' ')
init ml1m reader
Loading data filesLoad item meta data
{'length': 713, 'n_item': 1682, 'item_vec_size': 19, 'user_portrait_len': 24, 'max_seq_len': 50}
{'length': 713, 'n_item': 1682, 'item_vec_size': 19, 'user_portrait_len': 24, 'max_seq_len': 50}
epoch 1 training
self.sigmoid(preds):  tensor([0.5079, 0.5044, 0.5047,  ..., 0.5243, 0.5243, 0.5075],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6995, grad_fn=<MeanBackward0>) l2:  tensor(0.3466, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4713, 0.4973, 0.4590,  ..., 0.4980, 0.4577, 0.4736],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 1.,  ..., 1., 0., 0.])
loss:  tensor(0.7230, grad_fn=<MeanBackward0>) l2:  tensor(0.3449, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4732, 0.4679, 0.5038,  ..., 0.4780, 0.4955, 0.4688],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 0., 0., 1.])
loss:  tensor(0.7058, grad_fn=<MeanBackward0>) l2:  tensor(0.3437, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4436, 0.4453, 0.4436,  ..., 0.4701, 0.4590, 0.4696],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 1.,  ..., 1., 1., 0.])
loss:  tensor(0.7056, grad_fn=<MeanBackward0>) l2:  tensor(0.3427, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4328, 0.4228, 0.4565,  ..., 0.4046, 0.4076, 0.4022],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.7140, grad_fn=<MeanBackward0>) l2:  tensor(0.3421, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3810, 0.3907, 0.4143, 0.3787, 0.3537, 0.3907, 0.3949, 0.3897, 0.3897,
        0.4485, 0.3762, 0.3811, 0.3680, 0.3811, 0.3680, 0.3481, 0.3762, 0.3762,
        0.3734, 0.3762, 0.3550, 0.3977, 0.3860, 0.3637, 0.4045, 0.4238, 0.4506,
        0.3515, 0.4092, 0.4146, 0.4105, 0.4105, 0.4215, 0.4300, 0.4300, 0.4215,
        0.3659, 0.4300, 0.3701, 0.3827, 0.3736, 0.4231, 0.3912, 0.3736, 0.4361,
        0.3912, 0.3912, 0.3830, 0.3721, 0.4137, 0.3994, 0.3896, 0.4512, 0.3994,
        0.4045, 0.4045, 0.3983, 0.3644, 0.3644, 0.3880, 0.4323, 0.4476, 0.4024,
        0.3902, 0.4035, 0.3932, 0.3779, 0.4045, 0.4417, 0.4280, 0.3900, 0.3900,
        0.3997, 0.4403, 0.3991, 0.3999, 0.3997, 0.3665, 0.4437, 0.4380, 0.3581,
        0.3722, 0.4121, 0.4263, 0.3627, 0.3952, 0.4364, 0.3952, 0.3542, 0.4163,
        0.4323, 0.4027, 0.4323, 0.4189, 0.4323, 0.3920, 0.4189, 0.4335, 0.4238,
        0.4089, 0.3802, 0.3927, 0.4187, 0.3927, 0.3708, 0.4343, 0.3927, 0.3902,
        0.3924, 0.3919, 0.4326, 0.4054, 0.3909, 0.4328, 0.4184, 0.3665, 0.4020,
        0.4020, 0.3778, 0.3999, 0.3862, 0.3555, 0.3658, 0.3771, 0.3844, 0.3040,
        0.4021, 0.3632, 0.3562, 0.4264, 0.4246, 0.3848, 0.4368, 0.4359, 0.3896,
        0.3868, 0.3781, 0.4222, 0.3472, 0.3896, 0.3941, 0.4366, 0.3436, 0.4000,
        0.4069, 0.4523, 0.4000, 0.4069, 0.4009, 0.4000, 0.3847, 0.3729, 0.3824,
        0.4213, 0.4127, 0.3847, 0.3847, 0.3847, 0.3282, 0.3462, 0.3788, 0.4624,
        0.3908, 0.4235, 0.4029, 0.4029, 0.4335, 0.4021, 0.4029, 0.4029, 0.4002,
        0.4190, 0.4002, 0.4297, 0.4025, 0.3713, 0.3983, 0.4014, 0.4002, 0.4002,
        0.3895, 0.4224, 0.4335, 0.4296, 0.3659, 0.3916, 0.4168, 0.3916, 0.4022,
        0.4059, 0.4220, 0.3865, 0.3952, 0.3889, 0.3659, 0.4132, 0.4174, 0.3889,
        0.4359, 0.3952, 0.3982, 0.3942, 0.3813, 0.3942, 0.4162, 0.3982, 0.3717,
        0.4286, 0.3982, 0.4618, 0.4283, 0.4511, 0.4048, 0.4030, 0.3880, 0.4048,
        0.4048, 0.4445, 0.4818, 0.3944, 0.4203, 0.3141, 0.4123, 0.3830, 0.4319,
        0.3727, 0.3727, 0.3321, 0.3830, 0.3727, 0.4404, 0.3965, 0.3982, 0.4036,
        0.4397, 0.4052, 0.3732, 0.4052, 0.3867, 0.3982, 0.3621, 0.3901, 0.3823,
        0.3917, 0.3445, 0.3765, 0.3823, 0.4125, 0.4153, 0.4079, 0.3942, 0.4308,
        0.4343, 0.3546, 0.4409, 0.3810, 0.3757, 0.4618, 0.4246, 0.4403, 0.3742,
        0.3972, 0.3782, 0.2889, 0.4225, 0.2889, 0.3585, 0.3782, 0.3782, 0.3272,
        0.3915, 0.4359, 0.4045, 0.4000, 0.4045, 0.4030, 0.4045, 0.4030, 0.4030,
        0.3985, 0.3951, 0.3638, 0.3951, 0.4777, 0.3563, 0.4049, 0.3883, 0.3951,
        0.4127, 0.4201, 0.3941, 0.3909, 0.3764, 0.3450, 0.3567, 0.4068, 0.3860,
        0.3904, 0.3947, 0.3710, 0.3986, 0.3803, 0.3947, 0.3657, 0.3924, 0.3947,
        0.3816, 0.3657, 0.3654, 0.3878, 0.3987, 0.3883, 0.4440, 0.3943, 0.3833,
        0.3883, 0.4060, 0.4081, 0.4385, 0.4059, 0.3726, 0.3816, 0.4293, 0.3830,
        0.3767, 0.3765, 0.4293, 0.4053, 0.3742, 0.3881, 0.3852, 0.3852, 0.3989,
        0.3958, 0.3989, 0.3921, 0.3786, 0.4471, 0.4049, 0.3765, 0.3901, 0.3466,
        0.3693, 0.4116, 0.3833, 0.3832, 0.3522, 0.3833, 0.3901, 0.4017, 0.3892,
        0.3892, 0.4268, 0.3054, 0.3672, 0.4337, 0.3445, 0.3892, 0.3892, 0.3943,
        0.3844, 0.3800, 0.3844, 0.3703, 0.4262, 0.4118, 0.3859, 0.3908, 0.3584,
        0.4602, 0.4115, 0.4335, 0.3742, 0.3847, 0.4226, 0.3847, 0.3975, 0.3463,
        0.3847, 0.3500, 0.4220, 0.3404, 0.3995, 0.4382, 0.3779, 0.3945, 0.4336,
        0.3689, 0.3885, 0.4227, 0.3694, 0.4465, 0.3860, 0.3927, 0.3694, 0.3367,
        0.4813, 0.3517, 0.3960, 0.4060, 0.4265, 0.3889, 0.3736, 0.3629, 0.4217,
        0.3851, 0.3828, 0.3900, 0.3828, 0.3962, 0.3730, 0.3973, 0.3912, 0.4000,
        0.3772, 0.3970, 0.3970, 0.3750, 0.4007, 0.3991, 0.3901, 0.3457, 0.3995,
        0.4107, 0.4251, 0.3472, 0.4001, 0.3501, 0.3524, 0.3883, 0.4449, 0.4058,
        0.4122, 0.3910, 0.4058, 0.4004, 0.4383, 0.4004, 0.4058, 0.4058, 0.3692,
        0.3878, 0.3819, 0.3944, 0.3944, 0.3679, 0.4192, 0.4192, 0.4365, 0.3995,
        0.3539, 0.3965, 0.4409, 0.3827, 0.4395, 0.3965, 0.3939, 0.3678, 0.3946,
        0.4163, 0.3815, 0.3938, 0.3913, 0.3864, 0.3493, 0.3561, 0.3730, 0.3957,
        0.3868, 0.4747, 0.4305, 0.4213, 0.4213, 0.4305, 0.4305, 0.4305, 0.4305,
        0.3991, 0.4081, 0.3881, 0.3982, 0.4323, 0.4352, 0.4038, 0.4038, 0.3994,
        0.3982, 0.4038, 0.4380, 0.3894, 0.3765, 0.3848, 0.4280, 0.3911, 0.3911,
        0.3911, 0.4344, 0.4054, 0.3812, 0.3765, 0.4315, 0.4315, 0.3685, 0.4231,
        0.4222, 0.4315, 0.4315, 0.4315, 0.4654, 0.4227, 0.3969, 0.3886, 0.3886,
        0.3892, 0.3767, 0.3969, 0.3890, 0.4155, 0.3895, 0.3972, 0.4000, 0.3792,
        0.3937, 0.3691, 0.4092, 0.3965, 0.3701, 0.3951, 0.4247, 0.4077, 0.3800,
        0.4031, 0.4055, 0.3929, 0.4169, 0.4055, 0.3996, 0.4504, 0.4410, 0.4168,
        0.3721, 0.3721, 0.4101, 0.3962, 0.3721, 0.3962, 0.4061, 0.3683, 0.3446,
        0.3828, 0.3461, 0.3963, 0.4102, 0.3889, 0.3915, 0.4445, 0.3957, 0.4297,
        0.3915, 0.3915, 0.3928, 0.4372, 0.4197, 0.4372, 0.3775, 0.4116, 0.3703,
        0.3420, 0.3999, 0.4044, 0.4226, 0.4245, 0.3619, 0.3711, 0.4532, 0.3841,
        0.3841, 0.3972, 0.3725, 0.4320, 0.3686, 0.4000, 0.3921, 0.3978, 0.3742,
        0.3686, 0.3978, 0.3889, 0.3789, 0.3921, 0.4202, 0.4035, 0.3813, 0.3782,
        0.4067, 0.3630, 0.3572, 0.3984, 0.3968, 0.3630, 0.3941, 0.4136, 0.4229,
        0.4348, 0.4323, 0.4229, 0.4033, 0.4229, 0.3903, 0.4204, 0.4143, 0.3378,
        0.3866, 0.3822, 0.3866, 0.3325, 0.3822, 0.3639, 0.3822, 0.4030, 0.4801,
        0.4281, 0.3958, 0.4219, 0.4447, 0.4195, 0.3938, 0.3837, 0.3572, 0.3902,
        0.3952, 0.4038, 0.4038, 0.4409, 0.3952, 0.4038, 0.4038, 0.4038, 0.3952,
        0.3839, 0.4056, 0.4056, 0.4094, 0.3935, 0.4469, 0.3896, 0.3685, 0.4378,
        0.3999, 0.4532, 0.4015, 0.3920, 0.4015, 0.4079, 0.4485, 0.4421, 0.4275,
        0.4079, 0.4474, 0.4079, 0.3666, 0.3859, 0.3846, 0.3236, 0.3805, 0.4355,
        0.3677, 0.4209, 0.4212, 0.3711, 0.3691, 0.4349, 0.3500, 0.3982, 0.4127,
        0.3837, 0.4387, 0.4021, 0.3975, 0.4428, 0.3640, 0.3766, 0.3247, 0.3766,
        0.4147, 0.3413, 0.3950, 0.3766, 0.3766, 0.4002, 0.3320, 0.4014, 0.3857,
        0.3909, 0.4020, 0.4035, 0.4517, 0.4517, 0.3810, 0.4173, 0.3848, 0.3848,
        0.3848, 0.3848, 0.3848, 0.3938, 0.3938, 0.3967, 0.3938, 0.3938, 0.4007,
        0.3525, 0.3715, 0.3871, 0.3583, 0.3984, 0.4187, 0.3728, 0.3728, 0.4007,
        0.4345, 0.4391, 0.4210, 0.3794, 0.4391, 0.4223, 0.4287, 0.4180, 0.4391,
        0.4391], grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1.,
        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0.,
        1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,
        1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0.,
        0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1.,
        1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,
        1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1.,
        1., 0., 1., 0., 1., 0., 0., 0., 1., 0.])
loss:  tensor(0.7109, grad_fn=<MeanBackward0>) l2:  tensor(0.3417, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
Epoch 1; time 0.2377
epoch 1 validating; auc: 0.5382
Model (checkpoint) saved to output/ml1m/env/ml1m_user_env_lr0.003_reg0.0003_eval.model
epoch 2 training
self.sigmoid(preds):  tensor([0.3221, 0.3479, 0.3422,  ..., 0.3466, 0.3085, 0.3026],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 1.,  ..., 0., 0., 0.])
loss:  tensor(0.6979, grad_fn=<MeanBackward0>) l2:  tensor(0.3415, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.2981, 0.2872, 0.2860,  ..., 0.2883, 0.2515, 0.3143],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 1.,  ..., 1., 1., 0.])
loss:  tensor(0.7038, grad_fn=<MeanBackward0>) l2:  tensor(0.3415, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.2686, 0.2493, 0.1998,  ..., 0.3425, 0.3138, 0.3425],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 1.,  ..., 0., 0., 0.])
loss:  tensor(0.6973, grad_fn=<MeanBackward0>) l2:  tensor(0.3418, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.1408, 0.1870, 0.2313,  ..., 0.2348, 0.2374, 0.2558],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 1.,  ..., 1., 0., 1.])
loss:  tensor(0.6911, grad_fn=<MeanBackward0>) l2:  tensor(0.3422, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.1847, 0.2158, 0.2212,  ..., 0.1747, 0.1897, 0.1897],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 0., 0.])
loss:  tensor(0.6906, grad_fn=<MeanBackward0>) l2:  tensor(0.3427, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.1148, 0.1355, 0.1742, 0.1336, 0.1302, 0.1729, 0.1742, 0.1302, 0.2822,
        0.1742, 0.1349, 0.1761, 0.1338, 0.1201, 0.0974, 0.1471, 0.0921, 0.1594,
        0.3623, 0.0878, 0.1046, 0.1518, 0.0933, 0.1575, 0.1021, 0.1142, 0.1912,
        0.1309, 0.1455, 0.1816, 0.1302, 0.1495, 0.0755, 0.2056, 0.1495, 0.1254,
        0.1254, 0.1254, 0.1495, 0.1089, 0.1358, 0.1034, 0.1403, 0.1830, 0.0888,
        0.0732, 0.0931, 0.1830, 0.1046, 0.1421, 0.1319, 0.1319, 0.1319, 0.1319,
        0.1547, 0.1547, 0.2075, 0.1409, 0.2511, 0.0940, 0.2249, 0.1730, 0.1730,
        0.1730, 0.2871, 0.1604, 0.1730, 0.1730, 0.1044, 0.1404, 0.1789, 0.1789,
        0.1789, 0.0396, 0.0553, 0.0553, 0.0445, 0.0592, 0.0672, 0.0672, 0.0866,
        0.1714, 0.1404, 0.1167, 0.1714, 0.0552, 0.1334, 0.1418, 0.1714, 0.0991,
        0.0952, 0.1110, 0.0541, 0.1037, 0.1110, 0.1037, 0.1110, 0.0952, 0.0952,
        0.1226, 0.2265, 0.1569, 0.0628, 0.0882, 0.1048, 0.0575, 0.0297, 0.0773,
        0.1244, 0.2796, 0.2225, 0.1214, 0.1615, 0.1550, 0.1270, 0.2108, 0.1896,
        0.1213, 0.2108, 0.1510, 0.1807, 0.1490, 0.2144, 0.2049, 0.1042, 0.1088,
        0.0926, 0.0593, 0.1794, 0.1138, 0.1364, 0.1051, 0.1334, 0.1577, 0.2393,
        0.1761, 0.1590, 0.2099, 0.1590, 0.1480, 0.1327, 0.1327, 0.1085, 0.1327,
        0.1327, 0.1696, 0.0839, 0.1397, 0.0951, 0.0465, 0.1306, 0.1254, 0.1520,
        0.0575, 0.1150, 0.1260, 0.2815, 0.1373, 0.1373, 0.1829, 0.0895, 0.1887,
        0.2361, 0.1082, 0.1082, 0.1595, 0.1968, 0.1968, 0.0916, 0.0888, 0.1835,
        0.1480, 0.1835, 0.1233, 0.1233, 0.0795, 0.1258, 0.1835, 0.3051, 0.2245,
        0.1341, 0.0879, 0.2574, 0.1414, 0.1414, 0.1426, 0.2932, 0.0879, 0.1341,
        0.1190, 0.2021, 0.2021, 0.1904, 0.1314, 0.1437, 0.1904, 0.1904, 0.1521,
        0.1521, 0.1568, 0.1341, 0.1314, 0.1606, 0.1314, 0.2309, 0.0695, 0.1017,
        0.2440, 0.1936, 0.2843, 0.1986, 0.1519, 0.2045, 0.1927, 0.1457, 0.1333,
        0.1457, 0.0958, 0.1079, 0.0769, 0.1029, 0.2227, 0.1099, 0.0757, 0.0757,
        0.3364, 0.1785, 0.0864, 0.1255, 0.1905, 0.2858, 0.2273, 0.1146, 0.0806,
        0.0645, 0.1041, 0.1242, 0.1513, 0.1219, 0.0872, 0.1372, 0.1372, 0.1410,
        0.2104, 0.1171, 0.1291, 0.1522, 0.1037, 0.1291, 0.0466, 0.0689, 0.0689,
        0.0174, 0.1233, 0.1233, 0.1162, 0.0368, 0.0565, 0.1116, 0.1362, 0.1276,
        0.0743, 0.0650, 0.0791, 0.0735, 0.0703, 0.0486, 0.1113, 0.1025, 0.0701,
        0.1777, 0.1777, 0.1356, 0.1193, 0.0910, 0.1777, 0.1116, 0.1777, 0.1356,
        0.1435, 0.2076, 0.1451, 0.1423, 0.1451, 0.1469, 0.2600, 0.0932, 0.0815,
        0.1705, 0.1291, 0.1894, 0.0955, 0.2580, 0.1894, 0.1558, 0.1438, 0.1438,
        0.1438, 0.1894, 0.1894, 0.1395, 0.1503, 0.0945, 0.1231, 0.2462, 0.1715,
        0.1793, 0.1503, 0.2985, 0.1634, 0.2269, 0.1093, 0.0682, 0.2053, 0.2337,
        0.1442, 0.1602, 0.1602, 0.1602, 0.2053, 0.1178, 0.2614, 0.1264, 0.1429,
        0.1429, 0.1526, 0.1429, 0.1429, 0.1429, 0.0527, 0.1296, 0.1254, 0.1049,
        0.0859, 0.1690, 0.1049, 0.1103, 0.0859, 0.0455, 0.0924, 0.1616, 0.0523,
        0.1340, 0.1439, 0.2009, 0.1439, 0.1755, 0.1115, 0.1433, 0.1755, 0.0927,
        0.1204, 0.1795, 0.1368, 0.1189, 0.0927, 0.1368, 0.1356, 0.1386, 0.1795,
        0.0989, 0.2178, 0.1078, 0.1091, 0.1091, 0.1081, 0.1091, 0.0989, 0.2704,
        0.1177, 0.0633, 0.1000, 0.1268, 0.1564, 0.1268, 0.1268, 0.1134, 0.1221,
        0.0937, 0.1028, 0.0426, 0.0934, 0.1256, 0.1004, 0.1174, 0.1361, 0.0934,
        0.1183, 0.1174, 0.1004, 0.2969, 0.2155, 0.1714, 0.1360, 0.1277, 0.1516,
        0.2475, 0.1911, 0.0901, 0.1352, 0.2539, 0.0868, 0.1159, 0.1929, 0.3102,
        0.1568, 0.1728, 0.1837, 0.2315, 0.1837, 0.1766, 0.1580, 0.1293, 0.1293,
        0.1580, 0.1237, 0.1144, 0.1580, 0.1770, 0.1005, 0.1336, 0.1523, 0.1523,
        0.1128, 0.1202, 0.1523, 0.1793, 0.2534, 0.1202, 0.1171, 0.2461, 0.1686,
        0.1843, 0.1353, 0.1828, 0.0827, 0.1060, 0.2243, 0.1644, 0.0883, 0.3049,
        0.1736, 0.0993, 0.0993, 0.1358, 0.1810, 0.1358, 0.1396, 0.0755, 0.1736,
        0.1217, 0.2560, 0.1122, 0.1808, 0.1507, 0.1002, 0.0891, 0.1329, 0.1350,
        0.1507, 0.0878, 0.1193, 0.1973, 0.2319, 0.1538, 0.1075, 0.1971, 0.1538,
        0.3171, 0.1971, 0.1871, 0.0958, 0.2165, 0.0628, 0.2165, 0.2002, 0.2165,
        0.2165, 0.1558, 0.2165, 0.1762, 0.1538, 0.3172, 0.2350, 0.1644, 0.1345,
        0.1756, 0.1671, 0.1671, 0.1671, 0.0998, 0.2155, 0.2155, 0.2155, 0.2155,
        0.2118, 0.2155, 0.1037, 0.2155, 0.1525, 0.2082, 0.1500, 0.1049, 0.0443,
        0.1642, 0.1819, 0.0975, 0.1407, 0.1416, 0.0922, 0.0691, 0.1596, 0.1285,
        0.2633, 0.1144, 0.0717, 0.1458, 0.1651, 0.1127, 0.1038, 0.1463, 0.1650,
        0.1349, 0.2833, 0.1977, 0.0927, 0.0820, 0.0927, 0.1323, 0.1196, 0.1273,
        0.1273, 0.1273, 0.1711, 0.0990, 0.0823, 0.1845, 0.1168, 0.1273, 0.0918,
        0.2294, 0.1902, 0.1354, 0.0755, 0.1228, 0.0923, 0.1354, 0.1236, 0.0988,
        0.1769, 0.2482, 0.1613, 0.1552, 0.0859, 0.1905, 0.1588, 0.1266, 0.0737,
        0.1373, 0.0859, 0.2274, 0.1334, 0.1227, 0.1227, 0.1227, 0.1227, 0.2274,
        0.1490, 0.1490, 0.1114, 0.0993, 0.1210, 0.2369, 0.0993, 0.1300, 0.1219,
        0.1269, 0.1749, 0.1749, 0.0993, 0.2826, 0.0865, 0.2023, 0.0909, 0.1252,
        0.1628, 0.1255, 0.0486, 0.1318, 0.1318, 0.2030, 0.1364, 0.1132, 0.2358,
        0.1947, 0.1187, 0.1947, 0.1635, 0.2269, 0.1401, 0.1098, 0.1331, 0.1017,
        0.1331, 0.0620, 0.1119, 0.0843, 0.1017, 0.1017, 0.1017, 0.0872, 0.1247,
        0.1602, 0.1079, 0.1825, 0.1303, 0.1930, 0.0511, 0.1332, 0.1898, 0.1228,
        0.1661, 0.1661, 0.1291, 0.1334, 0.1072, 0.1661, 0.1852, 0.0857, 0.1661,
        0.0966, 0.1159, 0.1339, 0.0710, 0.0741, 0.0934, 0.0741, 0.1159, 0.1765,
        0.0754, 0.2664, 0.1419, 0.1377, 0.1270, 0.1167, 0.2432, 0.1412, 0.2104,
        0.1412, 0.2432, 0.1518, 0.2248, 0.1518, 0.1518, 0.0723, 0.1329, 0.1696,
        0.0944, 0.0397, 0.2666, 0.0795, 0.1029, 0.0795, 0.0632, 0.2224, 0.1394,
        0.0804, 0.1219, 0.1109, 0.0804, 0.1651, 0.1215, 0.1066, 0.2820, 0.1260,
        0.1651, 0.1651, 0.1651, 0.0471, 0.0718, 0.1943, 0.1932, 0.1526, 0.1033,
        0.1587, 0.1073, 0.1250, 0.2140, 0.1472, 0.1073, 0.0867, 0.1220, 0.1121,
        0.1794, 0.0690, 0.1121, 0.1220, 0.0912, 0.1817, 0.1408, 0.1397, 0.1330,
        0.2464, 0.3067, 0.0727, 0.1226, 0.1151, 0.2084, 0.0449, 0.0727, 0.2172,
        0.1772, 0.1214, 0.2271, 0.1613, 0.0827, 0.0485, 0.1298, 0.1111, 0.2049,
        0.1073, 0.1319, 0.1073, 0.1159, 0.1928, 0.1170, 0.1535, 0.1764, 0.0842,
        0.1764], grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.,
        0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0.,
        0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0.,
        0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,
        0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0.,
        0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0.,
        0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1.,
        0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0.,
        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,
        0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 0., 1., 0., 0., 1., 1., 1., 0.])
loss:  tensor(0.6944, grad_fn=<MeanBackward0>) l2:  tensor(0.3434, grad_fn=<AddBackward0>) l2*coef tensor(0.0001, grad_fn=<MulBackward0>)
Epoch 2; time 0.1564
epoch 2 validating; auc: 0.5675
Model (checkpoint) saved to output/ml1m/env/ml1m_user_env_lr0.003_reg0.0003_eval.model

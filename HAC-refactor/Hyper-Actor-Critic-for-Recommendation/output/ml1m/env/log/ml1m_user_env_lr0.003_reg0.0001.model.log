Namespace(model='ML1MUserResponse', reader='ML1MDataReader')
Namespace(seed=19, batch_size=128, lr=0.003, epoch=2, model_path='output/ml1m/env/ml1m_user_env_lr0.003_reg0.0001.model', loss='bce', l2_coef=0.0001, feature_dim=16, attn_n_head=2, hidden_dims=[256], dropout_rate=0.2, train_file='dataset/ml1m/ml1m_b_train.csv', val_file='dataset/ml1m/ml1m_b_test.csv', test_file='', n_worker=0, data_separator='@', user_meta_file='dataset/ml1m/user_info.npy', item_meta_file='dataset/ml1m/item_info.npy', max_seq_len=50, meta_data_separator=' ')
init ml1m reader
Loading data filesLoad item meta data
{'length': 5078, 'n_item': 1682, 'item_vec_size': 19, 'user_portrait_len': 24, 'max_seq_len': 50}
{'length': 5078, 'n_item': 1682, 'item_vec_size': 19, 'user_portrait_len': 24, 'max_seq_len': 50}
epoch 1 training
self.sigmoid(preds):  tensor([0.4950, 0.4985, 0.4985,  ..., 0.5107, 0.5021, 0.5073],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.6731, grad_fn=<MeanBackward0>) l2:  tensor(0.3466, grad_fn=<AddBackward0>) l2*coef tensor(3.4657e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4978, 0.5099, 0.4924,  ..., 0.5281, 0.5078, 0.4833],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 0., 1.])
loss:  tensor(0.6981, grad_fn=<MeanBackward0>) l2:  tensor(0.3455, grad_fn=<AddBackward0>) l2*coef tensor(3.4547e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4911, 0.4693, 0.4577,  ..., 0.4800, 0.4715, 0.4887],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 1., 1., 0.])
loss:  tensor(0.7175, grad_fn=<MeanBackward0>) l2:  tensor(0.3447, grad_fn=<AddBackward0>) l2*coef tensor(3.4467e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4938, 0.5042, 0.4776,  ..., 0.4284, 0.4646, 0.4275],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6916, grad_fn=<MeanBackward0>) l2:  tensor(0.3442, grad_fn=<AddBackward0>) l2*coef tensor(3.4417e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4336, 0.4455, 0.4153,  ..., 0.4046, 0.4556, 0.3997],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 0.])
loss:  tensor(0.6805, grad_fn=<MeanBackward0>) l2:  tensor(0.3439, grad_fn=<AddBackward0>) l2*coef tensor(3.4393e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4512, 0.4656, 0.4235,  ..., 0.4224, 0.4366, 0.4214],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 0.,  ..., 1., 0., 0.])
loss:  tensor(0.6771, grad_fn=<MeanBackward0>) l2:  tensor(0.3438, grad_fn=<AddBackward0>) l2*coef tensor(3.4379e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4138, 0.4312, 0.4537,  ..., 0.4296, 0.4033, 0.4090],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 1.,  ..., 1., 1., 0.])
loss:  tensor(0.6990, grad_fn=<MeanBackward0>) l2:  tensor(0.3438, grad_fn=<AddBackward0>) l2*coef tensor(3.4377e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3818, 0.3282, 0.3933,  ..., 0.3124, 0.4325, 0.4325],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0.,  ..., 0., 1., 1.])
loss:  tensor(0.6705, grad_fn=<MeanBackward0>) l2:  tensor(0.3440, grad_fn=<AddBackward0>) l2*coef tensor(3.4401e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3632, 0.3057, 0.3632,  ..., 0.3598, 0.3602, 0.3471],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.6851, grad_fn=<MeanBackward0>) l2:  tensor(0.3441, grad_fn=<AddBackward0>) l2*coef tensor(3.4408e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4534, 0.2993, 0.2993,  ..., 0.2435, 0.3206, 0.2189],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0.,  ..., 0., 0., 0.])
loss:  tensor(0.6839, grad_fn=<MeanBackward0>) l2:  tensor(0.3443, grad_fn=<AddBackward0>) l2*coef tensor(3.4430e-05, grad_fn=<MulBackward0>)
Iteration 10, loss: 0.6876741051673889
self.sigmoid(preds):  tensor([0.1867, 0.3049, 0.2182,  ..., 0.2608, 0.2183, 0.3855],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 0., 0., 1.])
loss:  tensor(0.6734, grad_fn=<MeanBackward0>) l2:  tensor(0.3446, grad_fn=<AddBackward0>) l2*coef tensor(3.4458e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3318, 0.3142, 0.2657,  ..., 0.1697, 0.3068, 0.1858],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 0.,  ..., 1., 0., 1.])
loss:  tensor(0.6836, grad_fn=<MeanBackward0>) l2:  tensor(0.3447, grad_fn=<AddBackward0>) l2*coef tensor(3.4467e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.2966, 0.3664, 0.3313,  ..., 0.2696, 0.3028, 0.2660],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 0., 1.])
loss:  tensor(0.6781, grad_fn=<MeanBackward0>) l2:  tensor(0.3449, grad_fn=<AddBackward0>) l2*coef tensor(3.4490e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4921, 0.2159, 0.2585,  ..., 0.1461, 0.1006, 0.3720],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.6811, grad_fn=<MeanBackward0>) l2:  tensor(0.3450, grad_fn=<AddBackward0>) l2*coef tensor(3.4498e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.1311, 0.2512, 0.4156,  ..., 0.1579, 0.3016, 0.3497],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6862, grad_fn=<MeanBackward0>) l2:  tensor(0.3451, grad_fn=<AddBackward0>) l2*coef tensor(3.4506e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.1328, 0.2090, 0.4420,  ..., 0.3088, 0.1352, 0.0527],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.6669, grad_fn=<MeanBackward0>) l2:  tensor(0.3455, grad_fn=<AddBackward0>) l2*coef tensor(3.4547e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.2298, 0.2882, 0.1388,  ..., 0.2443, 0.2113, 0.3410],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 0.,  ..., 1., 1., 1.])
loss:  tensor(0.6811, grad_fn=<MeanBackward0>) l2:  tensor(0.3452, grad_fn=<AddBackward0>) l2*coef tensor(3.4524e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.2487, 0.5520, 0.1331,  ..., 0.1881, 0.1449, 0.3339],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 0., 0.])
loss:  tensor(0.6750, grad_fn=<MeanBackward0>) l2:  tensor(0.3448, grad_fn=<AddBackward0>) l2*coef tensor(3.4481e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3175, 0.4901, 0.1260,  ..., 0.3645, 0.3645, 0.1068],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.6800, grad_fn=<MeanBackward0>) l2:  tensor(0.3444, grad_fn=<AddBackward0>) l2*coef tensor(3.4441e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.8275, 0.1026, 0.2934,  ..., 0.4078, 0.1496, 0.5050],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.6707, grad_fn=<MeanBackward0>) l2:  tensor(0.3442, grad_fn=<AddBackward0>) l2*coef tensor(3.4417e-05, grad_fn=<MulBackward0>)
Iteration 20, loss: 0.6826608628034592
self.sigmoid(preds):  tensor([0.4215, 0.2016, 0.4215,  ..., 0.1998, 0.1844, 0.1241],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 1.,  ..., 1., 0., 1.])
loss:  tensor(0.6771, grad_fn=<MeanBackward0>) l2:  tensor(0.3439, grad_fn=<AddBackward0>) l2*coef tensor(3.4387e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4499, 0.0705, 0.2966,  ..., 0.1336, 0.4547, 0.6295],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 1., 0., 1.])
loss:  tensor(0.6753, grad_fn=<MeanBackward0>) l2:  tensor(0.3437, grad_fn=<AddBackward0>) l2*coef tensor(3.4374e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4967, 0.4301, 0.4301,  ..., 0.0709, 0.0236, 0.4518],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 0., 1.])
loss:  tensor(0.6629, grad_fn=<MeanBackward0>) l2:  tensor(0.3437, grad_fn=<AddBackward0>) l2*coef tensor(3.4366e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.5057, 0.5057, 0.1098,  ..., 0.4955, 0.4528, 0.4528],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 0.,  ..., 1., 1., 1.])
loss:  tensor(0.6705, grad_fn=<MeanBackward0>) l2:  tensor(0.3436, grad_fn=<AddBackward0>) l2*coef tensor(3.4361e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.1823, 0.0382, 0.4507,  ..., 0.4899, 0.3868, 0.6040],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 1., 1., 1.])
loss:  tensor(0.6740, grad_fn=<MeanBackward0>) l2:  tensor(0.3437, grad_fn=<AddBackward0>) l2*coef tensor(3.4365e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.2946, 0.5513, 0.5513,  ..., 0.8875, 0.0515, 0.0515],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 0.])
loss:  tensor(0.6848, grad_fn=<MeanBackward0>) l2:  tensor(0.3437, grad_fn=<AddBackward0>) l2*coef tensor(3.4373e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.5793, 0.0035, 0.0728,  ..., 0.7012, 0.1576, 0.7872],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 0., 1.])
loss:  tensor(0.6667, grad_fn=<MeanBackward0>) l2:  tensor(0.3438, grad_fn=<AddBackward0>) l2*coef tensor(3.4375e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.0865, 0.3621, 0.0206,  ..., 0.9312, 0.5279, 0.0501],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 0., 1., 1.])
loss:  tensor(0.6794, grad_fn=<MeanBackward0>) l2:  tensor(0.3434, grad_fn=<AddBackward0>) l2*coef tensor(3.4345e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.8518, 0.0262, 0.8780,  ..., 0.7139, 0.5043, 0.0222],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 1.,  ..., 1., 0., 0.])
loss:  tensor(0.6683, grad_fn=<MeanBackward0>) l2:  tensor(0.3433, grad_fn=<AddBackward0>) l2*coef tensor(3.4330e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.0197, 0.0300, 0.0225,  ..., 0.0300, 0.4740, 0.0029],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 0., 0., 1.])
loss:  tensor(0.6569, grad_fn=<MeanBackward0>) l2:  tensor(0.3432, grad_fn=<AddBackward0>) l2*coef tensor(3.4321e-05, grad_fn=<MulBackward0>)
Iteration 30, loss: 0.6789856135845185
self.sigmoid(preds):  tensor([0.0093, 0.1865, 0.7392,  ..., 0.0286, 0.0474, 0.4947],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6609, grad_fn=<MeanBackward0>) l2:  tensor(0.3429, grad_fn=<AddBackward0>) l2*coef tensor(3.4287e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4681, 0.0058, 0.0492,  ..., 0.4292, 0.7099, 0.1097],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 1., 1., 1.])
loss:  tensor(0.6749, grad_fn=<MeanBackward0>) l2:  tensor(0.3426, grad_fn=<AddBackward0>) l2*coef tensor(3.4258e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.7032, 0.4954, 0.5216,  ..., 0.4845, 0.0661, 0.5093],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0.,  ..., 1., 0., 0.])
loss:  tensor(0.6767, grad_fn=<MeanBackward0>) l2:  tensor(0.3422, grad_fn=<AddBackward0>) l2*coef tensor(3.4217e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.7488, 0.0233, 0.6736,  ..., 0.0284, 0.0186, 0.0222],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 1.,  ..., 0., 0., 1.])
loss:  tensor(0.6744, grad_fn=<MeanBackward0>) l2:  tensor(0.3417, grad_fn=<AddBackward0>) l2*coef tensor(3.4175e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.8406, 0.0587, 0.5027,  ..., 0.0154, 0.8711, 0.7317],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.6742, grad_fn=<MeanBackward0>) l2:  tensor(0.3413, grad_fn=<AddBackward0>) l2*coef tensor(3.4131e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.2681, 0.7831, 0.9476,  ..., 0.9895, 0.4872, 0.0014],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6736, grad_fn=<MeanBackward0>) l2:  tensor(0.3409, grad_fn=<AddBackward0>) l2*coef tensor(3.4088e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.1637, 0.4499, 0.0490,  ..., 0.6533, 0.8692, 0.2683],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0.,  ..., 1., 1., 0.])
loss:  tensor(0.6645, grad_fn=<MeanBackward0>) l2:  tensor(0.3403, grad_fn=<AddBackward0>) l2*coef tensor(3.4030e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.0058, 0.6852, 0.2072,  ..., 0.0409, 0.3164, 0.2316],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 0.,  ..., 1., 0., 0.])
loss:  tensor(0.6524, grad_fn=<MeanBackward0>) l2:  tensor(0.3397, grad_fn=<AddBackward0>) l2*coef tensor(3.3967e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.0694, 0.4729, 0.1617,  ..., 0.0422, 0.1845, 0.0088],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 0., 0.])
loss:  tensor(0.6748, grad_fn=<MeanBackward0>) l2:  tensor(0.3388, grad_fn=<AddBackward0>) l2*coef tensor(3.3884e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([3.3259e-02, 5.0055e-02, 4.6231e-01, 4.6889e-02, 5.0055e-02, 8.1895e-03,
        1.6307e-02, 4.6231e-01, 1.6307e-02, 4.6231e-01, 5.3629e-02, 1.6906e-01,
        1.9866e-01, 2.1189e-01, 4.1370e-02, 4.8036e-01, 3.1013e-02, 7.9647e-01,
        1.3647e-02, 4.6134e-02, 2.2756e-02, 4.4385e-01, 1.7102e-02, 1.3048e-03,
        1.5577e-03, 2.2334e-02, 4.8892e-02, 6.9702e-02, 2.2334e-02, 2.2334e-02,
        9.6357e-01, 4.9741e-01, 7.4293e-02, 8.1158e-04, 4.9741e-01, 8.7031e-01,
        9.0308e-01, 8.4913e-01, 4.9741e-01, 8.1706e-03, 2.2864e-02, 1.2316e-03,
        4.8521e-01, 6.2838e-02, 2.8793e-02, 7.3741e-01, 6.5174e-02, 2.5849e-02,
        4.8521e-01, 7.3741e-01, 1.6622e-01, 7.2683e-01, 3.2489e-03, 5.0582e-01,
        3.8859e-01, 3.4176e-02, 7.4562e-01, 1.9089e-02, 6.8649e-02, 1.8190e-01,
        3.4270e-01, 7.0194e-01, 4.5881e-01, 7.0409e-02, 4.5881e-01, 2.7292e-01,
        2.4549e-01, 3.7059e-02, 7.5227e-01, 9.2121e-01, 3.8464e-02, 3.8464e-02,
        2.4930e-01, 3.8464e-02, 1.0032e-01, 9.5822e-03, 4.7609e-02, 3.8464e-02,
        3.8464e-02, 3.8464e-02, 7.3079e-02, 2.8091e-02, 2.4047e-03, 2.2434e-02,
        3.9663e-01, 1.8137e-01, 4.8296e-01, 8.4895e-01, 4.8296e-01, 8.4782e-02,
        4.8501e-01, 3.3626e-02, 7.4575e-01, 3.3626e-02, 2.0699e-02, 1.8617e-01,
        8.0617e-01, 4.6633e-01, 7.6272e-01, 2.0699e-02, 1.6943e-02, 6.2075e-02,
        2.1861e-02, 2.7213e-03, 6.2075e-02, 6.2075e-02, 4.6680e-01, 7.2164e-01,
        2.1861e-02, 3.9834e-03, 8.7257e-01, 9.8709e-01, 9.6048e-01, 7.2952e-03,
        4.7658e-01, 8.0706e-01, 9.9471e-02, 2.4931e-02, 8.7257e-01, 1.2555e-02,
        4.8576e-02, 1.5573e-02, 8.5010e-04, 7.3595e-04, 1.4336e-01, 4.7918e-01,
        1.4830e-03, 2.7048e-02, 5.9671e-01, 3.5895e-02, 9.8188e-01, 2.7051e-02,
        5.1461e-01, 4.9078e-01, 2.2655e-02, 2.7051e-02, 5.1461e-01, 3.5004e-01,
        2.9471e-01, 2.7051e-02, 2.8663e-02, 1.6335e-02, 3.7961e-01, 1.6335e-02,
        1.1778e-03, 4.9163e-01, 3.6604e-01, 2.1809e-02, 6.3189e-02, 2.5922e-03,
        2.4026e-02, 8.6973e-01, 5.7383e-01, 3.4570e-02, 3.6009e-01, 9.8400e-01,
        2.4026e-02, 4.7551e-01, 7.6093e-01, 4.7551e-01, 1.1003e-01, 1.7293e-02,
        5.4720e-02, 4.2699e-01, 5.4720e-02, 5.9750e-03, 1.7421e-01, 1.5693e-03,
        7.5889e-03, 4.9849e-01, 2.2334e-02, 7.5285e-01, 1.1613e-03, 7.5285e-01,
        4.9145e-01, 1.0016e-01, 6.0496e-02, 5.9628e-01, 1.3162e-01, 6.0496e-02,
        5.7988e-01, 6.9394e-01, 6.8753e-01, 9.3868e-01, 1.9893e-02, 4.1187e-02,
        8.3987e-01, 4.1187e-02, 4.1187e-02, 4.1187e-02, 1.5522e-02, 4.5707e-02,
        4.5707e-02, 4.5707e-02, 7.2602e-01, 7.0894e-02, 7.2602e-01, 4.5354e-01,
        4.5707e-02, 4.5707e-02, 6.5215e-01, 2.5156e-02, 1.9844e-02, 1.3358e-01,
        2.4288e-01, 7.9596e-01, 1.3787e-01, 2.5156e-02, 3.6269e-01, 6.8239e-01,
        1.1406e-01, 3.5913e-02, 5.5418e-02, 1.8527e-02, 5.8960e-01, 4.9279e-02,
        1.1406e-01, 1.9256e-02, 1.1406e-01, 1.3821e-01, 3.8213e-01, 2.7802e-02,
        7.7783e-01, 1.4500e-01, 6.8996e-02, 4.9365e-01, 1.7429e-02, 9.8349e-01,
        8.5746e-01, 4.9365e-01, 3.0408e-01, 8.6306e-01, 6.2246e-01, 4.0637e-01,
        7.7507e-01, 8.6306e-01, 7.4852e-02, 8.4268e-01, 9.3718e-01, 7.2228e-01,
        3.3345e-01, 3.4596e-01, 7.0180e-01, 8.8975e-03, 3.1608e-02, 2.5567e-01,
        1.3636e-02, 3.1608e-02, 1.9039e-02, 3.1608e-02, 1.6776e-02, 1.6776e-02,
        7.2581e-01, 3.3506e-01, 4.6016e-01, 1.6776e-02, 1.3291e-02, 9.5181e-01,
        4.3315e-02, 1.8246e-03, 7.7573e-01, 2.6168e-01, 7.4961e-01, 8.6168e-01,
        1.1784e-01, 5.9897e-01, 8.6168e-01, 9.0699e-02, 7.4961e-01, 9.5720e-01,
        9.5897e-01, 4.8638e-01, 3.5182e-02, 7.9430e-01, 2.2179e-01, 4.1203e-02,
        1.9105e-02, 4.0343e-02, 1.0092e-01, 2.5449e-01, 2.3999e-01, 1.2469e-01,
        7.5609e-01, 8.5232e-01, 4.4043e-02, 5.2811e-02, 9.6301e-01, 4.8202e-01,
        7.4826e-01, 9.6301e-01, 1.6894e-02, 4.4541e-01, 1.8669e-01, 4.4541e-01,
        1.4763e-01, 4.4541e-01, 4.4541e-01, 2.2267e-02, 4.4541e-01, 1.6894e-02,
        1.1373e-02, 9.8976e-01, 5.9018e-01, 9.6509e-01, 1.1373e-02, 4.3924e-01,
        7.2513e-03, 7.3243e-01, 4.3924e-01, 1.9446e-01, 1.4823e-02, 4.6431e-02,
        8.5896e-02, 8.5896e-02, 8.5896e-02, 8.5896e-02, 8.5896e-02, 8.5896e-02,
        8.5896e-02, 8.5896e-02, 6.1553e-02, 2.0739e-02, 1.0331e-01, 3.4006e-02,
        6.5525e-02, 4.7623e-01, 3.0031e-01, 1.8925e-01, 3.2062e-02, 6.1553e-02,
        2.9064e-02, 4.2373e-01, 1.8858e-02, 7.1840e-01, 2.5829e-01, 7.2259e-03,
        2.9064e-02, 9.9455e-03, 9.9455e-03, 9.9455e-03, 1.5281e-02, 3.1892e-01,
        1.5281e-02, 2.6583e-01, 3.1892e-01, 2.3181e-03, 5.4099e-02, 2.2286e-01,
        1.2921e-01, 2.0462e-02, 3.3106e-02, 9.0746e-01, 6.3668e-01, 5.0772e-01,
        8.3713e-01, 2.5260e-02, 7.8223e-01, 1.2084e-01, 8.4545e-01, 7.1368e-01,
        8.7699e-01, 9.4993e-01, 3.0117e-02, 1.4950e-02, 8.4571e-01, 4.6840e-01,
        7.2814e-01, 4.6840e-01, 3.5400e-01, 9.4993e-01, 3.5633e-01, 8.1743e-02,
        7.4740e-01, 6.6518e-01, 5.6629e-02, 2.7369e-01, 1.7888e-03, 4.6164e-01,
        4.4329e-01, 8.1743e-02, 1.1490e-01, 7.3033e-01, 1.1490e-01, 1.1490e-01,
        8.8780e-01, 1.1490e-01, 1.1490e-01, 1.1490e-01, 1.1490e-01, 1.1490e-01,
        6.6636e-03, 9.8952e-01, 4.7929e-01, 4.7929e-01, 8.0474e-01, 1.1785e-01,
        4.6723e-02, 4.7929e-01, 9.5625e-02, 2.2663e-02, 6.9434e-01, 8.4721e-01,
        7.2476e-01, 4.5982e-01, 4.6669e-03, 2.2155e-02, 7.2476e-01, 7.2476e-01,
        2.2050e-02, 7.8150e-01, 2.0104e-01, 1.2596e-01, 4.3151e-01, 6.5593e-01,
        1.2169e-02, 4.3151e-01, 4.3151e-01, 1.2596e-01, 1.2169e-02, 1.2169e-02,
        3.7316e-01, 4.6193e-01, 2.2471e-02, 6.2809e-02, 4.1321e-01, 1.7397e-02,
        4.6193e-01, 7.8279e-01, 9.7882e-01, 4.6193e-01, 2.4898e-02, 1.5295e-01,
        2.6359e-01, 1.8714e-02, 1.3716e-01, 1.7588e-03, 3.7702e-01, 4.9738e-02,
        5.3067e-02, 1.7351e-01, 2.2511e-02, 9.3633e-01, 9.0993e-01, 6.4744e-01,
        6.4744e-01, 4.3914e-02, 8.7664e-01, 7.8032e-01, 7.6700e-01, 3.6357e-01,
        1.4600e-02, 8.9233e-01, 5.8157e-03, 7.5065e-01, 4.7704e-01, 7.5065e-01,
        4.7704e-01, 2.1122e-01, 1.6095e-01, 1.4600e-02, 5.1985e-01, 5.2383e-02,
        8.5255e-01, 7.5631e-01, 5.1985e-01, 2.9477e-02, 2.9477e-02, 5.8830e-01,
        1.3815e-03, 7.4401e-02, 9.5146e-01, 1.4623e-02, 7.0863e-01, 1.3660e-02,
        1.3660e-02, 1.4117e-02, 5.7890e-01, 7.3582e-01, 4.6126e-01, 7.4395e-01,
        5.7124e-02, 4.3668e-03, 4.8814e-05, 5.7124e-02, 3.4136e-04, 8.6283e-03,
        3.4136e-04, 1.1458e-03, 9.7394e-05, 3.4136e-04, 4.2601e-02, 4.2601e-02,
        5.7335e-02, 3.6229e-02, 1.5737e-02, 7.2657e-03, 3.1578e-02, 1.5737e-02,
        1.5592e-01, 1.5737e-02, 4.8399e-01, 4.8399e-01, 1.8774e-02, 3.7044e-01,
        3.7044e-01, 2.8624e-01, 7.4202e-01, 4.8399e-01, 2.5509e-02, 7.1125e-01,
        1.0565e-01, 7.9163e-04, 5.1879e-02, 8.8296e-01, 7.8980e-01, 4.8347e-01,
        5.8653e-01, 2.8031e-02, 7.3827e-01, 7.0585e-01, 8.3974e-04, 1.5938e-01,
        4.7204e-01, 2.2718e-01, 7.8742e-01, 9.7668e-04, 3.3930e-01, 6.0395e-02,
        4.7204e-01, 8.6575e-01, 1.1379e-01, 4.1789e-02, 1.1896e-03, 3.6276e-01,
        7.8569e-01, 1.7801e-01, 4.8140e-01, 7.0799e-01, 8.5759e-02, 1.9548e-02,
        4.8804e-01, 7.2545e-01, 7.3334e-02, 9.7774e-01, 5.6807e-01, 5.5278e-02,
        5.3922e-04, 7.5157e-01, 1.3966e-03, 1.4707e-02, 7.5306e-04, 7.6445e-01,
        2.3561e-01, 4.8445e-01, 4.8445e-01, 5.8791e-02, 8.2343e-03, 2.3750e-03,
        1.7960e-01, 2.0369e-02, 8.2186e-01, 1.3672e-01, 8.1197e-04, 2.6221e-02,
        4.6762e-01, 4.6762e-01, 8.3783e-01, 4.6762e-01, 4.5731e-02, 3.2985e-01,
        1.7705e-01, 1.5339e-01, 7.9906e-01, 7.2020e-01, 4.8996e-01, 7.9500e-01,
        9.8710e-01, 1.5339e-01, 1.5339e-01, 4.8996e-01, 4.5219e-01, 4.5219e-01,
        8.3658e-01, 4.5219e-01, 7.0972e-01, 4.5219e-01, 3.2436e-02, 4.4148e-04,
        1.8990e-02, 3.2323e-03, 2.4625e-01, 2.1694e-01, 3.3015e-02, 1.1720e-01,
        1.4920e-01, 3.3015e-02, 9.8301e-02, 3.3015e-02, 4.7252e-01, 3.3015e-02,
        8.0765e-01, 5.1629e-01, 5.1629e-01, 5.1629e-01, 4.3537e-01, 5.7481e-02,
        2.6122e-01, 2.1774e-01, 2.6122e-01, 4.3211e-02, 5.4710e-04, 1.6829e-01,
        4.7941e-01, 7.4358e-01, 7.9527e-01, 4.7941e-01, 1.7192e-02, 1.4644e-01,
        1.0917e-01, 9.6314e-02, 2.3070e-02, 2.4984e-01, 1.3871e-01, 1.6287e-02,
        1.5964e-01, 2.3070e-02, 4.6533e-02, 3.5649e-01, 3.5649e-01, 1.6242e-03,
        7.2388e-01, 8.1709e-01, 1.5235e-01, 1.6913e-02, 1.3543e-02, 8.0658e-01,
        4.2005e-02, 1.8608e-02, 6.5088e-02, 8.0658e-01, 9.8708e-01, 1.9383e-02,
        1.7704e-02, 2.5829e-01, 3.6992e-03, 4.9236e-01, 6.4392e-01, 7.5122e-01,
        7.8829e-01, 4.9236e-01, 3.8501e-01, 1.9992e-02, 4.9767e-03, 2.6001e-01,
        1.3753e-01, 1.6823e-02, 7.4226e-01, 3.8501e-01, 9.5503e-01, 3.3032e-02,
        9.7841e-01, 4.6450e-01, 9.3995e-01, 1.5700e-01, 4.6450e-01, 9.2441e-01,
        3.4218e-01, 3.4218e-01, 3.4218e-01, 1.7951e-01, 3.5991e-01, 7.3692e-01,
        4.7700e-01, 7.3692e-01, 7.0721e-03, 1.4328e-02, 1.8473e-02, 3.5991e-01,
        9.5525e-01, 3.5991e-01, 4.7481e-01, 5.9542e-01, 7.4551e-01, 3.5014e-01,
        7.4551e-01, 4.9926e-02, 4.6120e-04, 8.0542e-02, 1.1597e-02, 2.4816e-03,
        1.7487e-01, 1.8837e-01, 4.6294e-01, 6.0354e-01, 4.6294e-01, 1.7487e-01,
        3.5883e-01, 1.4886e-01, 4.6294e-01, 4.6294e-01, 9.8743e-01, 7.3237e-01,
        4.0875e-04, 7.8053e-01, 4.5796e-01, 8.6229e-01, 9.6041e-01, 5.8443e-01,
        4.5796e-01, 3.2178e-01, 2.3806e-02, 5.1584e-01, 6.4643e-02, 1.4455e-02,
        2.9769e-02, 8.7239e-01, 7.9997e-02, 7.5121e-01, 2.3806e-02, 6.4693e-01,
        3.7479e-01, 2.1415e-02, 2.1415e-02, 8.9000e-01, 8.9000e-01, 2.8026e-02,
        7.4618e-01, 3.8883e-02, 2.1415e-02, 2.1415e-02, 1.8724e-02, 1.4484e-01,
        5.7378e-01, 7.2218e-01, 4.6025e-01, 2.4685e-01, 1.2576e-01, 1.4061e-02,
        3.5448e-02, 1.1717e-02, 7.8331e-01, 2.3117e-01, 2.4046e-02, 3.0297e-02,
        8.7815e-04, 3.7864e-01, 9.4965e-01, 8.4198e-01, 1.1016e-01, 1.5785e-02,
        2.5308e-02, 2.5308e-02, 2.5308e-02, 2.5308e-02, 2.5308e-02, 2.5308e-02,
        1.9583e-03, 4.9423e-01, 2.5308e-02, 2.5308e-02, 9.2134e-01, 7.5078e-01,
        2.9791e-02, 2.4416e-01, 2.2684e-02, 8.6075e-01, 1.9161e-01, 4.9651e-01,
        2.8683e-02, 1.9861e-01, 7.0424e-01, 1.2867e-01, 8.5125e-01, 8.5872e-01,
        3.5422e-01, 1.1628e-01, 4.7338e-01, 2.6413e-01, 3.7961e-02, 9.5325e-01,
        1.7929e-02, 3.6485e-03, 3.5356e-02, 1.3506e-02, 9.4256e-01, 4.7107e-01,
        8.7919e-01, 4.7250e-02, 1.7929e-02, 5.3250e-02, 4.8097e-01, 4.0350e-01,
        7.2349e-01, 1.9327e-01, 4.0350e-01, 6.3145e-02, 4.8097e-01, 7.2349e-01,
        4.8097e-01, 3.0366e-01, 4.7869e-01, 8.7133e-01, 7.4661e-01, 6.2110e-03,
        7.6029e-03, 4.7869e-01, 8.7133e-01, 4.7869e-01, 7.7388e-01, 7.7348e-01,
        2.0642e-02, 4.5529e-01, 2.0642e-02, 7.1071e-01, 1.6560e-01, 2.0642e-02,
        5.8336e-02, 4.5529e-01, 4.5529e-01, 2.7263e-02, 3.9649e-02, 3.0027e-01,
        3.7616e-01, 9.4867e-02, 9.4867e-02, 2.9182e-02, 6.9840e-02, 1.6009e-01,
        7.5138e-01, 5.1979e-01, 4.5960e-01, 2.2182e-02, 4.5960e-01, 4.5960e-01,
        7.2882e-01, 7.2882e-01, 4.5960e-01, 9.5651e-01, 4.5960e-01, 7.2882e-01,
        8.5488e-01, 4.1469e-02, 7.4365e-01, 5.0664e-01, 9.4785e-01, 7.4365e-01,
        9.4785e-01, 9.4785e-01, 2.8060e-02, 1.3354e-01, 7.1108e-01, 2.7155e-02,
        4.9835e-01, 4.9835e-01, 2.0683e-01, 9.4667e-01, 4.2742e-01, 2.0989e-02,
        5.7981e-02, 2.7155e-02], grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0.,
        0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0.,
        0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0.,
        0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1.,
        0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,
        1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.])
loss:  tensor(0.6684, grad_fn=<MeanBackward0>) l2:  tensor(0.3381, grad_fn=<AddBackward0>) l2*coef tensor(3.3808e-05, grad_fn=<MulBackward0>)
Iteration 40, loss: 0.6766165211796761
Epoch 1; time 0.9068
epoch 1 validating; auc: 0.5937
Model (checkpoint) saved to output/ml1m/env/ml1m_user_env_lr0.003_reg0.0001.model
epoch 2 training
self.sigmoid(preds):  tensor([0.2028, 0.9604, 0.0286,  ..., 0.0650, 0.4864, 0.3715],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 0.,  ..., 1., 1., 1.])
loss:  tensor(0.6666, grad_fn=<MeanBackward0>) l2:  tensor(0.3375, grad_fn=<AddBackward0>) l2*coef tensor(3.3747e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.0799, 0.5074, 0.9489,  ..., 0.0632, 0.7523, 0.8545],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 0.,  ..., 1., 0., 1.])
loss:  tensor(0.6693, grad_fn=<MeanBackward0>) l2:  tensor(0.3368, grad_fn=<AddBackward0>) l2*coef tensor(3.3679e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3820, 0.0302, 0.8960,  ..., 0.0186, 0.5198, 0.3749],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 0., 0., 0.])
loss:  tensor(0.6760, grad_fn=<MeanBackward0>) l2:  tensor(0.3360, grad_fn=<AddBackward0>) l2*coef tensor(3.3598e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.6221, 0.4306, 0.4306,  ..., 0.7629, 0.0291, 0.7999],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6816, grad_fn=<MeanBackward0>) l2:  tensor(0.3350, grad_fn=<AddBackward0>) l2*coef tensor(3.3497e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3171, 0.9897, 0.8541,  ..., 0.5284, 0.0023, 0.5284],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 0.,  ..., 1., 0., 0.])
loss:  tensor(0.6767, grad_fn=<MeanBackward0>) l2:  tensor(0.3340, grad_fn=<AddBackward0>) l2*coef tensor(3.3396e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([2.8711e-02, 5.0967e-04, 7.3255e-01,  ..., 5.4116e-01, 7.8001e-01,
        6.1182e-02], grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6645, grad_fn=<MeanBackward0>) l2:  tensor(0.3331, grad_fn=<AddBackward0>) l2*coef tensor(3.3311e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.9415, 0.4664, 0.4664,  ..., 0.1019, 0.7160, 0.1338],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 0.])
loss:  tensor(0.6566, grad_fn=<MeanBackward0>) l2:  tensor(0.3323, grad_fn=<AddBackward0>) l2*coef tensor(3.3227e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.0157, 0.7552, 0.0302,  ..., 0.6727, 0.0191, 0.2382],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.6746, grad_fn=<MeanBackward0>) l2:  tensor(0.3315, grad_fn=<AddBackward0>) l2*coef tensor(3.3152e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.0743, 0.0256, 0.5975,  ..., 0.9151, 0.5048, 0.1437],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 0., 0., 0.])
loss:  tensor(0.6769, grad_fn=<MeanBackward0>) l2:  tensor(0.3307, grad_fn=<AddBackward0>) l2*coef tensor(3.3067e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.0147, 0.1875, 0.4046,  ..., 0.0042, 0.6850, 0.6700],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 1.,  ..., 0., 1., 1.])
loss:  tensor(0.6788, grad_fn=<MeanBackward0>) l2:  tensor(0.3300, grad_fn=<AddBackward0>) l2*coef tensor(3.2995e-05, grad_fn=<MulBackward0>)
Iteration 10, loss: 0.6722118318080902
self.sigmoid(preds):  tensor([0.6061, 0.0212, 0.0212,  ..., 0.3732, 0.1134, 0.3732],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6712, grad_fn=<MeanBackward0>) l2:  tensor(0.3293, grad_fn=<AddBackward0>) l2*coef tensor(3.2933e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4007, 0.1274, 0.0923,  ..., 0.0232, 0.4264, 0.1668],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0.,  ..., 0., 1., 0.])
loss:  tensor(0.6751, grad_fn=<MeanBackward0>) l2:  tensor(0.3288, grad_fn=<AddBackward0>) l2*coef tensor(3.2882e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.0359, 0.3612, 0.3612,  ..., 0.1648, 0.6619, 0.0098],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6751, grad_fn=<MeanBackward0>) l2:  tensor(0.3281, grad_fn=<AddBackward0>) l2*coef tensor(3.2806e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3808, 0.0419, 0.0563,  ..., 0.6982, 0.3977, 0.4073],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6701, grad_fn=<MeanBackward0>) l2:  tensor(0.3270, grad_fn=<AddBackward0>) l2*coef tensor(3.2702e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.9645, 0.4991, 0.6276,  ..., 0.4018, 0.3466, 0.3466],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 0.,  ..., 1., 1., 1.])
loss:  tensor(0.6857, grad_fn=<MeanBackward0>) l2:  tensor(0.3258, grad_fn=<AddBackward0>) l2*coef tensor(3.2579e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.4939, 0.2159, 0.2159,  ..., 0.0148, 0.0148, 0.0848],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 1.,  ..., 0., 0., 1.])
loss:  tensor(0.6885, grad_fn=<MeanBackward0>) l2:  tensor(0.3248, grad_fn=<AddBackward0>) l2*coef tensor(3.2480e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.6717, 0.9197, 0.1660,  ..., 0.4896, 0.7233, 0.4896],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 0.])
loss:  tensor(0.6674, grad_fn=<MeanBackward0>) l2:  tensor(0.3237, grad_fn=<AddBackward0>) l2*coef tensor(3.2375e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.1263, 0.0168, 0.0754,  ..., 0.7221, 0.8651, 0.7220],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6651, grad_fn=<MeanBackward0>) l2:  tensor(0.3226, grad_fn=<AddBackward0>) l2*coef tensor(3.2261e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.9350, 0.0923, 0.5089,  ..., 0.0383, 0.1732, 0.1732],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 0.,  ..., 1., 1., 1.])
loss:  tensor(0.6809, grad_fn=<MeanBackward0>) l2:  tensor(0.3214, grad_fn=<AddBackward0>) l2*coef tensor(3.2137e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.0061, 0.0099, 0.0056,  ..., 0.1614, 0.4337, 0.0506],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0.,  ..., 1., 1., 1.])
loss:  tensor(0.6569, grad_fn=<MeanBackward0>) l2:  tensor(0.3203, grad_fn=<AddBackward0>) l2*coef tensor(3.2026e-05, grad_fn=<MulBackward0>)
Iteration 20, loss: 0.6729170441627502
self.sigmoid(preds):  tensor([0.5376, 0.0117, 0.0777,  ..., 0.0486, 0.3971, 0.6369],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0.,  ..., 0., 0., 0.])
loss:  tensor(0.6648, grad_fn=<MeanBackward0>) l2:  tensor(0.3194, grad_fn=<AddBackward0>) l2*coef tensor(3.1943e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.1590, 0.4491, 0.1543,  ..., 0.4822, 0.7063, 0.4822],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6568, grad_fn=<MeanBackward0>) l2:  tensor(0.3187, grad_fn=<AddBackward0>) l2*coef tensor(3.1873e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.9510, 0.0649, 0.6311,  ..., 0.1884, 0.8167, 0.4465],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 0.])
loss:  tensor(0.6668, grad_fn=<MeanBackward0>) l2:  tensor(0.3180, grad_fn=<AddBackward0>) l2*coef tensor(3.1801e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.8864, 0.1036, 0.9482,  ..., 0.4015, 0.0475, 0.5857],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 0.,  ..., 1., 0., 1.])
loss:  tensor(0.6780, grad_fn=<MeanBackward0>) l2:  tensor(0.3173, grad_fn=<AddBackward0>) l2*coef tensor(3.1730e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.7068, 0.4098, 0.2521,  ..., 0.3041, 0.3025, 0.0158],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0.,  ..., 0., 0., 1.])
loss:  tensor(0.6638, grad_fn=<MeanBackward0>) l2:  tensor(0.3165, grad_fn=<AddBackward0>) l2*coef tensor(3.1655e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.2466, 0.0388, 0.6245,  ..., 0.9474, 0.2482, 0.6286],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 1., 1., 1.])
loss:  tensor(0.6781, grad_fn=<MeanBackward0>) l2:  tensor(0.3158, grad_fn=<AddBackward0>) l2*coef tensor(3.1582e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.5228, 0.4111, 0.2425,  ..., 0.1811, 0.0793, 0.4227],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 0., 1.])
loss:  tensor(0.6710, grad_fn=<MeanBackward0>) l2:  tensor(0.3155, grad_fn=<AddBackward0>) l2*coef tensor(3.1550e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.0095, 0.1844, 0.4353,  ..., 0.6216, 0.8746, 0.5751],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 1., 1., 0.])
loss:  tensor(0.6634, grad_fn=<MeanBackward0>) l2:  tensor(0.3152, grad_fn=<AddBackward0>) l2*coef tensor(3.1524e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.8898, 0.0886, 0.7915,  ..., 0.0595, 0.1977, 0.0595],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 1.,  ..., 0., 0., 0.])
loss:  tensor(0.6820, grad_fn=<MeanBackward0>) l2:  tensor(0.3149, grad_fn=<AddBackward0>) l2*coef tensor(3.1489e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.0671, 0.0671, 0.0671,  ..., 0.1226, 0.0767, 0.3351],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 0.,  ..., 1., 0., 0.])
loss:  tensor(0.6656, grad_fn=<MeanBackward0>) l2:  tensor(0.3146, grad_fn=<AddBackward0>) l2*coef tensor(3.1465e-05, grad_fn=<MulBackward0>)
Iteration 30, loss: 0.6716280897458394
self.sigmoid(preds):  tensor([0.7510, 0.5509, 0.3611,  ..., 0.1749, 0.5588, 0.6760],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 0.,  ..., 1., 1., 0.])
loss:  tensor(0.6616, grad_fn=<MeanBackward0>) l2:  tensor(0.3147, grad_fn=<AddBackward0>) l2*coef tensor(3.1470e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.5881, 0.0106, 0.6769,  ..., 0.7172, 0.0506, 0.0053],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 1.,  ..., 1., 1., 1.])
loss:  tensor(0.6642, grad_fn=<MeanBackward0>) l2:  tensor(0.3146, grad_fn=<AddBackward0>) l2*coef tensor(3.1465e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.3507, 0.7960, 0.3507,  ..., 0.2762, 0.8627, 0.0543],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 1., 1.,  ..., 1., 0., 1.])
loss:  tensor(0.6720, grad_fn=<MeanBackward0>) l2:  tensor(0.3145, grad_fn=<AddBackward0>) l2*coef tensor(3.1453e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.2578, 0.4812, 0.7866,  ..., 0.0494, 0.0155, 0.1825],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 0., 0., 0.])
loss:  tensor(0.6692, grad_fn=<MeanBackward0>) l2:  tensor(0.3143, grad_fn=<AddBackward0>) l2*coef tensor(3.1428e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.8145, 0.0019, 0.2919,  ..., 0.7582, 0.0521, 0.0434],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 0., 0.])
loss:  tensor(0.6633, grad_fn=<MeanBackward0>) l2:  tensor(0.3141, grad_fn=<AddBackward0>) l2*coef tensor(3.1414e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.7991, 0.0088, 0.3473,  ..., 0.0242, 0.1235, 0.8260],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 1., 1.,  ..., 0., 1., 0.])
loss:  tensor(0.6710, grad_fn=<MeanBackward0>) l2:  tensor(0.3138, grad_fn=<AddBackward0>) l2*coef tensor(3.1383e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.9556, 0.0759, 0.0725,  ..., 0.9526, 0.0132, 0.3179],
       grad_fn=<SigmoidBackward0>)
target:  tensor([1., 0., 0.,  ..., 1., 1., 0.])
loss:  tensor(0.6640, grad_fn=<MeanBackward0>) l2:  tensor(0.3133, grad_fn=<AddBackward0>) l2*coef tensor(3.1333e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.0520, 0.0520, 0.1259,  ..., 0.4143, 0.5519, 0.5519],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 0., 1., 1.])
loss:  tensor(0.6796, grad_fn=<MeanBackward0>) l2:  tensor(0.3130, grad_fn=<AddBackward0>) l2*coef tensor(3.1297e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([0.0211, 0.8574, 0.0395,  ..., 0.0195, 0.3673, 0.7850],
       grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 0.,  ..., 1., 0., 1.])
loss:  tensor(0.6865, grad_fn=<MeanBackward0>) l2:  tensor(0.3128, grad_fn=<AddBackward0>) l2*coef tensor(3.1283e-05, grad_fn=<MulBackward0>)
self.sigmoid(preds):  tensor([9.9816e-01, 2.1389e-01, 9.0919e-04, 7.9009e-02, 5.7587e-02, 4.4545e-02,
        1.2447e-01, 1.1726e-02, 6.2497e-03, 1.1555e-01, 1.7174e-03, 7.2267e-02,
        1.1618e-01, 2.3816e-01, 3.0070e-02, 1.2962e-01, 5.3906e-01, 3.0070e-02,
        1.2962e-01, 7.2267e-02, 6.6586e-01, 9.0308e-03, 8.7608e-02, 5.8826e-02,
        4.8455e-01, 4.8748e-03, 1.3629e-01, 1.2284e-02, 2.6922e-04, 7.2206e-03,
        3.4187e-01, 9.1820e-01, 8.2481e-01, 5.8834e-01, 4.8248e-01, 7.9415e-01,
        1.1557e-01, 1.2438e-01, 2.9112e-01, 6.3573e-01, 5.5340e-01, 1.3729e-01,
        2.9810e-02, 5.5340e-01, 1.1878e-01, 7.5701e-01, 4.3914e-02, 8.0460e-01,
        3.6667e-01, 6.1656e-01, 5.7769e-01, 4.4710e-01, 1.2686e-01, 2.5684e-01,
        4.0767e-01, 1.0477e-01, 8.8666e-01, 5.7769e-01, 5.7769e-01, 4.0094e-01,
        6.1658e-01, 4.4221e-01, 2.8940e-01, 9.8819e-01, 9.6137e-01, 5.3599e-01,
        8.0785e-01, 3.9196e-02, 8.4152e-01, 9.7453e-01, 2.5884e-01, 7.8721e-02,
        2.0144e-01, 5.7401e-02, 1.4612e-01, 2.9509e-02, 5.0591e-02, 2.9579e-01,
        4.1018e-03, 1.0166e-02, 2.1119e-01, 5.7883e-01, 6.4066e-02, 3.3306e-02,
        1.4160e-02, 6.2901e-02, 2.5202e-01, 4.4134e-01, 3.6435e-02, 3.9728e-02,
        3.7344e-02, 2.2208e-01, 3.5036e-01, 7.2626e-01, 4.5001e-01, 6.5892e-02,
        4.5718e-01, 4.5001e-01, 5.4059e-02, 2.0914e-02, 1.2813e-01, 4.6844e-01,
        3.2758e-01, 2.3262e-01, 8.9805e-01, 3.2758e-01, 8.2880e-01, 3.6539e-02,
        8.0636e-01, 4.5079e-01, 7.6369e-01, 3.8635e-01, 5.7256e-01, 9.2684e-01,
        8.0265e-02, 7.2745e-01, 4.4167e-01, 3.9542e-01, 6.3907e-01, 6.1917e-01,
        9.8058e-02, 3.6078e-02, 5.0417e-01, 9.7087e-01, 2.9283e-02, 5.0417e-01,
        7.5273e-02, 8.4262e-01, 4.2602e-01, 5.0417e-01, 6.1551e-01, 4.1223e-02,
        2.3366e-02, 4.1805e-01, 2.1268e-01, 5.9061e-02, 1.0137e-01, 6.8624e-01,
        6.4416e-01, 7.2181e-02, 2.0584e-01, 3.1933e-02, 4.8073e-01, 8.2863e-01,
        9.0438e-03, 5.9059e-01, 1.3646e-02, 2.8356e-02, 7.2645e-01, 7.2645e-01,
        8.9807e-01, 1.2167e-01, 8.2646e-02, 4.6728e-01, 5.1142e-01, 8.3868e-01,
        7.6368e-01, 8.6638e-01, 4.8897e-01, 2.8491e-01, 9.5086e-02, 1.2999e-01,
        1.4216e-01, 5.5104e-02, 2.0462e-01, 1.2999e-01, 4.2511e-01, 2.0462e-01,
        2.4629e-01, 4.2511e-01, 5.1623e-02, 1.0263e-01, 3.9257e-01, 1.0263e-01,
        3.9257e-01, 5.2509e-01, 7.4711e-02, 3.5808e-01, 7.8196e-01, 5.3747e-01,
        6.0118e-02, 5.7437e-01, 2.5182e-01, 5.7437e-01, 2.9534e-02, 8.3592e-01,
        6.2318e-02, 4.2906e-01, 5.7437e-01, 4.2906e-01, 5.6537e-02, 7.7482e-01,
        2.3150e-02, 8.6898e-02, 3.4742e-01, 9.2727e-02, 6.2751e-01, 1.4108e-01,
        1.4108e-01, 1.4108e-01, 3.7993e-02, 2.1518e-01, 4.6415e-02, 4.6033e-03,
        2.2344e-02, 9.2795e-01, 6.1391e-01, 8.4279e-03, 9.4375e-01, 3.2435e-01,
        3.2494e-01, 4.9865e-01, 4.9865e-01, 7.5069e-01, 7.2240e-01, 6.7157e-01,
        4.9865e-01, 9.0903e-01, 3.6449e-02, 2.7539e-01, 3.7935e-02, 9.6262e-01,
        6.7411e-01, 3.0182e-03, 5.0040e-01, 8.2327e-01, 6.7411e-01, 9.2577e-01,
        1.5338e-01, 2.7904e-01, 1.1521e-01, 9.0441e-01, 6.0438e-01, 1.1521e-01,
        6.0438e-01, 6.0438e-01, 3.7092e-01, 5.7048e-01, 6.0438e-01, 7.9341e-01,
        5.2937e-01, 3.1484e-01, 4.9205e-02, 5.2937e-01, 5.2937e-01, 9.9180e-01,
        4.9205e-02, 9.0608e-01, 1.9212e-01, 5.2937e-01, 8.0336e-01, 5.9255e-02,
        4.7250e-01, 7.6247e-01, 3.6366e-01, 4.7250e-01, 4.7250e-01, 1.1584e-01,
        8.9572e-01, 7.7659e-01, 5.6325e-01, 5.9665e-02, 2.7085e-01, 1.4675e-01,
        1.6654e-01, 3.2943e-01, 5.9665e-02, 3.9868e-01, 5.6481e-01, 7.8875e-02,
        4.2325e-01, 3.5397e-01, 4.4503e-02, 8.6367e-02, 5.8153e-01, 8.6491e-01,
        1.3707e-01, 4.4503e-02, 4.8465e-03, 8.6491e-01, 2.2062e-01, 4.9700e-01,
        7.8721e-01, 2.2062e-01, 1.3611e-01, 8.8518e-01, 2.2062e-01, 8.8522e-01,
        9.7682e-01, 7.8721e-01, 3.0519e-01, 5.1300e-01, 6.2380e-01, 5.0501e-01,
        2.4138e-04, 8.9469e-02, 7.9172e-01, 1.1960e-01, 8.9469e-02, 6.7865e-01,
        4.7741e-02, 5.2187e-02, 5.2187e-02, 5.2187e-02, 3.3679e-02, 5.2979e-01,
        5.2187e-02, 5.2187e-02, 6.6953e-03, 5.2187e-02, 1.1952e-02, 8.5127e-02,
        3.6173e-03, 1.4632e-01, 4.0235e-01, 1.1952e-02, 1.1952e-02, 3.8831e-01,
        2.5595e-02, 2.4854e-01, 1.1724e-02, 7.1459e-04, 5.4392e-01, 1.4121e-01,
        2.0745e-01, 4.0139e-02, 6.7243e-01, 1.6456e-02, 5.7547e-01, 8.1390e-01,
        5.7095e-03, 3.8473e-01, 8.6689e-01, 2.2046e-03, 3.3209e-02, 6.0737e-01,
        1.1590e-01, 5.7384e-01, 6.6961e-01, 5.8473e-02, 9.6143e-01, 3.3812e-02,
        3.3812e-02, 4.4402e-02, 3.3812e-02, 3.3812e-02, 1.4124e-03, 3.3812e-02,
        6.5675e-03, 2.1172e-02, 5.0493e-02, 2.9718e-01, 7.5659e-01, 3.3532e-01,
        4.7683e-02, 9.4844e-01, 7.9493e-01, 5.0493e-02, 1.1110e-02, 1.2488e-01,
        2.3664e-02, 6.9935e-01, 1.6432e-01, 9.3835e-01, 9.3577e-01, 3.1362e-01,
        3.1362e-01, 2.4958e-01, 2.8575e-02, 6.1326e-02, 9.6159e-01, 9.9264e-01,
        6.7804e-03, 3.9498e-02, 7.3745e-01, 3.3250e-01, 7.7688e-02, 7.7688e-02,
        8.7956e-02, 2.5304e-02, 5.5126e-02, 4.2427e-01, 9.0488e-01, 4.2427e-01,
        3.1620e-01, 4.2427e-01, 5.6625e-01, 5.6625e-01, 4.2427e-01, 4.2427e-01,
        1.3379e-01, 8.7951e-01, 5.7959e-01, 8.7031e-01, 8.7951e-01, 4.3813e-01,
        2.5503e-01, 4.3813e-01, 2.5764e-01, 1.1631e-01, 1.6620e-01, 2.1501e-02,
        2.1501e-02, 5.9080e-02, 5.5723e-01, 3.4624e-02, 7.5083e-02, 1.3358e-01,
        1.6620e-01, 2.7106e-01, 1.6447e-02, 8.3212e-01, 8.2851e-01, 9.4417e-01,
        7.0807e-01, 7.7783e-01, 9.7791e-01, 8.3212e-01, 7.4741e-02, 1.2006e-01,
        8.3029e-01, 1.1406e-01, 4.8591e-01, 2.8723e-01, 7.3568e-01, 5.1801e-02,
        2.7584e-01, 2.8264e-02, 7.4256e-01, 9.3530e-02, 9.4240e-01, 6.6558e-01,
        4.0234e-01, 1.0555e-01, 4.0715e-01, 1.0368e-01, 8.6090e-01, 6.6877e-01,
        6.6558e-01, 1.8304e-01, 3.0226e-02, 5.6690e-01, 1.3558e-01, 5.1855e-02,
        7.1639e-01, 1.3558e-01, 5.6916e-01, 2.9828e-01, 5.2259e-01, 7.5812e-02,
        4.4976e-01, 4.0969e-01, 5.7657e-01, 9.6358e-01, 9.7903e-02, 7.7717e-01,
        1.1163e-01, 3.9847e-02, 9.2256e-02, 9.3498e-02, 5.5109e-04, 1.2633e-01,
        1.0140e-02, 3.3334e-02, 1.2102e-02, 4.2460e-04, 4.8204e-01, 4.4499e-03,
        3.3334e-02, 2.4891e-01, 3.8268e-01, 8.8824e-01, 8.7045e-01, 3.8268e-01,
        1.4774e-01, 6.5265e-01, 8.7658e-04, 2.1868e-02, 5.1861e-01, 5.1861e-01,
        5.8636e-01, 5.3312e-01, 4.2104e-01, 4.0189e-01, 1.7155e-01, 5.8636e-01,
        4.0189e-01, 4.0189e-01, 4.0189e-01, 5.8636e-01, 9.2627e-01, 1.0158e-02,
        7.7701e-02, 3.2416e-02, 5.3871e-01, 7.7701e-02, 4.1251e-01, 3.2416e-02,
        7.5212e-01, 8.1678e-02, 8.6240e-01, 8.9466e-01, 8.8436e-01, 2.5296e-01,
        8.8436e-01, 1.7296e-01, 1.4543e-01, 3.6222e-01, 2.7153e-01, 4.9017e-01,
        2.3569e-02, 2.3478e-02, 4.2153e-02, 1.7489e-01, 4.0042e-03, 6.0624e-02,
        4.2153e-02, 2.3569e-02, 3.7278e-04, 2.3569e-02, 6.7389e-01, 1.4605e-01,
        5.4286e-01, 1.6956e-03, 4.2533e-02, 6.5796e-01, 2.3666e-02, 6.5167e-01,
        3.1826e-01, 3.1187e-01, 3.3380e-02, 2.4437e-01, 8.0522e-01, 2.5802e-01,
        6.4875e-01, 9.0279e-01, 2.2593e-02, 7.2633e-01, 3.5113e-02, 3.5113e-02,
        1.7486e-01, 1.4314e-02, 1.4314e-02, 1.4314e-02, 2.5854e-01, 6.3276e-04,
        6.8122e-03, 6.3276e-04, 1.7486e-01, 2.8908e-03, 3.7152e-01, 1.5556e-01,
        1.5556e-01, 1.5556e-01, 1.5556e-01, 7.2941e-01, 1.5556e-01, 6.1152e-02,
        4.0185e-02, 4.0185e-02, 1.7274e-01, 2.1976e-02, 2.1976e-02, 1.1574e-02,
        5.0270e-02, 1.7274e-01, 1.5778e-01, 1.1574e-02, 1.5307e-01, 4.2802e-04,
        5.4070e-01, 5.4070e-01, 5.4070e-01, 5.4070e-01, 7.9589e-01, 1.2564e-01,
        5.4070e-01, 7.7579e-01, 2.9812e-01, 9.0621e-01, 2.5645e-01, 1.2325e-02,
        6.0805e-01, 2.5645e-01, 4.3756e-01, 2.5645e-01, 4.3756e-01, 2.5645e-01,
        1.2325e-02, 2.3259e-02, 9.7705e-01, 5.2450e-01, 9.1087e-01, 9.4725e-01,
        5.2450e-01, 9.6193e-01, 3.3654e-01, 2.0338e-01, 8.3223e-01, 3.3654e-01,
        5.1384e-01, 3.1753e-01, 6.5280e-01, 6.3541e-01, 6.5280e-01, 7.7776e-01,
        9.0610e-01, 5.0727e-01, 6.5280e-01, 6.5280e-01, 7.9573e-01, 6.6819e-01,
        6.6819e-01, 6.2972e-01, 6.6819e-01, 6.6819e-01, 1.9495e-01, 9.7983e-01,
        6.6819e-01, 6.6819e-01, 5.4598e-02, 5.2588e-01, 8.9631e-01, 9.7417e-01,
        5.3189e-02, 9.2095e-01, 1.1682e-02, 1.9333e-01, 5.2588e-01, 7.1808e-01,
        1.6274e-01, 6.5910e-01, 9.8434e-01, 3.4401e-01, 4.4528e-01, 7.2470e-01,
        6.5910e-01, 6.0363e-01, 4.4528e-01, 5.6787e-03, 5.5296e-01, 6.6724e-02,
        3.4542e-01, 6.6724e-02, 9.4100e-01, 6.6724e-02, 5.3361e-01, 6.6724e-02,
        5.3894e-01, 2.5871e-02, 3.0557e-01, 9.7286e-02, 4.1152e-01, 2.3569e-02,
        2.7041e-01, 2.3569e-02, 1.2632e-02, 4.1152e-01, 4.4190e-01, 9.9327e-04,
        3.7756e-01, 6.4863e-01, 6.0152e-01, 8.3879e-01, 7.7609e-01, 6.0152e-01,
        6.4863e-01, 6.4863e-01, 5.0532e-01, 6.4863e-01, 3.0266e-03, 8.5077e-01,
        6.9391e-02, 1.3659e-03, 2.2439e-02, 1.1839e-02, 3.5016e-02, 6.7425e-01,
        5.8065e-02, 3.7620e-03, 7.1259e-01, 9.7233e-01, 3.3746e-02, 9.0110e-01,
        8.2651e-01, 2.0660e-01, 9.9685e-01, 3.4735e-01, 2.0497e-02, 1.3208e-02,
        6.2449e-01, 5.0287e-03, 3.3713e-01, 3.3713e-01, 1.6896e-01, 5.9919e-01,
        3.3713e-01, 3.3713e-01, 3.3713e-01, 7.5470e-03, 6.1524e-01, 4.7701e-02,
        7.9607e-03, 5.3968e-01, 9.7323e-04, 5.1790e-02, 1.9306e-01, 8.6485e-01,
        8.6485e-01, 6.7835e-01, 3.0047e-02, 9.4190e-01, 8.7440e-01, 2.1117e-01,
        3.2913e-01, 5.2644e-01, 1.4840e-02, 3.5479e-01, 7.8706e-02, 7.0394e-02,
        1.1521e-02, 4.9122e-01, 1.1521e-02, 2.5263e-01, 4.9122e-01, 2.6480e-01,
        1.2546e-02, 4.8529e-01, 4.9122e-01, 4.3689e-04, 1.8473e-01, 4.1441e-01,
        1.7166e-01, 7.8057e-01, 3.7311e-01, 9.3136e-01, 1.3360e-01, 4.1441e-01,
        4.2851e-02, 2.8417e-01, 2.9930e-03, 7.0226e-01, 4.8216e-01, 5.1610e-02,
        5.1610e-02, 5.2597e-03, 4.8216e-01, 2.5759e-03, 3.0756e-02, 9.5781e-02,
        9.3809e-01, 7.6016e-01, 3.5839e-02, 3.1939e-02, 2.0186e-02, 1.5362e-01,
        7.9179e-02, 7.9179e-02, 7.9565e-01, 5.4267e-01, 4.6459e-01, 4.2176e-02,
        8.6300e-02, 4.6459e-01, 6.0262e-01, 3.0295e-01, 4.7824e-01, 4.6459e-01,
        1.4168e-01, 8.2702e-01, 8.8585e-02, 2.7683e-01, 1.4140e-01, 5.2383e-01,
        2.1107e-02, 8.1677e-01, 3.2098e-02, 6.4917e-01, 9.2256e-01, 7.2565e-01,
        1.1809e-02, 3.5749e-01, 5.6031e-02, 5.6031e-02, 3.2409e-01, 7.0193e-02,
        8.6713e-01, 7.0632e-01, 2.9998e-01, 5.7647e-02, 2.1572e-01, 2.8199e-02,
        2.8199e-02, 2.8199e-02, 2.8199e-02, 5.6058e-02, 2.8199e-02, 7.5552e-02,
        3.0572e-01, 1.3989e-02, 7.1626e-01, 2.1123e-02, 5.7252e-04, 3.8222e-01,
        3.8222e-01, 6.0562e-03, 7.7264e-01, 3.0029e-03, 3.8222e-01, 7.1755e-01,
        3.6612e-01, 5.7537e-02, 3.6612e-01, 3.6612e-01, 3.6612e-01, 1.0051e-01,
        4.9016e-02, 5.0384e-01, 5.0532e-02, 4.9016e-02, 8.2283e-02, 7.0837e-02,
        1.7781e-04, 1.6988e-01, 5.0297e-02, 7.0837e-02, 2.3209e-03, 4.7364e-02,
        8.9923e-02, 1.2840e-01, 1.5440e-02, 1.2048e-01, 4.9469e-02, 3.6603e-01,
        2.8405e-02, 2.2158e-02, 2.8405e-02, 4.1450e-01, 1.5440e-02, 1.2048e-01,
        8.7796e-01, 9.7307e-02, 4.5964e-01, 3.8680e-01, 7.5234e-01, 5.5145e-01,
        9.0872e-02, 9.0872e-02, 4.8288e-01, 8.8761e-01, 7.2272e-01, 8.9503e-01,
        5.5591e-01, 3.4068e-01, 4.7952e-01, 6.5196e-02, 8.7009e-02, 4.8822e-02,
        7.4672e-01, 2.7819e-02], grad_fn=<SigmoidBackward0>)
target:  tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0.,
        0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0.,
        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0.,
        1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0.,
        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0.,
        1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.])
loss:  tensor(0.6528, grad_fn=<MeanBackward0>) l2:  tensor(0.3128, grad_fn=<AddBackward0>) l2*coef tensor(3.1278e-05, grad_fn=<MulBackward0>)
Iteration 40, loss: 0.6708304136991501
Epoch 2; time 0.9051
epoch 2 validating; auc: 0.6006
Model (checkpoint) saved to output/ml1m/env/ml1m_user_env_lr0.003_reg0.0001.model

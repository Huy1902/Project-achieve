{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Huy1902/HAC/blob/main/Movie_Recommendation_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-03-19T00:18:57.199623Z",
          "iopub.status.busy": "2025-03-19T00:18:57.199298Z",
          "iopub.status.idle": "2025-03-19T00:18:57.490132Z",
          "shell.execute_reply": "2025-03-19T00:18:57.488891Z",
          "shell.execute_reply.started": "2025-03-19T00:18:57.1996Z"
        },
        "id": "weJBxe-ISl75",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of records:  937949\n",
            "number of users:  519435\n",
            "number of items per page:  9\n",
            "avg. lengths of user history:  36.35307676643399\n",
            "avg. dimensions of user_protrait:  42.0\n",
            "avg. dimensions of item_feature:  352.0\n",
            "number of behavior_policy_id:  1\n"
          ]
        }
      ],
      "source": [
        "with open('rl4rs/rl4rs_dataset_b_sl.csv', 'r') as f:\n",
        "    data = f.read().split('\\n')[1:-1]\n",
        "    print('number of records: ', len(data))\n",
        "    print('number of users: ', len(set([x.split('@')[1] for x in data])))\n",
        "    print('number of items per page: ', len(data[0].split('@')[3].split(',')))\n",
        "    print('avg. lengths of user history: ', sum([len(x.split('@')[5].split(',')) for x in data])/len(data))\n",
        "    print('avg. dimensions of user_protrait: ', sum([len(x.split('@')[6].split(',')) for x in data])/len(data))\n",
        "    print('avg. dimensions of item_feature: ', sum([len(x.split('@')[7].split(',')) for x in data])/len(data))\n",
        "    print('number of behavior_policy_id: ', len(set([x.split('@')[-1] for x in data])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of records:  937949\n",
            "number of users:  937949\n",
            "number of items per page:  9\n",
            "avg. lengths of user history:  36.35307676643399\n",
            "avg. dimensions of user_protrait:  42.0\n",
            "avg. dimensions of item_feature:  352.0\n",
            "number of behavior_policy_id:  1\n"
          ]
        }
      ],
      "source": [
        "with open('rl4rs/rl4rs_dataset_a_sl.csv', 'r') as f:\n",
        "    data = f.read().split('\\n')[1:-1]\n",
        "    print('number of records: ', len(data))\n",
        "    print('number of users: ', len(set([x.split('@')[1] for x in data])))\n",
        "    print('number of items per page: ', len(data[0].split('@')[3].split(',')))\n",
        "    print('avg. lengths of user history: ', sum([len(x.split('@')[5].split(',')) for x in data])/len(data))\n",
        "    print('avg. dimensions of user_protrait: ', sum([len(x.split('@')[6].split(',')) for x in data])/len(data))\n",
        "    print('avg. dimensions of item_feature: ', sum([len(x.split('@')[7].split(',')) for x in data])/len(data))\n",
        "    print('number of behavior_policy_id: ', len(set([x.split('@')[-1] for x in data])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of records:  781367\n",
            "number of users:  781367\n",
            "number of items per page:  9\n",
            "avg. lengths of user history:  48.076561974078764\n",
            "avg. dimensions of user_protrait:  42.0\n",
            "avg. dimensions of item_feature:  352.0\n",
            "number of behavior_policy_id:  1\n"
          ]
        }
      ],
      "source": [
        "with open('rl4rs/rl4rs_dataset_a_rl.csv', 'r') as f:\n",
        "    data = f.read().split('\\n')[1:-1]\n",
        "    print('number of records: ', len(data))\n",
        "    print('number of users: ', len(set([x.split('@')[1] for x in data])))\n",
        "    print('number of items per page: ', len(data[0].split('@')[3].split(',')))\n",
        "    print('avg. lengths of user history: ', sum([len(x.split('@')[5].split(',')) for x in data])/len(data))\n",
        "    print('avg. dimensions of user_protrait: ', sum([len(x.split('@')[6].split(',')) for x in data])/len(data))\n",
        "    print('avg. dimensions of item_feature: ', sum([len(x.split('@')[7].split(',')) for x in data])/len(data))\n",
        "    print('number of behavior_policy_id: ', len(set([x.split('@')[-1] for x in data])))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of records:  781367\n",
            "number of users:  439131\n",
            "number of items per page:  9\n",
            "avg. lengths of user history:  48.076561974078764\n",
            "avg. dimensions of user_protrait:  42.0\n",
            "avg. dimensions of item_feature:  352.0\n",
            "number of behavior_policy_id:  1\n"
          ]
        }
      ],
      "source": [
        "with open('rl4rs/rl4rs_dataset_b_rl.csv', 'r') as f:\n",
        "    data = f.read().split('\\n')[1:-1]\n",
        "    print('number of records: ', len(data))\n",
        "    print('number of users: ', len(set([x.split('@')[1] for x in data])))\n",
        "    print('number of items per page: ', len(data[0].split('@')[3].split(',')))\n",
        "    print('avg. lengths of user history: ', sum([len(x.split('@')[5].split(',')) for x in data])/len(data))\n",
        "    print('avg. dimensions of user_protrait: ', sum([len(x.split('@')[6].split(',')) for x in data])/len(data))\n",
        "    print('avg. dimensions of item_feature: ', sum([len(x.split('@')[7].split(',')) for x in data])/len(data))\n",
        "    print('number of behavior_policy_id: ', len(set([x.split('@')[-1] for x in data])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['1', '1', '2', '3', '4']\n",
            "Number of unique sessions: 439131\n"
          ]
        }
      ],
      "source": [
        "session = [entry.split('@')[1] for entry in data]\n",
        "print(session[:5])\n",
        "session = list(set(session))\n",
        "print(f\"Number of unique sessions: {len(session)}\")\n",
        "# Each user has a unique session id, so we can use this to identify users."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "path_to_data = 'rl4rs/rl4rs_dataset_b_rl.csv'\n",
        "path_to_item = 'rl4rs/item_info.csv'\n",
        "path_to_output = \"Hyper-Actor-Critic-for-Recommendation/dataset/rl4rs/\"\n",
        "seed = 2025"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extract train and test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training data size: 625093\n",
            "Evaluation data size: 156274\n"
          ]
        }
      ],
      "source": [
        "# Split the data into training (80%) and evaluation (20%) sets based on timestamp\n",
        "split_index = int(len(data) * 0.8)\n",
        "\n",
        "# Training data\n",
        "train_data = data[:split_index]\n",
        "\n",
        "# Evaluation data\n",
        "eval_data = data[split_index:]\n",
        "\n",
        "print(f\"Training data size: {len(train_data)}\")\n",
        "print(f\"Evaluation data size: {len(eval_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "import os\n",
        "\n",
        "header = ['timestamp', 'session_id', 'sequence_id', 'exposed_items', 'user_feedback', 'user_seqfeature', 'user_protrait', 'item_feature', 'behavior_policy_id']\n",
        "\n",
        "# Split each record into columns and save to CSV\n",
        "train_path = os.path.join(path_to_output, 'train.csv')\n",
        "test_path = os.path.join(path_to_output, 'test.csv')\n",
        "\n",
        "with open(train_path, 'w', newline='', encoding='utf-8') as train_file:\n",
        "  writer = csv.writer(train_file, delimiter='@')\n",
        "  writer.writerow(header)\n",
        "  for record in train_data:\n",
        "    writer.writerow(record.split('@'))\n",
        "\n",
        "with open(test_path, 'w', newline='', encoding='utf-8') as test_file:\n",
        "  writer = csv.writer(test_file, delimiter='@')\n",
        "  writer.writerow(header)\n",
        "  for record in eval_data:\n",
        "    writer.writerow(record.split('@'))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "name": "Movie Recommendation System",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30918,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Huy1902/HAC/blob/main/Movie_Recommendation_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-03-19T00:18:57.199623Z",
          "iopub.status.busy": "2025-03-19T00:18:57.199298Z",
          "iopub.status.idle": "2025-03-19T00:18:57.490132Z",
          "shell.execute_reply": "2025-03-19T00:18:57.488891Z",
          "shell.execute_reply.started": "2025-03-19T00:18:57.1996Z"
        },
        "id": "weJBxe-ISl75",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import random\n",
        "import os\n",
        "from IPython.display import display\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "path_to_data = 'ml-1m/ratings.dat'\n",
        "path_to_item = 'ml-1m/movies.dat'\n",
        "path_to_users = 'ml-1m/users.dat'\n",
        "path_to_dataset = 'ml-1m'\n",
        "path_to_output = \"Hyper-Actor-Critic-for-Recommendation/dataset/ml1m\"\n",
        "seed = 2025"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extract train and test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\lymst\\AppData\\Local\\Temp\\ipykernel_12476\\594470988.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  data = pd.read_csv(path_to_data, sep='::',\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv(path_to_data, sep='::', \n",
        "                    names=['userId', 'itemId', 'rating', 'timestamp'])\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "data['user_click'] = data['rating'].apply(lambda x: 1 if x > 3 else 0)\n",
        "data = data.sort_values(by=['userId', 'timestamp']).reset_index(drop=True)\n",
        "result = []\n",
        "test_df = []\n",
        "train_df = []\n",
        "for user_id, user_data in data.groupby('userId'):\n",
        "    user_data = user_data.reset_index(drop=True)\n",
        "    click_history = []\n",
        "    seq_id = 0\n",
        "    sep = random.randint(int(0.7 * len(user_data)), int(0.9 * len(user_data))) // 10\n",
        "    # Split into segments of 10 items\n",
        "    for i in range(0, len(user_data), 10):\n",
        "        if(i + 10 > len(user_data)):\n",
        "            break\n",
        "        segment = user_data[i:i+10]\n",
        "        slate_of_items = segment['itemId'].tolist()\n",
        "        user_clicks = segment['user_click'].tolist()\n",
        "        \n",
        "        row = {\n",
        "          'user_id': user_id,\n",
        "          'slate_of_items': slate_of_items,\n",
        "          'user_mid': user_clicks,\n",
        "          'user_mid_history': click_history[:],\n",
        "          'sequence_id': seq_id\n",
        "        }\n",
        "        result.append(row)\n",
        "        if seq_id < sep:\n",
        "            train_df.append(row)\n",
        "        else:\n",
        "            test_df.append(row)\n",
        "        # Update click history\n",
        "        click_history.extend(segment[segment['user_click'] == 1]['itemId'].tolist())\n",
        "        seq_id += 1\n",
        "\n",
        "train_df = pd.DataFrame(train_df)\n",
        "test_df = pd.DataFrame(test_df)\n",
        "result_df = pd.DataFrame(result)\n",
        "os.makedirs(path_to_output, exist_ok=True)\n",
        "train_df.to_csv(os.path.join(path_to_output, 'train.csv') , sep='@', index=False)\n",
        "test_df.to_csv(os.path.join(path_to_output, 'test.csv') , sep='@', index=False)\n",
        "\n",
        "result_df.to_csv(os.path.join(path_to_output, 'all.csv') , sep='@', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extract item_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 76920 entries, 0 to 76919\n",
            "Data columns (total 5 columns):\n",
            " #   Column            Non-Null Count  Dtype \n",
            "---  ------            --------------  ----- \n",
            " 0   user_id           76920 non-null  int64 \n",
            " 1   slate_of_items    76920 non-null  object\n",
            " 2   user_mid          76920 non-null  object\n",
            " 3   user_mid_history  76920 non-null  object\n",
            " 4   sequence_id       76920 non-null  int64 \n",
            "dtypes: int64(2), object(3)\n",
            "memory usage: 2.9+ MB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20463 entries, 0 to 20462\n",
            "Data columns (total 5 columns):\n",
            " #   Column            Non-Null Count  Dtype \n",
            "---  ------            --------------  ----- \n",
            " 0   user_id           20463 non-null  int64 \n",
            " 1   slate_of_items    20463 non-null  object\n",
            " 2   user_mid          20463 non-null  object\n",
            " 3   user_mid_history  20463 non-null  object\n",
            " 4   sequence_id       20463 non-null  int64 \n",
            "dtypes: int64(2), object(3)\n",
            "memory usage: 799.5+ KB\n"
          ]
        }
      ],
      "source": [
        "train_df.info()\n",
        "test_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Define the order of genres as per the problem statement\n",
        "genre_order = [\n",
        "    'Action',\n",
        "    'Adventure',\n",
        "    'Animation',\n",
        "    \"Children's\",\n",
        "    'Comedy',\n",
        "    'Crime',\n",
        "    'Documentary',\n",
        "    'Drama',\n",
        "    'Fantasy',\n",
        "    'Film-Noir',\n",
        "    'Horror',\n",
        "    'Musical',\n",
        "    'Mystery',\n",
        "    'Romance',\n",
        "    'Sci-Fi',\n",
        "    'Thriller',\n",
        "    'War',\n",
        "    'Western'\n",
        "]\n",
        "\n",
        "# Initialize genre_features with a dummy row for item 0\n",
        "genre_features = []\n",
        "genre_features.append([0] * len(genre_order))  # Dummy row for index 0\n",
        "\n",
        "# Path to the input movies.dat file and output directory\n",
        "path_to_movies = path_to_item\n",
        "path_to_output = path_to_output\n",
        "\n",
        "# Read the movies.dat file and process each line\n",
        "with open(path_to_movies, \"r\", encoding=\"latin-1\") as f:\n",
        "    for line in f:\n",
        "        # Split the line into MovieID, Title, Genres\n",
        "        parts = line.strip().split('::')\n",
        "        if len(parts) != 3:\n",
        "            continue  # Skip malformed lines\n",
        "        _, _, genres_str = parts\n",
        "        # Split genres into a list\n",
        "        movie_genres = genres_str.split('|')\n",
        "        # Create a binary vector for genres\n",
        "        genre_vector = [0] * len(genre_order)\n",
        "        for genre in movie_genres:\n",
        "            if genre in genre_order:\n",
        "                idx = genre_order.index(genre)\n",
        "                genre_vector[idx] = 1\n",
        "        genre_features.append(genre_vector)\n",
        "\n",
        "# Convert the list to a NumPy array\n",
        "item_info = np.array(genre_features, dtype=np.float32)\n",
        "\n",
        "# Save the array to item_info.npy\n",
        "np.save(os.path.join(path_to_output, \"item_info.npy\"), item_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3884, 18)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "item_meta = np.load(os.path.join(path_to_output, \"item_info.npy\"))\n",
        "item_meta.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extract user_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Define age categories and their order\n",
        "age_categories = [1, 18, 25, 35, 45, 50, 56]  # 7 categories\n",
        "\n",
        "# Initialize list to store user data\n",
        "users = []\n",
        "\n",
        "with open(path_to_users, \"r\", encoding=\"latin-1\") as f:\n",
        "    for line in f:\n",
        "        parts = line.strip().split(\"::\")\n",
        "        if len(parts) != 5:\n",
        "            continue  # Skip malformed lines\n",
        "        user_id = int(parts[0])\n",
        "        gender = parts[1]\n",
        "        age_code = int(parts[2])\n",
        "        occupation_code = int(parts[3])\n",
        "        users.append((user_id, gender, age_code, occupation_code))\n",
        "\n",
        "# Sort users by UserID\n",
        "users_sorted = sorted(users, key=lambda x: x[0])\n",
        "\n",
        "# Process each user into a feature vector\n",
        "feature_vectors = []\n",
        "for user in users_sorted:\n",
        "    _, gender, age_code, occupation_code = user\n",
        "    \n",
        "    # One-hot encode age (7 dimensions)\n",
        "    age_encoding = [0] * len(age_categories)\n",
        "    if age_code in age_categories:\n",
        "        idx = age_categories.index(age_code)\n",
        "        age_encoding[idx] = 1\n",
        "    \n",
        "    # One-hot encode gender (2 dimensions)\n",
        "    gender_encoding = [1, 0] if gender == \"M\" else [0, 1]\n",
        "    \n",
        "    # One-hot encode occupation (21 dimensions)\n",
        "    occupation_encoding = [0] * 21\n",
        "    occupation_encoding[occupation_code] = 1  # Directly use occupation_code\n",
        "    \n",
        "    # Combine features\n",
        "    feature_vector = age_encoding + gender_encoding + occupation_encoding\n",
        "    feature_vectors.append(feature_vector)\n",
        "\n",
        "# Add padding row for user_id=0\n",
        "padding_row = np.zeros((1, len(feature_vectors[0])), dtype=np.float32)\n",
        "user_features = np.array(feature_vectors, dtype=np.float32)\n",
        "user_info = np.concatenate((padding_row, user_features), axis=0)\n",
        "\n",
        "# Save to user_info.npy\n",
        "np.save(os.path.join(path_to_output, \"user_info.npy\"), user_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6041, 30)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "user_meta = np.load(os.path.join(path_to_output, \"user_info.npy\"))\n",
        "user_meta.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qryfWvJNSl8E"
      },
      "source": [
        "## Data extraction and Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-19T00:41:28.041154Z",
          "iopub.status.busy": "2025-03-19T00:41:28.040881Z",
          "iopub.status.idle": "2025-03-19T00:41:28.046354Z",
          "shell.execute_reply": "2025-03-19T00:41:28.045277Z",
          "shell.execute_reply.started": "2025-03-19T00:41:28.041133Z"
        },
        "id": "UrnGiHluSl8G",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class DataGenerator():\n",
        "\n",
        "    def __init__ (self):\n",
        "        path_to_data = 'ml-100k/u.data'\n",
        "        path_to_item = 'ml-100k/u.item'\n",
        "        self.mr = self.load(path_to_data, path_to_item)\n",
        "        # print(self.mr.info())\n",
        "        self.users = self.mr['userId'].unique()\n",
        "        self.movie = self.mr['itemId'].unique()\n",
        "        self.hist = self.generate_history_function()\n",
        "        \n",
        "        self.train = []\n",
        "        self.test = []\n",
        "\n",
        "    def load(self, path_to_data, path_to_item):\n",
        "        data = pd.read_csv(path_to_data, sep='\\t', \n",
        "                            names=['userId', 'itemId', 'rating', 'timestamp'])\n",
        "        movie_titles = pd.read_csv(path_to_item, sep='|', names=['itemId', 'itemName'],\n",
        "                                usecols=range(2), encoding='latin-1')\n",
        "        \n",
        "        return data.merge(movie_titles, on='itemId', how='left')\n",
        "    def generate_history_function(self):\n",
        "        '''\n",
        "        Group all rates given by users ad store them from older to most recent based on time\n",
        "        '''\n",
        "        historic_users = []\n",
        "        for i, u in enumerate(self.users):\n",
        "            movie_watched = self.mr[self.mr['userId'] == u]\n",
        "            movie_watched = movie_watched.sort_values('timestamp').reset_index(drop=True)\n",
        "            historic_users.append(movie_watched)\n",
        "\n",
        "        return historic_users\n",
        "    def sample_history(self, user_hist, action_ratio=0.8, max_samp_by_user=5, max_state=100,\n",
        "                       max_action=50, n_states=[], n_actions=[]):\n",
        "        '''\n",
        "        Making multiple samples for a given historic set, based on some number of states and actions\n",
        "        '''\n",
        "\n",
        "        n = len(user_hist)\n",
        "        sep = int(action_ratio * n)\n",
        "        n_sample = random.randint(1, max_samp_by_user)\n",
        "        if not n_states:\n",
        "            n_states = [min(random.randint(1, sep), max_state) for _ in range(n_sample)]\n",
        "        if not n_actions:\n",
        "            n_actions = [min(random.randint(1, n - sep), max_action) for _ in range(n_sample)]\n",
        "\n",
        "        assert len(n_states) == len(n_actions), 'Must have same size'\n",
        "\n",
        "        states = []\n",
        "        actions = []\n",
        "\n",
        "        for i in range(len(n_states)):\n",
        "            sample_states = user_hist.iloc[0:sep].sample(n_states[i])\n",
        "            sample_actions = user_hist.iloc[-(n-sep):].sample(n_actions[i])\n",
        "            \n",
        "            # format state and action\n",
        "            sample_state = []\n",
        "            sample_action = []\n",
        "            for index in range(n_states[i]):\n",
        "                row = sample_states.iloc[index]\n",
        "                state = str(row.loc['itemId']) + '&' + str(row.loc['rating'])\n",
        "                sample_state.append(state)\n",
        "                \n",
        "            for index in range(n_actions[i]):\n",
        "                row = sample_actions.iloc[index]\n",
        "                action = str(row.loc['itemId']) + '&' + str(row.loc['rating'])\n",
        "                sample_action.append(action)\n",
        "                \n",
        "            states.append(sample_state)\n",
        "            actions.append(sample_action)\n",
        "        return states, actions\n",
        "    \n",
        "    def get_train_test_split(self, test_ratio, seed=None):\n",
        "        '''\n",
        "        Split the data into train and test set\n",
        "        '''\n",
        "        if seed:\n",
        "            random.Random(seed).shuffle(self.hist)\n",
        "        else:\n",
        "            random.shuffle(self.hist)\n",
        "            \n",
        "        sep = int(test_ratio * len(self.hist))\n",
        "        self.train = self.hist[:sep]\n",
        "        self.test = self.hist[sep:]\n",
        "        self.user_train = [h.iloc[0, 0] for h in self.train]\n",
        "        self.user_test = [h.iloc[0, 0] for h in self.test]\n",
        "        \n",
        "    def write_csv(self, filename, hist_to_write, delimiter=';', action_ratio=0.8, max_sample_user=5,\n",
        "                  max_state=100, max_action=50, n_states=[], n_actions=[]):\n",
        "        with open(filename, mode='w') as file:\n",
        "            f_writer = csv.writer(file, delimiter=delimiter)\n",
        "            f_writer.writerow(['state', 'action_reward', 'n_state'])\n",
        "            for user_hist in hist_to_write:\n",
        "                states, actions = self.sample_history(user_hist, action_ratio, max_sample_user, max_state, max_action, n_states, n_actions)\n",
        "                for i in range(len(states)):\n",
        "                    state_str = '|'.join(states[i])\n",
        "                    action_str = '|'.join(actions[i])\n",
        "                    n_state_str = state_str + '|' + action_str\n",
        "                    f_writer.writerow([state_str, action_str, n_state_str])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EmbeddingModel(\n",
            "  (hidden_layer): Linear(in_features=500, out_features=100, bias=True)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (output_layer): Linear(in_features=100, out_features=500, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class EmbeddingModel(nn.Module):\n",
        "  def __init__ (self, movie_count, hidden_layer_size=100):\n",
        "    super(EmbeddingModel, self).__init__()\n",
        "    self.movie_count = movie_count\n",
        "    self.hidden_layer = nn.Linear(movie_count, hidden_layer_size)\n",
        "    self.dropout = nn.Dropout(0.2)\n",
        "    self.output_layer = nn.Linear(hidden_layer_size, movie_count)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.hidden_layer(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.dropout(x)\n",
        "    x = self.output_layer(x)\n",
        "    x = F.softmax(x, dim=-1)\n",
        "    return x\n",
        "movie_count = 500  # Adjust based on your dataset\n",
        "model = EmbeddingModel(movie_count)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "ename": "_IncompleteInputError",
          "evalue": "incomplete input (3085494191.py, line 20)",
          "output_type": "error",
          "traceback": [
            "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[31m    \u001b[39m\n    ^\n\u001b[31m_IncompleteInputError\u001b[39m\u001b[31m:\u001b[39m incomplete input\n"
          ]
        }
      ],
      "source": [
        "class EmbeddingGenerator:\n",
        "\n",
        "    def __init__(self, train_users, data):\n",
        "      self.train_users = train_users\n",
        "      \n",
        "      self.data = data.sort_values(by=['timestamp'])\n",
        "      self.data['userId'] = self.data['userId'] - 1\n",
        "      self.data['itemId'] = self.data['itemId'] - 1\n",
        "      \n",
        "      self.user_count = self.data['userId'].max() + 1\n",
        "      self.movie_count = self.data['itemId'].max() + 1\n",
        "      \n",
        "      # list of rated movies by each user\n",
        "      self.user_movies = {}\n",
        "      for userId in range(self.user_count):\n",
        "        self.user_movies[userId] = self.data[self.data.userId == userId].itemId.tolist()\n",
        "      self.model = self.define_model()\n",
        "      \n",
        "    def define_model(self, hidden_layer_size=100):\n",
        "      "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "name": "Movie Recommendation System",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30918,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
